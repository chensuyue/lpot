Search.setIndex({"docnames": ["autoapi/block_mask/index", "autoapi/neural_compressor/adaptor/adaptor/index", "autoapi/neural_compressor/adaptor/index", "autoapi/neural_compressor/adaptor/keras/index", "autoapi/neural_compressor/adaptor/keras_utils/conv2d/index", "autoapi/neural_compressor/adaptor/keras_utils/dense/index", "autoapi/neural_compressor/adaptor/keras_utils/depthwise_conv2d/index", "autoapi/neural_compressor/adaptor/keras_utils/index", "autoapi/neural_compressor/adaptor/keras_utils/pool2d/index", "autoapi/neural_compressor/adaptor/keras_utils/quantizer/index", "autoapi/neural_compressor/adaptor/keras_utils/separable_conv2d/index", "autoapi/neural_compressor/adaptor/mxnet/index", "autoapi/neural_compressor/adaptor/mxnet_utils/index", "autoapi/neural_compressor/adaptor/mxnet_utils/util/index", "autoapi/neural_compressor/adaptor/onnxrt/index", "autoapi/neural_compressor/adaptor/ox_utils/calibration/index", "autoapi/neural_compressor/adaptor/ox_utils/calibrator/index", "autoapi/neural_compressor/adaptor/ox_utils/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/activation/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/argmax/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/attention/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/binary_op/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/concat/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/conv/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/direct_q8/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/embed_layernorm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gather/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gavgpool/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/gemm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/lstm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/matmul/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/maxpool/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/norm/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/ops/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/pad/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/pooling/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/reduce/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/resize/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/split/index", "autoapi/neural_compressor/adaptor/ox_utils/operators/unary_op/index", "autoapi/neural_compressor/adaptor/ox_utils/quantizer/index", "autoapi/neural_compressor/adaptor/ox_utils/smooth_quant/index", "autoapi/neural_compressor/adaptor/ox_utils/util/index", "autoapi/neural_compressor/adaptor/ox_utils/weight_only/index", "autoapi/neural_compressor/adaptor/pytorch/index", "autoapi/neural_compressor/adaptor/query/index", "autoapi/neural_compressor/adaptor/tensorflow/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter_without_calib/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/dequantize_cast_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern/index", "autoapi/neural_compressor/adaptor/tf_utils/graph_util/index", "autoapi/neural_compressor/adaptor/tf_utils/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling/index", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph_common/index", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_calibration/index", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_scaler/index", "autoapi/neural_compressor/adaptor/tf_utils/tf2onnx_converter/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging/index", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat/index", "autoapi/neural_compressor/adaptor/tf_utils/util/index", "autoapi/neural_compressor/adaptor/torch_utils/autoround/autoround/index", "autoapi/neural_compressor/adaptor/torch_utils/autoround/export/index", "autoapi/neural_compressor/adaptor/torch_utils/autoround/index", "autoapi/neural_compressor/adaptor/torch_utils/autoround/model_wrapper/index", "autoapi/neural_compressor/adaptor/torch_utils/autoround/sign_sgd/index", "autoapi/neural_compressor/adaptor/torch_utils/awq/index", "autoapi/neural_compressor/adaptor/torch_utils/bf16_convert/index", "autoapi/neural_compressor/adaptor/torch_utils/gptq/index", "autoapi/neural_compressor/adaptor/torch_utils/hawq_metric/index", "autoapi/neural_compressor/adaptor/torch_utils/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/modified_pickle/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/quantize/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/torch_load/index", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/utils/index", "autoapi/neural_compressor/adaptor/torch_utils/mixed_precision/index", "autoapi/neural_compressor/adaptor/torch_utils/model_wrapper/index", "autoapi/neural_compressor/adaptor/torch_utils/pattern_detector/index", "autoapi/neural_compressor/adaptor/torch_utils/smooth_quant/index", "autoapi/neural_compressor/adaptor/torch_utils/symbolic_trace/index", "autoapi/neural_compressor/adaptor/torch_utils/teq/index", "autoapi/neural_compressor/adaptor/torch_utils/util/index", "autoapi/neural_compressor/adaptor/torch_utils/weight_only/index", "autoapi/neural_compressor/algorithm/algorithm/index", "autoapi/neural_compressor/algorithm/fast_bias_correction/index", "autoapi/neural_compressor/algorithm/index", "autoapi/neural_compressor/algorithm/smooth_quant/index", "autoapi/neural_compressor/algorithm/weight_correction/index", "autoapi/neural_compressor/benchmark/index", "autoapi/neural_compressor/common/base_config/index", "autoapi/neural_compressor/common/base_tuning/index", "autoapi/neural_compressor/common/index", "autoapi/neural_compressor/common/tuning_param/index", "autoapi/neural_compressor/common/utils/constants/index", "autoapi/neural_compressor/common/utils/index", "autoapi/neural_compressor/common/utils/logger/index", "autoapi/neural_compressor/common/utils/utility/index", "autoapi/neural_compressor/compression/callbacks/index", "autoapi/neural_compressor/compression/distillation/criterions/index", "autoapi/neural_compressor/compression/distillation/index", "autoapi/neural_compressor/compression/distillation/optimizers/index", "autoapi/neural_compressor/compression/distillation/utility/index", "autoapi/neural_compressor/compression/hpo/index", "autoapi/neural_compressor/compression/hpo/sa_optimizer/index", "autoapi/neural_compressor/compression/hpo/search_algorithms/index", "autoapi/neural_compressor/compression/hpo/search_space/index", "autoapi/neural_compressor/compression/index", "autoapi/neural_compressor/compression/pruner/criteria/index", "autoapi/neural_compressor/compression/pruner/dsnot/index", "autoapi/neural_compressor/compression/pruner/index", "autoapi/neural_compressor/compression/pruner/model_slim/auto_slim/index", "autoapi/neural_compressor/compression/pruner/model_slim/index", "autoapi/neural_compressor/compression/pruner/model_slim/pattern_analyzer/index", "autoapi/neural_compressor/compression/pruner/model_slim/weight_slim/index", "autoapi/neural_compressor/compression/pruner/patterns/base/index", "autoapi/neural_compressor/compression/pruner/patterns/index", "autoapi/neural_compressor/compression/pruner/patterns/mha/index", "autoapi/neural_compressor/compression/pruner/patterns/ninm/index", "autoapi/neural_compressor/compression/pruner/patterns/nxm/index", "autoapi/neural_compressor/compression/pruner/pruners/base/index", "autoapi/neural_compressor/compression/pruner/pruners/basic/index", "autoapi/neural_compressor/compression/pruner/pruners/block_mask/index", "autoapi/neural_compressor/compression/pruner/pruners/index", "autoapi/neural_compressor/compression/pruner/pruners/mha/index", "autoapi/neural_compressor/compression/pruner/pruners/pattern_lock/index", "autoapi/neural_compressor/compression/pruner/pruners/progressive/index", "autoapi/neural_compressor/compression/pruner/pruners/retrain_free/index", "autoapi/neural_compressor/compression/pruner/pruners/sparse_gpt/index", "autoapi/neural_compressor/compression/pruner/pruning/index", "autoapi/neural_compressor/compression/pruner/regs/index", "autoapi/neural_compressor/compression/pruner/schedulers/index", "autoapi/neural_compressor/compression/pruner/tf_criteria/index", "autoapi/neural_compressor/compression/pruner/utils/index", "autoapi/neural_compressor/compression/pruner/wanda/index", "autoapi/neural_compressor/compression/pruner/wanda/prune/index", "autoapi/neural_compressor/compression/pruner/wanda/utils/index", "autoapi/neural_compressor/compression/pruner/wanda/wrapper/index", "autoapi/neural_compressor/conf/config/index", "autoapi/neural_compressor/conf/dotdict/index", "autoapi/neural_compressor/conf/index", "autoapi/neural_compressor/conf/pythonic_config/index", "autoapi/neural_compressor/config/index", "autoapi/neural_compressor/contrib/index", "autoapi/neural_compressor/contrib/strategy/index", "autoapi/neural_compressor/contrib/strategy/sigopt/index", "autoapi/neural_compressor/contrib/strategy/tpe/index", "autoapi/neural_compressor/data/dataloaders/base_dataloader/index", "autoapi/neural_compressor/data/dataloaders/dataloader/index", "autoapi/neural_compressor/data/dataloaders/default_dataloader/index", "autoapi/neural_compressor/data/dataloaders/fetcher/index", "autoapi/neural_compressor/data/dataloaders/index", "autoapi/neural_compressor/data/dataloaders/mxnet_dataloader/index", "autoapi/neural_compressor/data/dataloaders/onnxrt_dataloader/index", "autoapi/neural_compressor/data/dataloaders/pytorch_dataloader/index", "autoapi/neural_compressor/data/dataloaders/sampler/index", "autoapi/neural_compressor/data/dataloaders/tensorflow_dataloader/index", "autoapi/neural_compressor/data/datasets/bert_dataset/index", "autoapi/neural_compressor/data/datasets/coco_dataset/index", "autoapi/neural_compressor/data/datasets/dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset/index", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index", "autoapi/neural_compressor/data/datasets/index", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index", "autoapi/neural_compressor/data/filters/coco_filter/index", "autoapi/neural_compressor/data/filters/filter/index", "autoapi/neural_compressor/data/filters/index", "autoapi/neural_compressor/data/index", "autoapi/neural_compressor/data/transforms/coco_transform/index", "autoapi/neural_compressor/data/transforms/imagenet_transform/index", "autoapi/neural_compressor/data/transforms/index", "autoapi/neural_compressor/data/transforms/postprocess/index", "autoapi/neural_compressor/data/transforms/tokenization/index", "autoapi/neural_compressor/data/transforms/transform/index", "autoapi/neural_compressor/experimental/benchmark/index", "autoapi/neural_compressor/experimental/common/criterion/index", "autoapi/neural_compressor/experimental/common/dataloader/index", "autoapi/neural_compressor/experimental/common/index", "autoapi/neural_compressor/experimental/common/metric/index", "autoapi/neural_compressor/experimental/common/model/index", "autoapi/neural_compressor/experimental/common/optimizer/index", "autoapi/neural_compressor/experimental/common/postprocess/index", "autoapi/neural_compressor/experimental/common/torch_utils/index", "autoapi/neural_compressor/experimental/component/index", "autoapi/neural_compressor/experimental/compression/index", "autoapi/neural_compressor/experimental/contrib/index", "autoapi/neural_compressor/experimental/contrib/strategy/index", "autoapi/neural_compressor/experimental/contrib/strategy/sigopt/index", "autoapi/neural_compressor/experimental/contrib/strategy/tpe/index", "autoapi/neural_compressor/experimental/data/dataloaders/base_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/default_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/fetcher/index", "autoapi/neural_compressor/experimental/data/dataloaders/index", "autoapi/neural_compressor/experimental/data/dataloaders/mxnet_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/pytorch_dataloader/index", "autoapi/neural_compressor/experimental/data/dataloaders/sampler/index", "autoapi/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader/index", "autoapi/neural_compressor/experimental/data/datasets/bert_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/coco_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset_v2/index", "autoapi/neural_compressor/experimental/data/datasets/imagenet_dataset/index", "autoapi/neural_compressor/experimental/data/datasets/index", "autoapi/neural_compressor/experimental/data/datasets/style_transfer_dataset/index", "autoapi/neural_compressor/experimental/data/filters/coco_filter/index", "autoapi/neural_compressor/experimental/data/filters/filter/index", "autoapi/neural_compressor/experimental/data/filters/index", "autoapi/neural_compressor/experimental/data/index", "autoapi/neural_compressor/experimental/data/transforms/imagenet_transform/index", "autoapi/neural_compressor/experimental/data/transforms/index", "autoapi/neural_compressor/experimental/data/transforms/tokenization/index", "autoapi/neural_compressor/experimental/data/transforms/transform/index", "autoapi/neural_compressor/experimental/distillation/index", "autoapi/neural_compressor/experimental/export/index", "autoapi/neural_compressor/experimental/export/qlinear2qdq/index", "autoapi/neural_compressor/experimental/export/tf2onnx/index", "autoapi/neural_compressor/experimental/export/torch2onnx/index", "autoapi/neural_compressor/experimental/graph_optimization/index", "autoapi/neural_compressor/experimental/index", "autoapi/neural_compressor/experimental/metric/bleu/index", "autoapi/neural_compressor/experimental/metric/bleu_util/index", "autoapi/neural_compressor/experimental/metric/coco_label_map/index", "autoapi/neural_compressor/experimental/metric/coco_tools/index", "autoapi/neural_compressor/experimental/metric/evaluate_squad/index", "autoapi/neural_compressor/experimental/metric/f1/index", "autoapi/neural_compressor/experimental/metric/index", "autoapi/neural_compressor/experimental/metric/metric/index", "autoapi/neural_compressor/experimental/mixed_precision/index", "autoapi/neural_compressor/experimental/model_conversion/index", "autoapi/neural_compressor/experimental/nas/basic_nas/index", "autoapi/neural_compressor/experimental/nas/dynas/index", "autoapi/neural_compressor/experimental/nas/index", "autoapi/neural_compressor/experimental/nas/nas/index", "autoapi/neural_compressor/experimental/nas/nas_utils/index", "autoapi/neural_compressor/experimental/nas/search_algorithms/index", "autoapi/neural_compressor/experimental/pruner_legacy/gradient_sensitivity/index", "autoapi/neural_compressor/experimental/pruner_legacy/group_lasso/index", "autoapi/neural_compressor/experimental/pruner_legacy/index", "autoapi/neural_compressor/experimental/pruner_legacy/magnitude/index", "autoapi/neural_compressor/experimental/pruner_legacy/pattern_lock/index", "autoapi/neural_compressor/experimental/pruner_legacy/pruner/index", "autoapi/neural_compressor/experimental/pruning/index", "autoapi/neural_compressor/experimental/pruning_recipes/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/pattern/index", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern/index", "autoapi/neural_compressor/experimental/pruning_v2/index", "autoapi/neural_compressor/experimental/pytorch_pruner/index", "autoapi/neural_compressor/experimental/pytorch_pruner/logger/index", "autoapi/neural_compressor/experimental/pytorch_pruner/patterns/index", "autoapi/neural_compressor/experimental/pytorch_pruner/prune_utils/index", "autoapi/neural_compressor/experimental/pytorch_pruner/pruner/index", "autoapi/neural_compressor/experimental/pytorch_pruner/pruning/index", "autoapi/neural_compressor/experimental/pytorch_pruner/scheduler/index", "autoapi/neural_compressor/experimental/quantization/index", "autoapi/neural_compressor/experimental/scheduler/index", "autoapi/neural_compressor/experimental/strategy/auto_mixed_precision/index", "autoapi/neural_compressor/experimental/strategy/basic/index", "autoapi/neural_compressor/experimental/strategy/bayesian/index", "autoapi/neural_compressor/experimental/strategy/exhaustive/index", "autoapi/neural_compressor/experimental/strategy/index", "autoapi/neural_compressor/experimental/strategy/mse/index", "autoapi/neural_compressor/experimental/strategy/mse_v2/index", "autoapi/neural_compressor/experimental/strategy/random/index", "autoapi/neural_compressor/experimental/strategy/strategy/index", "autoapi/neural_compressor/experimental/strategy/utils/constant/index", "autoapi/neural_compressor/experimental/strategy/utils/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_sampler/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_space/index", "autoapi/neural_compressor/experimental/strategy/utils/tuning_structs/index", "autoapi/neural_compressor/experimental/strategy/utils/utility/index", "autoapi/neural_compressor/index", "autoapi/neural_compressor/metric/bleu/index", "autoapi/neural_compressor/metric/bleu_util/index", "autoapi/neural_compressor/metric/coco_label_map/index", "autoapi/neural_compressor/metric/coco_tools/index", "autoapi/neural_compressor/metric/evaluate_squad/index", "autoapi/neural_compressor/metric/f1/index", "autoapi/neural_compressor/metric/index", "autoapi/neural_compressor/metric/metric/index", "autoapi/neural_compressor/mix_precision/index", "autoapi/neural_compressor/model/base_model/index", "autoapi/neural_compressor/model/index", "autoapi/neural_compressor/model/keras_model/index", "autoapi/neural_compressor/model/model/index", "autoapi/neural_compressor/model/mxnet_model/index", "autoapi/neural_compressor/model/nets_factory/index", "autoapi/neural_compressor/model/onnx_model/index", "autoapi/neural_compressor/model/tensorflow_model/index", "autoapi/neural_compressor/model/torch_model/index", "autoapi/neural_compressor/objective/index", "autoapi/neural_compressor/onnxrt/algorithms/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/calibrator/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/core/index", "autoapi/neural_compressor/onnxrt/algorithms/smoother/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/awq/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/gptq/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/rtn/index", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/utility/index", "autoapi/neural_compressor/onnxrt/index", "autoapi/neural_compressor/onnxrt/quantization/algorithm_entry/index", "autoapi/neural_compressor/onnxrt/quantization/autotune/index", "autoapi/neural_compressor/onnxrt/quantization/calibrate/index", "autoapi/neural_compressor/onnxrt/quantization/config/index", "autoapi/neural_compressor/onnxrt/quantization/index", "autoapi/neural_compressor/onnxrt/quantization/quantize/index", "autoapi/neural_compressor/onnxrt/utils/index", "autoapi/neural_compressor/onnxrt/utils/onnx_model/index", "autoapi/neural_compressor/onnxrt/utils/utility/index", "autoapi/neural_compressor/profiling/index", "autoapi/neural_compressor/profiling/parser/factory/index", "autoapi/neural_compressor/profiling/parser/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/factory/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/index", "autoapi/neural_compressor/profiling/parser/onnx_parser/parser/index", "autoapi/neural_compressor/profiling/parser/parser/index", "autoapi/neural_compressor/profiling/parser/result/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/factory/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/index", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/parser/index", "autoapi/neural_compressor/profiling/profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/utils/index", "autoapi/neural_compressor/profiling/profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/factory/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/profiler/index", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/utils/index", "autoapi/neural_compressor/quantization/index", "autoapi/neural_compressor/strategy/auto/index", "autoapi/neural_compressor/strategy/auto_mixed_precision/index", "autoapi/neural_compressor/strategy/basic/index", "autoapi/neural_compressor/strategy/bayesian/index", "autoapi/neural_compressor/strategy/conservative/index", "autoapi/neural_compressor/strategy/exhaustive/index", "autoapi/neural_compressor/strategy/hawq_v2/index", "autoapi/neural_compressor/strategy/index", "autoapi/neural_compressor/strategy/mse/index", "autoapi/neural_compressor/strategy/mse_v2/index", "autoapi/neural_compressor/strategy/random/index", "autoapi/neural_compressor/strategy/strategy/index", "autoapi/neural_compressor/strategy/utils/constant/index", "autoapi/neural_compressor/strategy/utils/index", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index", "autoapi/neural_compressor/strategy/utils/tuning_space/index", "autoapi/neural_compressor/strategy/utils/tuning_structs/index", "autoapi/neural_compressor/strategy/utils/utility/index", "autoapi/neural_compressor/template/api_doc_example/index", "autoapi/neural_compressor/template/index", "autoapi/neural_compressor/tensorflow/algorithms/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/conv2d/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/dense/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/depthwise_conv2d/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/pool2d/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/quantizer/index", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/separable_conv2d/index", "autoapi/neural_compressor/tensorflow/index", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index", "autoapi/neural_compressor/tensorflow/quantization/config/index", "autoapi/neural_compressor/tensorflow/quantization/index", "autoapi/neural_compressor/tensorflow/quantization/quantize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index", "autoapi/neural_compressor/tensorflow/quantization/utils/index", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index", "autoapi/neural_compressor/tensorflow/utils/constants/index", "autoapi/neural_compressor/tensorflow/utils/data/index", "autoapi/neural_compressor/tensorflow/utils/index", "autoapi/neural_compressor/tensorflow/utils/model/index", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index", "autoapi/neural_compressor/tensorflow/utils/nets_factory/index", "autoapi/neural_compressor/tensorflow/utils/utility/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/fp8_quant/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/modules/index", "autoapi/neural_compressor/torch/algorithms/habana_fp8/observer/index", "autoapi/neural_compressor/torch/algorithms/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index", "autoapi/neural_compressor/torch/algorithms/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/auto_accelerator/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quant_api/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/utility/index", "autoapi/neural_compressor/torch/algorithms/weight_only/index", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index", "autoapi/neural_compressor/torch/amp/autocast/index", "autoapi/neural_compressor/torch/amp/fp8/functions/index", "autoapi/neural_compressor/torch/amp/fp8/index", "autoapi/neural_compressor/torch/amp/index", "autoapi/neural_compressor/torch/index", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index", "autoapi/neural_compressor/torch/quantization/autotune/index", "autoapi/neural_compressor/torch/quantization/config/index", "autoapi/neural_compressor/torch/quantization/index", "autoapi/neural_compressor/torch/quantization/modules/index", "autoapi/neural_compressor/torch/quantization/quantize/index", "autoapi/neural_compressor/torch/utils/constants/index", "autoapi/neural_compressor/torch/utils/environ/index", "autoapi/neural_compressor/torch/utils/index", "autoapi/neural_compressor/torch/utils/utility/index", "autoapi/neural_compressor/training/index", "autoapi/neural_compressor/utils/collect_layer_histogram/index", "autoapi/neural_compressor/utils/constant/index", "autoapi/neural_compressor/utils/create_obj_from_config/index", "autoapi/neural_compressor/utils/index", "autoapi/neural_compressor/utils/kl_divergence/index", "autoapi/neural_compressor/utils/load_huggingface/index", "autoapi/neural_compressor/utils/logger/index", "autoapi/neural_compressor/utils/neural_insights_utils/index", "autoapi/neural_compressor/utils/options/index", "autoapi/neural_compressor/utils/pytorch/index", "autoapi/neural_compressor/utils/utility/index", "autoapi/neural_compressor/utils/weights_details/index", "autoapi/neural_compressor/version/index", "docs/build_docs/source/index", "docs/source/CODE_OF_CONDUCT", "docs/source/CONTRIBUTING", "docs/source/FX", "docs/source/NAS", "docs/source/SECURITY", "docs/source/Welcome", "docs/source/adaptor", "docs/source/add_new_adaptor", "docs/source/add_new_data_type", "docs/source/api-doc/adaptor", "docs/source/api-doc/adaptor/onnxrt", "docs/source/api-doc/adaptor/torch_utils", "docs/source/api-doc/api_doc_example", "docs/source/api-doc/apis", "docs/source/api-doc/benchmark", "docs/source/api-doc/compression", "docs/source/api-doc/config", "docs/source/api-doc/mix_precision", "docs/source/api-doc/model", "docs/source/api-doc/objective", "docs/source/api-doc/quantization", "docs/source/api-doc/strategy", "docs/source/api-doc/training", "docs/source/benchmark", "docs/source/calibration", "docs/source/coding_style", "docs/source/dataloader", "docs/source/dataset", "docs/source/design", "docs/source/diagnosis", "docs/source/distillation", "docs/source/distillation_quantization", "docs/source/distributed", "docs/source/examples_readme", "docs/source/export", "docs/source/faq", "docs/source/framework_yaml", "docs/source/get_started", "docs/source/incompatible_changes", "docs/source/infrastructure", "docs/source/installation_guide", "docs/source/legal_information", "docs/source/llm_recipes", "docs/source/metric", "docs/source/migration", "docs/source/mixed_precision", "docs/source/model", "docs/source/neural_coder/README", "docs/source/neural_coder/docs/AWSSageMakerSupport", "docs/source/neural_coder/docs/BigDLNanoSupport", "docs/source/neural_coder/docs/IntelCPU_PerformanceSetting", "docs/source/neural_coder/docs/PythonAPI", "docs/source/neural_coder/docs/PythonLauncher", "docs/source/neural_coder/docs/Quantization", "docs/source/neural_coder/docs/SupportMatrix", "docs/source/neural_coder/docs/release_notes/v0.4", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/DEVELOP", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/README", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/RELEASE", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/CHANGELOG", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/README", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/vsc-extension-quickstart", "docs/source/neural_insights/README", "docs/source/neural_insights/docs/source/onnx_accuracy_debug", "docs/source/neural_insights/docs/source/pytorch_nlp_cli_mode", "docs/source/neural_insights/docs/source/tf_accuracy_debug", "docs/source/neural_insights/gui/README", "docs/source/neural_solution/README", "docs/source/neural_solution/docs/source/README", "docs/source/neural_solution/docs/source/description_api", "docs/source/neural_solution/docs/source/ns_design_doc", "docs/source/neural_solution/docs/source/template/task_request_description", "docs/source/neural_solution/examples/README", "docs/source/neural_solution/examples/custom_models_optimized/tf_example1/README", "docs/source/neural_solution/examples/hf_models/README", "docs/source/neural_solution/examples/hf_models_grpc/README", "docs/source/neural_solution/frontend/README", "docs/source/objective", "docs/source/orchestration", "docs/source/pruning", "docs/source/publication_list", "docs/source/pythonic_style", "docs/source/quantization", "docs/source/quantization_layer_wise", "docs/source/quantization_mixed_precision", "docs/source/quantization_weight_only", "docs/source/releases_info", "docs/source/sigopt_strategy", "docs/source/smooth_quant", "docs/source/tensorboard", "docs/source/transform", "docs/source/tuning_strategies", "docs/source/user_guide", "docs/source/user_yaml", "docs/source/validated_model_list", "index"], "filenames": ["autoapi/block_mask/index.rst", "autoapi/neural_compressor/adaptor/adaptor/index.rst", "autoapi/neural_compressor/adaptor/index.rst", "autoapi/neural_compressor/adaptor/keras/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/conv2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/dense/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/depthwise_conv2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/pool2d/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/quantizer/index.rst", "autoapi/neural_compressor/adaptor/keras_utils/separable_conv2d/index.rst", "autoapi/neural_compressor/adaptor/mxnet/index.rst", "autoapi/neural_compressor/adaptor/mxnet_utils/index.rst", "autoapi/neural_compressor/adaptor/mxnet_utils/util/index.rst", "autoapi/neural_compressor/adaptor/onnxrt/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/calibration/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/calibrator/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/activation/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/argmax/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/attention/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/binary_op/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/concat/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/conv/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/direct_q8/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/embed_layernorm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gather/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gavgpool/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/gemm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/lstm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/matmul/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/maxpool/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/norm/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/ops/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/pad/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/pooling/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/reduce/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/resize/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/split/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/operators/unary_op/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/quantizer/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/smooth_quant/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/util/index.rst", "autoapi/neural_compressor/adaptor/ox_utils/weight_only/index.rst", "autoapi/neural_compressor/adaptor/pytorch/index.rst", "autoapi/neural_compressor/adaptor/query/index.rst", "autoapi/neural_compressor/adaptor/tensorflow/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_converter_without_calib/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/bf16_convert/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/dequantize_cast_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/bf16/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_layout/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_leakyrelu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_nan_to_random/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dilated_contraction/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/dummy_biasadd/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/expanddims_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_batch_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fold_constant/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_biasadd_add/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_conv_with_math/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_decomposed_in/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_gelu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_layer_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/graph_cse_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/grappler_pass/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/insert_print_node/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/pre_optimize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/remove_training_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/rename_batch_norm/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/split_shared_input/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/strip_unused_nodes/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/generic/switch_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/graph_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_fake_quant/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/freeze_value_without_calib/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_redundant_dequantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_conv_requantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_redundant_dequantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/fuse_matmul_requantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/meta_op_optimizer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_hostconst_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/post_quantized_op_cse/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/rnn_convert/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/int8/scale_propagation/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_node/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/onnx_schema/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/onnx/tf2onnx_utils/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/insert_qdq_pattern/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/merge_duplicated_qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_rewriter/qdq/share_qdq_y_pattern/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/graph_util/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/fake_quantize/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_config/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_helper/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/optimize_layer/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_add/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_layers/quantize_layer_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qat/quantize_wrapper/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_concatv2/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_deconv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_in/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_matmul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/fuse_qdq_pooling/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/qdq/optimize_qdq/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_bn/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_concatv2/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_conv/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_for_intel_cpu/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_matmul/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph/quantize_graph_pooling/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/quantize_graph_common/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_calibration/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/smooth_quant_scaler/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/tf2onnx_converter/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/bias_correction/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/graph_transform_base/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/insert_logging/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/transform_graph/rerange_quantized_concat/index.rst", "autoapi/neural_compressor/adaptor/tf_utils/util/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/autoround/autoround/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/autoround/export/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/autoround/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/autoround/model_wrapper/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/autoround/sign_sgd/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/awq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/bf16_convert/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/gptq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/hawq_metric/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/modified_pickle/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/quantize/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/torch_load/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/layer_wise_quant/utils/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/mixed_precision/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/model_wrapper/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/pattern_detector/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/smooth_quant/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/symbolic_trace/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/teq/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/util/index.rst", "autoapi/neural_compressor/adaptor/torch_utils/weight_only/index.rst", "autoapi/neural_compressor/algorithm/algorithm/index.rst", "autoapi/neural_compressor/algorithm/fast_bias_correction/index.rst", "autoapi/neural_compressor/algorithm/index.rst", "autoapi/neural_compressor/algorithm/smooth_quant/index.rst", "autoapi/neural_compressor/algorithm/weight_correction/index.rst", "autoapi/neural_compressor/benchmark/index.rst", "autoapi/neural_compressor/common/base_config/index.rst", "autoapi/neural_compressor/common/base_tuning/index.rst", "autoapi/neural_compressor/common/index.rst", "autoapi/neural_compressor/common/tuning_param/index.rst", "autoapi/neural_compressor/common/utils/constants/index.rst", "autoapi/neural_compressor/common/utils/index.rst", "autoapi/neural_compressor/common/utils/logger/index.rst", "autoapi/neural_compressor/common/utils/utility/index.rst", "autoapi/neural_compressor/compression/callbacks/index.rst", "autoapi/neural_compressor/compression/distillation/criterions/index.rst", "autoapi/neural_compressor/compression/distillation/index.rst", "autoapi/neural_compressor/compression/distillation/optimizers/index.rst", "autoapi/neural_compressor/compression/distillation/utility/index.rst", "autoapi/neural_compressor/compression/hpo/index.rst", "autoapi/neural_compressor/compression/hpo/sa_optimizer/index.rst", "autoapi/neural_compressor/compression/hpo/search_algorithms/index.rst", "autoapi/neural_compressor/compression/hpo/search_space/index.rst", "autoapi/neural_compressor/compression/index.rst", "autoapi/neural_compressor/compression/pruner/criteria/index.rst", "autoapi/neural_compressor/compression/pruner/dsnot/index.rst", "autoapi/neural_compressor/compression/pruner/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/auto_slim/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/pattern_analyzer/index.rst", "autoapi/neural_compressor/compression/pruner/model_slim/weight_slim/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/base/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/mha/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/ninm/index.rst", "autoapi/neural_compressor/compression/pruner/patterns/nxm/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/base/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/basic/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/block_mask/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/mha/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/pattern_lock/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/progressive/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/retrain_free/index.rst", "autoapi/neural_compressor/compression/pruner/pruners/sparse_gpt/index.rst", "autoapi/neural_compressor/compression/pruner/pruning/index.rst", "autoapi/neural_compressor/compression/pruner/regs/index.rst", "autoapi/neural_compressor/compression/pruner/schedulers/index.rst", "autoapi/neural_compressor/compression/pruner/tf_criteria/index.rst", "autoapi/neural_compressor/compression/pruner/utils/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/prune/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/utils/index.rst", "autoapi/neural_compressor/compression/pruner/wanda/wrapper/index.rst", "autoapi/neural_compressor/conf/config/index.rst", "autoapi/neural_compressor/conf/dotdict/index.rst", "autoapi/neural_compressor/conf/index.rst", "autoapi/neural_compressor/conf/pythonic_config/index.rst", "autoapi/neural_compressor/config/index.rst", "autoapi/neural_compressor/contrib/index.rst", "autoapi/neural_compressor/contrib/strategy/index.rst", "autoapi/neural_compressor/contrib/strategy/sigopt/index.rst", "autoapi/neural_compressor/contrib/strategy/tpe/index.rst", "autoapi/neural_compressor/data/dataloaders/base_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/default_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/fetcher/index.rst", "autoapi/neural_compressor/data/dataloaders/index.rst", "autoapi/neural_compressor/data/dataloaders/mxnet_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/onnxrt_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/pytorch_dataloader/index.rst", "autoapi/neural_compressor/data/dataloaders/sampler/index.rst", "autoapi/neural_compressor/data/dataloaders/tensorflow_dataloader/index.rst", "autoapi/neural_compressor/data/datasets/bert_dataset/index.rst", "autoapi/neural_compressor/data/datasets/coco_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset/index.rst", "autoapi/neural_compressor/data/datasets/dummy_dataset_v2/index.rst", "autoapi/neural_compressor/data/datasets/imagenet_dataset/index.rst", "autoapi/neural_compressor/data/datasets/index.rst", "autoapi/neural_compressor/data/datasets/style_transfer_dataset/index.rst", "autoapi/neural_compressor/data/filters/coco_filter/index.rst", "autoapi/neural_compressor/data/filters/filter/index.rst", "autoapi/neural_compressor/data/filters/index.rst", "autoapi/neural_compressor/data/index.rst", "autoapi/neural_compressor/data/transforms/coco_transform/index.rst", "autoapi/neural_compressor/data/transforms/imagenet_transform/index.rst", "autoapi/neural_compressor/data/transforms/index.rst", "autoapi/neural_compressor/data/transforms/postprocess/index.rst", "autoapi/neural_compressor/data/transforms/tokenization/index.rst", "autoapi/neural_compressor/data/transforms/transform/index.rst", "autoapi/neural_compressor/experimental/benchmark/index.rst", "autoapi/neural_compressor/experimental/common/criterion/index.rst", "autoapi/neural_compressor/experimental/common/dataloader/index.rst", "autoapi/neural_compressor/experimental/common/index.rst", "autoapi/neural_compressor/experimental/common/metric/index.rst", "autoapi/neural_compressor/experimental/common/model/index.rst", "autoapi/neural_compressor/experimental/common/optimizer/index.rst", "autoapi/neural_compressor/experimental/common/postprocess/index.rst", "autoapi/neural_compressor/experimental/common/torch_utils/index.rst", "autoapi/neural_compressor/experimental/component/index.rst", "autoapi/neural_compressor/experimental/compression/index.rst", "autoapi/neural_compressor/experimental/contrib/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/sigopt/index.rst", "autoapi/neural_compressor/experimental/contrib/strategy/tpe/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/base_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/default_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/fetcher/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/mxnet_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/onnxrt_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/pytorch_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/sampler/index.rst", "autoapi/neural_compressor/experimental/data/dataloaders/tensorflow_dataloader/index.rst", "autoapi/neural_compressor/experimental/data/datasets/bert_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/coco_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/dummy_dataset_v2/index.rst", "autoapi/neural_compressor/experimental/data/datasets/imagenet_dataset/index.rst", "autoapi/neural_compressor/experimental/data/datasets/index.rst", "autoapi/neural_compressor/experimental/data/datasets/style_transfer_dataset/index.rst", "autoapi/neural_compressor/experimental/data/filters/coco_filter/index.rst", "autoapi/neural_compressor/experimental/data/filters/filter/index.rst", "autoapi/neural_compressor/experimental/data/filters/index.rst", "autoapi/neural_compressor/experimental/data/index.rst", "autoapi/neural_compressor/experimental/data/transforms/imagenet_transform/index.rst", "autoapi/neural_compressor/experimental/data/transforms/index.rst", "autoapi/neural_compressor/experimental/data/transforms/tokenization/index.rst", "autoapi/neural_compressor/experimental/data/transforms/transform/index.rst", "autoapi/neural_compressor/experimental/distillation/index.rst", "autoapi/neural_compressor/experimental/export/index.rst", "autoapi/neural_compressor/experimental/export/qlinear2qdq/index.rst", "autoapi/neural_compressor/experimental/export/tf2onnx/index.rst", "autoapi/neural_compressor/experimental/export/torch2onnx/index.rst", "autoapi/neural_compressor/experimental/graph_optimization/index.rst", "autoapi/neural_compressor/experimental/index.rst", "autoapi/neural_compressor/experimental/metric/bleu/index.rst", "autoapi/neural_compressor/experimental/metric/bleu_util/index.rst", "autoapi/neural_compressor/experimental/metric/coco_label_map/index.rst", "autoapi/neural_compressor/experimental/metric/coco_tools/index.rst", "autoapi/neural_compressor/experimental/metric/evaluate_squad/index.rst", "autoapi/neural_compressor/experimental/metric/f1/index.rst", "autoapi/neural_compressor/experimental/metric/index.rst", "autoapi/neural_compressor/experimental/metric/metric/index.rst", "autoapi/neural_compressor/experimental/mixed_precision/index.rst", "autoapi/neural_compressor/experimental/model_conversion/index.rst", "autoapi/neural_compressor/experimental/nas/basic_nas/index.rst", "autoapi/neural_compressor/experimental/nas/dynas/index.rst", "autoapi/neural_compressor/experimental/nas/index.rst", "autoapi/neural_compressor/experimental/nas/nas/index.rst", "autoapi/neural_compressor/experimental/nas/nas_utils/index.rst", "autoapi/neural_compressor/experimental/nas/search_algorithms/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/gradient_sensitivity/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/group_lasso/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/magnitude/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/pattern_lock/index.rst", "autoapi/neural_compressor/experimental/pruner_legacy/pruner/index.rst", "autoapi/neural_compressor/experimental/pruning/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/pattern/index.rst", "autoapi/neural_compressor/experimental/pruning_recipes/patterns/tile_pattern/index.rst", "autoapi/neural_compressor/experimental/pruning_v2/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/logger/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/patterns/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/prune_utils/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/pruner/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/pruning/index.rst", "autoapi/neural_compressor/experimental/pytorch_pruner/scheduler/index.rst", "autoapi/neural_compressor/experimental/quantization/index.rst", "autoapi/neural_compressor/experimental/scheduler/index.rst", "autoapi/neural_compressor/experimental/strategy/auto_mixed_precision/index.rst", "autoapi/neural_compressor/experimental/strategy/basic/index.rst", "autoapi/neural_compressor/experimental/strategy/bayesian/index.rst", "autoapi/neural_compressor/experimental/strategy/exhaustive/index.rst", "autoapi/neural_compressor/experimental/strategy/index.rst", "autoapi/neural_compressor/experimental/strategy/mse/index.rst", "autoapi/neural_compressor/experimental/strategy/mse_v2/index.rst", "autoapi/neural_compressor/experimental/strategy/random/index.rst", "autoapi/neural_compressor/experimental/strategy/strategy/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/constant/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_sampler/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_space/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/tuning_structs/index.rst", "autoapi/neural_compressor/experimental/strategy/utils/utility/index.rst", "autoapi/neural_compressor/index.rst", "autoapi/neural_compressor/metric/bleu/index.rst", "autoapi/neural_compressor/metric/bleu_util/index.rst", "autoapi/neural_compressor/metric/coco_label_map/index.rst", "autoapi/neural_compressor/metric/coco_tools/index.rst", "autoapi/neural_compressor/metric/evaluate_squad/index.rst", "autoapi/neural_compressor/metric/f1/index.rst", "autoapi/neural_compressor/metric/index.rst", "autoapi/neural_compressor/metric/metric/index.rst", "autoapi/neural_compressor/mix_precision/index.rst", "autoapi/neural_compressor/model/base_model/index.rst", "autoapi/neural_compressor/model/index.rst", "autoapi/neural_compressor/model/keras_model/index.rst", "autoapi/neural_compressor/model/model/index.rst", "autoapi/neural_compressor/model/mxnet_model/index.rst", "autoapi/neural_compressor/model/nets_factory/index.rst", "autoapi/neural_compressor/model/onnx_model/index.rst", "autoapi/neural_compressor/model/tensorflow_model/index.rst", "autoapi/neural_compressor/model/torch_model/index.rst", "autoapi/neural_compressor/objective/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/calibrator/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/core/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/smoother/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/awq/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/gptq/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/rtn/index.rst", "autoapi/neural_compressor/onnxrt/algorithms/weight_only/utility/index.rst", "autoapi/neural_compressor/onnxrt/index.rst", "autoapi/neural_compressor/onnxrt/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/onnxrt/quantization/autotune/index.rst", "autoapi/neural_compressor/onnxrt/quantization/calibrate/index.rst", "autoapi/neural_compressor/onnxrt/quantization/config/index.rst", "autoapi/neural_compressor/onnxrt/quantization/index.rst", "autoapi/neural_compressor/onnxrt/quantization/quantize/index.rst", "autoapi/neural_compressor/onnxrt/utils/index.rst", "autoapi/neural_compressor/onnxrt/utils/onnx_model/index.rst", "autoapi/neural_compressor/onnxrt/utils/utility/index.rst", "autoapi/neural_compressor/profiling/index.rst", "autoapi/neural_compressor/profiling/parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/index.rst", "autoapi/neural_compressor/profiling/parser/onnx_parser/parser/index.rst", "autoapi/neural_compressor/profiling/parser/parser/index.rst", "autoapi/neural_compressor/profiling/parser/result/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/factory/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/index.rst", "autoapi/neural_compressor/profiling/parser/tensorflow_parser/parser/index.rst", "autoapi/neural_compressor/profiling/profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/onnxrt_profiler/utils/index.rst", "autoapi/neural_compressor/profiling/profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/factory/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/profiler/index.rst", "autoapi/neural_compressor/profiling/profiler/tensorflow_profiler/utils/index.rst", "autoapi/neural_compressor/quantization/index.rst", "autoapi/neural_compressor/strategy/auto/index.rst", "autoapi/neural_compressor/strategy/auto_mixed_precision/index.rst", "autoapi/neural_compressor/strategy/basic/index.rst", "autoapi/neural_compressor/strategy/bayesian/index.rst", "autoapi/neural_compressor/strategy/conservative/index.rst", "autoapi/neural_compressor/strategy/exhaustive/index.rst", "autoapi/neural_compressor/strategy/hawq_v2/index.rst", "autoapi/neural_compressor/strategy/index.rst", "autoapi/neural_compressor/strategy/mse/index.rst", "autoapi/neural_compressor/strategy/mse_v2/index.rst", "autoapi/neural_compressor/strategy/random/index.rst", "autoapi/neural_compressor/strategy/strategy/index.rst", "autoapi/neural_compressor/strategy/utils/constant/index.rst", "autoapi/neural_compressor/strategy/utils/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_sampler/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_space/index.rst", "autoapi/neural_compressor/strategy/utils/tuning_structs/index.rst", "autoapi/neural_compressor/strategy/utils/utility/index.rst", "autoapi/neural_compressor/template/api_doc_example/index.rst", "autoapi/neural_compressor/template/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/calibration/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/core/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/smoother/scaler/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/conv2d/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/dense/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/depthwise_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/pool2d/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/quantizer/index.rst", "autoapi/neural_compressor/tensorflow/algorithms/static_quant/keras_utils/separable_conv2d/index.rst", "autoapi/neural_compressor/tensorflow/index.rst", "autoapi/neural_compressor/tensorflow/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/tensorflow/quantization/config/index.rst", "autoapi/neural_compressor/tensorflow/quantization/index.rst", "autoapi/neural_compressor/tensorflow/quantization/quantize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_add_to_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_layout/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_leakyrelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_nan_to_random/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/convert_placeholder_to_const/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dilated_contraction/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/dummy_biasadd/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/expanddims_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fetch_weight_from_reshape/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fold_constant/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_biasadd_add/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_column_wise_mul/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_conv_with_math/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_bn/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_decomposed_in/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_gelu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_layer_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_pad_with_fp32_conv/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/fuse_reshape_transpose/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/graph_cse_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/grappler_pass/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/insert_print_node/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/move_squeeze_after_relu/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/pre_optimize/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/remove_training_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/rename_batch_norm/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/split_shared_input/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_equivalent_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/strip_unused_nodes/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/generic/switch_optimizer/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/graph_base/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_rewriter/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/graph_util/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/quantize_graph_common/index.rst", "autoapi/neural_compressor/tensorflow/quantization/utils/utility/index.rst", "autoapi/neural_compressor/tensorflow/utils/constants/index.rst", "autoapi/neural_compressor/tensorflow/utils/data/index.rst", "autoapi/neural_compressor/tensorflow/utils/index.rst", "autoapi/neural_compressor/tensorflow/utils/model/index.rst", "autoapi/neural_compressor/tensorflow/utils/model_wrappers/index.rst", "autoapi/neural_compressor/tensorflow/utils/nets_factory/index.rst", "autoapi/neural_compressor/tensorflow/utils/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/fp8_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/modules/index.rst", "autoapi/neural_compressor/torch/algorithms/habana_fp8/observer/index.rst", "autoapi/neural_compressor/torch/algorithms/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/load/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/modified_pickle/index.rst", "autoapi/neural_compressor/torch/algorithms/layer_wise/utils/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/static_quant/index.rst", "autoapi/neural_compressor/torch/algorithms/static_quant/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/awq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/gptq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/auto_accelerator/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/bitpack/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/config/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/core/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/optimizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/qtensor/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quant_api/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/quantizer/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/hqq/utility/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/modules/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/rtn/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/teq/index.rst", "autoapi/neural_compressor/torch/algorithms/weight_only/utility/index.rst", "autoapi/neural_compressor/torch/amp/autocast/index.rst", "autoapi/neural_compressor/torch/amp/fp8/functions/index.rst", "autoapi/neural_compressor/torch/amp/fp8/index.rst", "autoapi/neural_compressor/torch/amp/index.rst", "autoapi/neural_compressor/torch/index.rst", "autoapi/neural_compressor/torch/quantization/algorithm_entry/index.rst", "autoapi/neural_compressor/torch/quantization/autotune/index.rst", "autoapi/neural_compressor/torch/quantization/config/index.rst", "autoapi/neural_compressor/torch/quantization/index.rst", "autoapi/neural_compressor/torch/quantization/modules/index.rst", "autoapi/neural_compressor/torch/quantization/quantize/index.rst", "autoapi/neural_compressor/torch/utils/constants/index.rst", "autoapi/neural_compressor/torch/utils/environ/index.rst", "autoapi/neural_compressor/torch/utils/index.rst", "autoapi/neural_compressor/torch/utils/utility/index.rst", "autoapi/neural_compressor/training/index.rst", "autoapi/neural_compressor/utils/collect_layer_histogram/index.rst", "autoapi/neural_compressor/utils/constant/index.rst", "autoapi/neural_compressor/utils/create_obj_from_config/index.rst", "autoapi/neural_compressor/utils/index.rst", "autoapi/neural_compressor/utils/kl_divergence/index.rst", "autoapi/neural_compressor/utils/load_huggingface/index.rst", "autoapi/neural_compressor/utils/logger/index.rst", "autoapi/neural_compressor/utils/neural_insights_utils/index.rst", "autoapi/neural_compressor/utils/options/index.rst", "autoapi/neural_compressor/utils/pytorch/index.rst", "autoapi/neural_compressor/utils/utility/index.rst", "autoapi/neural_compressor/utils/weights_details/index.rst", "autoapi/neural_compressor/version/index.rst", "docs/build_docs/source/index.rst", "docs/source/CODE_OF_CONDUCT.md", "docs/source/CONTRIBUTING.md", "docs/source/FX.md", "docs/source/NAS.md", "docs/source/SECURITY.md", "docs/source/Welcome.md", "docs/source/adaptor.md", "docs/source/add_new_adaptor.md", "docs/source/add_new_data_type.md", "docs/source/api-doc/adaptor.rst", "docs/source/api-doc/adaptor/onnxrt.rst", "docs/source/api-doc/adaptor/torch_utils.rst", "docs/source/api-doc/api_doc_example.rst", "docs/source/api-doc/apis.rst", "docs/source/api-doc/benchmark.rst", "docs/source/api-doc/compression.rst", "docs/source/api-doc/config.rst", "docs/source/api-doc/mix_precision.rst", "docs/source/api-doc/model.rst", "docs/source/api-doc/objective.rst", "docs/source/api-doc/quantization.rst", "docs/source/api-doc/strategy.rst", "docs/source/api-doc/training.rst", "docs/source/benchmark.md", "docs/source/calibration.md", "docs/source/coding_style.md", "docs/source/dataloader.md", "docs/source/dataset.md", "docs/source/design.md", "docs/source/diagnosis.md", "docs/source/distillation.md", "docs/source/distillation_quantization.md", "docs/source/distributed.md", "docs/source/examples_readme.md", "docs/source/export.md", "docs/source/faq.md", "docs/source/framework_yaml.md", "docs/source/get_started.md", "docs/source/incompatible_changes.md", "docs/source/infrastructure.md", "docs/source/installation_guide.md", "docs/source/legal_information.md", "docs/source/llm_recipes.md", "docs/source/metric.md", "docs/source/migration.md", "docs/source/mixed_precision.md", "docs/source/model.md", "docs/source/neural_coder/README.md", "docs/source/neural_coder/docs/AWSSageMakerSupport.md", "docs/source/neural_coder/docs/BigDLNanoSupport.md", "docs/source/neural_coder/docs/IntelCPU_PerformanceSetting.md", "docs/source/neural_coder/docs/PythonAPI.md", "docs/source/neural_coder/docs/PythonLauncher.md", "docs/source/neural_coder/docs/Quantization.md", "docs/source/neural_coder/docs/SupportMatrix.md", "docs/source/neural_coder/docs/release_notes/v0.4.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/DEVELOP.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/README.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab/RELEASE.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/DEVELOP.md", "docs/source/neural_coder/extensions/neural_compressor_ext_lab_alibaba/RELEASE.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/CHANGELOG.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/README.md", "docs/source/neural_coder/extensions/neural_compressor_ext_vscode/vsc-extension-quickstart.md", "docs/source/neural_insights/README.md", "docs/source/neural_insights/docs/source/onnx_accuracy_debug.md", "docs/source/neural_insights/docs/source/pytorch_nlp_cli_mode.md", "docs/source/neural_insights/docs/source/tf_accuracy_debug.md", "docs/source/neural_insights/gui/README.md", "docs/source/neural_solution/README.md", "docs/source/neural_solution/docs/source/README.md", "docs/source/neural_solution/docs/source/description_api.md", "docs/source/neural_solution/docs/source/ns_design_doc.md", "docs/source/neural_solution/docs/source/template/task_request_description.md", "docs/source/neural_solution/examples/README.md", "docs/source/neural_solution/examples/custom_models_optimized/tf_example1/README.md", "docs/source/neural_solution/examples/hf_models/README.md", "docs/source/neural_solution/examples/hf_models_grpc/README.md", "docs/source/neural_solution/frontend/README.md", "docs/source/objective.md", "docs/source/orchestration.md", "docs/source/pruning.md", "docs/source/publication_list.md", "docs/source/pythonic_style.md", "docs/source/quantization.md", "docs/source/quantization_layer_wise.md", "docs/source/quantization_mixed_precision.md", "docs/source/quantization_weight_only.md", "docs/source/releases_info.md", "docs/source/sigopt_strategy.md", "docs/source/smooth_quant.md", "docs/source/tensorboard.md", "docs/source/transform.md", "docs/source/tuning_strategies.md", "docs/source/user_guide.md", "docs/source/user_yaml.md", "docs/source/validated_model_list.md", "index.rst"], "titles": ["<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">block_mask</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.adaptor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.dense</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.depthwise_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.pool2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.keras_utils.separable_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.mxnet_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.onnxrt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.calibrator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.activation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.argmax</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.attention</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.binary_op</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.concat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.direct_q8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.embed_layernorm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gather</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gavgpool</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.gemm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.lstm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.maxpool</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.ops</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.pad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.reduce</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.resize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.split</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.operators.unary_op</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.ox_utils.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.pytorch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.query</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tensorflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_converter_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.bf16</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.graph_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.quantize_graph_common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.smooth_quant_calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.smooth_quant_scaler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.tf2onnx_converter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.bias_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.insert_logging</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.tf_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.autoround.autoround</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.autoround.export</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.autoround</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.autoround.model_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.autoround.sign_sgd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.bf16_convert</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.hawq_metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.layer_wise_quant.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.model_wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.pattern_detector</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.symbolic_trace</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.teq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.adaptor.torch_utils.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.algorithm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.fast_bias_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.smooth_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.algorithm.weight_correction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.benchmark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.base_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.base_tuning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.tuning_param</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.common.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.callbacks</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.criterions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.optimizers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.distillation.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.sa_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.search_algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.hpo.search_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.criteria</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.dsnot</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.auto_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.pattern_analyzer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.model_slim.weight_slim</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.mha</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.ninm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.patterns.nxm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.block_mask</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.mha</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.pattern_lock</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.progressive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.retrain_free</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruners.sparse_gpt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.regs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.schedulers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.tf_criteria</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.prune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.compression.pruner.wanda.wrapper</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.dotdict</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.conf.pythonic_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy.sigopt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.contrib.strategy.tpe</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.base_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.default_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.fetcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.mxnet_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.onnxrt_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.pytorch_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.dataloaders.tensorflow_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.bert_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.coco_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dummy_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.dummy_dataset_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.imagenet_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.datasets.style_transfer_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters.coco_filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters.filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.filters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.coco_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.imagenet_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.postprocess</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.tokenization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.data.transforms.transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.benchmark</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.criterion</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.postprocess</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.common.torch_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.component</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.compression</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy.sigopt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.contrib.strategy.tpe</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.base_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.default_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.fetcher</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.mxnet_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.onnxrt_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.pytorch_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.dataloaders.tensorflow_dataloader</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.bert_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.coco_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dummy_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.dummy_dataset_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.imagenet_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.datasets.style_transfer_dataset</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters.coco_filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters.filter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.filters</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.imagenet_transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.tokenization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.data.transforms.transform</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.distillation</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.qlinear2qdq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.tf2onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.export.torch2onnx</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.graph_optimization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.bleu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.bleu_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.coco_label_map</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.coco_tools</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.evaluate_squad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.f1</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.metric.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.model_conversion</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.basic_nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.dynas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.nas</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.nas_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.nas.search_algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.gradient_sensitivity</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.group_lasso</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.magnitude</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.pattern_lock</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruner_legacy.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns.pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_recipes.patterns.tile_pattern</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pruning_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.patterns</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.prune_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.pruner</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.pruning</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.pytorch_pruner.scheduler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.scheduler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.auto_mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.bayesian</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.exhaustive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.mse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.mse_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.tuning_structs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.experimental.strategy.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.bleu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.bleu_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.coco_label_map</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.coco_tools</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.evaluate_squad</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.f1</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.metric.metric</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.mix_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.base_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.keras_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.mxnet_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.nets_factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.onnx_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.tensorflow_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.model.torch_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.objective</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother.calibrator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.smoother</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.rtn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.algorithms.weight_only.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.autotune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.calibrate</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils.onnx_model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.onnxrt.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.onnx_parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.result</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.parser.tensorflow_parser.parser</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.onnxrt_profiler.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.profiler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.profiling.profiler.tensorflow_profiler.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.auto</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.auto_mixed_precision</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.basic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.bayesian</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.conservative</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.exhaustive</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.hawq_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.mse</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.mse_v2</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.strategy</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_sampler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_space</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.tuning_structs</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.strategy.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.template.api_doc_example</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.template</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.calibration</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.smoother.scaler</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_rewriter</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.graph_util</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.quantize_graph_common</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.quantization.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.data</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.model</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.model_wrappers</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.nets_factory</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.tensorflow.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.fp8_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.modules</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.habana_fp8.observer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.load</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.modified_pickle</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.layer_wise.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant.static_quant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.static_quant.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.awq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.gptq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.bitpack</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.core</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.optimizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.qtensor</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.quant_api</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.quantizer</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.hqq.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.modules</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.rtn</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.teq</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.algorithms.weight_only.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.autocast</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.fp8.functions</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp.fp8</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.amp</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.algorithm_entry</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.autotune</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.modules</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.quantization.quantize</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.constants</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.environ</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.torch.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.training</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.collect_layer_histogram</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.constant</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.create_obj_from_config</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.kl_divergence</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.load_huggingface</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.logger</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.neural_insights_utils</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.options</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.pytorch</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.utility</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.utils.weights_details</span></code>", "<code class=\"xref py py-mod docutils literal notranslate\"><span class=\"pre\">neural_compressor.version</span></code>", "Intel\u00ae Neural Compressor Documentation", "Contributor Covenant Code of Conduct", "Contribution Guidelines", "FX", "Neural Architecture Search", "Security Policy", "Intel\u00ae Neural Compressor", "Adaptor", "How to Add An Adaptor", "How to Support New Data Type, Like Int4, with a Few Line Changes", "Adaptor", "ONNX Runtime", "Torch Utils", "API Document Example", "APIs", "Benchmark", "Compression", "Config", "Mix Precision", "Model", "Objective", "Quantization", "Strategy", "Training", "Benchmarking", "Calibration Algorithms in Quantization", "INC Coding Conventions", "DataLoader", "Dataset", "Design", "Diagnosis", "Distillation", "Distillation for Quantization", "Distributed Training and Inference (Evaluation)", "Examples", "Export", "Frequently Asked Questions", "Framework YAML Configuration Files", "Getting Started", "Incompatible changes between v1.2 and v1.1", "Infrastructure of Intel\u00ae Neural Compressor", "Installation", "Legal Information", "LLMs Quantization Recipes", "Metrics", "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X", "Mixed Precision", "Model", "Neural Coder", "AWS Amazon SageMaker Support", "BigDL Nano Support", "Intel CPU Platforms: Best Performance Setting", "Neural Coder as Python API", "Python Launcher", "Neural Coder for Quantization", "Supported Optimization Features", "v0.4", "Changelog", "neural_compressor_ext_lab", "Intel\u00ae Neural Compressor as JupyterLab Extension", "Making a new release of neural_compressor_ext_lab", "Changelog", "neural_compressor_ext_lab_alibaba", "Making a new release of neural_compressor_ext_lab_alibaba", "Change Log", "Neural Coder", "Welcome to your VS Code Extension", "Neural Insights", "Step by step example how to debug accuracy with Neural Insights", "Step by step example how to dump weights data for PyTorch model with Neural Insights", "Step by step example how to debug accuracy with Neural Insights", "Getting Started with Create React App", "What\u2019s Neural Solution?", "Get started", "Neural Solution API", "Design Doc for Optimization as a Service [WIP]", "Task request description", "Examples List", "An end-to-end example: quantize a custom model with Neural Solution", "An end-to-end example: quantize a Hugging Face model with Neural Solution", "An end-to-end example: quantize a Hugging Face model with Neural Solution gRPC API", "Client", "Objective", "Optimization Orchestration", "Pruning", "Full Publications/Events (79)", "Pythonic Style Access for Configurations", "Quantization", "Layer Wise Quantization (LWQ)", "Turn OFF Auto Mixed Precision during Quantization", "Weight Only Quantization (WOQ)", "Release", "SigOpt Strategy", "Smooth Quant", "TensorBoard", "Transform", "Tuning Strategies", "User Guide", "User YAML Configuration Files", "Validated Models", "Intel\u00ae Neural Compressor Documentation"], "terms": {"block": [0, 44, 149, 166, 170, 171, 196, 207, 210, 215, 221, 341, 382, 388, 391, 443, 521, 522, 538, 608, 650, 652, 658, 664], "mask": [0, 196, 203, 205, 208, 210, 214, 215, 245, 288, 314, 343, 367, 652, 667], "adaptor_registri": [1, 575], "cl": [1, 163, 172, 187, 189, 193, 194, 203, 208, 217, 218, 219, 247, 254, 262, 264, 269, 290, 297, 303, 325, 332, 336, 341, 343, 345, 356, 371, 382, 436, 509, 518, 565, 594], "sourc": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 181, 184, 185, 186, 187, 189, 190, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 257, 258, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 276, 277, 278, 280, 281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 300, 302, 303, 304, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 336, 337, 338, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 362, 363, 364, 365, 367, 368, 369, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 390, 391, 393, 394, 395, 396, 400, 401, 403, 405, 407, 408, 409, 410, 412, 413, 415, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 439, 440, 441, 442, 443, 446, 447, 449, 451, 460, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 501, 502, 504, 506, 507, 508, 509, 516, 517, 518, 520, 521, 522, 523, 524, 526, 533, 535, 536, 537, 538, 539, 544, 545, 546, 549, 553, 554, 555, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 571, 574, 610, 613, 626, 628, 630, 631, 633, 653], "The": [1, 3, 11, 14, 16, 34, 54, 74, 113, 119, 121, 140, 148, 149, 150, 153, 162, 164, 170, 172, 177, 178, 179, 181, 185, 186, 187, 189, 193, 194, 196, 197, 201, 203, 205, 206, 208, 209, 210, 215, 216, 217, 218, 219, 220, 221, 226, 227, 229, 230, 233, 234, 235, 245, 246, 247, 248, 249, 253, 254, 262, 264, 267, 269, 272, 276, 277, 278, 288, 289, 290, 291, 292, 296, 297, 303, 304, 309, 311, 312, 313, 315, 316, 318, 320, 321, 322, 324, 325, 327, 328, 330, 331, 332, 333, 336, 338, 341, 342, 343, 344, 345, 346, 348, 349, 350, 351, 353, 354, 355, 356, 360, 362, 364, 365, 366, 368, 369, 371, 372, 380, 382, 393, 394, 401, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 440, 442, 443, 446, 447, 451, 460, 463, 465, 485, 502, 504, 507, 509, 516, 521, 533, 539, 544, 545, 549, 553, 554, 555, 557, 559, 560, 564, 565, 566, 569, 571, 572, 575, 576, 577, 578, 580, 584, 587, 590, 592, 593, 594, 595, 596, 598, 599, 601, 603, 605, 607, 608, 609, 611, 612, 613, 614, 615, 618, 619, 621, 624, 626, 627, 628, 630, 631, 633, 634, 635, 636, 638, 639, 640, 641, 642, 643, 644, 646, 650, 651, 652, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667], "decor": [1, 16, 34, 67, 68, 70, 148, 172, 178, 185, 189, 193, 194, 203, 208, 217, 219, 262, 269, 303, 318, 325, 332, 336, 341, 343, 345, 356, 359, 371, 382, 401, 436, 478, 479, 481, 502, 509, 533, 539, 553, 565, 571, 572, 575, 664], "us": [1, 13, 16, 34, 42, 43, 44, 48, 49, 70, 103, 105, 116, 141, 149, 150, 153, 157, 162, 164, 170, 171, 177, 187, 189, 193, 194, 196, 201, 203, 208, 212, 213, 217, 219, 220, 223, 227, 229, 230, 233, 234, 243, 244, 245, 246, 247, 248, 249, 252, 261, 262, 263, 264, 269, 276, 277, 286, 287, 288, 289, 290, 291, 292, 295, 302, 303, 307, 308, 309, 311, 312, 314, 318, 319, 320, 325, 332, 333, 336, 338, 341, 343, 344, 345, 346, 347, 350, 353, 356, 359, 360, 364, 365, 367, 371, 382, 387, 388, 390, 391, 401, 418, 423, 424, 428, 431, 433, 436, 440, 442, 443, 449, 451, 481, 504, 509, 516, 520, 521, 522, 524, 536, 538, 539, 549, 553, 554, 555, 556, 557, 558, 560, 565, 569, 570, 571, 572, 575, 576, 592, 593, 594, 596, 598, 599, 600, 601, 603, 605, 607, 609, 610, 613, 614, 615, 616, 617, 618, 620, 621, 624, 626, 628, 630, 631, 633, 635, 636, 637, 638, 639, 646, 647, 648, 650, 652, 653, 654, 655, 656, 657, 658, 659, 660, 662, 663, 664, 666, 667], "regist": [1, 16, 34, 160, 162, 172, 178, 187, 189, 193, 194, 196, 198, 203, 204, 208, 211, 217, 218, 219, 220, 247, 254, 262, 264, 269, 290, 297, 303, 318, 325, 332, 336, 341, 343, 345, 356, 359, 371, 382, 401, 436, 442, 461, 509, 516, 517, 524, 553, 562, 572, 575, 594, 596, 601, 612, 613, 634, 650, 661, 664], "all": [1, 13, 16, 34, 44, 45, 63, 97, 156, 162, 163, 170, 171, 172, 174, 177, 178, 186, 189, 194, 198, 203, 211, 221, 229, 230, 235, 236, 243, 247, 254, 262, 263, 269, 272, 278, 286, 290, 297, 303, 308, 311, 314, 316, 318, 325, 332, 336, 337, 341, 347, 356, 359, 364, 367, 369, 371, 373, 382, 436, 442, 461, 474, 504, 507, 509, 516, 518, 521, 522, 523, 557, 565, 569, 570, 574, 575, 576, 577, 594, 595, 596, 601, 605, 609, 613, 616, 624, 627, 628, 631, 632, 633, 634, 635, 638, 639, 641, 642, 646, 647, 648, 651, 652, 653, 655, 657, 658, 661, 663, 664], "subclass": [1, 16, 34, 172, 189, 193, 194, 203, 208, 217, 219, 240, 244, 247, 254, 262, 269, 283, 287, 290, 297, 303, 318, 325, 332, 336, 341, 343, 345, 356, 359, 371, 382, 436, 575], "paramet": [1, 11, 13, 14, 16, 42, 43, 44, 45, 67, 68, 70, 86, 105, 116, 132, 140, 141, 148, 149, 150, 153, 155, 156, 157, 162, 163, 167, 168, 170, 171, 172, 177, 178, 179, 181, 185, 186, 187, 189, 191, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 226, 227, 229, 230, 233, 234, 244, 245, 247, 254, 258, 262, 264, 269, 276, 277, 287, 288, 290, 297, 300, 303, 304, 306, 307, 308, 309, 311, 312, 314, 315, 316, 318, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 336, 338, 341, 342, 343, 344, 345, 346, 350, 356, 360, 362, 364, 365, 367, 368, 369, 371, 372, 376, 380, 382, 387, 388, 390, 391, 394, 401, 418, 423, 424, 428, 436, 440, 442, 443, 446, 449, 460, 463, 478, 479, 481, 497, 502, 507, 509, 516, 518, 520, 521, 522, 523, 524, 533, 536, 538, 539, 549, 553, 554, 557, 560, 561, 562, 564, 565, 571, 576, 595, 596, 599, 601, 608, 612, 613, 627, 633, 634, 635, 636, 641, 646, 647, 652, 655, 656, 658, 660, 661, 663, 664, 666], "framework_specific_info": [1, 3, 11, 14, 45, 47, 451, 575], "base": [1, 11, 13, 14, 16, 34, 46, 47, 86, 105, 116, 120, 122, 132, 144, 149, 153, 157, 160, 166, 170, 172, 178, 179, 186, 193, 194, 195, 196, 198, 204, 211, 218, 220, 230, 235, 238, 243, 245, 247, 254, 262, 272, 278, 281, 286, 288, 290, 297, 303, 318, 324, 326, 332, 333, 336, 338, 343, 353, 356, 360, 371, 373, 380, 381, 382, 387, 395, 433, 436, 440, 497, 504, 507, 517, 521, 572, 574, 575, 576, 577, 594, 596, 600, 601, 605, 613, 614, 621, 622, 624, 633, 636, 641, 644, 647, 648, 652, 653, 655, 658, 660, 661, 662, 664, 667], "framework": [1, 3, 11, 13, 14, 45, 153, 177, 178, 187, 189, 198, 204, 208, 211, 215, 216, 217, 231, 232, 236, 237, 241, 244, 245, 246, 247, 248, 249, 250, 251, 252, 254, 256, 259, 262, 264, 265, 269, 274, 275, 279, 280, 282, 284, 287, 288, 289, 290, 291, 292, 293, 294, 295, 297, 299, 301, 303, 309, 318, 319, 346, 354, 360, 371, 372, 373, 374, 376, 434, 440, 451, 461, 557, 574, 575, 577, 593, 594, 598, 601, 602, 606, 607, 608, 609, 612, 613, 614, 635, 636, 652, 653, 655, 659, 662, 663, 664, 665, 666, 667], "layer": [1, 3, 11, 14, 46, 47, 116, 117, 118, 119, 121, 122, 149, 156, 159, 161, 163, 167, 171, 175, 187, 190, 199, 201, 202, 203, 207, 212, 221, 224, 225, 229, 230, 264, 271, 341, 342, 451, 509, 515, 518, 523, 536, 555, 557, 565, 574, 575, 576, 577, 600, 608, 636, 652, 658, 659, 665], "mxnet_util": 2, "util": [2, 12, 17, 105, 110, 111, 139, 142, 155, 157, 158, 159, 168, 178, 188, 195, 198, 222, 229, 230, 271, 310, 312, 342, 352, 363, 365, 384, 385, 387, 388, 390, 396, 416, 421, 432, 460, 463, 514, 515, 546, 576, 577, 578, 593, 594, 601, 613, 616, 636, 652, 655, 664, 665], "ox_util": 2, "oper": [2, 17, 43, 104, 110, 140, 148, 201, 202, 207, 225, 229, 230, 258, 300, 341, 418, 423, 446, 499, 502, 571, 592, 595, 598, 603, 633, 639, 652, 655, 658, 661, 663, 664], "activ": [2, 17, 29, 44, 141, 154, 170, 171, 190, 229, 230, 271, 360, 387, 440, 442, 449, 522, 575, 576, 577, 593, 598, 600, 605, 613, 634, 635, 638, 646, 647, 648, 654, 655, 658, 661, 662, 666], "argmax": [2, 17, 29], "attent": [2, 17, 29, 166, 199, 201, 212, 229, 230, 245, 288, 521, 569, 599, 652], "binary_op": [2, 17, 29], "concat": [2, 17, 29, 147], "conv": [2, 17, 29, 58, 62, 66, 71, 72, 73, 92, 109, 175, 229, 230, 396, 469, 473, 477, 482, 483, 484, 571, 576, 577, 613, 652, 654, 655, 664], "direct_q8": [2, 17, 29], "embed_layernorm": [2, 17, 29], "gather": [2, 13, 17, 29, 229, 230, 341], "gavgpool": [2, 17, 29], "gemm": [2, 17, 29, 229, 230, 396], "lstm": [2, 17, 29], "matmul": [2, 17, 29, 44, 53, 59, 65, 73, 94, 109, 128, 137, 207, 229, 230, 341, 387, 388, 390, 391, 396, 461, 464, 470, 476, 484, 605, 636, 658, 664], "maxpool": [2, 17, 29, 129, 138, 605], "norm": [2, 17, 29], "op": [2, 13, 17, 29, 45, 51, 53, 65, 66, 67, 68, 69, 70, 71, 72, 74, 78, 81, 85, 88, 91, 92, 93, 94, 96, 105, 107, 109, 123, 124, 125, 131, 133, 134, 135, 136, 141, 143, 146, 148, 155, 157, 168, 170, 171, 175, 201, 229, 230, 308, 353, 360, 361, 418, 423, 429, 431, 433, 440, 441, 442, 449, 464, 476, 477, 478, 479, 480, 481, 482, 483, 485, 489, 492, 496, 502, 520, 521, 538, 539, 553, 559, 565, 575, 576, 577, 598, 605, 613, 614, 637, 638, 652, 655, 657, 659, 661, 662, 664, 666], "pad": [2, 17, 29, 44, 71, 72, 245, 262, 288, 303, 391, 482, 483, 596, 663], "pool": [2, 17, 29, 643], "reduc": [2, 17, 29, 229, 230, 575, 593, 600, 613, 614, 633, 634, 652, 653, 655, 656, 657, 658, 661, 664, 666], "resiz": [2, 17, 29, 245, 246, 258, 262, 288, 289, 300, 303, 596, 663], "split": [2, 17, 29, 43, 82, 149, 171, 261, 262, 302, 303, 493, 522, 536, 571, 656, 658, 661, 663], "unary_op": [2, 17, 29], "calibr": [2, 11, 13, 14, 17, 44, 49, 89, 90, 140, 170, 171, 177, 229, 230, 233, 234, 276, 277, 309, 346, 385, 386, 387, 388, 391, 393, 394, 424, 448, 460, 463, 520, 522, 538, 549, 559, 575, 577, 596, 607, 608, 652, 655, 658, 664, 665, 666], "quantiz": [2, 11, 13, 14, 16, 17, 42, 43, 44, 48, 49, 88, 92, 94, 96, 99, 107, 112, 113, 114, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 149, 150, 154, 155, 156, 157, 158, 159, 163, 164, 165, 167, 169, 170, 171, 175, 177, 179, 184, 186, 229, 230, 233, 234, 258, 265, 272, 276, 277, 300, 308, 309, 310, 320, 347, 353, 359, 363, 384, 385, 387, 388, 390, 391, 401, 429, 431, 433, 442, 446, 447, 449, 451, 515, 518, 520, 521, 522, 523, 531, 535, 536, 537, 538, 554, 555, 559, 560, 564, 565, 575, 582, 594, 595, 596, 601, 602, 605, 607, 608, 612, 615, 616, 621, 623, 624, 627, 640, 642, 643, 645, 651, 653, 659, 662, 663, 664, 665, 666], "smooth_quant": [2, 17, 161, 170, 174, 229, 230, 363, 594, 655, 661], "weight_onli": [2, 17, 230, 564, 594, 656, 658], "tf_util": 2, "graph_rewrit": [2, 111], "bf16": [2, 44, 87, 111, 155, 229, 230, 360, 387, 388, 390, 391, 440, 575, 576, 605, 613, 618, 623, 627, 633, 657, 664, 667], "gener": [2, 13, 48, 49, 87, 111, 122, 148, 156, 170, 177, 181, 201, 221, 233, 234, 235, 244, 247, 248, 249, 250, 262, 276, 277, 278, 287, 290, 291, 292, 293, 303, 311, 319, 350, 364, 372, 396, 419, 424, 428, 443, 461, 498, 502, 504, 523, 546, 554, 570, 571, 575, 577, 595, 599, 612, 613, 614, 616, 621, 626, 628, 630, 631, 633, 635, 636, 650, 652, 653, 655, 657, 658, 661, 662, 663, 664], "int8": [2, 18, 19, 43, 44, 87, 111, 123, 124, 125, 131, 133, 134, 135, 136, 143, 148, 171, 176, 177, 229, 230, 258, 300, 306, 307, 308, 360, 362, 387, 388, 390, 391, 401, 440, 442, 461, 502, 538, 564, 565, 570, 571, 574, 575, 576, 577, 592, 596, 600, 605, 611, 613, 614, 618, 621, 623, 624, 627, 633, 636, 638, 653, 654, 655, 657, 658, 659, 660, 661, 662, 663, 666], "onnx": [2, 14, 15, 16, 29, 41, 43, 44, 87, 111, 142, 175, 229, 230, 241, 284, 306, 307, 308, 372, 379, 385, 387, 388, 390, 391, 393, 394, 400, 401, 418, 563, 570, 574, 575, 576, 578, 595, 598, 602, 603, 605, 606, 608, 614, 615, 618, 623, 624, 636, 653, 654, 658, 659, 661, 664], "qdq": [2, 42, 87, 111, 112, 113, 142, 170, 171, 229, 230, 306, 307, 308, 538, 575, 598, 603, 608, 623, 624, 655, 659, 661], "graph_bas": [2, 87, 111, 498], "quantize_graph": [2, 111], "qat": [2, 111, 112, 168, 230, 320, 380, 507, 600, 601, 608, 613, 655], "quantize_graph_bas": [2, 111, 112], "quantize_graph_bn": [2, 111, 112], "quantize_graph_concatv2": [2, 111, 112], "quantize_graph_conv": [2, 111, 112], "quantize_graph_for_intel_cpu": [2, 111, 112], "quantize_graph_matmul": [2, 111, 112], "quantize_graph_pool": [2, 111, 112], "transform_graph": [2, 111], "bias_correct": [2, 111, 145], "graph_transform_bas": [2, 111, 145], "insert_log": [2, 111, 145], "rerange_quantized_concat": [2, 111, 145], "graph_convert": [2, 111], "graph_converter_without_calib": [2, 111], "graph_util": [2, 111, 500], "quantize_graph_common": [2, 111, 500], "smooth_quant_calibr": [2, 111], "smooth_quant_scal": [2, 111], "tf2onnx_convert": [2, 111], "torch_util": [2, 266, 310, 363, 656, 661], "layer_wise_qu": [2, 158, 230, 656], "modified_pickl": [2, 158, 159, 514, 515], "torch_load": [2, 158, 159], "bf16_convert": [2, 52, 87, 111, 158], "hawq_metr": [2, 158], "model_wrapp": [2, 15, 151, 158, 505], "pattern_detector": [2, 158], "symbolic_trac": [2, 158], "tensorflow": [2, 52, 54, 75, 76, 77, 87, 95, 101, 102, 103, 104, 105, 106, 110, 111, 112, 114, 117, 130, 140, 141, 142, 145, 148, 187, 189, 220, 229, 230, 244, 245, 246, 247, 250, 252, 254, 262, 269, 287, 288, 289, 290, 293, 295, 297, 303, 307, 308, 309, 312, 314, 318, 319, 320, 346, 354, 365, 367, 371, 372, 380, 417, 418, 422, 423, 424, 434, 565, 570, 572, 574, 575, 576, 593, 594, 595, 598, 599, 600, 602, 605, 606, 608, 609, 613, 614, 615, 623, 624, 635, 638, 652, 653, 654, 660, 661, 664, 666], "kerasadaptor": [3, 451], "mxnetadaptor": 11, "do": [11, 14, 153, 156, 186, 217, 229, 230, 244, 245, 287, 288, 304, 308, 311, 314, 344, 364, 367, 523, 564, 569, 576, 594, 596, 601, 605, 608, 612, 613, 628, 631, 652, 657, 659, 661, 664], "inspect": [11, 14, 659, 662], "tensor": [11, 13, 14, 15, 16, 43, 44, 70, 105, 140, 148, 149, 150, 153, 157, 162, 163, 170, 171, 196, 198, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 220, 230, 262, 303, 306, 308, 341, 343, 353, 380, 391, 433, 446, 481, 502, 507, 509, 516, 518, 521, 538, 539, 560, 564, 565, 571, 577, 594, 595, 596, 598, 652, 655, 659, 662, 663, 664], "dict": [11, 13, 14, 44, 45, 116, 148, 149, 150, 153, 155, 156, 157, 162, 170, 171, 172, 177, 189, 193, 196, 198, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 224, 227, 229, 230, 233, 234, 244, 263, 269, 276, 277, 287, 306, 308, 313, 314, 315, 316, 318, 321, 324, 325, 326, 333, 336, 338, 341, 342, 343, 344, 345, 350, 353, 359, 362, 366, 367, 368, 369, 371, 372, 380, 387, 388, 390, 394, 396, 424, 439, 442, 443, 461, 502, 507, 509, 516, 521, 522, 523, 536, 538, 544, 545, 554, 555, 557, 564, 565, 571, 576, 594, 603, 612, 652, 654, 655, 661, 662, 664], "specif": [11, 14, 42, 46, 104, 116, 153, 171, 177, 178, 189, 221, 225, 229, 230, 245, 246, 247, 248, 252, 254, 269, 288, 289, 290, 291, 295, 297, 327, 328, 330, 331, 332, 371, 424, 504, 536, 539, 562, 569, 572, 575, 576, 593, 594, 595, 598, 599, 605, 607, 611, 612, 613, 614, 615, 616, 620, 621, 623, 627, 633, 635, 641, 650, 652, 654, 658, 664, 666], "configur": [11, 13, 14, 45, 118, 149, 155, 170, 171, 177, 178, 221, 226, 229, 230, 233, 234, 236, 247, 250, 263, 268, 276, 277, 290, 293, 304, 308, 309, 320, 321, 322, 324, 333, 338, 342, 346, 347, 353, 371, 372, 382, 424, 433, 442, 460, 463, 521, 536, 549, 554, 556, 557, 563, 564, 571, 572, 575, 576, 596, 598, 613, 620, 634, 641, 646, 647, 648, 650, 652, 655, 658, 659, 661, 663, 664, 667], "mxnetqueri": 11, "local_config_fil": [11, 14, 47, 451], "defin": [11, 14, 46, 86, 153, 157, 181, 193, 194, 201, 203, 208, 209, 210, 215, 216, 217, 218, 219, 229, 230, 233, 234, 276, 277, 321, 322, 324, 325, 326, 333, 338, 341, 342, 343, 345, 372, 395, 424, 497, 554, 564, 569, 572, 575, 576, 595, 596, 599, 600, 605, 608, 612, 613, 634, 651, 652, 655, 658, 660, 661, 662, 664, 666], "queri": [11, 13, 14, 47, 148, 170, 201, 212, 229, 230, 451, 502, 521, 576, 577, 643, 655], "interfac": [11, 14, 46, 86, 113, 226, 309, 333, 338, 346, 347, 497, 557, 608, 613, 624, 642, 655, 659], "each": [11, 14, 46, 141, 148, 157, 162, 170, 171, 221, 229, 230, 243, 247, 250, 258, 262, 286, 290, 293, 300, 303, 312, 314, 315, 316, 353, 365, 367, 368, 369, 433, 449, 502, 516, 538, 565, 570, 575, 576, 577, 594, 596, 598, 599, 600, 605, 613, 618, 624, 627, 633, 641, 643, 650, 652, 656, 658, 660, 662, 663, 664, 665], "adapt": [11, 14, 46, 149, 569, 574, 576, 596, 624, 653], "should": [11, 14, 46, 55, 115, 116, 162, 186, 199, 201, 212, 229, 230, 233, 234, 243, 245, 247, 262, 267, 276, 277, 286, 288, 290, 303, 308, 312, 365, 371, 372, 424, 443, 466, 516, 539, 554, 565, 571, 572, 575, 576, 577, 596, 599, 601, 612, 613, 619, 628, 631, 633, 635, 636, 650, 652, 655, 658, 663, 664, 666], "implement": [11, 14, 46, 110, 143, 147, 153, 154, 162, 233, 234, 240, 243, 244, 245, 247, 276, 277, 283, 286, 287, 288, 290, 311, 364, 372, 382, 424, 431, 499, 516, 522, 554, 577, 595, 596, 612, 613, 624, 634, 652, 655, 658, 659, 662, 664, 666], "inherit": [11, 14, 46, 186, 187, 213, 214, 219, 229, 242, 262, 264, 272, 285, 303, 343, 345, 524, 572, 575, 576, 596], "backend": [11, 14, 15, 41, 42, 46, 175, 189, 229, 230, 231, 232, 236, 237, 241, 245, 246, 248, 249, 250, 251, 252, 256, 259, 262, 268, 269, 274, 275, 279, 280, 282, 284, 288, 289, 291, 292, 293, 294, 295, 299, 301, 303, 319, 354, 372, 373, 374, 376, 434, 571, 577, 598, 601, 607, 608, 613, 614, 622, 641, 646, 647, 648, 654, 658, 663, 664, 666], "own": [11, 14, 46, 74, 162, 243, 262, 286, 303, 382, 485, 516, 572, 576, 595, 596, 608, 612, 635, 639, 650, 658, 660, 665], "mxnet": [12, 13, 16, 230, 240, 244, 247, 250, 254, 262, 283, 287, 290, 293, 297, 303, 309, 318, 346, 371, 372, 377, 424, 570, 574, 575, 576, 593, 595, 602, 605, 608, 609, 613, 614, 615, 654, 664, 666], "init": [12, 17, 42, 174, 188, 198, 200, 222, 596, 612, 664], "optyp": [13, 229, 230, 306, 576], "enum": 13, "type": [13, 16, 42, 43, 44, 45, 74, 96, 105, 116, 122, 132, 140, 148, 149, 155, 156, 157, 162, 170, 171, 172, 181, 187, 189, 193, 194, 197, 201, 202, 203, 208, 217, 218, 219, 221, 224, 227, 229, 230, 243, 245, 247, 254, 262, 264, 269, 286, 288, 290, 297, 303, 308, 311, 312, 314, 318, 325, 332, 336, 341, 343, 345, 350, 356, 360, 362, 364, 365, 367, 371, 380, 382, 387, 388, 390, 391, 401, 428, 429, 436, 440, 442, 443, 446, 460, 463, 485, 502, 507, 509, 516, 521, 522, 523, 536, 538, 539, 553, 564, 565, 575, 576, 596, 598, 601, 603, 605, 608, 613, 614, 634, 636, 641, 642, 646, 647, 655, 656, 658, 660, 663, 664, 665, 666], "isiter": 13, "obj": [13, 105, 198, 221, 244, 287, 304, 309, 320, 321, 322, 324, 333, 338, 342, 346, 372, 382, 424, 554, 557, 565], "bool": [13, 42, 43, 44, 141, 148, 149, 150, 153, 156, 162, 168, 170, 171, 185, 197, 203, 229, 230, 245, 247, 258, 262, 288, 290, 300, 303, 308, 312, 318, 341, 359, 365, 371, 387, 388, 396, 401, 439, 443, 449, 461, 502, 516, 522, 523, 536, 538, 539, 546, 549, 560, 564, 565, 595, 596, 612, 644, 654, 663], "check": [13, 44, 67, 68, 105, 148, 149, 170, 171, 221, 236, 247, 290, 306, 342, 478, 479, 502, 509, 522, 564, 565, 574, 598, 601, 609, 617, 619, 621, 628, 631, 632, 636, 639, 642, 643, 659], "whether": [13, 43, 44, 105, 116, 148, 149, 150, 153, 156, 162, 170, 171, 203, 229, 230, 243, 245, 258, 262, 286, 288, 300, 303, 312, 314, 318, 341, 365, 367, 371, 387, 388, 390, 401, 502, 509, 516, 520, 522, 523, 536, 538, 539, 557, 560, 564, 565, 575, 596, 612, 655, 658, 661, 663], "object": [13, 42, 43, 44, 45, 74, 86, 105, 116, 132, 148, 149, 153, 155, 157, 160, 162, 168, 170, 177, 186, 196, 198, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 226, 227, 229, 230, 233, 234, 235, 245, 246, 247, 262, 263, 265, 276, 277, 278, 288, 289, 290, 303, 304, 309, 314, 322, 324, 327, 328, 330, 331, 332, 333, 338, 341, 342, 343, 344, 345, 346, 350, 363, 367, 371, 372, 380, 381, 418, 423, 424, 428, 442, 485, 497, 502, 504, 507, 509, 516, 517, 521, 526, 538, 553, 554, 557, 564, 565, 571, 572, 576, 582, 592, 594, 595, 596, 604, 612, 613, 615, 651, 652, 654, 655, 663, 664, 665, 667], "i": [13, 43, 44, 45, 48, 49, 51, 54, 55, 60, 64, 70, 82, 85, 105, 132, 143, 148, 149, 150, 153, 156, 157, 160, 162, 164, 168, 170, 171, 176, 177, 179, 181, 186, 189, 190, 196, 197, 201, 202, 208, 213, 214, 215, 216, 217, 218, 220, 221, 229, 230, 233, 234, 235, 243, 244, 245, 246, 247, 248, 249, 252, 254, 258, 262, 263, 265, 269, 271, 272, 276, 277, 278, 286, 287, 288, 289, 290, 291, 292, 295, 297, 300, 303, 311, 314, 316, 318, 320, 325, 333, 338, 342, 343, 347, 354, 364, 367, 369, 371, 372, 382, 391, 394, 401, 407, 408, 412, 424, 429, 434, 442, 443, 465, 466, 471, 475, 481, 493, 496, 502, 504, 509, 516, 517, 521, 522, 523, 526, 536, 538, 539, 554, 560, 564, 565, 569, 570, 571, 572, 575, 576, 577, 578, 580, 584, 587, 590, 592, 593, 594, 595, 596, 598, 599, 600, 601, 603, 604, 605, 608, 609, 610, 612, 613, 614, 615, 616, 617, 618, 619, 621, 622, 624, 626, 627, 628, 630, 631, 633, 634, 635, 636, 638, 639, 640, 641, 642, 643, 644, 646, 648, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667], "iter": [13, 15, 105, 140, 148, 149, 153, 170, 171, 177, 202, 208, 215, 219, 229, 230, 233, 234, 238, 243, 247, 248, 265, 276, 277, 281, 286, 290, 291, 343, 345, 372, 384, 424, 446, 460, 463, 502, 504, 521, 522, 526, 538, 554, 557, 571, 572, 575, 592, 595, 596, 613, 652, 654, 655, 661, 662, 664, 666], "return": [13, 16, 44, 45, 54, 67, 68, 70, 74, 105, 116, 148, 149, 153, 155, 156, 157, 162, 168, 170, 171, 172, 177, 187, 189, 193, 194, 197, 198, 201, 203, 204, 208, 211, 217, 218, 219, 221, 224, 227, 233, 234, 247, 254, 258, 262, 263, 264, 269, 276, 277, 290, 297, 300, 303, 308, 311, 312, 314, 315, 316, 318, 324, 325, 332, 336, 341, 342, 343, 345, 350, 356, 360, 362, 364, 365, 367, 368, 369, 371, 372, 376, 380, 382, 387, 388, 390, 391, 396, 401, 418, 423, 424, 428, 436, 440, 442, 443, 460, 461, 463, 465, 478, 479, 481, 485, 502, 507, 509, 516, 520, 521, 522, 523, 526, 536, 538, 546, 549, 553, 554, 557, 562, 564, 565, 571, 572, 576, 577, 595, 596, 601, 612, 615, 646, 647, 648, 650, 652, 655, 658, 661, 662, 664], "true": [13, 43, 44, 85, 113, 146, 148, 149, 150, 156, 162, 171, 177, 193, 197, 229, 230, 243, 245, 247, 248, 261, 262, 263, 286, 288, 290, 291, 302, 303, 308, 312, 318, 336, 359, 365, 371, 382, 387, 388, 390, 396, 424, 439, 443, 461, 496, 502, 504, 516, 520, 522, 523, 536, 537, 538, 539, 546, 549, 557, 560, 564, 565, 576, 595, 596, 598, 601, 605, 612, 613, 616, 619, 620, 635, 636, 637, 638, 644, 646, 654, 655, 656, 658, 661, 662, 663, 664, 666], "els": [13, 148, 153, 171, 230, 243, 286, 382, 502, 538, 562, 621, 658, 662], "fals": [13, 14, 15, 41, 42, 43, 44, 47, 48, 49, 71, 72, 89, 92, 99, 102, 103, 105, 113, 131, 136, 143, 146, 147, 148, 149, 150, 153, 154, 156, 161, 162, 168, 170, 171, 177, 187, 190, 223, 229, 230, 235, 237, 242, 244, 245, 247, 258, 262, 263, 264, 265, 271, 278, 280, 285, 287, 288, 290, 300, 303, 314, 318, 367, 371, 382, 388, 396, 401, 424, 443, 461, 482, 483, 502, 504, 516, 522, 523, 536, 538, 546, 557, 560, 564, 565, 575, 576, 595, 596, 605, 612, 613, 626, 630, 636, 644, 647, 648, 654, 655, 658, 661, 662, 663, 664, 666], "boolean": [13, 149], "ensure_list": 13, "x": [13, 55, 74, 149, 156, 202, 229, 230, 244, 262, 287, 303, 350, 428, 443, 466, 485, 523, 593, 594, 598, 601, 614, 615, 641, 642, 646, 647, 649, 655, 656, 661, 662, 663, 665], "ensur": [13, 262, 303, 350, 428, 601, 655, 663], "list": [13, 42, 43, 44, 54, 105, 140, 148, 149, 153, 155, 156, 157, 166, 170, 177, 178, 179, 181, 194, 201, 202, 207, 212, 217, 221, 224, 229, 230, 233, 234, 238, 245, 258, 262, 263, 276, 277, 281, 288, 300, 303, 307, 308, 311, 312, 314, 315, 316, 318, 325, 333, 338, 341, 344, 359, 364, 365, 367, 368, 369, 371, 372, 380, 384, 385, 387, 388, 390, 391, 394, 396, 401, 407, 408, 412, 424, 439, 443, 446, 461, 465, 502, 507, 521, 523, 538, 545, 546, 554, 555, 565, 571, 574, 575, 596, 603, 605, 609, 611, 613, 616, 621, 623, 626, 627, 630, 638, 641, 643, 644, 650, 652, 654, 655, 657, 661, 662, 664], "input": [13, 15, 42, 43, 44, 45, 54, 60, 64, 67, 68, 70, 71, 72, 74, 82, 83, 85, 86, 105, 109, 110, 116, 122, 141, 148, 149, 150, 153, 155, 165, 167, 168, 169, 170, 171, 175, 201, 202, 221, 229, 230, 233, 234, 245, 246, 247, 249, 258, 261, 262, 267, 276, 277, 288, 289, 290, 292, 300, 302, 303, 306, 307, 308, 371, 372, 376, 380, 385, 391, 394, 424, 449, 465, 471, 475, 478, 479, 481, 482, 483, 485, 493, 494, 496, 497, 499, 502, 504, 507, 521, 535, 536, 537, 538, 539, 553, 554, 560, 562, 564, 565, 572, 575, 576, 592, 593, 595, 596, 598, 599, 600, 601, 603, 605, 607, 612, 613, 614, 615, 616, 621, 652, 654, 655, 658, 661, 662, 663, 666], "check_mx_vers": 13, "version": [13, 54, 104, 149, 153, 165, 170, 201, 230, 307, 308, 363, 465, 535, 569, 571, 575, 594, 605, 609, 610, 613, 626, 628, 630, 631, 653, 661, 664, 665], "str": [13, 42, 43, 44, 140, 149, 150, 155, 157, 162, 163, 166, 167, 168, 170, 171, 172, 178, 181, 185, 187, 189, 198, 201, 224, 229, 230, 245, 246, 247, 254, 258, 262, 264, 268, 269, 288, 289, 290, 297, 300, 303, 307, 308, 311, 312, 314, 316, 318, 325, 336, 359, 362, 364, 365, 367, 369, 371, 384, 385, 387, 388, 390, 391, 393, 394, 396, 401, 409, 417, 419, 422, 423, 439, 442, 443, 446, 461, 463, 509, 516, 518, 521, 524, 536, 538, 539, 544, 546, 553, 557, 560, 562, 565, 566, 594, 595, 596, 612, 644, 654, 662, 663], "mx": 13, "__version__": [13, 160, 517, 594], "combine_cap": 13, "current": [13, 70, 104, 167, 171, 196, 198, 201, 204, 208, 211, 229, 230, 320, 327, 328, 330, 331, 332, 341, 343, 350, 354, 428, 434, 481, 538, 565, 571, 572, 575, 577, 593, 594, 601, 605, 613, 616, 620, 633, 641, 650, 652, 655, 658, 661, 664], "new": [13, 16, 44, 148, 149, 167, 177, 181, 235, 247, 262, 263, 278, 290, 303, 342, 382, 391, 502, 504, 524, 538, 539, 570, 574, 576, 601, 613, 614, 627, 633, 634, 635, 636, 642, 643, 646, 647, 652, 653, 655, 658, 659, 660, 663, 665, 666], "combin": [13, 170, 179, 229, 230, 233, 234, 258, 272, 276, 277, 300, 372, 424, 509, 521, 554, 565, 571, 575, 608, 613, 651, 653, 655, 657, 658, 663, 664], "capabl": [13, 47, 360, 440, 576, 577, 592, 605, 613, 614, 624, 635, 640, 652, 654, 655, 664, 666], "contain": [13, 67, 68, 70, 74, 139, 148, 149, 157, 162, 170, 171, 177, 186, 198, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 219, 221, 229, 230, 233, 234, 245, 246, 247, 276, 277, 288, 289, 290, 304, 308, 309, 314, 315, 316, 320, 333, 336, 338, 341, 342, 343, 344, 345, 346, 367, 368, 369, 372, 424, 478, 479, 481, 485, 501, 502, 516, 522, 554, 557, 564, 593, 596, 599, 608, 612, 634, 641, 646, 647, 648, 652, 658, 662, 664, 665], "make_nc_model": 13, "target": [13, 42, 43, 102, 149, 150, 153, 156, 170, 201, 219, 221, 230, 342, 345, 350, 428, 523, 560, 596, 601, 613, 652, 662, 663, 664, 666], "sym_model": 13, "ctx": 13, "input_desc": 13, "convert": [13, 43, 48, 49, 50, 53, 54, 55, 56, 57, 66, 74, 86, 99, 100, 102, 103, 104, 105, 131, 136, 140, 142, 150, 155, 170, 201, 229, 230, 245, 258, 261, 262, 288, 300, 302, 303, 307, 314, 320, 342, 360, 367, 440, 443, 446, 451, 464, 465, 466, 467, 468, 477, 485, 497, 571, 576, 613, 614, 618, 655, 657, 658, 661, 663, 664], "symbol": [13, 43, 155, 168, 170, 311, 364, 372, 424, 571, 615], "model": [13, 15, 16, 29, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 116, 118, 140, 141, 142, 148, 149, 150, 153, 154, 155, 156, 157, 161, 162, 163, 164, 166, 167, 168, 169, 170, 171, 175, 177, 179, 186, 193, 198, 199, 201, 208, 209, 210, 213, 215, 216, 217, 219, 221, 223, 229, 230, 233, 234, 241, 244, 245, 247, 262, 263, 266, 267, 276, 277, 284, 287, 288, 290, 303, 304, 306, 307, 308, 309, 310, 318, 319, 320, 321, 324, 327, 328, 330, 331, 332, 333, 338, 342, 343, 344, 345, 346, 347, 350, 351, 353, 354, 355, 356, 363, 371, 372, 382, 384, 385, 387, 388, 390, 391, 393, 394, 400, 401, 417, 422, 423, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 442, 443, 446, 449, 460, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 480, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 502, 507, 509, 516, 518, 520, 521, 522, 523, 536, 537, 538, 539, 544, 545, 549, 553, 554, 560, 562, 564, 565, 567, 570, 571, 572, 574, 575, 577, 582, 592, 593, 594, 595, 596, 598, 599, 600, 601, 602, 607, 608, 610, 612, 614, 616, 621, 623, 624, 627, 633, 635, 640, 642, 643, 644, 645, 650, 651, 653, 655, 659, 660, 662, 663, 664, 665, 666], "an": [13, 67, 68, 70, 105, 141, 143, 148, 149, 153, 157, 160, 162, 170, 171, 176, 190, 208, 229, 230, 238, 243, 247, 262, 266, 271, 281, 286, 290, 303, 310, 311, 315, 316, 324, 325, 347, 363, 364, 368, 369, 372, 418, 423, 424, 443, 449, 478, 479, 481, 502, 516, 517, 524, 526, 538, 539, 554, 565, 567, 569, 571, 572, 574, 575, 577, 593, 595, 596, 597, 598, 603, 611, 612, 613, 614, 616, 620, 621, 624, 633, 636, 637, 638, 641, 644, 650, 652, 653, 655, 658, 660, 661, 662, 663, 664], "neural": [13, 157, 177, 186, 189, 203, 204, 205, 206, 217, 229, 230, 257, 258, 259, 262, 263, 266, 269, 272, 300, 301, 303, 305, 310, 317, 318, 320, 333, 338, 341, 344, 346, 347, 352, 358, 363, 370, 371, 372, 376, 402, 424, 431, 432, 438, 506, 562, 567, 570, 575, 576, 577, 592, 593, 594, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 610, 611, 614, 615, 617, 618, 621, 623, 624, 626, 628, 630, 631, 632, 644, 650, 651, 653, 655, 658, 659, 661, 662, 663, 664, 666, 667], "compressor": [13, 177, 186, 189, 205, 206, 217, 229, 230, 257, 258, 259, 262, 263, 266, 269, 272, 300, 301, 303, 305, 310, 317, 318, 320, 341, 344, 346, 347, 352, 358, 363, 370, 371, 372, 376, 402, 424, 432, 438, 506, 562, 567, 570, 572, 575, 576, 577, 592, 593, 594, 596, 597, 599, 600, 601, 602, 603, 604, 605, 606, 607, 610, 611, 614, 615, 616, 617, 621, 623, 624, 626, 628, 630, 631, 632, 635, 636, 637, 638, 640, 641, 648, 650, 651, 652, 653, 655, 658, 659, 661, 662, 663, 664, 665, 666, 667], "tupl": [13, 105, 148, 170, 194, 230, 233, 234, 258, 262, 276, 277, 300, 303, 308, 359, 372, 391, 424, 439, 502, 521, 526, 544, 554, 564, 576, 594, 596, 612, 613, 655, 663], "symnet": 13, "arg": [13, 54, 105, 149, 170, 245, 246, 247, 288, 289, 290, 341, 350, 393, 428, 443, 465, 523, 538, 544, 560, 561, 596, 601, 613, 622, 652, 655, 658, 661, 662, 663], "aux": 13, "data": [13, 42, 43, 44, 56, 105, 140, 148, 149, 157, 162, 167, 170, 171, 175, 201, 229, 230, 233, 234, 263, 265, 276, 277, 308, 310, 350, 360, 362, 363, 372, 385, 391, 395, 401, 417, 422, 424, 428, 440, 442, 446, 460, 463, 467, 502, 505, 509, 516, 521, 538, 554, 557, 562, 565, 574, 575, 593, 595, 596, 601, 605, 606, 609, 612, 613, 614, 635, 636, 638, 641, 646, 647, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665], "descript": [13, 132, 197, 443, 571, 576, 577, 595, 641, 645, 661], "ncmodel": 13, "fuse": [13, 58, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 91, 92, 93, 94, 96, 131, 136, 168, 170, 175, 469, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 521, 571, 661, 662], "suppli": 13, "get_framework_nam": 13, "get": [13, 42, 43, 44, 45, 67, 68, 70, 104, 105, 148, 149, 156, 163, 167, 170, 177, 185, 189, 190, 194, 196, 198, 199, 201, 204, 211, 218, 219, 220, 221, 227, 230, 238, 262, 263, 269, 271, 281, 303, 308, 341, 343, 345, 353, 360, 362, 371, 380, 388, 395, 401, 424, 433, 440, 442, 461, 478, 479, 481, 502, 507, 509, 518, 521, 523, 533, 538, 553, 557, 560, 562, 565, 576, 593, 604, 608, 609, 611, 613, 619, 636, 638, 646, 647, 653, 658, 661, 664, 665, 668], "name": [13, 43, 45, 54, 67, 68, 70, 104, 105, 110, 116, 140, 148, 149, 150, 155, 156, 157, 162, 163, 167, 168, 170, 172, 177, 178, 179, 181, 190, 193, 194, 196, 201, 203, 208, 211, 212, 217, 218, 219, 220, 221, 224, 227, 229, 230, 245, 246, 247, 250, 254, 260, 262, 263, 267, 270, 271, 288, 289, 290, 293, 297, 303, 306, 307, 308, 313, 318, 336, 341, 343, 345, 360, 362, 366, 371, 376, 380, 382, 394, 401, 424, 440, 442, 446, 465, 478, 479, 481, 499, 502, 507, 509, 516, 518, 521, 523, 524, 538, 553, 555, 557, 562, 565, 570, 571, 577, 594, 596, 598, 601, 603, 605, 610, 612, 613, 615, 619, 626, 630, 634, 635, 641, 652, 655, 659, 660, 662, 664, 666, 667], "context": [13, 539, 565, 654, 658], "prepare_model_data": 13, "nc_model": [13, 333, 338], "data_x": 13, "prepar": [13, 44, 170, 391, 571, 574, 596, 601, 606, 635, 646, 647, 648, 652, 655], "dataload": [13, 15, 42, 44, 140, 141, 149, 154, 156, 157, 167, 170, 171, 177, 198, 199, 201, 217, 221, 223, 233, 234, 245, 256, 266, 276, 277, 288, 299, 304, 310, 333, 338, 347, 363, 384, 385, 387, 388, 394, 417, 422, 424, 446, 449, 504, 522, 523, 537, 538, 554, 557, 571, 574, 575, 576, 598, 599, 600, 601, 606, 607, 613, 614, 635, 636, 651, 652, 655, 656, 657, 658, 661, 662, 663, 665, 666], "need": [13, 42, 105, 109, 150, 167, 171, 177, 181, 201, 217, 230, 233, 234, 235, 243, 244, 247, 254, 262, 265, 267, 268, 276, 277, 278, 286, 287, 290, 297, 303, 308, 347, 353, 371, 372, 382, 385, 424, 433, 504, 522, 554, 564, 565, 571, 575, 594, 595, 596, 598, 599, 601, 608, 613, 616, 618, 619, 622, 626, 627, 628, 630, 631, 633, 634, 635, 636, 637, 638, 640, 644, 646, 652, 654, 655, 656, 657, 658, 659, 661, 663, 664, 666], "run": [13, 140, 148, 162, 171, 177, 208, 221, 229, 230, 233, 234, 244, 261, 263, 276, 277, 287, 302, 342, 343, 350, 372, 424, 428, 446, 502, 516, 523, 537, 539, 554, 575, 592, 601, 604, 605, 613, 616, 618, 620, 621, 622, 624, 626, 627, 628, 630, 631, 633, 641, 642, 643, 644, 646, 647, 648, 653, 655, 658, 659, 660, 662, 664, 666], "loader": [13, 140, 233, 234, 276, 277, 372, 424, 446, 460, 463, 554, 560, 595, 655], "dataloaderwrap": 13, "prepare_model": 13, "create_data_exampl": 13, "creat": [13, 16, 105, 160, 181, 229, 230, 235, 245, 247, 265, 278, 288, 290, 314, 324, 325, 360, 367, 394, 418, 423, 440, 442, 443, 504, 517, 524, 557, 569, 572, 575, 596, 615, 626, 628, 630, 631, 634, 646, 647, 648, 652, 655, 660, 662, 664, 665], "exampl": [13, 44, 149, 153, 157, 162, 170, 171, 177, 178, 179, 181, 194, 201, 202, 217, 229, 230, 245, 246, 247, 258, 262, 288, 289, 290, 300, 303, 314, 315, 316, 318, 344, 367, 368, 369, 371, 372, 382, 387, 388, 390, 401, 424, 442, 443, 509, 516, 522, 524, 536, 538, 553, 554, 564, 565, 569, 574, 576, 577, 582, 607, 608, 616, 619, 620, 621, 624, 641, 644, 657, 659, 663, 664, 665, 668], "prepare_dataload": 13, "io": [13, 162, 516, 639], "ndarray_to_devic": 13, "ndarrai": [13, 42, 43, 67, 68, 70, 262, 303, 478, 479, 481, 555, 604, 663], "devic": [13, 79, 89, 90, 91, 92, 93, 94, 97, 107, 131, 136, 147, 149, 150, 156, 161, 162, 164, 170, 171, 198, 201, 202, 217, 221, 223, 229, 230, 490, 516, 523, 539, 560, 576, 595, 599, 613, 614, 616, 619, 624, 633, 652, 654, 656, 658], "is_model_quant": 13, "query_quantizable_nod": 13, "node": [13, 42, 43, 44, 50, 54, 55, 56, 57, 60, 62, 64, 67, 68, 70, 74, 77, 80, 82, 83, 84, 98, 102, 103, 105, 110, 132, 140, 148, 201, 306, 308, 380, 391, 401, 423, 446, 465, 466, 467, 468, 471, 473, 475, 478, 479, 481, 485, 488, 491, 493, 494, 495, 499, 502, 507, 575, 598, 601, 636, 640, 643, 646, 647, 648, 656, 662, 664, 667], "given": [13, 16, 43, 67, 68, 70, 104, 105, 116, 148, 149, 163, 170, 224, 262, 303, 314, 367, 424, 478, 479, 481, 502, 518, 526, 538, 553, 572, 577, 652, 661, 663], "map": [13, 43, 105, 148, 162, 170, 230, 262, 303, 306, 308, 309, 313, 315, 316, 318, 333, 338, 343, 346, 366, 368, 369, 371, 502, 516, 594, 596, 601, 612, 613, 626, 630, 638, 652, 655, 658], "quantize_sym_model": 13, "qconfig": [13, 150, 170, 564, 658, 662], "accord": [13, 122, 170, 177, 229, 230, 245, 246, 247, 262, 288, 289, 290, 303, 353, 431, 433, 557, 572, 575, 596, 601, 636, 641, 646, 647, 648, 652, 657, 661, 663, 664], "run_forward": 13, "b_filter": 13, "collector": [13, 157, 555], "none": [13, 14, 41, 43, 44, 45, 47, 48, 49, 63, 89, 102, 104, 105, 110, 116, 142, 148, 149, 153, 154, 156, 157, 161, 162, 163, 164, 165, 167, 169, 170, 171, 177, 178, 179, 181, 185, 186, 187, 194, 196, 198, 199, 201, 205, 217, 221, 223, 225, 226, 227, 229, 230, 233, 234, 235, 237, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 258, 262, 263, 264, 265, 272, 276, 277, 278, 280, 285, 286, 287, 288, 289, 290, 291, 292, 293, 295, 300, 303, 304, 307, 308, 309, 314, 318, 319, 320, 321, 324, 333, 338, 342, 346, 350, 351, 353, 354, 355, 356, 360, 367, 371, 372, 382, 394, 417, 422, 423, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 440, 443, 451, 460, 461, 463, 474, 499, 502, 504, 509, 516, 518, 521, 522, 523, 533, 535, 537, 538, 539, 545, 546, 549, 554, 555, 557, 560, 562, 564, 565, 575, 576, 595, 596, 612, 636, 655, 658, 662, 663, 664], "pre_batch": 13, "post_batch": 13, "forward": [13, 149, 170, 221, 539, 576, 613, 635, 652, 654, 655, 658, 661, 662], "propag": [13, 100], "filter": [13, 245, 246, 247, 248, 249, 250, 252, 256, 288, 289, 290, 291, 292, 293, 295, 299, 310, 363, 504, 509, 565, 577, 596, 608, 652, 662], "which": [13, 42, 56, 83, 110, 149, 153, 156, 157, 162, 167, 171, 178, 196, 201, 202, 204, 208, 209, 210, 212, 215, 216, 217, 219, 221, 229, 230, 245, 246, 247, 258, 263, 288, 289, 290, 300, 311, 316, 325, 327, 328, 330, 331, 332, 336, 341, 342, 343, 345, 350, 364, 369, 371, 376, 382, 385, 388, 401, 424, 428, 467, 494, 499, 509, 516, 522, 523, 553, 565, 569, 571, 572, 575, 576, 577, 593, 595, 596, 598, 599, 601, 604, 605, 608, 612, 613, 614, 615, 617, 621, 624, 627, 633, 634, 635, 638, 641, 646, 647, 648, 651, 652, 654, 655, 656, 657, 658, 659, 661, 662, 663, 664, 665, 666], "batch": [13, 149, 170, 235, 237, 238, 243, 244, 265, 278, 280, 281, 286, 287, 504, 538, 554, 595, 599, 600, 613, 651, 652, 655, 661, 663, 664, 667], "infer": [13, 43, 105, 140, 150, 170, 171, 201, 309, 346, 380, 382, 424, 446, 507, 521, 522, 538, 539, 554, 575, 576, 593, 599, 600, 613, 614, 633, 650, 652, 653, 655, 658, 661, 662, 664], "collect": [13, 16, 43, 149, 170, 179, 260, 262, 265, 267, 268, 270, 303, 316, 318, 369, 371, 509, 555, 565, 576, 655, 662, 664], "inform": [13, 149, 157, 196, 198, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 230, 233, 234, 265, 267, 268, 276, 277, 341, 343, 344, 345, 347, 371, 384, 565, 569, 570, 573, 574, 575, 576, 577, 578, 580, 584, 587, 590, 593, 594, 599, 605, 613, 615, 628, 631, 634, 635, 638, 639, 641, 642, 646, 647, 652, 657, 658, 659, 661, 662, 666, 667, 668], "dure": [13, 160, 162, 203, 207, 219, 229, 230, 341, 345, 382, 394, 516, 517, 565, 576, 598, 613, 615, 640, 650, 651, 652, 655, 661, 662, 666], "call": [13, 42, 162, 167, 172, 201, 209, 210, 215, 314, 343, 367, 385, 516, 539, 571, 572, 575, 595, 607, 622, 624, 634, 652, 655, 661, 662, 663], "prior": [13, 88, 664], "after": [13, 78, 148, 150, 170, 199, 203, 208, 210, 215, 229, 230, 245, 258, 262, 265, 288, 300, 303, 343, 429, 443, 489, 502, 560, 565, 572, 576, 596, 598, 599, 600, 603, 608, 612, 613, 626, 627, 630, 634, 638, 650, 651, 652, 655, 657, 658, 660, 661, 662, 663, 664], "count": [13, 572, 596, 658], "int": [13, 16, 42, 43, 44, 105, 140, 148, 149, 150, 154, 166, 170, 171, 181, 185, 199, 229, 230, 244, 245, 246, 258, 262, 287, 288, 289, 300, 303, 307, 308, 312, 314, 318, 325, 365, 367, 371, 384, 387, 388, 390, 391, 396, 401, 409, 418, 423, 442, 443, 446, 447, 451, 460, 463, 502, 521, 522, 536, 538, 546, 560, 565, 594, 595, 596, 612, 613, 644, 654, 658, 663], "make_symbol_block": 13, "gluon": [13, 372, 424, 615], "symbolblock": 13, "make_modul": 13, "parse_tune_config": 13, "tune_cfg": [13, 148, 155, 170, 502, 520, 521, 575, 577, 664], "quantizable_nod": 13, "strategi": [13, 170, 215, 229, 230, 231, 247, 274, 290, 310, 363, 574, 575, 576, 577, 582, 593, 594, 595, 601, 608, 613, 621, 633, 638, 653, 654, 655, 657, 658, 659, 665, 666], "config": [13, 44, 115, 116, 118, 122, 170, 177, 178, 179, 181, 185, 196, 198, 199, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 229, 233, 234, 245, 276, 277, 288, 327, 328, 330, 331, 332, 333, 338, 341, 342, 343, 344, 345, 360, 361, 363, 372, 387, 388, 390, 393, 394, 418, 423, 440, 441, 442, 443, 447, 451, 460, 520, 521, 554, 557, 564, 565, 572, 574, 576, 577, 582, 592, 594, 595, 598, 599, 600, 601, 603, 606, 608, 612, 613, 614, 615, 635, 636, 651, 652, 654, 655, 657, 658, 660, 662, 664], "tune": [13, 45, 149, 177, 178, 179, 184, 229, 230, 233, 234, 245, 247, 276, 277, 288, 290, 309, 346, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 362, 372, 382, 394, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 439, 440, 441, 442, 545, 554, 565, 575, 576, 593, 594, 595, 596, 598, 601, 608, 610, 613, 614, 633, 637, 640, 642, 643, 650, 652, 653, 657, 659, 660, 662, 666], "from": [13, 43, 45, 61, 67, 68, 70, 105, 148, 149, 150, 153, 162, 163, 167, 170, 171, 177, 179, 181, 186, 187, 194, 196, 198, 204, 205, 206, 207, 211, 213, 214, 215, 216, 217, 218, 219, 220, 221, 229, 230, 233, 234, 235, 238, 242, 245, 246, 247, 248, 249, 250, 252, 257, 258, 264, 265, 268, 276, 277, 278, 281, 285, 288, 289, 290, 291, 292, 293, 295, 300, 304, 306, 307, 308, 311, 314, 315, 316, 320, 325, 341, 342, 343, 345, 360, 362, 364, 367, 368, 369, 372, 380, 382, 387, 401, 424, 440, 442, 443, 451, 472, 478, 479, 481, 502, 504, 507, 509, 516, 518, 521, 526, 536, 538, 554, 557, 560, 564, 565, 569, 570, 571, 572, 575, 577, 592, 594, 595, 596, 598, 599, 600, 601, 602, 603, 604, 606, 608, 611, 612, 614, 615, 616, 620, 621, 622, 624, 634, 636, 638, 639, 643, 646, 647, 648, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665], "distribute_calib_tensor": 13, "calib_tensor": 13, "calib_cfg": 13, "tensor_to_nod": 13, "distribut": [13, 16, 143, 176, 229, 230, 235, 237, 238, 242, 243, 244, 265, 278, 280, 281, 285, 286, 287, 387, 504, 559, 574, 576, 595, 599, 609, 628, 631, 635, 638, 646, 653, 655, 658, 659, 661, 665, 667], "depend": [13, 233, 234, 263, 276, 277, 372, 424, 554, 570, 604, 605, 639, 654, 655, 664], "algorithm": [13, 44, 153, 156, 170, 178, 181, 193, 226, 230, 311, 318, 326, 363, 364, 371, 394, 401, 509, 553, 557, 559, 572, 575, 576, 577, 594, 599, 600, 605, 608, 611, 622, 627, 652, 655, 662, 666], "set": [13, 43, 51, 96, 105, 115, 148, 149, 162, 167, 170, 177, 179, 185, 189, 221, 227, 229, 230, 233, 234, 235, 245, 247, 250, 262, 263, 268, 269, 276, 277, 278, 288, 290, 293, 303, 314, 320, 333, 338, 342, 347, 367, 371, 372, 380, 423, 424, 443, 451, 502, 504, 507, 516, 538, 553, 554, 562, 565, 569, 572, 576, 592, 595, 596, 599, 601, 603, 605, 607, 608, 609, 612, 613, 614, 616, 618, 620, 634, 635, 636, 637, 638, 639, 643, 646, 652, 654, 655, 658, 660, 661, 664, 666], "kl": [13, 16, 229, 230, 555, 559, 576, 577, 593, 605, 613, 664, 666], "minmax": [13, 16, 576, 577, 593, 605, 655, 666], "calib_model": 13, "qsym_model": 13, "calib_data": [13, 161], "calibdata": 13, "threshold": [13, 173, 197, 555, 559, 612], "amp_convert": 13, "amp_cfg": 13, "support": [13, 42, 43, 44, 97, 104, 149, 167, 175, 178, 187, 189, 198, 204, 211, 215, 216, 229, 230, 233, 234, 244, 245, 247, 254, 258, 262, 264, 265, 266, 269, 276, 277, 287, 288, 290, 297, 300, 303, 310, 318, 320, 325, 341, 343, 347, 354, 360, 363, 371, 372, 376, 382, 385, 387, 388, 390, 391, 394, 401, 424, 434, 440, 443, 554, 557, 559, 560, 565, 567, 574, 576, 594, 611, 613, 616, 621, 624, 627, 633, 640, 641, 644, 653, 657, 660, 664, 665], "amp": [13, 149, 616, 623, 642, 658], "wrap": [13, 105, 116, 149, 187, 225, 264, 314, 367, 539, 571, 601, 628, 631], "dataiterload": 13, "data_it": [13, 201], "collectorbas": 13, "calibcollector": 13, "include_tensors_kl": 13, "include_tensors_minmax": 13, "num_bin": [13, 16, 555], "8001": [13, 555, 641, 646, 647, 648], "tensorcollector": 13, "include_nod": 13, "qtensor_to_tensor": 13, "build": [13, 42, 44, 115, 172, 173, 175, 176, 321, 324, 375, 377, 379, 380, 381, 391, 400, 507, 575, 576, 577, 609, 615, 626, 628, 630, 631, 634, 653, 664], "up": [13, 100, 212, 262, 303, 342, 521, 601, 602, 605, 608, 624, 628, 631, 633, 652, 653, 654, 655, 660, 663, 664, 666], "namecollector": 13, "cache_kl": 13, "cache_minmax": 13, "tensors_kl": 13, "tensors_minmax": 13, "onnxruntimeadaptor": 14, "rt": 14, "onnxrt_weightonlyadaptor": 14, "onnxrt_qlinearopsadaptor": [14, 575], "onnxrt_integeropsadaptor": 14, "onnxrt_qdqadaptor": 14, "onnxrtqueri": 14, "dynam": [14, 149, 162, 230, 235, 278, 308, 360, 440, 504, 516, 575, 595, 599, 603, 608, 613, 616, 621, 622, 623, 624, 627, 633, 653, 664, 667], "static": [14, 41, 42, 47, 167, 175, 201, 230, 308, 360, 385, 424, 440, 451, 460, 461, 549, 575, 576, 577, 598, 603, 608, 613, 616, 621, 622, 623, 624, 627, 633, 636, 644, 646, 647, 648, 656, 661, 664, 667], "format": [14, 18, 43, 54, 148, 150, 170, 229, 230, 245, 246, 247, 288, 289, 290, 308, 314, 320, 360, 367, 440, 443, 451, 465, 502, 560, 574, 576, 577, 594, 596, 601, 603, 612, 613, 614, 615, 616, 638, 641, 653, 655, 658, 659], "onnxrtaug": 15, "dump_op_typ": 15, "black_nod": 15, "white_nod": 15, "cpuexecutionprovid": [15, 41, 42, 44, 384, 385, 387, 388, 390, 396, 614, 655], "reduce_rang": [15, 41, 42, 229, 230, 401, 577, 654], "kwarg": [15, 43, 105, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 135, 137, 138, 149, 163, 170, 171, 199, 229, 230, 247, 260, 262, 267, 270, 290, 303, 359, 361, 371, 372, 373, 375, 377, 379, 380, 381, 384, 393, 396, 400, 424, 439, 441, 443, 507, 518, 523, 536, 538, 544, 554, 560, 561, 564, 565, 595], "augment": 15, "dump": [15, 160, 170, 177, 308, 384, 509, 517, 521, 565, 570, 638, 655, 659, 662], "calib_registri": 16, "calib_method": 16, "calibratorbas": 16, "minmaxcalibr": 16, "percentilecalibr": 16, "2048": [16, 149, 156, 171, 509, 523, 546, 565, 658], "percentil": [16, 44, 140, 171, 390, 391, 446, 461, 536, 538, 593], "99": [16, 179, 461, 667], "999": [16, 461, 666], "option": [16, 44, 105, 149, 150, 153, 162, 170, 171, 181, 185, 203, 229, 230, 233, 234, 245, 262, 276, 277, 288, 303, 307, 308, 314, 320, 341, 347, 360, 363, 367, 371, 372, 387, 388, 390, 391, 401, 424, 440, 442, 443, 509, 516, 522, 533, 536, 538, 539, 554, 558, 560, 565, 576, 577, 594, 595, 596, 605, 609, 613, 627, 641, 644, 646, 647, 648, 652, 655, 658, 660, 661, 663, 664, 666], "number": [16, 44, 67, 68, 105, 140, 149, 150, 170, 171, 178, 194, 197, 199, 205, 206, 229, 230, 243, 246, 258, 262, 286, 289, 300, 303, 315, 316, 318, 341, 350, 368, 369, 371, 387, 388, 390, 391, 418, 423, 428, 443, 446, 478, 479, 522, 524, 538, 557, 565, 592, 595, 596, 601, 612, 641, 643, 652, 655, 658, 660, 661, 663, 664], "bin": [16, 162, 163, 509, 516, 518, 565, 604], "histogram": [16, 509, 555, 565, 635, 662], "valu": [16, 43, 44, 56, 67, 68, 70, 89, 90, 105, 143, 148, 149, 162, 170, 176, 177, 179, 194, 196, 201, 202, 212, 220, 221, 227, 229, 230, 233, 234, 245, 248, 249, 258, 262, 263, 276, 277, 288, 291, 292, 300, 303, 314, 318, 342, 350, 353, 360, 367, 371, 372, 388, 401, 424, 428, 433, 440, 442, 443, 467, 478, 479, 481, 502, 504, 516, 521, 526, 539, 554, 555, 557, 565, 571, 576, 577, 593, 596, 598, 605, 612, 613, 614, 619, 636, 638, 644, 650, 652, 654, 655, 658, 659, 661, 663, 664, 666], "default": [16, 44, 97, 148, 149, 150, 153, 162, 170, 171, 178, 179, 181, 185, 197, 221, 227, 229, 230, 233, 234, 237, 245, 246, 247, 258, 262, 276, 277, 280, 288, 289, 290, 300, 303, 307, 308, 311, 320, 342, 362, 364, 371, 380, 387, 388, 390, 391, 396, 401, 442, 461, 502, 507, 509, 516, 522, 533, 536, 538, 539, 546, 549, 557, 560, 565, 571, 575, 594, 595, 596, 605, 608, 609, 612, 613, 614, 621, 624, 626, 630, 638, 641, 646, 647, 648, 650, 652, 654, 655, 657, 658, 660, 661, 663, 664, 666], "float": [16, 43, 44, 140, 141, 149, 153, 157, 171, 179, 197, 203, 208, 218, 221, 229, 230, 245, 258, 288, 300, 312, 314, 315, 316, 343, 365, 367, 368, 369, 388, 391, 396, 439, 443, 446, 449, 461, 520, 524, 536, 538, 546, 549, 562, 565, 594, 596, 612, 654, 655, 661, 663], "A": [16, 55, 74, 75, 103, 116, 140, 141, 148, 149, 160, 170, 178, 179, 184, 186, 193, 194, 196, 198, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 229, 230, 247, 262, 265, 267, 268, 290, 303, 304, 311, 314, 315, 316, 318, 321, 324, 325, 326, 333, 336, 338, 341, 342, 343, 344, 345, 350, 364, 367, 368, 369, 371, 372, 376, 380, 428, 446, 449, 466, 485, 486, 502, 506, 507, 509, 517, 520, 524, 538, 554, 565, 570, 576, 594, 595, 596, 602, 605, 612, 613, 615, 626, 627, 630, 633, 641, 652, 653, 655, 658, 661, 663, 664, 666], "between": [16, 42, 143, 176, 214, 229, 230, 262, 303, 315, 318, 368, 371, 418, 423, 565, 571, 575, 576, 577, 593, 598, 599, 608, 612, 613, 624, 655, 658, 659, 660, 661, 663, 664], "0": [16, 43, 44, 54, 90, 105, 148, 149, 150, 153, 161, 162, 170, 171, 173, 175, 178, 179, 187, 194, 196, 197, 199, 221, 223, 225, 229, 230, 235, 237, 242, 244, 245, 248, 249, 252, 258, 262, 264, 265, 278, 280, 285, 287, 288, 291, 292, 295, 300, 303, 308, 309, 318, 325, 333, 338, 346, 371, 382, 387, 388, 390, 391, 394, 396, 401, 424, 429, 443, 461, 465, 502, 504, 516, 521, 524, 536, 538, 546, 560, 571, 594, 595, 596, 599, 601, 603, 604, 605, 609, 610, 612, 613, 614, 619, 621, 626, 630, 636, 646, 647, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 666], "100": [16, 177, 178, 179, 194, 197, 229, 230, 247, 290, 396, 443, 460, 463, 524, 592, 596, 601, 607, 613, 638, 654, 655, 663, 664, 666, 667], "klcalibr": 16, "128": [16, 44, 149, 154, 156, 170, 171, 223, 245, 248, 249, 262, 288, 291, 292, 303, 388, 396, 504, 522, 523, 538, 596, 613, 655, 658, 663, 667], "num_quantized_bin": 16, "histogramcollector": 16, "collctor": 16, "smooth_distribut": 16, "p": [16, 153, 634, 635, 658], "ep": [16, 176, 614], "0001": [16, 194, 229, 230, 599, 613, 654], "smooth": [16, 140, 141, 148, 167, 175, 229, 230, 359, 384, 393, 396, 446, 447, 449, 461, 502, 594, 652, 664], "discret": [16, 194, 664], "mai": [16, 148, 160, 162, 327, 328, 330, 331, 332, 443, 502, 516, 517, 539, 569, 570, 576, 593, 594, 598, 603, 604, 610, 614, 626, 630, 636, 639, 641, 653, 655, 658, 661, 664], "have": [16, 74, 83, 141, 148, 162, 198, 202, 204, 211, 243, 265, 286, 311, 314, 341, 343, 364, 367, 371, 424, 442, 443, 449, 485, 494, 502, 516, 569, 570, 576, 577, 594, 595, 596, 598, 601, 605, 610, 612, 613, 614, 616, 633, 636, 639, 641, 646, 647, 648, 650, 652, 655, 656, 658, 661, 664, 665], "been": [16, 149, 162, 198, 204, 211, 311, 341, 343, 364, 509, 516, 572, 577, 594, 599, 613, 614, 633, 658, 661], "normal": [16, 33, 262, 303, 316, 369, 613, 642, 650, 658, 661, 663], "1": [16, 42, 43, 44, 55, 74, 89, 105, 109, 113, 146, 148, 149, 150, 153, 162, 165, 167, 170, 171, 173, 175, 176, 177, 179, 187, 194, 196, 197, 209, 210, 212, 229, 230, 235, 237, 242, 244, 245, 246, 248, 249, 252, 253, 258, 262, 263, 264, 265, 278, 280, 285, 287, 288, 289, 291, 292, 295, 296, 300, 303, 309, 314, 315, 316, 318, 333, 338, 343, 346, 347, 367, 368, 369, 371, 382, 385, 387, 388, 390, 391, 394, 401, 424, 442, 443, 447, 466, 485, 502, 504, 509, 516, 521, 522, 535, 536, 538, 546, 557, 560, 565, 569, 571, 574, 575, 577, 593, 595, 596, 598, 599, 603, 605, 606, 609, 611, 612, 614, 617, 619, 635, 636, 643, 644, 646, 647, 648, 650, 651, 652, 654, 655, 656, 658, 659, 660, 661, 662, 663, 664, 665, 666], "replac": [16, 149, 163, 167, 170, 171, 316, 369, 518, 522, 538, 594, 601, 613, 624, 659], "zero": [16, 43, 44, 149, 150, 156, 171, 208, 221, 262, 303, 343, 388, 391, 401, 523, 538, 565, 574, 638, 652, 655, 658, 661, 663, 664], "multipli": [16, 229, 230, 658], "scale": [16, 43, 44, 100, 141, 143, 149, 156, 165, 167, 169, 170, 171, 175, 176, 258, 262, 300, 303, 387, 388, 391, 401, 449, 522, 523, 535, 536, 537, 538, 655, 658, 660, 661, 663, 664], "factor": [16, 141, 153, 449, 658, 661, 667], "take": [16, 203, 230, 233, 234, 238, 262, 267, 276, 277, 281, 303, 341, 350, 371, 372, 424, 428, 554, 569, 571, 572, 595, 598, 599, 605, 613, 633, 652, 655, 657, 658, 663, 664, 666], "correspond": [16, 157, 201, 212, 229, 230, 245, 288, 311, 314, 318, 364, 367, 371, 539, 557, 565, 575, 605, 613, 652, 654, 655, 660, 664], "amount": [16, 661], "off": [16, 67, 68, 70, 478, 479, 481, 570, 658], "non": [16, 342, 565, 571, 598, 658, 664], "ref": [16, 148, 502], "http": [16, 156, 157, 196, 197, 205, 206, 215, 216, 217, 223, 245, 247, 288, 290, 311, 312, 314, 315, 316, 341, 343, 344, 364, 365, 367, 368, 369, 371, 395, 424, 523, 546, 571, 574, 596, 598, 606, 609, 610, 613, 622, 628, 631, 635, 637, 638, 639, 640, 641, 644, 646, 647, 648, 652, 659], "hanj": 16, "c": [16, 74, 247, 290, 485, 565, 596, 604, 609, 658, 664], "illinoi": 16, "edu": [16, 247, 290, 596], "cs412": 16, "bk3": 16, "diverg": [16, 555, 559, 577, 593, 599, 664], "pdf": [16, 197, 223], "github": [16, 157, 205, 206, 217, 245, 288, 311, 312, 315, 316, 341, 344, 364, 365, 368, 369, 371, 395, 424, 570, 574, 596, 598, 602, 609, 610, 613, 622, 628, 631, 635, 637, 638, 639, 640, 641, 644, 647, 648, 659], "com": [16, 157, 205, 206, 217, 245, 288, 311, 312, 315, 316, 341, 344, 364, 365, 368, 369, 371, 395, 424, 569, 574, 594, 596, 598, 606, 609, 610, 613, 616, 622, 635, 637, 638, 640, 641, 644, 647, 648, 659, 660, 667], "apach": [16, 610], "incub": 16, "blob": [16, 157, 205, 206, 311, 312, 315, 316, 341, 364, 365, 368, 369, 371, 395, 424, 613, 622, 644, 647, 648], "master": [16, 205, 206, 217, 311, 312, 315, 316, 341, 344, 364, 365, 368, 369, 371, 424, 613, 664], "python": [16, 75, 148, 160, 162, 247, 266, 290, 310, 363, 395, 443, 486, 502, 509, 516, 517, 565, 567, 571, 594, 596, 598, 601, 604, 609, 613, 618, 624, 627, 633, 637, 638, 640, 641, 643, 646, 648, 652, 653, 663], "contrib": [16, 310, 363], "py": [16, 148, 157, 177, 208, 229, 230, 312, 314, 315, 316, 343, 365, 367, 368, 369, 395, 443, 502, 571, 575, 594, 598, 601, 609, 613, 618, 620, 621, 622, 628, 631, 635, 637, 638, 640, 641, 643, 644, 646, 647, 648, 655, 659, 662], "microsoft": [16, 395, 574, 575], "onnxruntim": [16, 229, 230, 241, 247, 254, 284, 290, 297, 319, 395, 418, 575, 593, 595, 608, 609, 614, 636, 654], "main": [16, 156, 189, 194, 212, 217, 269, 344, 393, 394, 395, 460, 463, 523, 544, 545, 549, 571, 595, 598, 601, 613, 620, 622, 634, 643, 652, 655, 658], "tool": [16, 148, 307, 395, 502, 565, 574, 575, 613, 626, 630, 636, 639, 640, 641, 652, 653, 655], "arrai": [16, 43, 44, 148, 162, 262, 303, 314, 325, 367, 391, 401, 502, 516, 565, 663], "small": [16, 67, 68, 69, 70, 431, 478, 479, 480, 481, 572, 638, 639, 652, 658, 664, 667], "probabl": [16, 229, 230, 559, 658], "activationoper": 18, "onnx_quant": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40], "onnx_nod": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 87, 101, 111], "removableactivationoper": 18, "remov": [18, 43, 51, 57, 60, 74, 80, 83, 84, 85, 96, 98, 140, 199, 212, 316, 369, 446, 468, 471, 485, 491, 494, 495, 496, 569, 613, 626, 630, 639, 646, 647, 652, 662], "qactivationoper": 18, "children": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 36, 38, 39, 163, 518], "initi": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 36, 38, 39, 42, 43, 44, 105, 116, 148, 153, 162, 187, 208, 233, 234, 242, 245, 264, 276, 277, 285, 288, 342, 343, 360, 391, 424, 440, 502, 516, 526, 554, 572, 577, 596, 612, 632, 652, 655, 661, 664], "qoper": [18, 34, 229, 230, 603, 636], "float16activationoper": 18, "float16": [18, 21, 43, 149, 150, 539, 560, 596, 658], "argmaxoper": 19, "qargmaxoper": 19, "attentionoper": 20, "qattentionoper": 20, "qattent": 20, "binari": [21, 148, 318, 371, 502, 604, 612, 628, 631, 659], "binaryoper": 21, "binarydirect8bitoper": 21, "qbinaryoper": 21, "qbinari": 21, "float16binaryoper": 21, "concatoper": 22, "qconcatoper": 22, "qconcat": 22, "convoper": 23, "qconvoper": 23, "qlinearconv": 23, "direct8bit": 24, "direct8bitoper": 24, "qdirectoper": 24, "qdirect": 24, "embedlayernorm": 25, "embedlayernormalizationoper": 25, "qembedlayernormalizationoper": 25, "qembedlayernorm": 25, "gatheroper": 26, "qgatheroper": 26, "qgather": 26, "globalaveragepool": 27, "globalaveragepooloper": 27, "qglobalaveragepooloper": 27, "qlinearglobalaveragepool": 27, "gemmoper": 28, "qgemmoper": 28, "qgemm": 28, "lstmoper": 30, "matmuloper": 31, "qmatmuloper": 31, "qlinearmatmul": 31, "fusedmatmuloper": 31, "fusedmatmul": 31, "maxpooloper": 32, "qmaxpooloper": 32, "qmaxpool": 32, "batchnormalizationoper": 33, "batchnorm": [33, 62, 67, 121, 473, 478, 571, 661], "normalizationoper": 33, "op_registri": 34, "op_typ": [34, 140, 141, 148, 224, 361, 396, 441, 446, 449, 461, 502, 521], "qop_registri": 34, "padoper": 35, "qpadoper": 35, "qpad": 35, "averagepool": 36, "pooloper": 36, "qpooloper": 36, "qlinearaveragepool": 36, "reduceoper": 37, "reduceminmaxoper": 37, "reducemin": 37, "reducemax": 37, "resizeoper": 38, "qresizeoper": 38, "qresiz": 38, "splitoper": 39, "qsplitoper": 39, "qsplit": 39, "unari": 40, "unaryoper": 40, "unarydirect8bitoper": 40, "q_config": [41, 170, 308, 575], "mode": [41, 42, 43, 45, 110, 162, 167, 254, 297, 314, 360, 367, 380, 385, 401, 440, 499, 507, 516, 549, 562, 564, 565, 575, 576, 598, 608, 626, 630, 638, 639, 655, 657, 658, 664], "quantization_param": 41, "op_types_to_quant": 41, "fallback_list": 41, "fp32": [41, 42, 44, 79, 131, 136, 143, 170, 171, 176, 229, 230, 233, 234, 276, 277, 307, 308, 318, 353, 360, 371, 387, 388, 390, 391, 396, 429, 433, 440, 460, 463, 490, 509, 522, 536, 538, 557, 560, 564, 565, 570, 574, 575, 577, 598, 605, 606, 612, 613, 614, 623, 635, 636, 637, 638, 654, 655, 657, 658, 659, 660, 661, 662, 664, 666, 667], "add_qdq_pair_to_weight": [41, 229, 230, 655], "optypes_to_exclude_output_qu": [41, 229, 230, 655], "dedicated_qdq_pair": [41, 229, 230, 655], "smoothquant": [42, 167, 170, 175, 385, 447, 574, 611, 653, 658, 665], "onnxrt": [42, 43, 44, 245, 247, 254, 262, 288, 290, 297, 303, 318, 371, 417, 563, 575, 598, 614, 635, 655, 667], "get_quant_dequant_output": 42, "input_data": [42, 595], "output_data": 42, "loss": [42, 179, 187, 229, 230, 264, 309, 318, 333, 338, 346, 371, 539, 554, 593, 598, 599, 600, 601, 602, 611, 612, 613, 614, 624, 636, 638, 651, 652, 653, 655, 658, 661, 664, 666], "output": [42, 43, 44, 51, 54, 59, 74, 98, 105, 110, 148, 149, 150, 170, 171, 190, 201, 202, 207, 221, 227, 229, 230, 233, 234, 267, 271, 276, 277, 307, 308, 311, 341, 364, 371, 372, 380, 391, 424, 465, 470, 485, 499, 502, 507, 509, 521, 536, 538, 539, 554, 560, 561, 565, 571, 575, 576, 599, 600, 601, 603, 605, 607, 612, 613, 615, 624, 633, 634, 636, 641, 642, 646, 647, 648, 651, 652, 654, 655, 658, 659, 661, 662, 663, 664, 666], "numpi": [42, 43, 67, 68, 70, 105, 148, 262, 303, 314, 325, 367, 391, 478, 479, 481, 502, 604, 661, 663], "7": [42, 171, 177, 197, 229, 230, 382, 396, 401, 538, 577, 592, 604, 605, 613, 652, 655, 659, 661, 664, 667], "bit": [42, 44, 149, 154, 170, 171, 229, 230, 387, 388, 390, 391, 401, 442, 522, 536, 538, 546, 577, 593, 600, 614, 653, 655, 658, 661], "execut": [42, 43, 54, 156, 162, 177, 208, 209, 210, 229, 230, 343, 347, 349, 388, 423, 424, 425, 427, 465, 516, 520, 523, 554, 557, 564, 565, 598, 599, 600, 613, 614, 618, 619, 626, 627, 633, 634, 635, 636, 640, 643, 651, 652, 655, 658, 660, 664, 667], "provid": [42, 43, 44, 102, 105, 110, 149, 201, 233, 234, 262, 276, 277, 303, 309, 314, 333, 338, 346, 347, 367, 372, 384, 385, 387, 388, 390, 391, 396, 424, 499, 524, 554, 558, 560, 572, 574, 575, 576, 577, 592, 595, 598, 600, 601, 602, 608, 609, 611, 612, 613, 614, 615, 616, 620, 624, 627, 633, 634, 635, 641, 642, 652, 654, 655, 658, 661, 662, 664, 665, 666, 667], "make_sub_graph": 42, "opset": [42, 102, 104, 105, 230, 307, 308, 603], "ir_vers": 42, "thi": [42, 45, 86, 110, 132, 139, 143, 147, 149, 153, 157, 160, 162, 170, 171, 176, 179, 181, 186, 190, 193, 199, 201, 203, 205, 206, 207, 208, 212, 213, 214, 215, 217, 218, 219, 225, 229, 230, 233, 234, 244, 245, 246, 247, 248, 249, 250, 252, 262, 265, 271, 272, 276, 277, 287, 288, 289, 290, 291, 292, 293, 295, 303, 311, 314, 315, 316, 318, 327, 328, 330, 331, 332, 333, 338, 341, 343, 345, 346, 347, 350, 353, 364, 367, 368, 369, 371, 372, 382, 424, 428, 433, 442, 443, 497, 499, 501, 504, 516, 517, 521, 522, 539, 554, 564, 565, 569, 570, 571, 572, 575, 576, 577, 593, 594, 595, 596, 599, 600, 601, 603, 604, 605, 608, 610, 611, 612, 613, 614, 615, 616, 618, 619, 621, 622, 624, 626, 628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 641, 642, 646, 647, 648, 652, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665], "quant_dequant_data": 42, "qtype": [42, 43, 401, 575], "3": [42, 44, 148, 149, 150, 162, 179, 197, 210, 230, 247, 262, 290, 303, 314, 367, 387, 388, 390, 391, 396, 443, 502, 516, 565, 571, 572, 574, 593, 594, 595, 596, 599, 601, 603, 605, 606, 609, 612, 613, 614, 616, 620, 624, 626, 630, 635, 640, 641, 643, 644, 646, 650, 652, 654, 655, 658, 659, 660, 661, 663, 664, 667], "scheme": [42, 43, 44, 149, 154, 165, 170, 171, 387, 388, 390, 391, 401, 522, 535, 536, 538, 575, 576, 577, 595, 605, 624, 658, 664, 666], "sym": [42, 43, 44, 149, 150, 171, 401, 522, 536, 538, 576, 577, 605, 655, 658, 666], "dequant": [42, 43, 44, 51, 88, 91, 92, 93, 94, 96, 149, 157, 170, 171, 391, 509, 538, 565, 571, 576, 661, 662], "asym": [42, 43, 44, 149, 154, 165, 170, 171, 387, 388, 390, 391, 401, 522, 535, 536, 538, 577, 605, 658, 666], "ortsmoothqu": 42, "fake": [42, 44, 113, 165, 167, 171, 175, 181, 385, 442, 522, 535, 536, 538, 613, 655, 658, 661], "channel": [42, 43, 44, 143, 150, 167, 171, 175, 176, 199, 202, 207, 229, 230, 258, 262, 300, 303, 341, 385, 388, 536, 538, 560, 574, 575, 577, 608, 609, 616, 618, 623, 638, 652, 658, 663, 667], "For": [42, 44, 149, 170, 171, 175, 181, 197, 201, 202, 205, 206, 217, 230, 247, 262, 290, 303, 315, 316, 318, 341, 344, 368, 369, 371, 372, 385, 387, 388, 390, 424, 522, 536, 538, 569, 571, 573, 575, 577, 599, 600, 601, 603, 605, 608, 616, 618, 619, 621, 624, 635, 636, 641, 652, 657, 658, 661, 662, 664, 666, 667], "more": [42, 148, 149, 167, 175, 179, 181, 205, 206, 262, 303, 341, 385, 502, 539, 572, 573, 574, 576, 593, 594, 596, 599, 601, 603, 606, 608, 609, 611, 613, 614, 616, 624, 628, 631, 636, 641, 650, 651, 652, 657, 658, 661, 664, 665, 667], "detail": [42, 153, 167, 175, 178, 179, 201, 262, 303, 385, 565, 566, 569, 574, 576, 577, 593, 594, 599, 605, 606, 607, 611, 612, 613, 614, 616, 624, 633, 641, 642, 652, 658, 659, 660, 661, 662, 664, 665], "pleas": [42, 149, 156, 157, 167, 175, 196, 205, 206, 207, 215, 216, 217, 229, 230, 245, 246, 247, 250, 288, 289, 290, 293, 341, 343, 344, 371, 385, 424, 443, 523, 571, 572, 573, 574, 575, 592, 593, 596, 600, 601, 603, 609, 611, 612, 614, 616, 617, 621, 624, 640, 641, 642, 652, 655, 657, 658, 659, 660, 661, 664, 665], "refer": [42, 149, 156, 157, 167, 175, 196, 205, 206, 207, 215, 216, 217, 221, 229, 230, 245, 288, 311, 312, 318, 341, 343, 344, 364, 365, 371, 385, 424, 443, 523, 571, 575, 576, 592, 595, 596, 598, 600, 601, 603, 607, 609, 610, 612, 613, 614, 616, 621, 624, 635, 636, 638, 640, 641, 642, 650, 654, 656, 659, 663, 664], "accur": [42, 156, 167, 175, 216, 385, 523, 546, 652, 658, 661], "effici": [42, 167, 175, 385, 572, 574, 593, 595, 599, 616, 641, 651, 652, 653, 658, 661, 664], "post": [42, 97, 98, 156, 167, 175, 215, 230, 233, 234, 276, 277, 385, 424, 523, 546, 569, 574, 575, 576, 598, 600, 601, 603, 608, 609, 616, 622, 633, 643, 652, 653, 656, 658, 661, 662, 664], "train": [42, 57, 80, 149, 156, 167, 175, 186, 209, 210, 213, 215, 216, 229, 230, 233, 234, 245, 247, 262, 272, 276, 277, 288, 290, 303, 304, 320, 343, 363, 385, 424, 468, 491, 523, 546, 557, 572, 574, 575, 576, 582, 596, 598, 599, 600, 603, 608, 614, 616, 622, 633, 638, 646, 651, 653, 656, 658, 660, 661, 664, 666], "larg": [42, 43, 167, 175, 216, 385, 574, 595, 599, 611, 613, 653, 656, 658, 661, 667], "languag": [42, 167, 175, 216, 311, 364, 385, 569, 574, 603, 611, 637, 653, 656, 658, 661], "2": [42, 43, 44, 54, 74, 105, 109, 149, 150, 162, 167, 171, 173, 175, 177, 179, 197, 203, 209, 210, 223, 229, 230, 246, 263, 289, 314, 316, 318, 343, 350, 367, 369, 371, 382, 385, 387, 388, 390, 391, 401, 428, 443, 465, 485, 516, 522, 536, 538, 565, 571, 575, 593, 595, 596, 598, 599, 605, 608, 609, 610, 611, 612, 614, 637, 643, 644, 646, 647, 648, 650, 652, 653, 655, 656, 658, 659, 660, 661, 663, 664, 665], "spiq": [42, 167, 175, 385, 661], "free": [42, 167, 175, 215, 233, 234, 276, 277, 385, 424, 569, 622, 627, 635, 643, 650, 660, 661], "per": [42, 43, 44, 167, 171, 175, 177, 229, 230, 263, 385, 388, 391, 538, 539, 559, 575, 577, 595, 641, 652, 657, 658, 667], "we": [42, 43, 67, 68, 70, 74, 86, 143, 150, 162, 167, 175, 176, 177, 179, 201, 205, 212, 229, 230, 244, 263, 265, 287, 311, 314, 364, 367, 385, 395, 401, 431, 478, 479, 481, 485, 497, 516, 569, 571, 575, 576, 577, 594, 595, 598, 601, 603, 605, 611, 612, 613, 620, 621, 624, 628, 631, 633, 634, 636, 639, 646, 647, 648, 650, 651, 652, 654, 655, 656, 658, 659, 660, 661, 662, 664, 665], "onli": [42, 44, 54, 63, 70, 86, 109, 115, 143, 162, 167, 169, 171, 175, 176, 177, 189, 194, 198, 204, 211, 229, 230, 245, 263, 265, 269, 288, 308, 320, 341, 343, 354, 385, 391, 394, 396, 424, 434, 442, 443, 465, 474, 481, 497, 516, 523, 537, 539, 546, 565, 574, 575, 576, 577, 592, 593, 595, 598, 599, 601, 604, 605, 611, 613, 614, 621, 634, 652, 653, 654, 655, 656, 661, 662, 664, 665, 666], "inplac": [42, 167, 385, 520, 536, 549], "mean": [42, 44, 149, 167, 171, 203, 212, 229, 230, 258, 262, 300, 303, 316, 318, 341, 353, 369, 371, 385, 433, 536, 571, 576, 577, 595, 598, 601, 605, 612, 613, 619, 638, 652, 655, 656, 658, 661, 663, 664, 666, 667], "weight": [42, 43, 44, 60, 61, 122, 140, 141, 143, 148, 149, 150, 153, 154, 157, 167, 169, 170, 171, 176, 179, 196, 198, 202, 205, 206, 207, 208, 209, 210, 211, 213, 214, 215, 216, 218, 220, 229, 230, 308, 341, 343, 360, 371, 385, 387, 388, 390, 391, 394, 396, 401, 424, 431, 440, 442, 446, 449, 471, 472, 502, 509, 522, 523, 537, 538, 539, 546, 565, 566, 574, 575, 576, 577, 593, 598, 600, 605, 607, 611, 613, 635, 646, 650, 652, 653, 654, 655, 656, 661, 662, 664, 665, 666], "chang": [42, 96, 143, 149, 150, 167, 176, 209, 210, 212, 213, 215, 216, 219, 229, 230, 343, 345, 385, 431, 565, 570, 576, 595, 601, 604, 610, 613, 616, 626, 627, 630, 633, 639, 652, 662, 663, 664], "you": [42, 162, 167, 229, 230, 243, 245, 286, 288, 343, 371, 385, 424, 516, 539, 570, 571, 576, 594, 595, 596, 598, 601, 609, 610, 612, 614, 616, 618, 619, 621, 626, 630, 633, 634, 635, 636, 637, 638, 639, 641, 652, 655, 658, 659, 660, 661, 662, 665], "can": [42, 43, 44, 143, 153, 157, 162, 167, 176, 179, 193, 201, 202, 203, 208, 216, 217, 219, 229, 230, 233, 234, 244, 247, 262, 263, 265, 276, 277, 287, 290, 303, 314, 316, 318, 341, 343, 345, 367, 369, 371, 372, 382, 385, 391, 401, 424, 516, 539, 554, 565, 571, 572, 574, 575, 576, 577, 592, 594, 595, 596, 598, 599, 600, 601, 603, 605, 608, 609, 611, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 624, 626, 627, 628, 630, 631, 633, 634, 636, 638, 639, 640, 641, 643, 650, 651, 652, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 666, 667], "recov": [42, 167, 385, 564, 565, 575, 600], "helper": [43, 45, 110, 116, 148, 170, 245, 246, 247, 261, 288, 289, 290, 302, 306, 307, 308, 380, 401, 499, 502, 507, 524, 563], "get_node_original_nam": 43, "origin": [43, 44, 140, 148, 149, 163, 167, 170, 197, 201, 213, 221, 223, 230, 245, 262, 263, 288, 303, 327, 328, 330, 331, 332, 342, 343, 362, 391, 401, 429, 442, 446, 502, 518, 538, 560, 565, 570, 596, 621, 652, 655, 663, 664, 666], "simple_progress_bar": [43, 401], "total": [43, 208, 262, 303, 318, 343, 371, 401, 596, 598, 652, 658, 663, 667], "progress": [43, 195, 198, 211, 247, 290, 401, 627, 633, 635, 652, 655], "bar": [43, 247, 290, 401, 633, 653], "case": [43, 70, 74, 153, 162, 171, 177, 179, 230, 244, 261, 262, 263, 287, 302, 303, 309, 333, 338, 346, 382, 401, 481, 485, 516, 522, 577, 594, 595, 599, 600, 601, 605, 607, 612, 617, 621, 633, 634, 635, 638, 644, 647, 648, 650, 652, 653, 655, 658, 659, 661, 663, 665, 666, 667], "where": [43, 153, 162, 229, 230, 314, 318, 367, 371, 401, 442, 516, 565, 577, 593, 598, 599, 626, 630, 634, 661, 662], "tqdm": [43, 401, 613], "t": [43, 67, 68, 70, 143, 153, 162, 176, 203, 229, 230, 262, 265, 303, 316, 369, 401, 478, 479, 481, 516, 571, 575, 594, 598, 599, 601, 613, 614, 634, 639, 652, 655, 658, 664, 666], "dtype_to_nam": 43, "dtype_map": 43, "dtype": [43, 44, 102, 105, 150, 229, 230, 248, 249, 258, 262, 291, 292, 300, 303, 391, 504, 536, 538, 539, 546, 560, 576, 577, 596, 598, 603, 605, 616, 638, 654, 655, 658, 661, 662, 663, 666], "its": [43, 60, 96, 148, 157, 201, 210, 213, 215, 221, 230, 241, 247, 262, 284, 290, 303, 306, 312, 313, 343, 350, 365, 366, 428, 471, 502, 569, 596, 599, 610, 612, 614, 624, 626, 630, 633, 634, 652, 658, 660, 663, 664], "string": [43, 45, 116, 148, 149, 156, 160, 162, 177, 185, 187, 189, 193, 194, 201, 203, 208, 217, 218, 219, 221, 226, 229, 230, 247, 264, 269, 290, 304, 309, 311, 314, 320, 321, 322, 324, 325, 333, 338, 341, 342, 343, 344, 345, 346, 364, 367, 376, 380, 401, 502, 507, 509, 516, 517, 523, 533, 557, 562, 565, 612, 663], "represent": [43, 160, 517, 569, 571, 593, 600, 652, 655], "quanttyp": [43, 442], "repres": [43, 203, 207, 208, 217, 218, 221, 247, 252, 290, 295, 314, 316, 318, 367, 369, 371, 387, 388, 390, 391, 569, 577, 593, 596, 603, 641, 652, 655, 656, 664], "make_quant_nod": 43, "make": [43, 105, 143, 176, 193, 203, 208, 217, 219, 243, 286, 341, 343, 345, 565, 569, 575, 576, 592, 594, 595, 605, 612, 613, 621, 626, 630, 633, 635, 652, 655, 656, 657, 658, 660, 661, 664], "quantizelinear": 43, "make_dquant_nod": 43, "axi": [43, 230], "dequantizelinear": 43, "is_b_transpos": [43, 401], "inuput": [43, 401], "b": [43, 74, 149, 153, 245, 288, 401, 485, 565, 570, 593, 596, 612, 652, 658, 661, 664], "transpos": [43, 73, 150, 207, 258, 262, 303, 307, 341, 401, 484, 658, 663], "split_shared_bia": 43, "share": [43, 44, 82, 98, 109, 141, 149, 171, 391, 449, 493, 522, 536, 538, 604, 605, 658, 661, 664], "float_to_float16": 43, "float_to_bfloat16": 43, "bfloat16": [43, 539, 614, 616, 624, 657], "cast_tensor": 43, "is_large_model": 43, "tensorproto": [43, 105], "raw": [43, 177, 246, 250, 253, 289, 293, 296, 353, 433, 612, 637, 664], "remove_init_from_model_input": 43, "collate_pr": 43, "result": [43, 148, 157, 170, 179, 258, 262, 300, 303, 311, 314, 315, 316, 318, 364, 367, 368, 369, 371, 404, 424, 431, 502, 521, 554, 564, 565, 569, 572, 574, 595, 598, 599, 601, 608, 610, 612, 613, 621, 622, 633, 634, 637, 641, 642, 643, 644, 650, 652, 653, 655, 658, 660, 661, 662, 663, 664, 665, 667], "quantize_data_with_scale_zero": 43, "zero_point": [43, 44, 391], "point": [43, 44, 149, 171, 258, 300, 315, 316, 325, 350, 368, 369, 388, 391, 401, 428, 538, 565, 612, 633, 638, 639, 655, 658, 661, 663, 664], "To": [43, 314, 367, 382, 401, 570, 576, 577, 594, 596, 598, 601, 614, 617, 620, 626, 628, 630, 631, 635, 639, 652, 654, 657, 658, 659, 661, 664, 666], "pack": [43, 61, 401, 472], "comput": [43, 44, 105, 149, 153, 157, 170, 311, 312, 315, 316, 318, 364, 365, 368, 369, 371, 387, 388, 390, 391, 401, 539, 554, 565, 593, 595, 600, 603, 612, 613, 614, 616, 627, 636, 652, 653, 655, 658, 661, 664], "linear": [43, 149, 150, 156, 165, 169, 170, 171, 175, 199, 201, 202, 207, 212, 221, 224, 229, 230, 341, 401, 523, 535, 537, 538, 571, 599, 603, 613, 652, 658, 661, 664], "transform": [43, 50, 143, 145, 146, 147, 149, 156, 166, 169, 215, 245, 246, 247, 248, 249, 250, 252, 254, 256, 288, 289, 290, 291, 292, 293, 295, 297, 299, 310, 363, 401, 504, 520, 521, 523, 537, 546, 571, 572, 574, 593, 596, 599, 600, 601, 602, 606, 611, 613, 616, 621, 622, 623, 624, 636, 644, 647, 648, 652, 653, 657, 658, 661, 662, 664, 666, 667], "when": [43, 54, 64, 70, 148, 160, 162, 179, 202, 208, 213, 221, 229, 230, 245, 246, 254, 262, 288, 289, 297, 303, 312, 342, 343, 365, 401, 424, 465, 475, 481, 502, 516, 517, 539, 554, 569, 572, 576, 594, 595, 596, 613, 624, 626, 627, 630, 634, 635, 638, 639, 640, 642, 646, 652, 655, 658, 661, 663, 664], "uint8": [43, 171, 258, 300, 314, 362, 367, 401, 442, 538, 575, 596, 605, 654, 655, 663, 666], "rmin": [43, 401, 655], "rmax": [43, 401, 655], "m": [43, 157, 171, 205, 206, 229, 230, 341, 401, 538, 570, 599, 609, 616, 618, 621, 624, 628, 631, 641, 652, 667], "max": [43, 104, 143, 149, 171, 176, 179, 194, 197, 229, 230, 262, 303, 315, 316, 350, 368, 369, 401, 428, 509, 538, 565, 574, 598, 609, 613, 636, 638, 652, 655, 658, 661, 663, 664], "ab": [43, 156, 171, 196, 215, 216, 343, 401, 523, 538, 546, 652, 655, 661], "np": [43, 262, 303, 350, 391, 428, 601, 643, 661, 663, 664], "calculate_scale_zp": 43, "quantize_rang": [43, 401], "calcul": [43, 60, 170, 196, 205, 221, 230, 248, 249, 291, 292, 315, 316, 341, 343, 353, 368, 369, 433, 471, 504, 555, 565, 593, 596, 612, 613, 624, 636, 650, 652, 655, 658, 660, 661, 664, 666], "quantize_data": [43, 401], "add": [43, 53, 64, 109, 119, 148, 189, 221, 229, 230, 245, 247, 269, 288, 290, 342, 360, 401, 440, 464, 475, 502, 565, 570, 571, 577, 595, 596, 601, 603, 605, 612, 613, 628, 631, 635, 636, 643, 646, 647, 660, 661, 662, 664, 665], "necessari": [43, 217, 401, 569, 572, 576, 615, 634, 652, 660, 664], "intermedi": [43, 157, 187, 229, 230, 264, 401, 571, 608, 655], "full": [43, 149, 150, 245, 246, 247, 288, 289, 290, 401, 560, 565, 574, 593, 596, 598, 604, 610, 634, 639, 652, 658, 659], "equat": [43, 316, 318, 369, 371, 401, 655, 661], "r": [43, 143, 176, 401, 598, 609, 634, 635, 637, 638, 640, 641, 655, 667], "": [43, 44, 105, 143, 148, 162, 176, 201, 202, 203, 207, 208, 209, 210, 213, 215, 216, 221, 224, 226, 227, 229, 230, 244, 247, 261, 262, 263, 265, 267, 287, 290, 302, 303, 316, 341, 343, 369, 371, 372, 376, 388, 401, 424, 502, 509, 516, 526, 538, 539, 562, 565, 569, 570, 572, 576, 577, 594, 598, 599, 601, 603, 605, 608, 613, 614, 621, 624, 626, 630, 633, 636, 638, 641, 651, 652, 653, 654, 655, 658, 659, 660, 661, 664, 665, 666, 667], "q": [43, 44, 107, 109, 131, 401, 658, 661], "z": [43, 401, 593, 594, 599, 661], "real": [43, 248, 265, 291, 401, 504, 576, 593, 601, 635, 642, 653, 655], "quantize_data_per_channel": 43, "dequantize_data_with_scale_zero": 43, "tensor_valu": 43, "scale_valu": 43, "zo_valu": 43, "dequantize_data": 43, "valueinfo": 43, "tensor_nam": [43, 148, 162, 163, 502, 516, 518], "new_dtyp": 43, "cast": [43, 51, 657, 663], "info": [43, 170, 171, 205, 206, 221, 260, 265, 270, 341, 376, 509, 521, 522, 560, 561, 565, 571, 594, 598, 615, 643, 648], "quantizedvalu": 43, "new_quantized_nam": 43, "scale_nam": 43, "zero_point_nam": 43, "quantized_value_typ": 43, "quint8": 43, "linearli": 43, "quantizediniti": 43, "quantized_data": 43, "quantizationmod": 43, "quantizedvaluetyp": 43, "quantformat": 43, "quantize_nparrai": 43, "arr": [43, 509, 565], "low": [43, 149, 150, 233, 234, 248, 249, 276, 277, 291, 292, 309, 319, 346, 372, 504, 575, 576, 592, 593, 596, 601, 613, 614, 638, 653, 655, 658, 661, 664], "high": [43, 248, 249, 291, 292, 504, 596, 598, 609, 638, 653, 664], "attribute_to_kwarg": 43, "attribut": [43, 83, 104, 105, 148, 170, 201, 212, 227, 230, 494, 502, 539, 565, 575, 595, 605, 607, 613, 654, 666], "make_nod": 43, "find_by_nam": [43, 401], "item_list": [43, 401], "find": [43, 67, 68, 70, 105, 148, 224, 318, 325, 350, 371, 401, 428, 478, 479, 481, 502, 565, 575, 598, 611, 619, 626, 630, 633, 634, 636, 638, 652, 658, 660, 661, 662, 664], "item": [43, 221, 227, 229, 230, 261, 302, 342, 360, 401, 440, 509, 526, 593, 601, 652, 661, 664], "trt_env_setup": 43, "environ": [43, 177, 263, 569, 592, 626, 630, 633, 641, 644, 646, 647, 648, 664], "variabl": [43, 160, 177, 218, 229, 230, 247, 263, 290, 350, 428, 442, 517, 609, 652, 664], "tensorrt": [43, 593, 614, 655], "to_numpi": 43, "infer_shap": 43, "in_mp": 43, "int_max": 43, "31": [43, 667], "auto_merg": 43, "guess_output_rank": 43, "verbos": [43, 308, 350, 428], "base_dir": 43, "shape": [43, 44, 105, 148, 149, 203, 248, 249, 258, 262, 291, 292, 300, 303, 314, 367, 391, 502, 504, 574, 596, 605, 606, 613, 635, 636, 658, 661, 663], "weightonli": 44, "get_blob_s": 44, "group_siz": [44, 149, 154, 165, 170, 171, 387, 388, 390, 391, 442, 522, 535, 536, 538, 546, 658], "has_zp": 44, "blob_siz": 44, "how": [44, 149, 162, 171, 179, 186, 196, 203, 209, 210, 215, 216, 229, 230, 262, 303, 304, 341, 391, 516, 536, 538, 570, 571, 573, 575, 595, 596, 599, 600, 601, 607, 612, 613, 627, 628, 631, 632, 633, 635, 646, 647, 648, 652, 653, 655, 661, 663, 664, 665, 666], "mani": [44, 149, 171, 371, 391, 424, 536, 538, 594, 595, 609, 658, 664, 666], "element": [44, 149, 171, 179, 205, 206, 221, 243, 286, 314, 341, 367, 391, 536, 538, 565, 596, 608, 612, 652, 658, 661], "one": [44, 109, 110, 115, 149, 150, 162, 170, 171, 177, 203, 207, 212, 215, 216, 217, 219, 262, 272, 303, 311, 314, 318, 320, 341, 344, 345, 364, 367, 371, 391, 499, 516, 521, 536, 538, 539, 572, 575, 593, 599, 600, 601, 605, 608, 609, 612, 613, 614, 616, 617, 621, 622, 624, 626, 627, 630, 633, 634, 635, 638, 639, 640, 641, 643, 650, 651, 652, 654, 655, 656, 658, 659, 661, 663, 664], "zp": [44, 149, 171, 391, 536, 538, 661], "make_matmul_weight_only_nod": [44, 391], "weight_shap": [44, 391], "num_bit": [44, 113, 149, 165, 170, 171, 387, 388, 390, 391, 535, 661], "k_block": [44, 391], "q_weight": [44, 391], "accuracy_level": [44, 387, 388, 390, 391, 396], "matmulfpq4": [44, 391], "accuraci": [44, 177, 179, 221, 229, 230, 233, 234, 276, 277, 304, 309, 318, 333, 338, 346, 371, 372, 382, 387, 388, 390, 391, 394, 424, 429, 443, 539, 554, 562, 571, 574, 576, 577, 593, 595, 596, 598, 600, 601, 602, 603, 611, 612, 613, 624, 633, 635, 642, 643, 646, 647, 650, 651, 652, 653, 654, 658, 659, 660, 661, 662, 665, 666, 667], "level": [44, 181, 201, 387, 388, 390, 391, 429, 443, 561, 569, 643, 661, 664], "unset": [44, 387, 388, 390, 391], "jbla": [44, 387, 388, 390, 391], "kernel": [44, 175, 229, 230, 387, 388, 390, 391, 575, 576, 664], "fp16": [44, 230, 360, 387, 388, 390, 391, 440, 655], "4": [44, 54, 149, 150, 154, 165, 170, 171, 177, 197, 203, 212, 229, 230, 254, 257, 258, 262, 297, 300, 303, 311, 312, 314, 364, 365, 367, 387, 388, 390, 391, 394, 396, 442, 443, 465, 522, 535, 536, 538, 546, 569, 575, 577, 592, 601, 602, 605, 608, 609, 612, 613, 621, 641, 643, 647, 652, 655, 658, 661, 663, 664, 667], "matmulnbit": [44, 391], "new_init": [44, 391], "matmul_weight_only_nod": [44, 391], "quant_tensor": [44, 391, 538], "32": [44, 149, 154, 171, 199, 387, 388, 390, 391, 396, 442, 522, 536, 538, 546, 601, 607, 658, 667], "ratio": [44, 143, 176, 203, 208, 221, 229, 230, 258, 262, 300, 303, 343, 390, 391, 596, 613, 636, 652, 663, 667], "group": [44, 149, 150, 153, 171, 218, 328, 387, 388, 390, 391, 538, 574, 608, 652, 658, 662, 663, 664, 667], "clip": [44, 171, 387, 390, 391, 522, 536, 538, 658, 661], "qdq_tensor": [44, 391], "quant": [44, 148, 149, 170, 171, 229, 230, 360, 384, 387, 388, 391, 393, 396, 440, 451, 461, 502, 522, 536, 538, 571, 594, 611, 613, 655], "pad_tensor": [44, 391], "rowi": [44, 391], "so": [44, 105, 262, 303, 391, 442, 571, 575, 598, 604, 608, 614, 619, 621, 637, 638, 639, 655, 657, 658, 661, 662, 663, 665], "divis": [44, 391], "pade": [44, 391], "rtn_quantiz": [44, 171, 390, 536], "weight_config": [44, 149, 150, 154, 156, 169, 171, 387, 388, 390, 522, 523, 536, 537], "round": [44, 143, 149, 171, 176, 390, 396, 536, 546, 574, 653, 655, 658, 661], "nearst": [44, 171, 390], "method": [44, 141, 143, 149, 160, 162, 170, 171, 193, 218, 229, 230, 238, 243, 244, 245, 247, 254, 262, 265, 281, 286, 287, 288, 290, 297, 303, 324, 325, 326, 360, 387, 388, 390, 440, 442, 449, 516, 517, 522, 536, 539, 557, 558, 560, 561, 571, 572, 574, 593, 594, 595, 596, 598, 599, 600, 612, 613, 651, 652, 655, 657, 658, 661, 663, 664], "modelproto": [44, 306, 372, 385, 387, 388, 390, 391, 393, 394, 401, 615], "onnxmodel": [44, 379, 384, 385, 387, 388, 390, 391, 400, 417], "fc2": [44, 170, 171, 387, 388, 390, 522, 536, 538], "rtn": [44, 170, 393, 396, 461, 544, 546, 594, 656, 658], "get_weight_scal": 44, "apply_awq_scal": 44, "absorb_pair": 44, "output_dict": 44, "appli": [44, 113, 126, 127, 128, 131, 133, 137, 148, 149, 165, 169, 186, 212, 214, 272, 312, 365, 387, 388, 390, 393, 460, 502, 535, 537, 544, 569, 576, 577, 613, 616, 618, 624, 633, 637, 638, 643, 651, 652, 655, 657, 660, 661, 664, 665, 666], "salient": [44, 171, 522, 652, 658], "apply_awq_clip": 44, "mse": [44, 170, 171, 229, 230, 310, 318, 352, 363, 371, 388, 396, 424, 432, 522, 565, 598, 612, 638, 654, 658, 659], "prepare_input": [44, 391], "n_sampl": [44, 149, 154, 170, 171, 522, 538], "sampl": [44, 77, 149, 170, 171, 179, 229, 230, 238, 243, 245, 246, 247, 258, 262, 281, 286, 288, 289, 290, 300, 303, 318, 325, 350, 371, 428, 488, 522, 538, 572, 595, 596, 602, 608, 634, 655, 658, 661, 663, 664, 666, 667], "session": [44, 148, 244, 287, 380, 391, 502, 507, 613, 662], "awq_quant": [44, 171, 387, 522], "enable_auto_scal": [44, 171, 387, 396, 658], "enable_mse_search": [44, 171, 387, 396, 658], "awar": [44, 154, 157, 171, 186, 230, 272, 320, 341, 387, 431, 522, 554, 575, 576, 577, 593, 600, 601, 603, 608, 633, 643, 651, 653, 658, 664], "awq": [44, 171, 393, 396, 656, 658], "enabl": [44, 109, 149, 153, 157, 171, 208, 229, 230, 343, 522, 539, 576, 577, 601, 609, 614, 616, 618, 621, 622, 624, 635, 637, 638, 640, 643, 652, 653, 661, 664], "gptq": [44, 171, 393, 396, 546, 594, 656, 658], "w": [44, 156, 262, 303, 523, 652, 661, 663], "h": [44, 229, 230, 262, 303, 601, 641, 642, 646, 647, 648, 663], "blocksiz": [44, 388, 396], "percdamp": [44, 388, 396, 546, 658], "01": [44, 149, 179, 229, 230, 387, 388, 396, 546, 613, 654, 658, 664, 666, 667], "actord": [44, 388, 396, 658], "perchannel": [44, 388, 396], "hessian": [44, 157, 388, 431, 658, 664], "matrix": [44, 371, 424, 574, 624, 665], "percent": 44, "averag": [44, 315, 316, 318, 368, 369, 371, 388, 612, 613, 658, 664, 667], "diagon": [44, 388, 658], "dampen": [44, 153], "rearrang": [44, 215, 388, 652, 658], "consid": [44, 148, 153, 318, 371, 502, 569, 593, 594, 599, 634, 664], "diag": 44, "error": [44, 105, 149, 157, 162, 318, 353, 371, 388, 433, 516, 561, 598, 612, 617, 638, 639, 642, 658, 661, 664], "gptq_quantiz": [44, 171, 388, 523], "get_ops_recurs": 45, "prefix": [45, 148, 155, 162, 163, 168, 170, 177, 502, 516, 518, 538, 616, 621, 662], "graph_info": 45, "templateadaptor": 45, "tampl": 45, "dictionari": [45, 67, 68, 70, 148, 149, 155, 157, 162, 170, 193, 224, 227, 229, 230, 261, 302, 314, 321, 324, 326, 367, 401, 478, 479, 481, 502, 509, 516, 521, 553, 565], "yaml": [45, 221, 227, 230, 233, 234, 245, 247, 263, 276, 277, 288, 290, 304, 309, 320, 321, 322, 324, 333, 338, 346, 347, 451, 564, 565, 575, 577, 607, 612, 613, 650, 654, 662, 663], "file": [45, 105, 148, 160, 162, 163, 170, 174, 190, 217, 221, 226, 229, 230, 233, 234, 245, 246, 247, 250, 261, 262, 268, 271, 276, 277, 288, 289, 290, 293, 302, 303, 304, 309, 314, 320, 321, 322, 324, 333, 338, 342, 344, 346, 347, 367, 372, 382, 407, 408, 412, 424, 502, 509, 516, 517, 518, 564, 565, 570, 572, 575, 576, 577, 601, 604, 607, 610, 612, 613, 615, 619, 628, 631, 632, 633, 634, 636, 637, 638, 639, 641, 642, 646, 647, 648, 650, 654, 655, 658, 662, 663], "pytorchadaptor": 45, "api": [45, 70, 75, 110, 153, 156, 273, 309, 314, 346, 359, 360, 367, 371, 424, 439, 440, 443, 481, 486, 499, 509, 523, 531, 565, 571, 578, 580, 584, 587, 590, 598, 603, 608, 609, 613, 618, 622, 623, 624, 640, 641, 645, 659, 660, 664, 668], "pytorch_ipexadaptor": 45, "intel": [45, 189, 205, 206, 217, 266, 269, 305, 310, 317, 318, 341, 344, 352, 358, 363, 370, 371, 402, 424, 432, 438, 509, 567, 569, 570, 572, 573, 575, 576, 577, 593, 596, 597, 599, 600, 602, 603, 605, 606, 610, 611, 614, 615, 616, 621, 623, 624, 635, 636, 637, 638, 640, 641, 650, 651, 652, 653, 655, 657, 658, 659, 661, 662, 664, 665, 666], "extens": [45, 160, 162, 509, 516, 517, 565, 572, 574, 575, 605, 608, 609, 611, 613, 614, 615, 617, 622, 623, 624, 628, 631, 632, 636, 652, 653, 655, 658, 661, 664, 665, 666], "ipex": [45, 164, 170, 229, 230, 521, 564, 608, 613, 614, 618, 622, 623, 661], "pytorch_fxadaptor": 45, "fx": [45, 170, 229, 354, 434, 608, 614, 622, 623, 637, 653, 655, 657], "graph": [45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 112, 113, 114, 117, 130, 132, 136, 139, 142, 143, 145, 146, 147, 148, 201, 244, 287, 309, 373, 380, 423, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497, 499, 501, 502, 507, 571, 575, 596, 599, 601, 607, 615, 616, 635, 638, 655, 656, 657, 662], "pytorchweightonlyadaptor": 45, "querybackendcap": [46, 575, 576], "tensorflowadaptor": 47, "stock": [47, 622, 661], "spr": 47, "tensorflow_itexadaptor": 47, "itex": [47, 109, 229, 230, 307, 614, 655, 661], "tensorflowqueri": [47, 575], "performance_onli": [47, 48, 49, 107, 131, 136, 147, 229, 613], "itex_mod": [47, 48, 89, 107, 131, 136], "quant_mod": [47, 360, 440, 576, 577], "graphconvert": 48, "qt_config": 48, "recip": [48, 201, 229, 230, 309, 346, 574, 613, 656, 658, 661, 664], "int8_sequ": 48, "fp32_op": [48, 50, 107], "bf16_op": [48, 50, 107, 576, 657], "data_load": [48, 49, 575], "calib_func": [48, 154, 170, 171, 424, 522, 537, 538, 657], "fake_qu": [48, 88, 107, 131, 136], "qdq_enabl": 48, "new_api": [48, 49, 71, 72, 77, 79, 92, 99, 131, 136, 143, 482, 483, 488, 490], "use_bf16": [48, 49, 229, 654], "without": [49, 90, 148, 197, 213, 262, 303, 343, 362, 442, 502, 569, 599, 601, 613, 624, 635, 638, 652, 653, 654, 664, 665], "graphconverterwithoutcalib": 49, "recover_config": 49, "rewrit": [50, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 106, 107, 108, 109, 198, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 492, 493, 494, 495, 496, 497], "bf16convert": [50, 657], "rerewrit": 51, "dequantizecastoptim": 51, "b16": 51, "dequantize_cast_optim": [52, 87, 111], "biasadd": [53, 59, 64, 66, 109, 464, 470, 475, 477, 605], "convertaddtobiasaddoptim": [53, 464], "conv2d": [53, 59, 60, 61, 65, 66, 71, 125, 135, 143, 156, 461, 464, 470, 471, 472, 476, 477, 482, 523, 576, 577, 598, 603, 605, 638, 661, 662, 664], "addv2": [53, 69, 464, 480, 605], "layout": [54, 465], "convertlayoutoptim": [54, 465], "convers": [54, 55, 230, 320, 465, 466, 570, 575, 576, 613, 614, 655, 657, 661], "optim": [54, 74, 75, 79, 80, 116, 118, 148, 149, 153, 188, 191, 192, 193, 195, 198, 201, 210, 215, 226, 229, 230, 266, 272, 309, 310, 326, 346, 350, 363, 428, 465, 485, 486, 490, 491, 502, 554, 555, 562, 565, 572, 574, 592, 594, 598, 599, 600, 601, 605, 606, 608, 609, 611, 613, 615, 616, 618, 620, 621, 624, 627, 635, 638, 639, 640, 642, 644, 653, 654, 655, 657, 658, 660, 661, 662, 664, 666], "nchw": [54, 258, 465], "nhwc": [54, 258, 465], "It": [54, 162, 171, 184, 186, 190, 203, 233, 234, 271, 276, 277, 316, 318, 325, 341, 346, 353, 369, 371, 372, 424, 429, 433, 465, 516, 538, 554, 575, 576, 577, 593, 598, 599, 613, 619, 622, 627, 633, 634, 635, 636, 638, 639, 641, 652, 655, 658, 659, 660, 664, 666], "exist": [54, 177, 227, 263, 380, 465, 507, 509, 565, 603, 612, 620, 664], "abov": [54, 465, 575, 576, 577, 599, 635, 636, 638, 641, 652, 655, 661, 664], "graph_def": [54, 140, 141, 148, 307, 372, 380, 423, 424, 446, 449, 465, 502, 507], "leakyrelu": [55, 466, 661], "convertleakyreluoptim": [55, 466], "below": [55, 66, 74, 229, 230, 347, 371, 395, 424, 466, 477, 485, 570, 571, 574, 575, 576, 577, 595, 598, 599, 601, 607, 612, 616, 618, 626, 627, 630, 633, 636, 641, 650, 651, 652, 654, 655, 658, 660, 661, 662, 664, 665], "subgraph": [55, 66, 105, 168, 466, 477, 656, 664], "mul": [55, 65, 66, 69, 171, 175, 466, 476, 477, 480, 522, 603, 658, 661], "maximum": [55, 149, 179, 203, 208, 229, 230, 245, 262, 288, 303, 312, 343, 350, 365, 380, 428, 466, 507, 577, 593, 596, 598, 613, 652, 655, 661, 663], "note": [55, 160, 207, 314, 354, 367, 434, 466, 517, 572, 574, 576, 577, 594, 595, 598, 601, 603, 605, 609, 611, 613, 618, 621, 626, 630, 633, 635, 639, 641, 643, 652, 655, 658, 661, 662, 664, 665, 666], "coeffici": [55, 149, 218, 466, 652], "less": [55, 148, 170, 229, 230, 466, 509, 538, 565, 592, 599, 613, 640, 652], "than": [55, 148, 245, 262, 288, 303, 466, 509, 539, 565, 572, 574, 592, 596, 607, 638, 646, 650, 651, 652, 655, 658, 660, 663, 664], "valid": [55, 67, 68, 105, 184, 208, 211, 221, 229, 230, 247, 290, 314, 342, 343, 367, 380, 466, 478, 479, 507, 572, 574, 575, 596, 598, 599, 602, 605, 608, 610, 613, 624, 638, 652, 655, 658, 659], "nan": [56, 467], "random": [56, 148, 149, 185, 193, 229, 230, 258, 262, 300, 303, 310, 326, 350, 352, 363, 428, 432, 467, 502, 509, 565, 572, 613, 652, 654, 663, 666], "convertnantorandom": [56, 467], "const": [56, 57, 63, 64, 67, 68, 70, 82, 98, 467, 468, 474, 475, 478, 479, 481, 493], "consist": [56, 63, 467, 474, 570, 571, 594, 641, 661, 664], "placehold": [57, 243, 286, 468, 594], "convertplaceholdertoconst": [57, 468], "dilat": [58, 469], "contract": [58, 469], "dilatedcontract": [58, 469], "spacetobatchnd": [58, 469], "batchtospacend": [58, 469], "pattern": [58, 59, 61, 78, 96, 107, 108, 109, 131, 136, 170, 193, 194, 195, 196, 198, 201, 202, 208, 209, 210, 211, 213, 215, 216, 218, 226, 229, 230, 247, 290, 310, 331, 332, 334, 339, 343, 360, 363, 440, 469, 470, 472, 489, 575, 594, 596, 605, 608, 613, 634, 651, 654, 661, 664, 667], "inject": [59, 470, 613], "dummi": [59, 201, 248, 249, 291, 292, 318, 371, 470, 504, 574, 596, 606, 612, 613, 635], "injectdummybiasaddoptim": [59, 470], "fusion": [59, 61, 70, 78, 109, 126, 127, 128, 131, 132, 133, 137, 470, 472, 481, 489, 571, 575, 605], "expanddim": [60, 471], "expanddimsoptim": [60, 471], "next": [60, 238, 281, 443, 471, 572, 576, 577, 595, 654, 658, 664], "fetch": [61, 170, 174, 238, 281, 472, 576, 596, 646, 647, 648], "reshap": [61, 67, 68, 73, 472, 478, 479, 484, 661], "fetchweightfromreshapeoptim": [61, 472], "handl": [61, 148, 167, 175, 184, 472, 502, 561, 571, 573, 594, 595, 641, 661], "fold": [62, 63, 170, 171, 308, 396, 461, 473, 474, 522, 537, 538, 605, 658, 661], "foldbatchnormnodesoptim": [62, 473], "graphfoldconstantoptim": [63, 474], "sequenc": [63, 105, 149, 202, 205, 206, 229, 230, 245, 261, 262, 288, 302, 303, 312, 316, 341, 365, 369, 474, 526, 575, 596, 605, 652, 658, 663], "self": [63, 170, 171, 201, 229, 230, 382, 474, 522, 538, 539, 575, 576, 595, 596, 608, 612, 635, 660, 662, 664], "supported_op_typ": [63, 474], "fusebiasaddandaddoptim": [64, 475], "second": [64, 162, 202, 229, 230, 245, 288, 429, 475, 516, 565, 598, 613, 626, 630, 634, 646, 647, 658, 661, 664, 666], "columnwis": [65, 476], "fusecolumnwisemuloptim": [65, 476], "depthwiseconv2dn": [65, 71, 125, 135, 476, 482, 605], "math": [66, 477, 655], "fuseconvwithmathoptim": [66, 477], "elimin": [66, 477, 640], "sub": [66, 170, 177, 201, 263, 477, 521, 572, 594, 664], "realdiv": [66, 69, 477, 480], "decompos": [67, 68, 478, 479], "fusedecomposedbnoptim": [67, 478], "input_graph_def": [67, 68, 70, 478, 479, 481], "node_name_from_input": [67, 68, 70, 478, 479, 481], "node_nam": [67, 68, 70, 148, 380, 409, 478, 479, 481, 502, 507, 576], "strip": [67, 68, 70, 83, 84, 148, 478, 479, 481, 494, 495, 502, 662], "port": [67, 68, 70, 478, 479, 481, 635, 642], "other": [67, 68, 70, 149, 153, 160, 167, 175, 244, 287, 316, 369, 380, 478, 479, 481, 507, 517, 569, 571, 576, 577, 594, 598, 605, 608, 610, 613, 615, 636, 650, 652, 655, 661, 663, 664, 667], "underli": [67, 68, 70, 162, 478, 479, 481, 516], "node_from_map": [67, 68, 70, 478, 479, 481], "node_map": [67, 68, 70, 478, 479, 481], "pull": [67, 68, 70, 478, 479, 481], "def": [67, 68, 70, 179, 233, 234, 276, 277, 401, 424, 443, 478, 479, 481, 509, 539, 553, 554, 571, 575, 594, 595, 596, 599, 600, 601, 612, 613, 655, 661, 662, 664], "entri": [67, 68, 70, 157, 189, 269, 309, 347, 393, 394, 460, 463, 478, 479, 481, 544, 545, 549, 565, 594, 610], "index": [67, 68, 70, 105, 177, 221, 230, 238, 243, 247, 281, 286, 290, 325, 478, 479, 481, 565, 596, 612, 634, 638, 658, 661], "everi": [67, 68, 70, 203, 206, 208, 229, 230, 341, 343, 478, 479, 481, 575, 595, 621, 626, 630, 656, 658, 664], "identifi": [67, 68, 70, 162, 314, 367, 380, 478, 479, 481, 507, 516, 641, 652, 658], "want": [67, 68, 70, 201, 229, 230, 243, 245, 286, 288, 343, 429, 478, 479, 481, 539, 554, 571, 575, 595, 596, 601, 613, 621, 633, 634, 641, 650, 655, 658, 660, 662, 664], "nodedef": [67, 68, 70, 478, 479, 481], "rais": [67, 68, 70, 105, 160, 162, 170, 198, 204, 211, 221, 314, 341, 342, 343, 367, 372, 443, 478, 479, 481, 516, 517, 538, 574, 594, 635, 652, 653], "valueerror": [67, 68, 70, 170, 314, 367, 443, 478, 479, 481, 538, 604], "If": [67, 68, 70, 74, 162, 171, 177, 181, 229, 230, 233, 234, 247, 262, 276, 277, 290, 303, 342, 372, 424, 443, 478, 479, 481, 485, 516, 526, 538, 539, 554, 570, 571, 576, 592, 594, 595, 596, 601, 609, 610, 612, 613, 619, 627, 628, 631, 633, 639, 644, 650, 652, 655, 658, 660, 661, 662, 663, 664], "isn": [67, 68, 70, 478, 479, 481], "present": [67, 68, 70, 478, 479, 481, 598, 641, 653, 661], "values_from_const": [67, 68, 70, 478, 479, 481], "node_def": [67, 68, 70, 478, 479, 481], "extract": [67, 68, 70, 148, 201, 247, 290, 362, 442, 478, 479, 481, 502, 596], "ha": [67, 68, 70, 74, 149, 156, 162, 207, 208, 263, 311, 341, 343, 364, 443, 478, 479, 481, 485, 509, 516, 523, 570, 572, 575, 576, 577, 595, 603, 608, 613, 614, 619, 633, 638, 639, 641, 644, 652, 654, 655, 657, 660, 661, 664], "access": [67, 68, 70, 227, 230, 478, 479, 481, 560, 565, 628, 631, 635], "valid_reshape_input": [67, 68, 478, 479], "reshape_in0_ndef": [67, 68, 478, 479], "reshape_in1_ndef": [67, 68, 478, 479], "ar": [67, 68, 105, 150, 162, 170, 203, 208, 209, 210, 215, 216, 229, 230, 245, 262, 288, 303, 314, 318, 325, 341, 342, 343, 347, 349, 350, 367, 371, 387, 388, 390, 394, 425, 427, 428, 442, 443, 478, 479, 516, 521, 539, 557, 564, 565, 569, 570, 571, 572, 575, 576, 594, 595, 596, 598, 599, 600, 601, 602, 603, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 616, 619, 621, 624, 627, 633, 635, 636, 638, 639, 640, 641, 644, 650, 651, 652, 653, 655, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666], "bypass_reshap": [67, 68, 478, 479], "input_node_map": [67, 68, 478, 479], "input_nam": [67, 68, 102, 142, 230, 307, 308, 478, 479, 603], "get_const_dim_count": [67, 68, 478, 479], "dimens": [67, 68, 105, 149, 237, 262, 280, 303, 478, 479, 596, 599, 658, 663], "instancenorm": [68, 479, 661], "fusedecomposedinoptim": [68, 479], "gelu": [69, 480], "fusegeluoptim": [69, 480], "sqrt": [69, 480, 598], "erf": [69, 480], "layernorm": [70, 481, 661], "fuselayernormoptim": [70, 481], "remap": [70, 162, 481, 516], "smaller": [70, 262, 303, 481, 599, 613, 652, 663], "fusedbatcnormv3": [70, 481], "And": [70, 481, 570, 571, 592, 594, 613, 619, 661], "further": [70, 230, 481, 569, 614, 615, 616, 618, 627, 633, 655], "restrict": [70, 162, 229, 230, 481, 516, 652, 660], "2d": [70, 481, 661], "3d": [70, 481, 653, 661], "kera": [70, 116, 189, 201, 221, 230, 247, 254, 269, 290, 297, 375, 380, 461, 463, 481, 507, 509, 576, 595, 601, 615, 623, 624], "fusepadwithconv2doptim": [71, 482], "excluded_op_nam": [71, 72, 226, 229, 230, 482, 483, 613, 652], "cfg": [71, 72, 170, 226, 360, 440, 482, 483, 521, 557, 576, 577], "itex_qdq_mod": [71, 72, 482, 483], "conv3d": [71, 125, 482], "fusepadwithfp32conv2doptim": [72, 483], "fusetransposereshapeoptim": [73, 484], "cse": [74, 98, 485], "graphcseoptim": [74, 485], "introduc": [74, 485, 575, 576, 577, 605, 613, 655, 658, 659, 661, 665], "ident": [74, 80, 202, 485, 491, 569, 599], "three": [74, 221, 245, 288, 349, 425, 427, 485, 571, 575, 576, 593, 609, 614, 627, 641, 651, 655, 657, 660, 661, 662], "d": [74, 170, 485, 521, 599, 607, 634, 636, 642, 652, 667], "those": [74, 162, 353, 433, 485, 516, 565, 598, 599, 600, 607, 613, 614, 651, 652, 655, 664], "child": [74, 156, 163, 485, 518, 523, 662], "b1": [74, 485], "c1c2": [74, 485], "d1": [74, 485, 565], "c1": [74, 485], "c2": [74, 485], "memori": [74, 149, 150, 170, 309, 333, 338, 346, 382, 485, 538, 565, 593, 595, 600, 613, 614, 616, 650, 652, 655, 656, 658, 661, 664, 667], "bound": [74, 177, 194, 262, 303, 314, 350, 367, 428, 485, 612, 663], "like": [74, 96, 98, 148, 149, 162, 181, 201, 221, 230, 233, 234, 235, 247, 276, 277, 278, 290, 309, 318, 343, 346, 347, 371, 380, 394, 424, 485, 502, 504, 507, 516, 554, 570, 571, 572, 575, 576, 598, 599, 600, 608, 621, 636, 638, 651, 652, 655, 658, 659, 661, 664], "relu": [74, 78, 109, 485, 489, 571, 605, 661, 662], "relu6": [74, 485, 605], "updat": [74, 153, 163, 170, 196, 197, 203, 221, 343, 371, 424, 485, 518, 562, 604, 611, 612, 613, 619, 624, 627, 643, 652, 658, 661, 664, 665], "graphdef": [74, 148, 380, 423, 485, 502, 507, 615], "grappler": [75, 486, 605], "grappleroptim": [75, 486], "input_output_nam": [75, 486], "opt_cfg": [75, 486], "wrapper": [75, 102, 103, 104, 105, 122, 140, 149, 155, 165, 169, 187, 198, 244, 262, 264, 265, 267, 268, 287, 303, 314, 318, 367, 371, 376, 380, 446, 486, 506, 507, 535, 537, 657], "leverag": [75, 150, 486, 560, 572, 574, 599, 603, 616, 633, 651, 655, 658, 664], "built": [75, 189, 212, 231, 232, 236, 241, 245, 246, 251, 253, 255, 256, 258, 259, 262, 267, 269, 274, 275, 279, 282, 284, 288, 289, 294, 296, 298, 299, 300, 301, 303, 347, 371, 374, 382, 424, 486, 526, 554, 572, 575, 596, 601, 613, 626, 630, 650, 655, 660, 663, 664, 666], "convert_add_to_biasadd": [76, 87, 111, 487, 498], "convert_layout": [76, 87, 111, 487, 498], "convert_leakyrelu": [76, 87, 111, 487, 498], "convert_nan_to_random": [76, 87, 111, 487, 498], "convert_placeholder_to_const": [76, 87, 111, 487, 498], "dilated_contract": [76, 87, 111, 487, 498], "dummy_biasadd": [76, 87, 111, 487, 498], "expanddims_optim": [76, 87, 111, 487, 498], "fetch_weight_from_reshap": [76, 87, 111, 487, 498], "fold_batch_norm": [76, 87, 111, 487, 498], "fold_const": [76, 87, 111, 487, 498], "fuse_biasadd_add": [76, 87, 111, 487, 498], "fuse_column_wise_mul": [76, 87, 111, 487, 498], "fuse_conv_with_math": [76, 87, 111, 487, 498], "fuse_decomposed_bn": [76, 87, 111, 487, 498], "fuse_decomposed_in": [76, 87, 111, 487, 498], "fuse_gelu": [76, 87, 111, 487, 498], "fuse_layer_norm": [76, 87, 111, 487, 498], "fuse_pad_with_conv": [76, 87, 111, 487, 498], "fuse_pad_with_fp32_conv": [76, 87, 111, 487, 498], "fuse_reshape_transpos": [76, 87, 111, 487, 498], "graph_cse_optim": [76, 87, 111, 487, 498], "grappler_pass": [76, 87, 111, 487, 498], "insert_print_nod": [76, 87, 111, 487, 498], "move_squeeze_after_relu": [76, 87, 111, 487, 498], "pre_optim": [76, 87, 111, 487, 498], "remove_training_nod": [76, 87, 111, 487, 498], "rename_batch_norm": [76, 87, 111, 487, 498], "split_shared_input": [76, 87, 111, 487, 498], "strip_equivalent_nod": [76, 87, 111, 148, 487, 498, 502], "strip_unused_nod": [76, 87, 111, 148, 487, 498, 502], "switch_optim": [76, 87, 111, 487, 498], "insert": [77, 105, 107, 109, 113, 146, 149, 167, 175, 488, 538, 571, 576, 595, 608, 613, 616, 652, 655, 657, 658, 661, 662], "print": [77, 156, 157, 201, 318, 371, 443, 488, 523, 565, 601, 612, 613, 635, 636, 652, 661, 664], "insertprintminmaxnod": [77, 488], "pre_node_nam": [77, 488], "post_node_nam": [77, 488], "pass": [77, 148, 149, 160, 162, 177, 185, 371, 394, 424, 488, 502, 509, 516, 517, 533, 539, 564, 565, 570, 571, 575, 592, 596, 599, 600, 601, 607, 612, 613, 634, 641, 652, 654, 655, 657, 661, 666], "move": [78, 149, 162, 489, 516, 571, 639, 654, 658, 659], "squeez": [78, 489, 571], "movesqueezeafterreluoptim": [78, 489], "match": [78, 102, 162, 201, 314, 315, 367, 368, 489, 516, 599, 634, 658], "pre": [79, 116, 163, 201, 233, 234, 245, 276, 277, 288, 372, 424, 490, 518, 546, 554, 594, 596, 599, 600, 613, 621, 638, 652, 653, 655, 658, 662, 664], "entranc": [79, 194, 236, 490], "preoptim": [79, 490], "removetrainingnodesoptim": [80, 491], "protected_nod": [80, 491], "types_to_splic": [80, 491], "checknumer": [80, 491], "stopgradi": [80, 491], "renam": [81, 492, 659], "fusedbatchnorm": [81, 492], "fusedbatchnormv2": [81, 492], "renamebatchnormoptim": [81, 492], "splitsharedinputoptim": [82, 493], "equival": [83, 169, 494, 537, 574, 653, 658, 661], "stripequivalentnodesoptim": [83, 494], "output_node_nam": [83, 84, 131, 132, 136, 148, 494, 495, 502], "same": [83, 141, 148, 150, 171, 179, 197, 215, 230, 245, 262, 288, 303, 314, 367, 449, 494, 502, 522, 526, 539, 565, 575, 577, 592, 595, 596, 599, 601, 605, 613, 617, 621, 626, 630, 652, 654, 655, 658, 661, 662, 663, 664], "unus": [84, 148, 495, 502], "stripunusednodesoptim": [84, 495], "input_node_nam": [84, 131, 136, 148, 495, 502], "switch": [85, 496, 616, 662], "switchoptim": [85, 496], "condit": [85, 245, 246, 247, 262, 288, 289, 290, 303, 349, 425, 427, 496, 596, 610, 663, 664], "graphrewriterbas": [86, 497], "abstract": [86, 186, 194, 262, 303, 304, 309, 346, 497, 575, 577, 607], "freeze_fake_qu": [87, 95, 111], "freeze_valu": [87, 95, 111], "freeze_value_without_calib": [87, 95, 111], "fuse_conv_redundant_dequant": [87, 95, 111], "fuse_conv_requant": [87, 95, 111], "fuse_matmul_redundant_dequant": [87, 95, 111], "fuse_matmul_requant": [87, 95, 111], "meta_op_optim": [87, 95, 111], "post_hostconst_convert": [87, 95, 111], "post_quantized_op_cs": [87, 95, 111], "rnn_convert": [87, 95, 111], "scale_propag": [87, 95, 111], "onnx_graph": [87, 101, 111], "onnx_schema": [87, 101, 111], "tf2onnx_util": [87, 101, 111], "insert_qdq_pattern": [87, 106, 111], "merge_duplicated_qdq": [87, 106, 111], "share_qdq_y_pattern": [87, 106, 111], "freez": [88, 89, 90, 148, 502, 616, 652], "fakequ": 88, "freezefakequantopoptim": 88, "follow": [88, 110, 179, 202, 247, 290, 311, 314, 364, 367, 499, 569, 570, 571, 572, 575, 576, 577, 594, 595, 596, 599, 600, 601, 605, 609, 610, 612, 613, 614, 615, 616, 617, 618, 626, 630, 635, 637, 638, 641, 646, 651, 652, 654, 655, 658, 661, 662, 664], "freezevaluetransform": 89, "max_min_data": [89, 90], "postfix": [89, 90], "tensor_data": [89, 509, 565, 566], "th": [89, 90], "gpu": [89, 90, 97, 149, 162, 229, 230, 516, 539, 574, 592, 608, 613, 614, 618, 624, 633, 654, 655, 656], "freezevaluewithoutcalibtransform": 90, "95": [90, 318, 371, 612, 667], "quantizedconv": [91, 92], "quantizeddeconv": 91, "redund": [91, 93], "fuseconvredundantdequantizetransform": 91, "cpu": [91, 92, 93, 94, 149, 150, 156, 161, 162, 164, 170, 229, 230, 509, 516, 523, 539, 560, 565, 574, 576, 592, 593, 608, 613, 614, 616, 618, 624, 633, 641, 653, 654, 655, 656, 657, 658, 662], "_quantizedconv": 91, "_quantizeddeconv": 91, "successor": [91, 92, 93, 94], "requant": [92, 94, 662], "fuseconvrequantizetransform": 92, "quantizedmatmul": [93, 94], "fusematmulredundantdequantizetransform": 93, "_quantizedmatmul": [93, 94], "fusematmulrequantizedequantizetransform": 94, "quantizedmatmulwithbiasanddequant": 94, "fusematmulrequantizetransform": 94, "fusematmulrequantizedequantizenewapitransform": 94, "fusematmulrequantizenewapitransform": 94, "newapi": 94, "meta": [96, 611, 653, 667], "metainfochangingmemopoptim": 96, "metaop": 96, "With": [96, 382, 571, 575, 577, 595, 613, 621, 626, 630, 634, 640, 650, 652, 653, 660, 661, 664, 667], "better": [96, 229, 230, 233, 234, 276, 277, 325, 372, 424, 554, 594, 600, 612, 614, 652, 653, 655, 658, 660, 661, 664], "perform": [96, 140, 149, 153, 177, 218, 229, 230, 245, 257, 258, 263, 288, 300, 309, 333, 338, 346, 353, 371, 382, 424, 429, 433, 446, 447, 539, 570, 571, 572, 575, 576, 592, 596, 597, 598, 600, 602, 603, 608, 609, 612, 613, 614, 615, 616, 618, 622, 624, 627, 633, 639, 650, 651, 652, 653, 654, 655, 656, 657, 658, 661, 662, 664, 666, 667], "hostconst": 97, "posthostconstconvert": 97, "just": [97, 235, 260, 262, 265, 267, 268, 270, 278, 303, 382, 504, 572, 613, 623, 627, 633, 641, 651, 655, 661, 663, 664], "postcseoptim": 98, "duplic": [98, 108, 350, 428], "quantizev2": 98, "decreas": [98, 638, 652], "size": [98, 149, 171, 179, 205, 206, 237, 238, 244, 247, 253, 258, 262, 280, 281, 287, 290, 296, 300, 303, 341, 380, 382, 387, 388, 390, 507, 538, 565, 569, 576, 595, 596, 601, 604, 613, 633, 634, 650, 652, 655, 656, 658, 661, 663, 666, 667], "rnn": 99, "quantizedrnnconvert": 99, "calibration_data": [99, 107], "rnn_detail": 99, "scalepropagationtransform": 100, "direct": [100, 207, 341, 652], "export": [101, 230, 310, 314, 363, 367, 574, 606, 619, 634, 636, 662, 665], "onnxgraph": 102, "output_shap": 102, "extra_opset": 102, "output_nam": [102, 142, 230, 307, 308, 603], "is_subgraph": 102, "graph_nam": 102, "manipul": [102, 103], "onnxnod": 103, "skip_convers": 103, "schema": [104, 171, 538], "onnxopschema": 104, "domain": [104, 105, 229, 230, 652, 664], "since_vers": 104, "get_schema": 104, "max_inclusive_opset_vers": 104, "within": [104, 178, 209, 210, 215, 216, 224, 309, 314, 346, 367, 380, 418, 423, 507, 569, 571, 577, 593, 614, 626, 630, 633, 641, 652, 653, 661, 664], "get_max_supported_opset_vers": 104, "packag": [104, 575, 604, 609, 633, 634, 653, 659, 664], "set_nam": 105, "find_opset": 105, "assert_error": 105, "bool_val": 105, "error_msg": 105, "messag": [105, 146, 570, 641, 642, 646, 647, 648, 664], "map_numpy_to_onnx_dtyp": 105, "np_dtype": 105, "map_onnx_to_numpy_typ": 105, "onnx_typ": 105, "add_port_to_nam": 105, "nr": 105, "get_tensorflow_node_attr": 105, "pars": [105, 148, 170, 245, 246, 258, 262, 288, 289, 300, 303, 407, 408, 412, 502, 521, 576, 577, 663], "get_tensorflow_tensor_shap": 105, "get_tensorflow_node_shape_attr": 105, "attr": [105, 148, 201, 502], "map_tensorflow_dtyp": 105, "get_tensorflow_tensor_data": 105, "convert_tensorflow_tensor_to_onnx": 105, "read_tensorflow_node_attr": 105, "read": [105, 148, 162, 250, 262, 293, 303, 342, 502, 516, 596, 657, 660], "infer_onnx_shape_dtyp": 105, "opset_vers": [105, 142, 230, 307, 308, 603], "input_shap": [105, 249, 292, 504, 596], "input_dtyp": 105, "sometim": [105, 571, 598, 655], "make_onnx_shap": 105, "seqtyp": 105, "tensor_dtyp": 105, "around": 105, "signifi": 105, "make_onnx_inputs_output": 105, "elem_typ": 105, "text": [105, 149, 153, 217, 261, 262, 302, 303, 311, 316, 344, 364, 369, 603, 610, 622, 644, 647, 648, 652, 653, 658, 661, 663, 667], "datatyp": [105, 170, 657, 664, 667], "save_protobuf": 105, "path": [105, 140, 148, 150, 163, 170, 201, 217, 221, 226, 245, 246, 247, 262, 288, 289, 290, 303, 304, 307, 308, 309, 320, 321, 322, 324, 333, 338, 342, 344, 346, 347, 360, 372, 380, 385, 387, 388, 390, 393, 394, 401, 423, 424, 440, 446, 502, 507, 509, 518, 560, 562, 565, 571, 572, 575, 596, 598, 601, 607, 612, 613, 614, 615, 619, 622, 633, 636, 638, 641, 646, 647, 648, 651, 658, 663, 666], "as_text": 105, "save": [105, 148, 161, 162, 198, 221, 229, 230, 247, 290, 307, 308, 347, 380, 424, 502, 507, 509, 516, 554, 555, 560, 565, 571, 575, 607, 613, 614, 615, 617, 621, 626, 630, 636, 641, 646, 647, 648, 651, 655, 656, 658, 661], "protobuf": [105, 380, 507, 636], "is_onnx_domain": 105, "is_list_or_tupl": 105, "are_shapes_equ": 105, "src": [105, 634], "dest": 105, "equal": [105, 143, 148, 176, 443, 509, 565, 652, 658], "get_subgraphs_from_onnx": 105, "model_proto": 105, "over": [105, 162, 247, 290, 318, 371, 516, 576, 602, 606, 608, 612, 624, 633, 639, 643, 652, 654, 661, 664], "df": 105, "initialize_name_count": 105, "avoid": [105, 162, 170, 171, 245, 288, 516, 522, 538, 571, 594, 662], "conflict": [105, 594, 604], "counter": 105, "make_nam": 105, "get_index_from_strided_slice_of_shap": 105, "outputs_to_valu": 105, "stride": [105, 262, 303, 663], "slice": 105, "compute_const_folding_using_tf": 105, "g": [105, 149, 153, 162, 203, 229, 230, 516, 539, 570, 599, 602, 606, 616, 621, 652, 658, 659, 661, 664], "const_node_valu": 105, "graph_output": 105, "constant": [105, 308, 310, 350, 352, 358, 363, 428, 432, 438, 558, 594, 595, 605, 636, 663], "tf": [105, 116, 141, 148, 201, 221, 244, 245, 246, 247, 262, 287, 288, 289, 290, 303, 378, 380, 449, 461, 502, 506, 507, 508, 509, 594, 601, 609, 615, 653, 657, 663], "generategraphwithqdqpattern": 107, "op_wise_config": [107, 131, 136, 576], "quantized_nod": 107, "llm_weight_minmax": 107, "dq": [107, 109, 131, 661], "pair": [107, 229, 230, 576, 595, 613, 614, 659], "befor": [107, 109, 150, 156, 175, 193, 203, 208, 210, 215, 217, 219, 229, 230, 245, 288, 341, 343, 345, 523, 570, 577, 595, 596, 599, 600, 601, 604, 605, 609, 613, 628, 631, 637, 638, 655, 658, 660, 662, 664], "merg": [108, 237, 280, 360, 440, 628, 631, 662, 664], "mergeduplicatedqdqoptim": 108, "y": [109, 229, 230, 262, 303, 350, 428, 594, 598, 604, 619, 661, 663], "shareqdqforitexypatternoptim": 109, "break": [109, 601, 613], "graphanalyz": [110, 499], "extend_engin": [110, 499], "analyz": [110, 201, 380, 499, 507, 660, 661, 662], "under": [110, 150, 229, 230, 247, 290, 401, 499, 509, 539, 553, 560, 564, 570, 572, 574, 596, 610, 612, 613, 616, 621, 622, 633, 641, 651, 652, 653, 656, 658, 662, 664], "singleton": [110, 499, 509, 565], "specifi": [110, 149, 162, 170, 177, 181, 221, 229, 230, 233, 234, 262, 263, 276, 277, 303, 309, 314, 318, 320, 321, 324, 333, 338, 346, 347, 367, 371, 372, 424, 443, 499, 516, 520, 521, 526, 554, 564, 565, 576, 577, 601, 605, 612, 613, 621, 635, 641, 645, 646, 647, 648, 650, 652, 654, 658, 663, 664, 666], "graphrewriterhelp": [110, 499], "encapsul": [110, 233, 234, 276, 277, 372, 424, 499, 554, 615], "quantize_lay": [111, 112, 114], "fake_quant": [111, 112, 114], "quantize_config": [111, 112, 114, 576], "quantize_help": [111, 112, 114], "quantize_wrapp": [111, 112, 114], "fuse_qdq_bn": [111, 112, 130], "fuse_qdq_concatv2": [111, 112, 130], "fuse_qdq_conv": [111, 112, 130], "fuse_qdq_deconv": [111, 112, 130], "fuse_qdq_in": [111, 112, 130], "fuse_qdq_matmul": [111, 112, 130], "fuse_qdq_pool": [111, 112, 130], "optimize_qdq": [111, 112, 130], "optimize_lay": [112, 114, 117], "quantize_layer_add": [112, 114, 117], "quantize_layer_bas": [112, 114, 117], "quantize_layer_bn": [112, 114, 117], "fakequantizebas": 113, "abc": [113, 316, 369, 524, 575, 662, 664], "fakequant": 113, "per_channel": [113, 576, 577, 605, 655, 666], "8": [113, 149, 162, 171, 229, 230, 261, 302, 394, 516, 538, 546, 571, 576, 593, 594, 605, 609, 640, 641, 652, 653, 658, 661, 664, 667], "channel_axi": [113, 173, 176], "symmetr": [113, 149, 150, 387, 388, 390, 560, 577, 655, 658, 663, 664], "narrow_rang": 113, "quantizeconfig": [115, 116], "custom": [115, 149, 160, 170, 171, 177, 230, 347, 371, 382, 517, 522, 538, 564, 592, 599, 600, 616, 639, 640, 641, 645, 647, 648, 652, 653, 658, 660], "There": [115, 347, 349, 425, 427, 594, 598, 599, 605, 608, 613, 616, 638, 640, 641, 658, 661, 664, 666], "instanc": [115, 116, 177, 197, 229, 230, 233, 234, 263, 276, 277, 315, 316, 318, 321, 324, 327, 328, 330, 331, 332, 350, 362, 368, 369, 371, 372, 424, 428, 442, 539, 554, 562, 565, 569, 570, 571, 575, 592, 613, 618, 624, 658, 664, 666, 667], "global": [115, 203, 229, 230, 327, 328, 330, 331, 332, 341, 442, 565, 571, 613, 652, 654, 664], "class": [116, 152, 160, 170, 198, 204, 211, 325, 372, 424, 517, 548, 571, 572, 576, 594, 595, 596, 599, 612, 613, 624, 650, 651, 655, 659, 662, 664, 666], "init_quantize_config": 116, "quantize_recip": 116, "begin": [116, 153, 209, 210, 215, 343, 594, 595, 599, 600, 613, 652, 664], "process": [116, 140, 149, 157, 177, 184, 203, 208, 209, 210, 217, 219, 221, 229, 230, 233, 234, 245, 246, 247, 258, 262, 263, 276, 277, 288, 289, 290, 300, 303, 341, 343, 345, 349, 350, 372, 424, 425, 427, 428, 446, 520, 539, 554, 564, 565, 572, 575, 576, 577, 593, 595, 596, 599, 600, 601, 603, 613, 617, 638, 640, 641, 643, 651, 652, 655, 656, 658, 661, 662, 663, 666], "model_nam": [116, 229, 230], "special": [116, 162, 201, 382, 516, 571, 595, 612, 613, 650, 652, 658, 665], "decid": [116, 179, 229, 230, 312, 343, 365, 575, 576, 613, 655, 659, 664], "qat_clone_funct": 116, "leav": [116, 627], "quantizewrapp": [116, 122], "wrapped_lay": [116, 197], "config_quantizable_lay": 118, "quantizelayeradd": 119, "quantizelay": 120, "quantizelayerbas": 120, "quantizelayerbatchnorm": 121, "quantizewrapperbas": 122, "fusedbatchnormv3": [123, 133], "fusenodestartwithfusedbatchnormv3": [123, 133], "_quantizedfusedbatchnorm": 123, "concatv2": [124, 134, 147, 605], "fusenodestartwithconcatv2": [124, 134], "quantizedconcatv2": [124, 134], "fusenodestartwithconv2d": [125, 135], "conv2dbackpropinput": 126, "conv3dbackpropinputv2": 126, "fusenodestartwithdeconv2d": 126, "fusedinstancenorm": 127, "fusenodestartwithfusedinstancenorm": 127, "batchmatmul": 128, "batchmatmulv2": 128, "fusenodestartwithmatmul": [128, 137], "avgpool": [129, 138, 605], "fusenodestartwithpool": [129, 138], "optimizeqdqgraph": 131, "input_graph": [131, 136, 143, 419, 423, 575], "op_wise_sequ": [131, 136], "quantizegraph": 132, "quantizegraphbas": 132, "quantizenodebas": 132, "quantizegraphforintel": 136, "common": [139, 160, 162, 193, 230, 260, 310, 320, 324, 325, 326, 363, 394, 396, 461, 463, 501, 516, 517, 545, 546, 549, 557, 569, 594, 596, 600, 601, 603, 607, 609, 613, 655, 661], "herlper": [139, 501], "quantizegraphhelp": [139, 501], "sever": [139, 219, 262, 303, 345, 347, 501, 572, 598, 599, 600, 608, 613, 614, 626, 630, 641, 652, 654, 656, 661, 663, 664, 666], "staticmethod": [139, 501], "function": [139, 140, 160, 184, 209, 210, 215, 229, 230, 233, 234, 246, 276, 277, 289, 321, 324, 333, 338, 385, 446, 501, 517, 570, 571, 572, 575, 576, 577, 592, 595, 599, 600, 603, 607, 608, 609, 611, 612, 613, 614, 624, 634, 640, 641, 652, 655, 658, 659, 660, 661, 662, 664, 665], "smoothquantcalibr": [140, 446], "dataset": [140, 141, 149, 170, 217, 233, 234, 235, 237, 238, 242, 243, 244, 256, 265, 276, 277, 278, 280, 281, 285, 286, 287, 299, 310, 314, 315, 316, 318, 347, 363, 367, 368, 369, 371, 372, 424, 446, 449, 504, 538, 554, 557, 572, 574, 575, 576, 595, 601, 606, 612, 613, 621, 635, 636, 646, 652, 655, 658, 659, 661, 664, 666, 667], "outlier": [140, 446, 576, 593, 598, 638, 658, 661], "smoothquantcalibrationllm": [140, 446], "model_path": [140, 148, 171, 446, 502, 523, 546, 598, 646], "temp_path": [140, 446], "weight_name_map": [140, 446], "llm": [140, 141, 149, 156, 216, 446, 449, 523, 574, 652, 653, 656, 658, 661], "eval_func": [140, 233, 234, 276, 277, 347, 350, 351, 353, 354, 355, 356, 372, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 443, 446, 554, 571, 595, 596, 598, 599, 600, 601, 613, 636, 655, 656, 657, 658, 664, 666], "temporari": [140, 170, 446, 565, 569], "store": [140, 194, 196, 198, 201, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 220, 229, 230, 247, 290, 336, 343, 446, 607], "median": [140, 446], "autotrack": [140, 148, 446, 502], "smoothquantscal": [141, 449], "alpha": [141, 161, 165, 175, 196, 218, 396, 449, 461, 535, 594, 655, 664], "scales_per_op": [141, 396, 449, 461], "individu": [141, 203, 341, 418, 423, 449, 569, 641, 652, 661], "smoothquantscalerllm": [141, 449], "tensorflowqdqtoonnxqdqconvert": 142, "shape_overrid": 142, "inputs_as_nchw": [142, 307], "default_opset_vers": 142, "bia": [143, 229, 230, 658, 662], "correct": [143, 176, 221, 229, 230, 314, 315, 316, 318, 342, 367, 368, 369, 371, 569, 616], "biascorrect": 143, "fp32_graph": 143, "weight_empir": 143, "Will": [143, 599, 608], "our": [143, 170, 229, 230, 395, 572, 574, 603, 613, 634, 635, 638, 660, 665], "task": [143, 245, 252, 288, 295, 318, 371, 596, 599, 600, 603, 608, 612, 613, 636, 640, 643, 652, 656, 658, 661, 667], "close": [143, 176, 593, 642], "w_int8": [143, 176], "u": [143, 176, 616, 635, 640], "w_fp32": [143, 176], "varianc": [143, 176, 197, 598], "differ": [143, 153, 172, 176, 178, 181, 187, 193, 212, 229, 230, 238, 247, 262, 264, 281, 290, 303, 309, 318, 324, 326, 335, 346, 371, 382, 559, 569, 571, 572, 576, 595, 596, 598, 599, 601, 602, 607, 608, 612, 613, 615, 626, 630, 635, 638, 641, 650, 652, 655, 658, 661, 662, 663, 664], "wise": [143, 159, 161, 163, 171, 176, 229, 230, 350, 353, 388, 428, 429, 433, 515, 518, 536, 574, 576, 608, 638, 652, 658, 661, 662, 664, 665, 666], "minim": [143, 153, 176, 350, 428, 576, 577, 593, 599, 602, 612, 613, 626, 630, 652, 655, 664], "scale_c": [143, 176], "shift": [143, 176, 258, 300, 634, 663], "notic": [143, 176, 263, 610, 614, 636, 659], "first": [143, 149, 162, 170, 176, 178, 202, 227, 229, 230, 245, 288, 314, 360, 367, 429, 440, 509, 516, 538, 565, 571, 572, 575, 576, 577, 596, 598, 609, 614, 618, 627, 628, 631, 634, 636, 637, 638, 654, 655, 657, 658, 660, 661, 662, 664, 666], "empir": [143, 176], "solut": [143, 176, 574, 575, 576, 604, 618, 622, 627, 653, 658, 659, 661, 664, 665], "don": [143, 176, 203, 229, 230, 571, 639, 652, 664], "min": [143, 149, 171, 176, 194, 230, 396, 509, 538, 565, 598, 636, 638, 652, 655, 658, 661, 663, 664], "graphtransform": 144, "graphtransformbas": 144, "input_pb": [144, 146, 147], "log": [146, 177, 184, 201, 407, 408, 412, 561, 571, 624, 646, 647, 648, 660, 662, 664], "insertlog": 146, "node_name_list": 146, "show_nam": 146, "show_op": 146, "first_n": 146, "summar": [146, 594, 599], "1024": [146, 247, 290, 619], "dump_fp32": 146, "rerang": 147, "rerangequantizedconcat": 147, "rerange_quant": 147, "version1_lt_version2": [148, 509, 565], "version1": [148, 509, 565], "version2": [148, 509, 565], "version1_gt_version2": [148, 509, 565], "greater": [148, 509, 565, 646, 652, 664], "version1_eq_version2": [148, 509, 565], "version1_gte_version2": [148, 509, 565], "version1_lte_version2": [148, 509, 565], "disable_random": [148, 502, 509], "seed": [148, 149, 185, 193, 229, 230, 326, 502, 509, 565, 613, 666], "disabl": [148, 229, 230, 502, 509, 569, 633, 638, 657, 658, 661], "read_graph": [148, 502], "in_graph": [148, 502], "in_graph_is_binari": [148, 502], "write_graph": [148, 502], "out_graph_def": [148, 502], "out_graph_fil": [148, 502], "write": [148, 254, 297, 502, 565, 601, 607, 613, 616, 662], "is_ckpt_format": [148, 502], "ckpt": [148, 372, 380, 424, 502, 507, 667], "folder": [148, 247, 252, 290, 295, 372, 424, 502, 564, 596, 621, 626, 630, 639, 646, 647, 648, 658, 662], "is_saved_model_format": [148, 502], "saved_model": [148, 320, 502, 656], "get_estimator_graph": 148, "estim": [148, 149, 318, 371, 380, 507, 664], "input_fn": [148, 380, 507], "get_tensor_by_nam": [148, 502], "try_cnt": [148, 502], "import": [148, 153, 177, 179, 194, 229, 230, 320, 372, 382, 424, 443, 502, 509, 554, 565, 571, 572, 574, 577, 592, 595, 596, 598, 599, 600, 601, 603, 606, 612, 613, 614, 615, 616, 620, 622, 635, 636, 644, 650, 651, 652, 654, 655, 656, 657, 659, 660, 661, 662, 663, 664, 665], "scope": [148, 502, 570, 576, 613], "onc": [148, 162, 189, 219, 269, 345, 349, 425, 427, 502, 516, 576, 577, 595, 633, 639, 652, 653, 664, 667], "both": [148, 150, 179, 230, 502, 569, 572, 575, 600, 613, 617, 636, 638, 640, 652, 654, 655, 658, 661, 664], "compat": [148, 380, 502, 507, 570, 601, 615, 628, 631, 633, 652, 659], "v1": [148, 257, 258, 300, 315, 316, 318, 368, 369, 371, 380, 502, 507, 601, 603, 604, 612, 615, 637, 652, 659, 660, 661, 667], "suffix": [148, 502], "time": [148, 162, 179, 185, 197, 229, 230, 262, 303, 318, 350, 371, 382, 428, 502, 509, 516, 533, 565, 576, 595, 598, 601, 604, 613, 621, 623, 626, 630, 633, 634, 639, 642, 646, 647, 650, 652, 653, 655, 658, 660, 661, 662, 663, 664], "got": [148, 502, 576, 604, 662], "iterator_sess_run": [148, 502], "sess": [148, 380, 502, 507], "iter_op": [148, 502], "feed_dict": [148, 244, 287, 502], "output_tensor": [148, 380, 502, 507], "measur": [148, 263, 372, 502, 559, 572, 575, 592, 598, 599, 612, 613, 658, 662, 664, 667], "integr": [148, 187, 264, 502, 575, 613, 634, 635, 640, 658], "makeiter": [148, 502], "feed": [148, 244, 287, 502, 599, 652], "end": [148, 153, 208, 209, 210, 215, 229, 230, 245, 261, 262, 288, 302, 303, 343, 349, 425, 427, 502, 575, 576, 577, 599, 600, 605, 609, 613, 627, 643, 650, 652, 662, 663, 664], "predict": [148, 262, 267, 303, 311, 315, 316, 318, 364, 368, 369, 371, 424, 502, 572, 599, 612, 624, 658, 661, 662, 663], "pred": [148, 318, 371, 502, 612], "collate_tf_pr": [148, 502], "collat": [148, 170, 502], "get_input_output_node_nam": [148, 502], "fix_ref_type_of_graph_def": [148, 502], "fix": [148, 213, 215, 245, 288, 343, 502, 595, 596, 620, 652, 655, 658, 664], "strip_unused_lib": [148, 502], "offici": [148, 311, 315, 316, 364, 368, 369, 502, 569, 661], "r1": [148, 502], "15": [148, 502, 605, 609, 647], "branch": [148, 502, 570], "get_graph_def": [148, 502], "auto_input_output": [148, 502], "get_model_input_shap": [148, 502], "get_tensor_val_from_graph_nod": [148, 502], "graph_node_name_map": [148, 502], "kei": [148, 149, 157, 162, 163, 167, 201, 212, 221, 227, 229, 230, 325, 342, 380, 443, 502, 507, 509, 516, 518, 538, 555, 557, 565, 574, 576, 635, 636, 642, 653, 658, 662, 664], "val": [148, 221, 247, 250, 290, 293, 342, 502, 598, 613, 638], "tensor_v": [148, 502], "int8_node_name_revers": [148, 502], "revers": [148, 502, 636], "tf_diagnosis_help": [148, 502], "fp32_model": [148, 157, 170, 308, 502, 565, 575, 656, 658], "quan_model": [148, 502], "save_path": [148, 307, 308, 502, 575, 615], "diagnosi": [148, 229, 230, 502, 613, 636, 637, 638, 653, 659, 665], "generate_feed_dict": [148, 502], "input_tensor": [148, 197, 380, 502, 507], "get_weight_from_input_tensor": [148, 502], "input_tensor_nam": [148, 380, 502, 507], "associ": [148, 162, 314, 367, 502, 516], "search": [148, 156, 171, 193, 194, 201, 215, 226, 230, 233, 234, 276, 277, 309, 311, 321, 324, 325, 326, 346, 350, 364, 387, 428, 502, 523, 536, 538, 565, 574, 594, 608, 612, 616, 617, 627, 652, 653, 658, 661, 662, 664, 665], "look": [148, 212, 502, 575, 577, 605, 612, 635, 636, 638, 661, 666], "sq_weight_tensor": [148, 502], "sq_weights_nod": [148, 502], "two": [148, 157, 162, 177, 202, 207, 214, 219, 247, 252, 263, 290, 295, 314, 341, 345, 347, 354, 367, 434, 502, 516, 565, 570, 571, 572, 594, 595, 596, 599, 601, 603, 605, 613, 614, 640, 641, 643, 652, 655, 657, 658, 660, 661, 664, 666], "apply_inlin": [148, 502], "func": [148, 170, 502, 538, 565, 655, 666], "inlin": [148, 502, 616, 621, 624], "definit": [148, 152, 165, 238, 243, 281, 286, 502, 535, 548], "concret": [148, 502, 664], "new_graph_def": [148, 502], "construct_function_from_graph_def": [148, 502], "frozen_func": [148, 502], "rebuild": [148, 502, 617, 626, 630], "reconstruct": [148, 502, 653], "new_func": [148, 502], "parse_saved_model": [148, 502], "output_tensor_nam": [148, 380, 502, 507], "_saved_model": [148, 502], "load": [148, 160, 162, 163, 245, 261, 262, 288, 302, 303, 372, 380, 424, 502, 507, 509, 514, 515, 517, 518, 564, 565, 576, 595, 626, 630, 634, 636, 654, 655, 656, 661], "reconstruct_saved_model": [148, 502], "trackabl": [148, 502], "destin": [148, 306, 320, 502], "quant_weight_asym": 149, "v": [149, 153, 624, 633, 652, 664, 666], "min_scal": 149, "max_scal": 149, "asymmetr": [149, 577, 655, 658, 664], "e": [149, 162, 203, 229, 230, 516, 539, 569, 570, 599, 602, 606, 616, 621, 622, 626, 630, 652, 658, 661, 664], "perturb": 149, "minimum": [149, 203, 229, 230, 577, 593, 598, 613, 624, 652, 661, 664], "quant_weight_sym": 149, "quant_weight_actor": 149, "quant_weight": [149, 171], "hand": [149, 572], "issu": [149, 569, 570, 573, 574, 609, 636, 638, 655, 662], "quant_weight_w_scal": [149, 171, 538], "round_st": 149, "torch": [149, 150, 152, 153, 155, 156, 157, 158, 159, 162, 163, 165, 166, 167, 168, 170, 171, 175, 198, 201, 202, 204, 212, 226, 229, 230, 308, 372, 424, 560, 564, 571, 574, 577, 578, 599, 601, 603, 613, 614, 615, 616, 621, 624, 636, 655, 658, 661, 662], "straight": 149, "through": [149, 157, 233, 234, 276, 277, 371, 372, 424, 574, 592, 605, 607, 608, 612, 619, 640, 650, 651, 652, 654, 655, 658], "omniqu": 149, "saveinput": 149, "seqlen": 149, "256": [149, 252, 258, 295, 300, 546, 596, 601, 613, 663], "block_nam": 149, "cach": [149, 245, 288, 539, 604, 655, 658], "get_modul": [149, 163, 167, 518, 538], "nn": [149, 152, 156, 163, 165, 167, 170, 171, 201, 202, 212, 224, 229, 230, 308, 372, 424, 518, 521, 522, 523, 535, 538, 539, 544, 545, 548, 549, 553, 560, 564, 571, 599, 613, 615, 658, 661, 662], "set_modul": [149, 167, 170, 538, 553], "new_modul": [149, 163, 167, 170, 518, 538, 553], "get_scale_shap": 149, "wrapper_block": 149, "enable_minmax_tun": 149, "conv1d": [149, 156, 224, 523, 577], "indic": [149, 162, 178, 179, 186, 197, 229, 230, 238, 243, 245, 281, 286, 288, 304, 314, 325, 367, 387, 388, 390, 516, 524, 571, 595, 604, 636, 641, 662], "unwrapper_block": 149, "unwrap": 149, "wrapperlinear": 149, "wrappertransformerconv1d": 149, "sampling_input": 149, "input_id": [149, 245, 262, 288, 303, 613], "input_oth": 149, "length": [149, 212, 229, 230, 245, 262, 288, 303, 314, 367, 574, 596, 612, 653, 655, 658, 663], "id": [149, 177, 261, 263, 302, 311, 313, 314, 315, 316, 364, 366, 367, 368, 369, 612, 641, 642, 646, 647, 648, 660, 664], "current_input_id": 149, "current_input_oth": 149, "move_input_to_devic": 149, "check_is_cpu": 149, "otherwis": [149, 162, 247, 262, 290, 303, 516, 565, 569, 576, 596, 628, 631, 654, 658, 663], "block_forward": 149, "amp_dtyp": 149, "automat": [149, 199, 201, 202, 229, 230, 247, 250, 257, 258, 290, 293, 300, 309, 319, 346, 571, 574, 592, 596, 608, 613, 614, 616, 618, 621, 622, 624, 626, 627, 628, 630, 631, 633, 640, 643, 651, 652, 655, 661, 663, 664], "mix": [149, 155, 164, 229, 230, 348, 360, 372, 426, 440, 539, 574, 575, 582, 608, 616, 622, 623, 624, 665], "precis": [149, 155, 164, 229, 230, 233, 234, 276, 277, 309, 316, 318, 319, 346, 348, 360, 369, 371, 372, 382, 426, 429, 440, 539, 565, 574, 575, 576, 582, 592, 593, 600, 601, 605, 608, 616, 622, 623, 624, 653, 654, 655, 658, 661, 664, 665], "collect_round_v": 149, "collect_minmax_scal": 149, "get_batch_dim": 149, "posit": [149, 179, 197, 262, 303, 549, 569, 612, 616, 641, 646, 647, 648], "dim": [149, 262, 303, 661, 663], "wrappermultiblock": 149, "module_list": 149, "act": [149, 221, 243, 286, 569], "singl": [149, 179, 196, 219, 229, 230, 238, 245, 262, 281, 288, 303, 314, 343, 345, 367, 371, 394, 424, 571, 596, 598, 609, 639, 652, 656, 661], "get_block_nam": 149, "network": [149, 157, 196, 203, 204, 343, 431, 539, 572, 593, 599, 600, 603, 613, 635, 653, 655, 661, 664], "get_tokenizer_funct": 149, "token": [149, 245, 256, 259, 262, 288, 299, 301, 303, 310, 311, 312, 363, 364, 365, 560, 596, 612, 613, 635, 636, 658, 660, 661, 663, 664], "truncat": [149, 245, 262, 288, 303, 596, 663], "field": [149, 179, 229, 230, 247, 290, 314, 367, 571, 575, 577, 601, 613, 660, 664, 666], "get_dataload": 149, "data_nam": 149, "neelnanda": 149, "pile": 149, "10k": [149, 602, 606], "42": [149, 193, 230, 326, 667], "test": [149, 177, 229, 230, 262, 303, 570, 574, 598, 609, 641, 646, 667], "shuffl": [149, 235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595, 613, 655], "enable_full_rang": [149, 150, 154, 171, 538, 560, 656, 658], "cuda": [149, 162, 221, 516, 524, 539, 614, 616, 618, 652, 655], "lr_schedul": [149, 613, 652], "dataset_nam": [149, 637], "dataset_split": 149, "use_quant_input": 149, "lr": [149, 153, 229, 230, 599, 601, 613], "005": [149, 658], "minmax_lr": 149, "low_gpu_mem_usag": 149, "200": [149, 261, 302, 571, 642, 664], "512": 149, "sampler": [149, 179, 235, 237, 239, 242, 244, 265, 278, 280, 282, 285, 287, 299, 310, 359, 439, 504, 595, 601], "rand": [149, 616, 661], "n_block": [149, 171, 522, 658], "gradient_accumulate_step": 149, "not_use_ms": 149, "dynamic_max_gap": 149, "data_typ": [149, 154, 171, 362, 442, 522], "signround": 149, "advanc": [149, 157, 229, 230, 569, 574, 576, 582, 611, 652, 655, 658, 666], "cheng": 149, "wenhua": 149, "et": [149, 153, 157, 593, 658, 661], "al": [149, 153, 157, 593, 658, 661], "via": [149, 309, 333, 338, 346, 569, 574, 601, 608, 613, 616, 633, 652, 653], "sign": [149, 197, 362, 442, 570, 574, 577, 593, 635, 653, 655, 658, 660], "gradient": [149, 153, 196, 327, 574, 608, 613, 652, 653, 667], "descent": [149, 153, 201, 574, 653], "arxiv": [149, 156, 196, 197, 215, 216, 223, 343, 523, 546, 574, 593, 652, 653, 658, 661], "preprint": [149, 593, 652, 658, 661], "2309": 149, "05516": 149, "2023": [149, 574, 648, 652, 658, 661, 667], "pytorch": [149, 187, 189, 190, 198, 201, 204, 207, 208, 211, 216, 217, 224, 229, 230, 244, 245, 247, 250, 254, 262, 264, 269, 271, 287, 288, 290, 293, 297, 303, 308, 309, 318, 319, 339, 341, 344, 346, 354, 363, 371, 372, 381, 424, 434, 558, 565, 570, 571, 572, 574, 575, 576, 577, 593, 594, 595, 599, 600, 602, 605, 608, 609, 611, 613, 614, 615, 616, 618, 621, 622, 623, 624, 633, 635, 644, 647, 648, 652, 653, 654, 658, 659, 661, 664, 666], "empti": [149, 163, 179, 229, 230, 518, 526, 619, 656], "layer1": [149, 201, 229, 230, 613, 652, 655], "layer_nam": [149, 225, 230, 652], "rang": [149, 150, 171, 248, 249, 262, 291, 292, 303, 387, 401, 443, 504, 522, 536, 538, 554, 560, 574, 575, 577, 593, 596, 598, 599, 600, 601, 613, 636, 638, 651, 652, 655, 658, 661, 663], "learn": [149, 153, 574, 575, 576, 595, 596, 603, 607, 608, 609, 613, 614, 616, 618, 621, 622, 624, 627, 628, 631, 633, 652, 653, 655, 661, 662, 664, 665], "rate": [149, 153, 613, 652, 655], "schedul": [149, 195, 198, 208, 209, 210, 215, 216, 218, 229, 230, 310, 339, 343, 363, 613, 640, 641, 643, 651], "futur": [149, 175, 233, 234, 265, 276, 277, 608, 611, 613, 624, 646, 647, 648, 665], "accumul": [149, 359, 439, 664], "step": [149, 153, 196, 207, 208, 209, 210, 214, 215, 219, 229, 230, 341, 343, 345, 554, 576, 577, 598, 599, 600, 601, 613, 628, 631, 633, 646, 647, 648, 651, 652, 654, 657, 658, 660, 661, 662, 664], "squar": [149, 318, 353, 371, 433, 598, 612, 638, 664], "gap": [149, 598, 615], "addit": [149, 170, 230, 554, 576, 577, 599, 627, 635, 641, 658, 659, 664], "keyword": [149, 162, 230, 516], "argument": [149, 162, 230, 443, 516, 526, 549, 572, 598, 637, 638, 641, 644, 646, 647, 648, 658], "autooptround": 149, "adamw": [149, 189, 269], "autoadamround": 149, "export_compressed_model": [150, 523, 536, 546, 560, 658], "compression_dtyp": [150, 560, 658], "int32": [150, 171, 522, 536, 560, 596, 658], "compression_dim": [150, 560, 658], "scale_dtyp": [150, 560, 658], "float32": [150, 248, 249, 262, 291, 292, 303, 314, 367, 504, 560, 575, 592, 596, 613, 655, 658, 661, 663], "use_optimum_format": [150, 560, 658], "weightonlylinear": [150, 658], "json": [150, 170, 246, 262, 289, 303, 564, 596, 615, 634, 641, 642, 646, 647, 648, 658, 663], "compress": [150, 156, 310, 333, 338, 363, 382, 523, 554, 560, 567, 574, 582, 599, 608, 613, 633, 635, 650, 651, 652, 653, 655, 661, 665, 667], "comoress": [150, 560], "select": [150, 171, 218, 221, 230, 245, 288, 536, 538, 560, 571, 572, 593, 608, 609, 633, 652, 655, 658, 662, 664], "choos": [150, 171, 247, 290, 522, 536, 538, 560, 608, 621, 653, 659, 661, 664, 666], "popular": [150, 310, 363, 567, 574, 575, 576, 593, 599, 602, 603, 606, 611, 613, 652, 655, 658, 664, 665], "huggingfac": [150, 201, 212, 245, 288, 560, 596, 602, 606, 621, 622, 623, 624, 644, 645, 647, 648, 661, 667], "why": [150, 661, 662], "g_idx": 150, "instead": [150, 153, 227, 230, 244, 287, 565, 619, 621, 624, 639, 652, 658], "record": [150, 157, 170, 187, 190, 245, 246, 247, 253, 264, 271, 288, 289, 290, 296, 538, 565, 596, 638, 658, 660, 662, 664], "order": [150, 161, 170, 179, 197, 311, 312, 347, 350, 353, 362, 364, 365, 388, 428, 433, 442, 571, 598, 612, 636, 654, 658, 661, 662, 664], "packed_weight": 150, "qweight": 150, "5": [150, 161, 175, 179, 187, 197, 229, 230, 249, 258, 264, 292, 300, 318, 371, 394, 396, 424, 461, 575, 596, 603, 605, 609, 612, 613, 638, 643, 646, 647, 652, 654, 655, 658, 661, 663, 664, 666, 667], "alwai": [150, 179, 267, 314, 367, 371, 424, 598, 612, 613, 638, 658], "even": [150, 656, 658, 661], "modul": [152, 158, 159, 198, 204, 211, 323, 329, 339, 340, 515, 534, 547, 571, 594, 595, 599, 608, 612, 613, 615, 652, 654, 657, 658, 662, 665], "sgd": [153, 189, 229, 230, 269, 599, 613, 654, 666], "param": [153, 170, 177, 181, 189, 235, 263, 269, 278, 318, 350, 371, 428, 504, 565, 575, 615, 664], "requir": [153, 170, 171, 229, 230, 236, 347, 380, 423, 507, 522, 538, 539, 571, 575, 576, 592, 593, 595, 598, 600, 601, 605, 613, 614, 615, 617, 627, 633, 635, 640, 641, 644, 647, 648, 652, 655, 658, 659, 660, 661, 662, 664, 666], "momentum": [153, 196, 343, 608, 613, 652, 666], "weight_decai": [153, 194, 613, 666], "nesterov": [153, 613, 666], "maxim": [153, 613, 652, 664], "foreach": 153, "differenti": 153, "stochast": 153, "align": [153, 262, 303, 569, 658, 663], "rule": [153, 598, 616, 652], "110mm": 153, "4pt": 153, "textbf": 153, "gamma": 153, "theta_0": 153, "f": [153, 162, 198, 516, 594, 599, 601, 655, 658, 661], "theta": 153, "lambda": [153, 162, 516, 656], "decai": 153, "hspace": 153, "13mm": 153, "mu": [153, 598], "tau": 153, "textit": 153, "ex": 153, "ldot": 153, "5mm": 153, "g_t": 153, "leftarrow": 153, "nabla_": 153, "f_t": 153, "theta_": 153, "neq": 153, "10mm": 153, "15mm": 153, "_t": 153, "_": [153, 233, 234, 276, 277, 424, 571, 572, 574, 575, 576, 593, 598, 599, 601, 603, 605, 613, 614, 615, 616, 622, 626, 628, 630, 631, 638, 641, 642, 650, 652, 655, 658, 659, 660, 661, 662, 664, 666], "g_": 153, "theta_t": 153, "bf": 153, "formula": [153, 652, 661], "On": [153, 655, 667], "deep": [153, 227, 509, 574, 575, 576, 595, 608, 609, 613, 614, 616, 618, 621, 622, 624, 627, 633, 653, 655, 664, 665, 667], "l2": [153, 230, 652], "penalti": [153, 311, 312, 364, 365, 612], "xdoctest": [153, 162, 516], "skip": [153, 162, 516, 662, 664], "9": [153, 196, 229, 230, 571, 609, 613, 652, 654, 661, 664, 666, 667], "zero_grad": [153, 601, 613, 652], "loss_fn": 153, "backward": [153, 539, 554, 599, 600, 601, 613, 651, 652, 655, 659], "subtli": 153, "sutskev": 153, "some": [153, 199, 201, 229, 230, 245, 288, 342, 576, 577, 594, 596, 598, 603, 609, 612, 613, 635, 636, 637, 638, 641, 650, 652, 655, 657, 658, 661, 662, 664, 665, 667], "written": [153, 613], "v_": 153, "p_": 153, "denot": [153, 661], "veloc": 153, "respect": [153, 569, 605, 652, 661, 666], "contrast": [153, 203, 341, 663], "emploi": 153, "form": [153, 316, 369, 598, 599, 633], "analog": 153, "modifi": [153, 212, 247, 290, 423, 442, 571, 577, 601, 605, 637, 638, 652, 666], "d_p_list": 153, "momentum_buffer_list": 153, "has_sparse_grad": 153, "see": [153, 160, 197, 223, 262, 303, 311, 364, 517, 539, 569, 570, 571, 573, 594, 610, 613, 626, 627, 630, 633, 634, 638, 639, 658, 661, 662, 664], "actawareweightqu": [154, 522], "example_input": [154, 164, 167, 169, 170, 171, 229, 230, 308, 520, 521, 522, 537, 538, 549, 564, 603], "algo": [154, 181, 451, 522, 557], "bf16modulewrapp": 155, "bf16modul": 155, "mixed_precision_model": 155, "bf16_symbolic_trac": 155, "fx_sub_module_list": 155, "trace": [155, 157, 168, 170, 201, 229, 230, 308, 431, 520, 521, 549, 571, 623, 664], "_description_": 155, "is_leaf": [156, 523], "judg": [156, 523], "trace_gptq_target_block": [156, 523], "module_typ": [156, 523], "modulelist": [156, 523], "sequenti": [156, 179, 243, 286, 347, 349, 425, 427, 523, 664], "stack": [156, 523], "structur": [156, 202, 213, 214, 229, 230, 343, 361, 441, 523, 565, 608, 632, 634, 637, 646, 652, 653, 655, 662, 665, 667], "critic": [156, 212, 523, 569], "gptq_related_block": [156, 523], "embed": [156, 170, 523, 593, 652], "transformers_pr": [156, 523], "todo": [156, 179, 181, 245, 248, 288, 291, 314, 360, 367, 440, 504, 523], "transformers_nam": [156, 523], "find_lay": [156, 224, 523], "find_layers_nam": [156, 523], "log_quantizable_layers_per_transform": [156, 523], "transformer_block": [156, 523], "maxq": [156, 523], "gptquantiz": [156, 523], "nsampl": [156, 171, 223, 523, 658], "use_max_length": [156, 171, 523, 658], "pad_max_length": [156, 171, 658], "layer_wis": [156, 171, 514, 564, 656], "pretrain": [156, 523, 560, 616, 622], "url": [156, 247, 290, 523, 570, 610, 644, 645, 652], "org": [156, 196, 197, 215, 216, 223, 314, 343, 367, 523, 546, 571, 598, 609, 628, 631, 652], "2210": [156, 523, 546, 658], "17323": [156, 523, 546, 658], "node_collector": 157, "hook": [157, 186, 190, 212, 271, 272, 333, 338, 557, 599, 600, 613, 652, 661, 662], "hessiantrac": 157, "q_model": [157, 161, 230, 320, 424, 460, 463, 521, 571, 574, 595, 596, 598, 601, 603, 606, 607, 612, 613, 615, 635, 636, 655, 656, 657, 658], "criterion": [157, 179, 186, 188, 189, 195, 196, 203, 208, 209, 210, 212, 215, 216, 220, 229, 230, 266, 269, 310, 363, 599, 600, 613, 652, 655, 661, 664, 666], "yao": 157, "zhewei": 157, "pyhessian": 157, "len": [157, 230, 262, 303, 596, 601, 663], "2020": 157, "ieee": [157, 614, 661], "intern": [157, 243, 286, 360, 440, 595, 596, 612, 652], "confer": [157, 652, 661], "big": [157, 598, 658], "dong": 157, "zhen": 157, "hawq": [157, 431, 664], "v2": [157, 431, 595, 601, 603, 604, 609, 622, 659, 661, 664, 665, 667], "system": [157, 162, 177, 263, 516, 565, 592, 619, 652, 667], "33": [157, 667], "18518": 157, "18529": 157, "openvinotoolkit": 157, "nncf": 157, "develop": [157, 181, 382, 570, 571, 594, 609, 613, 614, 616, 622, 633, 639, 652, 653, 657, 660], "hessian_trac": 157, "compare_weight": 157, "float_dict": 157, "ani": [157, 162, 181, 314, 316, 359, 367, 369, 418, 423, 439, 443, 516, 524, 539, 549, 562, 565, 569, 574, 577, 594, 601, 616, 621, 634, 635, 639, 640, 652, 660, 664], "quantized_dict": 157, "compar": [157, 318, 371, 565, 600, 612, 636, 652, 655, 658, 660, 662, 664], "being": [157, 314, 367, 577, 641], "wt_compare_dict": 157, "float_model": 157, "state_dict": [157, 601, 658, 662], "qmodel": 157, "compute_error": 157, "state": [157, 202, 539, 577, 619, 652], "weight_dict": 157, "hawq_top": 157, "enable_act": 157, "portabl": [160, 517], "serial": [160, 162, 516, 517], "copyreg": [160, 517], "mechan": [160, 196, 517, 652, 660, 665], "pickler": [160, 517], "pickletool": [160, 517], "comment": [160, 517, 569, 576, 596, 612, 613, 658, 663], "unpickl": [160, 162, 516, 517], "misc": [160, 517, 610], "format_vers": [160, 517], "compatible_format": [160, 517], "except": [160, 162, 443, 516, 517, 565, 594, 639, 655, 656], "pickleerror": [160, 517], "pickl": [160, 162, 516, 517], "picklingerror": [160, 517], "unpicklingerror": [160, 517], "problem": [160, 245, 288, 318, 371, 517, 612, 614, 634], "secur": [160, 517, 574, 635, 653, 668], "violat": [160, 517], "also": [160, 202, 244, 247, 262, 287, 290, 303, 311, 364, 371, 382, 424, 517, 539, 570, 572, 575, 576, 577, 595, 598, 602, 606, 608, 612, 613, 616, 621, 626, 627, 630, 633, 634, 635, 638, 639, 650, 652, 653, 655, 657, 658, 661, 664], "includ": [160, 187, 196, 201, 203, 218, 220, 229, 230, 245, 247, 254, 262, 264, 288, 290, 297, 303, 309, 319, 341, 346, 443, 517, 539, 565, 569, 575, 576, 577, 595, 596, 598, 609, 610, 611, 612, 613, 616, 619, 622, 627, 639, 643, 646, 647, 648, 652, 655, 657, 658, 662, 664], "necessarili": [160, 517], "limit": [160, 194, 350, 428, 517, 565, 574, 598, 599, 611, 655, 658, 659, 662], "attributeerror": [160, 443, 517], "eoferror": [160, 517], "importerror": [160, 517, 604], "indexerror": [160, 517], "layerwisequ": 161, "pretrained_model_name_or_path": [161, 163, 518], "op_cfg": 161, "output_dir": [161, 560, 613, 621, 622, 637, 638, 644, 647, 648], "memomeri": 161, "file_lik": [162, 516], "map_loc": [162, 516], "pickle_modul": [162, 198, 516], "weights_onli": [162, 516], "pickle_load_arg": [162, 516], "facil": [162, 516], "treat": [162, 516, 595], "storag": [162, 516, 574, 606, 612, 635, 638, 658, 661], "thei": [162, 263, 443, 516, 569, 594, 599, 605, 613, 621, 636, 639, 650], "deseri": [162, 516], "were": [162, 318, 371, 516, 619, 652], "fail": [162, 516, 571, 595, 603, 642], "becaus": [162, 179, 207, 212, 262, 303, 341, 516, 571, 638, 655, 661, 663, 664], "doesn": [162, 262, 303, 516, 575, 601, 613, 614, 634, 666], "certain": [162, 224, 516, 660], "howev": [162, 516, 639, 652, 658, 661], "altern": [162, 229, 230, 424, 516], "callabl": [162, 229, 230, 316, 369, 394, 447, 460, 463, 516, 524, 544, 549, 554, 594, 595], "locat": [162, 172, 221, 262, 303, 516, 601, 619, 626, 630, 633, 641, 655, 659, 663, 666], "resid": [162, 516], "tag": [162, 380, 507, 516, 661, 662], "wa": [162, 229, 230, 516, 575, 613, 638, 639, 642, 653, 664], "builtin": [162, 516, 601], "device_id": [162, 516], "either": [162, 230, 314, 367, 516, 617, 621, 641, 651, 654, 655], "final": [162, 201, 208, 221, 343, 516, 576, 613, 619, 650, 652, 655, 659, 664], "alreadi": [162, 177, 247, 261, 263, 290, 302, 516, 575, 596, 608, 628, 631, 635, 644, 664], "right": [162, 258, 300, 314, 367, 516, 569, 570, 571, 633, 639, 661, 663], "fall": [162, 170, 516], "back": [162, 170, 262, 268, 303, 516, 598, 633, 639], "behavior": [162, 516, 569, 575, 576, 577, 605, 615, 658, 662, 664, 666], "wasn": [162, 516], "appear": [162, 516, 569, 627, 633, 635], "ones": [162, 314, 367, 516, 652], "put": [162, 247, 290, 516, 596, 599], "user": [162, 177, 189, 201, 213, 221, 229, 230, 233, 234, 247, 250, 254, 262, 263, 269, 276, 277, 290, 293, 297, 303, 309, 333, 338, 344, 346, 347, 371, 372, 382, 424, 429, 442, 516, 521, 554, 565, 571, 572, 574, 575, 576, 577, 582, 592, 594, 595, 599, 600, 603, 605, 608, 611, 612, 613, 614, 615, 616, 617, 618, 620, 621, 622, 624, 627, 633, 640, 641, 642, 643, 646, 647, 648, 650, 651, 652, 653, 655, 656, 657, 659, 661, 662, 663, 664, 668], "register_packag": [162, 516], "readlin": [162, 516], "tell": [162, 371, 424, 516, 654], "seek": [162, 516, 658], "o": [162, 443, 516, 594, 609, 618, 636], "pathlik": [162, 516], "metadata": [162, 516], "primit": [162, 516], "unless": [162, 516, 605], "implicitli": [162, 181, 516], "known": [162, 265, 350, 428, 516, 613, 652, 655, 662, 664], "insecur": [162, 516, 635], "possibl": [162, 263, 516, 539, 598, 635, 651, 652, 656, 657, 664], "construct": [162, 245, 248, 249, 252, 260, 265, 267, 268, 270, 288, 291, 292, 295, 371, 376, 380, 442, 504, 506, 507, 516, 557, 569, 576, 577, 596, 601, 652, 664], "malici": [162, 516], "arbitrari": [162, 516, 613, 651], "code": [162, 201, 233, 234, 263, 276, 277, 320, 344, 347, 424, 516, 554, 571, 574, 575, 576, 577, 596, 599, 600, 601, 607, 608, 610, 612, 616, 618, 620, 621, 622, 624, 627, 633, 637, 638, 640, 641, 642, 650, 651, 652, 653, 654, 655, 660, 661, 662, 663], "never": [162, 516, 664], "could": [162, 167, 175, 203, 233, 234, 247, 276, 277, 290, 347, 372, 424, 516, 554, 569, 571, 600, 613, 651, 652, 655, 658, 661, 665], "come": [162, 516, 611, 664], "untrust": [162, 516], "unsaf": [162, 516], "tamper": [162, 516], "trust": [162, 516, 598, 635], "load_state_dict": [162, 516], "ram": [162, 516], "surg": [162, 516], "checkpoint": [162, 380, 507, 516, 564, 615], "By": [162, 201, 229, 230, 311, 364, 516, 576, 577, 612, 615, 626, 627, 630, 652, 653, 658, 664], "decod": [162, 257, 258, 300, 311, 364, 516, 612, 663], "byte": [162, 516], "utf": [162, 261, 302, 516], "unicodedecodeerror": [162, 516], "ascii": [162, 516], "codec": [162, 516], "0x": [162, 516], "incorrect": [162, 516], "extra": [162, 316, 369, 516, 613, 658], "encod": [162, 314, 367, 516, 636, 663], "latin1": [162, 516], "them": [162, 201, 245, 288, 516, 571, 577, 595, 598, 603, 605, 607, 636, 639, 651, 652, 658, 664], "keep": [162, 212, 221, 342, 429, 516, 571, 575, 594, 632, 633, 659], "later": [162, 167, 175, 516, 594, 640, 641, 662], "byte_arrai": [162, 516], "undefin": [162, 221, 342, 516], "filepath": [162, 516, 565, 594], "pt": [162, 516, 564, 609, 615, 637, 653, 655, 657, 658], "onto": [162, 516], "loc": [162, 516], "bytesio": [162, 516], "open": [162, 266, 310, 363, 516, 557, 567, 569, 574, 603, 604, 613, 628, 631, 634, 635, 639, 640, 641, 653], "rb": [162, 516], "buffer": [162, 516], "get_children": [163, 518], "get_named_children": [163, 518], "dowload_hf_model": [163, 518], "repo_id": [163, 518], "cache_dir": [163, 518], "repo_typ": [163, 518], "revis": [163, 518], "download": [163, 247, 290, 518, 596, 598, 609, 638, 644, 659], "hug": [163, 518, 574, 640, 653], "face": [163, 518, 569, 574, 582, 616, 620, 640, 642, 653, 659, 667], "hf": [163, 518, 611, 661, 667], "hub": [163, 518, 574, 602, 606, 624], "load_empty_model": [163, 518, 656], "automodelforcausallm": [163, 518], "get_super_module_by_nam": [163, 518], "module_nam": [163, 196, 198, 208, 209, 210, 211, 213, 214, 215, 216, 218, 220, 343, 509, 518, 565], "father": [163, 201, 518], "update_modul": [163, 518], "load_layer_wise_quantized_model": [163, 518], "load_tensor_from_shard": [163, 518], "shard": [163, 518], "load_tensor": [163, 518], "ipex_mixed_precis": 164, "fakeaffinetensorquantfunct": [165, 535], "affin": [165, 535, 655], "teqlinearfakequ": [165, 535], "orig_lay": [165, 535], "mullinear": [165, 171, 522, 535], "input_scal": [165, 535], "detector": 166, "transformerbasedmodelblockpatterndetector": [166, 521], "pattern_lst": [166, 521], "block_pattern": [166, 521], "detect": [166, 170, 201, 229, 230, 314, 318, 367, 371, 376, 521, 570, 571, 616, 623, 624, 652, 664], "ffn": [166, 212, 521], "torchsmoothqu": [167, 661], "q_func": [167, 233, 234, 276, 277, 350, 351, 353, 354, 355, 356, 425, 428, 429, 430, 431, 433, 434, 435, 436, 575, 576, 613, 664], "traced_model": [167, 168], "whose": [167, 175, 203, 342, 380, 507, 607, 661, 664], "absorb": [167, 170, 171, 175, 522, 538, 658], "trace_and_fuse_sub_graph": 168, "is_qat": 168, "tequant": [169, 537], "absorb_to_lay": [169, 170, 171, 537, 538], "extra_config": [169, 171], "trainabl": [169, 537, 574, 653, 658], "move_input_devic": 170, "auto": [170, 178, 199, 201, 229, 230, 348, 363, 394, 426, 432, 545, 565, 571, 593, 616, 619, 621, 623, 624, 652, 655, 658], "kind": [170, 613], "forward_wrapp": 170, "get_embedding_contigu": 170, "contigu": 170, "is_fused_modul": 170, "_propagate_qconfig_help": 170, "collate_torch_pr": 170, "collate_result": 170, "input2tupl": 170, "append_attr": 170, "fx_model": 170, "fx_white_list": 170, "append": [170, 347, 350, 428, 571, 600, 613, 651], "graphmodul": [170, 571, 657], "dir": [170, 245, 288, 560, 564, 596, 604, 607], "generate_activation_observ": 170, "smooth_quant_en": 170, "observ": [170, 577, 658, 660, 662, 664], "what": [170, 208, 243, 286, 371, 424, 554, 569, 653], "check_cfg_and_qconfig": 170, "op_infos_from_cfg": [170, 521], "output_tensor_ids_op_nam": [170, 521], "paser_cfg": [170, 521], "ops_nam": [170, 521], "get_quantizable_ops_from_cfg": [170, 521], "input_tensor_ids_op_nam": [170, 521], "update_sq_scal": 170, "ipex_config_path": 170, "smoothquant_scale_info": 170, "ipex_config": 170, "auto_copi": 170, "fetch_modul": [170, 538, 553], "op_nam": [170, 226, 229, 230, 361, 441, 521, 538, 553, 565, 566, 576, 613, 652, 662], "simple_infer": [170, 521], "get_example_input": [170, 538], "example_inp": [170, 538], "get_fallback_ord": 170, "confidence_batch": [170, 664], "fallback": [170, 230, 353, 354, 431, 433, 434, 603, 614, 636, 657, 664], "requantize_cfg": 170, "confid": 170, "ordered_op": 170, "get_mse_order_per_fp32": 170, "influenc": [170, 652], "last": [170, 196, 221, 229, 230, 595, 614, 616, 618, 623, 627, 655, 658, 661], "fallback_ord": 170, "get_mse_order_per_int8": 170, "get_torch_vers": 170, "match_datatype_pattern": 170, "calculate_quant_min_max": 170, "unsign": [170, 362, 442, 577, 658], "qmin": 170, "qmax": 170, "get_depth": [170, 521], "depth": [170, 521, 599, 657], "get_dict_at_depth": [170, 521], "target_depth": [170, 521], "nest": [170, 227, 509, 521], "get_element_under_depth": [170, 521], "ops_lst": [170, 521], "get_op_type_by_nam": 170, "quantizable_op": [170, 521], "collect_weight_info": 170, "fc": [170, 230, 652], "_type_": [170, 560], "get_module_input_output": [170, 538], "module_hook_config": [170, 538], "input_func": [170, 538], "output_func": [170, 538], "help": [170, 190, 271, 320, 538, 594, 611, 615, 616, 622, 633, 641, 646, 647, 648, 658, 664, 665], "module_name_list": [170, 538], "fc1": [170, 171, 522, 538], "preprocess": [170, 229, 230, 245, 262, 288, 303, 442, 538, 557, 601, 663], "usag": [170, 178, 179, 181, 244, 287, 314, 320, 347, 367, 401, 443, 509, 524, 538, 553, 576, 596, 601, 602, 616, 624, 635, 641, 646, 647, 648, 650, 654, 658, 663], "input_valu": [170, 538], "output_valu": [170, 538], "total_valu": [170, 538], "get_absorb_lay": [170, 538], "supported_lay": [170, 538], "no_absorb_lay": [170, 538], "allow": [170, 350, 428, 538, 539, 599, 601, 612, 613, 614, 635, 640, 652, 654, 658, 661, 664, 666], "absorpt": [170, 538], "eg": [170, 227, 247, 290, 509, 538, 596, 654], "absorbed_1": [170, 538], "xx": [170, 538], "get_block_prefix": [170, 538], "block_list": [170, 538], "block_num": [170, 538], "block_prefix": [170, 538], "get_hidden_st": [170, 538], "calib": [170, 538, 576], "rest": [170, 538, 640, 641, 646, 647, 648], "part": [170, 199, 208, 341, 343, 538, 571, 609, 614, 628, 631, 641, 643, 652, 656, 661, 665], "total_block_kwarg": [170, 538], "total_block_arg": [170, 538], "quantize_4bit": [171, 538], "quantil": [171, 536, 538, 664], "nf4": [171, 536, 538, 574, 658], "return_int": [171, 522, 538, 658], "fp4": [171, 536, 538, 574, 658], "q_tensor": [171, 538], "qdq_weight_asym": [171, 538], "qdq_weight_sym": [171, 538], "full_rang": [171, 538], "amax": [171, 538], "qdq_weight_actor": [171, 538], "place": [171, 520, 538, 600, 609, 646, 652, 662, 664], "search_clip": [171, 538], "best": [171, 179, 186, 262, 303, 304, 309, 346, 353, 387, 433, 538, 569, 572, 594, 609, 616, 622, 633, 639, 650, 655, 658, 661, 663, 664], "num": [171, 536, 538, 565], "best_clip_ratio": [171, 538], "group_dim": [171, 536, 546, 658], "gptq_perm": 171, "perm": [171, 262, 303, 663], "absorb_lay": [171, 522], "absorb_dict": [171, 522], "absorbed_lay": [171, 522], "fc3": [171, 522], "oom": [171, 522], "teq_quant": [171, 537], "algorithm_registri": 172, "algorithm_typ": 172, "registr": [172, 247, 254, 262, 290, 297, 303, 336], "algorithmschedul": 172, "conf": [172, 177, 186, 230, 233, 234, 263, 276, 277, 320, 327, 328, 330, 331, 332, 333, 338, 350, 351, 353, 354, 355, 356, 360, 372, 382, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 440, 443, 554, 571, 572, 574, 577, 592, 599, 606, 607, 613, 614, 615, 635, 637, 638, 651, 655, 656, 657, 658, 660, 661, 664], "control": [172, 229, 230, 571, 613, 639, 652, 664], "phase": [172, 572, 613, 652, 655, 657, 664], "fastbiascorrect": [173, 176], "fast_bias_correct": [174, 229, 230, 363, 655], "weight_correct": [174, 229, 230, 363, 655], "weightcorrect": 176, "1e": [176, 661, 666], "05": [176, 230, 318, 371, 396, 612, 661, 667], "evalu": [177, 179, 186, 203, 229, 233, 234, 245, 263, 276, 277, 288, 304, 311, 314, 315, 316, 318, 320, 364, 367, 368, 369, 371, 372, 382, 394, 424, 554, 557, 572, 575, 576, 594, 596, 599, 600, 607, 608, 611, 612, 613, 614, 616, 622, 624, 627, 633, 650, 652, 655, 660, 661, 662, 664, 666], "set_env_var": [177, 263], "env_var": [177, 263], "overwrite_exist": [177, 263], "env": [177, 263, 604, 646, 647, 648], "set_all_env_var": [177, 263], "physic": [177, 263, 569, 592, 641], "core": [177, 229, 230, 263, 386, 570, 592, 610, 626, 630, 641, 667], "get_architectur": [177, 263], "architectur": [177, 263, 321, 324, 574, 592, 599, 613, 640, 652, 653, 658, 665], "get_threads_per_cor": [177, 263], "thread": [177, 229, 230, 263, 418, 423, 539, 595, 643], "get_thread": [177, 263], "get_physical_id": [177, 263], "socket": [177, 263, 565, 641, 643, 667], "get_core_id": [177, 263], "get_bounded_thread": [177, 263], "core_id": [177, 263], "bind": [177, 263], "run_inst": 177, "b_dataload": [177, 229, 230, 592, 613], "b_func": [177, 592], "benchmarkconfig": [177, 229, 230, 592, 598, 613], "goal": [177, 179, 304, 309, 333, 338, 346, 372, 424, 576, 595, 651, 655, 664], "prefer": [177, 309, 346, 424, 652, 658], "space": [177, 193, 194, 209, 210, 215, 216, 229, 230, 233, 234, 276, 277, 309, 316, 321, 324, 325, 326, 346, 350, 353, 360, 369, 372, 424, 428, 433, 440, 569, 570, 572, 575, 576, 577, 594, 652, 655, 661, 666], "etc": [177, 186, 261, 302, 304, 309, 316, 333, 338, 346, 369, 372, 424, 564, 574, 599, 608, 635, 639, 652, 660, 664], "generate_prefix": 177, "core_list": 177, "command": [177, 263, 554, 598, 601, 616, 618, 621, 626, 630, 634, 635, 637, 638, 639, 641], "numactl": [177, 604, 619, 627], "call_on": 177, "cmd": 177, "log_fil": [177, 417, 422], "window": [177, 592, 609, 633, 634], "config_inst": 177, "raw_cmd": 177, "multi": [177, 199, 201, 212, 314, 367, 371, 424, 572, 595, 596, 608, 613, 650, 652, 655, 664], "trigger": [177, 208, 343], "summary_benchmark": 177, "summari": [177, 554, 598, 628, 631, 662, 667], "profil": [177, 230, 363], "benchmark_with_raw_cmd": 177, "fit_with_raw_cmd": 177, "cores_per_inst": [177, 229, 230, 592, 613, 654], "num_of_inst": [177, 229, 230, 592, 613, 654], "fit": [177, 203, 229, 230, 350, 372, 424, 428, 443, 554, 571, 574, 592, 595, 596, 598, 601, 606, 607, 612, 613, 614, 615, 635, 636, 652, 655, 656, 657, 658], "pb": [177, 229, 230, 372, 380, 424, 507, 574, 592, 601, 606, 613, 615, 635, 638, 646, 662, 667], "eval_dataload": [177, 229, 230, 233, 234, 276, 277, 347, 350, 351, 353, 354, 355, 356, 372, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 554, 592, 607, 612, 613, 635, 655, 656, 664], "register_config": [178, 594], "framework_nam": [178, 594], "algo_nam": [178, 594], "prioriti": [178, 524, 594, 644], "examplealgorithm": 178, "examplealgorithmconfig": 178, "larger": [178, 524, 576, 652, 658, 661], "higher": [178, 229, 230, 233, 234, 276, 277, 325, 372, 424, 524, 554, 571, 598, 599, 603, 612, 636, 652, 655, 660], "tri": [178, 230, 594, 664], "stage": [178, 349, 354, 425, 427, 434, 599, 652, 662, 664], "baseconfig": [178, 181, 461, 463, 549, 594], "white_list": [178, 396, 461, 546], "op_name_or_module_typ": [178, 396, 461, 546], "default_white_list": [178, 396, 461, 546], "composableconfig": [178, 594], "register_supported_configs_for_fwk": 178, "fwk_name": [178, 594], "eval_acc": [179, 394], "eval_perf": [179, 394], "mold": 179, "user_eval_fns1": 179, "user_eval_fns2": 179, "eval_fn": [179, 394, 545], "user_eval_fns3": 179, "user_eval_fns4": 179, "sequentialsampl": [179, 243, 286], "config_sourc": 179, "_configset": 179, "tuningconfig": [179, 394, 545], "config_set": [179, 394], "max_trial": [179, 229, 230, 613, 664], "default_sampl": 179, "tolerable_loss": [179, 229, 230, 613, 664], "found": [179, 186, 304, 574, 594, 599, 611, 614, 621, 638, 642, 661, 664, 667], "from_fwk_config": 179, "configset": 179, "timeout": [179, 229, 230, 613, 654, 664, 666], "exit": [179, 229, 230, 349, 425, 427, 613, 641, 646, 647, 648, 666], "much": [179, 186, 196, 229, 230, 262, 303, 304, 599, 627, 661, 663], "metric": [179, 186, 229, 230, 233, 234, 266, 276, 277, 304, 309, 310, 325, 333, 338, 346, 347, 363, 372, 424, 554, 557, 572, 575, 576, 596, 598, 601, 613, 614, 635, 655, 660, 661, 662, 664, 665, 666, 667], "accept": [179, 229, 230, 443, 569, 592, 594, 595, 635, 658], "rel": [179, 197, 229, 230, 382, 613, 636, 654, 664, 666, 667], "neg": [179, 197], "refin": [179, 607, 652], "tune_config": [179, 394, 545, 576], "config1": 179, "config2": 179, "toler": [179, 638], "fp32_baselin": [179, 557, 575], "config1_metr": 179, "config2_metr": 179, "98": [179, 229, 230, 613, 652, 654, 667], "trial": [179, 664], "config3_metr": 179, "97": [179, 613, 667], "Not": [179, 359, 360, 439, 440, 509, 565, 572, 594], "achiev": [179, 309, 346, 603, 611, 613, 636, 651, 652, 653, 655, 661, 662, 664], "config_metr": 179, "reach": [179, 203, 219, 229, 230, 345, 570, 595, 635, 652, 664], "paramlevel": 181, "enumer": [181, 325, 554, 575, 599, 600, 601, 613, 651, 652, 662], "deriv": [181, 186, 196, 205, 206, 207, 213, 214, 215, 216, 217, 218, 219, 220, 304, 341, 343, 345], "tuningparam": 181, "default_v": 181, "tunable_typ": 181, "op_level": 181, "tunabl": 181, "fakealgoconfig": 181, "params_list": [181, 394], "simpl": [181, 262, 303, 609, 613, 652, 660, 661, 664], "give": [181, 576, 633, 664], "enough": [181, 655], "simple_attr": 181, "complex": [181, 594, 613, 614, 652], "explicitli": [181, 229, 230, 607, 652], "complex_attr": 181, "model_attr": 181, "model_level": 181, "explain": [181, 577, 598, 661], "logger": [183, 310, 339, 363, 509, 521, 555, 558, 565], "tuninglogg": 184, "unifi": [184, 309, 346, 575, 576, 577, 595, 607, 608, 612, 613, 615], "assist": [184, 659], "team": [184, 316, 369, 569, 657], "retriev": [184, 243, 286, 652], "dump_elapsed_tim": [185, 509, 533, 565, 575], "customized_msg": [185, 509, 533, 565], "elaps": [185, 509, 533, 565], "set_random_se": [185, 229, 230, 565], "set_workspac": [185, 229, 230, 565], "workspac": [185, 229, 230, 564, 565, 615, 641, 646, 647, 648], "set_resume_from": [185, 229, 230, 565], "resume_from": [185, 229, 230, 565], "set_tensorboard": [185, 229, 230, 565], "tensorboard": [185, 229, 230, 557, 565, 575, 613, 636], "compon": [186, 304, 310, 347, 363, 571, 594, 598, 601, 609, 610, 616, 633, 641, 651, 652], "quantizationawaretrainingcallback": 186, "pruningcallback": 186, "distillationcallback": 186, "basecallback": 186, "design": [186, 244, 267, 272, 287, 371, 429, 572, 574, 613, 621, 624, 652, 655, 665], "mainli": [186, 219, 272, 345, 574, 613, 652, 655], "prune": [186, 195, 196, 198, 199, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 221, 229, 230, 272, 273, 310, 327, 328, 330, 331, 332, 336, 338, 339, 341, 342, 343, 345, 347, 363, 565, 574, 601, 602, 605, 606, 608, 651, 653, 665, 666], "distil": [186, 195, 229, 230, 264, 271, 272, 310, 363, 574, 602, 606, 608, 651, 665, 666], "In": [186, 205, 206, 207, 212, 213, 214, 218, 230, 244, 272, 287, 314, 341, 343, 367, 382, 539, 569, 571, 572, 574, 575, 576, 595, 596, 598, 599, 600, 601, 612, 613, 623, 626, 627, 630, 636, 637, 638, 639, 646, 647, 648, 650, 651, 652, 655, 657, 658, 660, 661, 662, 663, 664, 665], "adaptor": [186, 229, 230, 362, 442, 451, 557, 574, 577, 608, 656, 657, 659, 661, 662, 665], "pipelin": [186, 304, 321, 322, 347, 570, 600, 613, 651], "knowledg": [186, 187, 229, 230, 264, 304, 600, 602, 606, 608, 613, 615, 666], "transfer": [186, 252, 295, 304, 596, 599, 600, 613, 661], "teacher": [186, 229, 230, 304, 599, 600, 613, 667], "student": [186, 190, 229, 230, 245, 271, 288, 304, 596, 599, 600, 667], "distillation_conf": [186, 226, 304], "_epoch_ran": [186, 304], "integ": [186, 207, 208, 229, 230, 304, 314, 318, 325, 341, 343, 367, 371, 443, 575, 577, 593, 655, 658, 661, 664], "epoch": [186, 209, 210, 215, 304, 343, 554, 595, 599, 600, 601, 613, 651, 652, 666], "ran": [186, 304], "eval_frequ": [186, 304], "frequenc": [186, 208, 229, 230, 304, 343, 613, 652, 666], "term": [186, 209, 210, 215, 216, 218, 304, 570, 593, 599, 610, 612, 650, 651, 664], "best_scor": [186, 304], "best_model": [186, 304, 564, 658], "critet": [187, 264], "tensorflowcrossentropyloss": [187, 264], "pytorchcrossentropyloss": [187, 264], "tensorflowsparsecategoricalcrossentropi": 187, "tensorflowknowledgedistillationloss": [187, 264], "pytorchknowledgedistillationloss": [187, 264, 613], "pytorchintermediatelayersknowledgedistillationloss": [187, 264], "tensorflowcriterion": [187, 264], "pytorchcriterion": [187, 264], "criterion_registri": [187, 264], "criterion_typ": [187, 264], "registry_criterion": [187, 264], "param_dict": [187, 189, 264, 269], "crossentropyloss": [187, 229, 230, 599, 613], "sparsecategoricalcrossentropyloss": 187, "knowledgedistillationframework": [187, 264], "student_model": [187, 230, 264, 613], "teacher_model": [187, 229, 230, 264, 599, 600, 613], "knowledgedistillationloss": [187, 264, 613, 666], "temperatur": [187, 229, 230, 264, 613, 666], "loss_typ": [187, 193, 229, 230, 264, 613, 666], "ce": [187, 229, 230, 264, 613, 666], "loss_weight": [187, 229, 230, 264, 613, 666], "pytorchknowledgedistillationlosswrapp": [187, 264], "tensorflowknowledgedistillationlosswrapp": 187, "tensorflowknowledgedistillationlossextern": [187, 264], "intermediatelayersknowledgedistillationloss": [187, 264], "layer_map": [187, 230, 264, 599], "add_origin_loss": [187, 230, 264], "pytorchintermediatelayersknowledgedistillationlosswrapp": [187, 264], "selfknowledgedistillationloss": [187, 264], "selfknowledg": [187, 264], "pytorchselfknowledgedistillationloss": 187, "pytorchselfknowledgedistillationlosswrapp": 187, "multipl": [189, 199, 231, 232, 236, 237, 245, 246, 248, 249, 250, 251, 252, 256, 259, 262, 269, 274, 275, 279, 280, 282, 288, 289, 291, 292, 293, 294, 295, 299, 301, 303, 319, 372, 373, 374, 376, 382, 539, 592, 596, 603, 613, 640, 643, 651, 652, 660, 661, 664], "tensorflowoptim": [189, 269], "pytorchoptim": [189, 269], "optimizer_registri": [189, 269], "optimizer_typ": [189, 269], "cross": [189, 269, 318, 371, 607, 664], "tensorflowsgd": [189, 269], "tensorflowadamw": [189, 269], "tensorflow_addon": [189, 269], "tensorflowadam": 189, "adam": [189, 666], "pytorchsgd": [189, 269], "record_output": [190, 271], "output_process": [190, 271], "get_activ": [190, 271], "hyper": [191, 666], "sa_optim": [191, 195], "simul": [192, 577], "anneal": 192, "register_search": 193, "searcher": [193, 201, 230, 326], "registri": [193, 194, 196, 203, 208, 217, 218, 219, 220, 341, 343, 345, 572], "sure": [193, 203, 208, 217, 219, 341, 343, 345, 592, 635], "search_spac": [193, 226, 230, 321, 324, 325, 326], "gridsearch": [193, 326], "grid": [193, 230, 326, 572, 652], "whole": [193, 326, 577, 635, 655, 667], "exhaust": [193, 230, 310, 326, 352, 363, 432, 654], "randomsearch": [193, 326], "randomli": [193, 262, 303, 326, 350, 428, 572, 661, 663, 664], "bayesianoptimizationsearch": [193, 326], "bayesian": [193, 230, 310, 326, 352, 363, 432, 572, 652, 654], "xgbsearcher": 193, "higher_is_bett": [193, 229, 230, 371, 424, 664, 666], "reg": [193, 195, 198, 209, 210, 215, 216, 230], "min_train_sampl": [193, 230], "10": [193, 229, 230, 247, 290, 350, 428, 574, 592, 596, 603, 609, 613, 635, 636, 652, 654, 663, 664, 667], "xgboost": [193, 652], "searchspac": 194, "factori": [194, 378, 404, 406, 411, 414, 416, 421, 508], "actual": [194, 318, 371, 601], "interv": [194, 214, 652], "continu": [194, 206, 314, 341, 367, 572, 611, 613, 634, 652, 665], "learning_r": [194, 229, 230, 613, 654, 666], "001": [194, 247, 290, 596, 601, 661, 666], "num_train_epoch": [194, 613, 652], "20": [194, 262, 303, 638, 641, 646, 647, 648, 652, 663, 666, 667], "register_searchspac": 194, "pruner": [194, 195, 310, 327, 328, 329, 330, 331, 333, 338, 339, 341, 344, 363, 613, 652, 666], "basesearchspac": 194, "discretesearchspac": 194, "continuoussearchspac": 194, "hpo": [195, 233, 276, 652], "model_slim": [195, 198, 212], "auto_slim": [195, 198, 200], "pattern_analyz": [195, 198, 200], "weight_slim": [195, 198, 200, 212], "mha": [195, 198, 204, 211, 652], "ninm": [195, 198, 204], "nxm": [195, 198, 204, 214, 229, 230, 337, 341, 652], "basic": [195, 198, 201, 203, 211, 229, 230, 261, 302, 310, 321, 341, 352, 356, 359, 363, 432, 436, 439, 554, 608, 609, 613, 635, 654, 660], "block_mask": [195, 196, 198, 211], "pattern_lock": [195, 198, 211, 229, 230, 310, 329, 363], "retrain_fre": [195, 196, 198, 211, 652], "wanda": [195, 198], "criteria": [195, 198, 229, 230, 309, 333, 338, 341, 343, 346, 571, 633, 661], "tf_criteria": [195, 198], "callback": [195, 333, 338, 554, 557, 571, 613, 651, 652, 655], "register_criterion": [196, 220], "get_criterion": 196, "pruningcriterion": [196, 220], "about": [196, 220, 565, 569, 594, 595, 613, 638, 639, 652, 657, 664, 665, 667], "score": [196, 203, 208, 212, 220, 229, 230, 311, 312, 314, 315, 316, 318, 343, 364, 365, 367, 368, 369, 371, 431, 557, 571, 612, 636, 650, 652, 660, 664], "magnitudecriterion": [196, 220], "magnitud": [196, 220, 229, 230, 310, 318, 329, 363, 371, 608, 652], "criterion_class": [196, 220], "determin": [196, 203, 208, 220, 229, 230, 559, 569, 571, 593, 652, 655], "gradientcriterion": 196, "absolut": [196, 229, 230, 318, 371, 612, 613, 652, 655, 664], "snipcriterion": 196, "snip": [196, 229, 230, 343, 608, 652, 667], "product": [196, 574, 608, 614, 616, 617, 633, 639, 653, 655, 660, 664], "shot": [196, 215, 216, 219, 272, 343, 345, 572, 608, 613, 652, 653, 658], "connect": [196, 343, 633, 635, 642, 652, 660], "sensit": [196, 327, 343, 608, 652], "1810": [196, 343], "02340": [196, 343], "snipmomentumcriterion": 196, "snip_momentum": [196, 229, 230, 613, 652], "preserv": [196, 593, 652, 658], "beta": 196, "blockmaskcriterion": 196, "retrainfreecriterion": 196, "return_reorder_indic": 197, "6": [197, 229, 230, 605, 655, 661, 664, 667], "remain": [197, 621], "unchang": 197, "flip": [197, 258, 262, 300, 303, 663], "initial_metr": 197, "sparsity_ratio": [197, 223], "prune_n": [197, 223], "prune_m": [197, 223], "pow_of_var_regrow": 197, "max_cycle_tim": 197, "without_same_sign": 197, "update_threshold": 197, "power": [197, 599, 613, 627, 653], "cycl": [197, 572], "paper": [197, 223, 599, 652, 658, 661], "2310": 197, "08915": 197, "pickle_protocol": 198, "_use_new_zipfile_seri": 198, "prepare_prun": [198, 652], "loss_func": [198, 217], "assertionerror": [198, 204, 211, 221, 341, 342, 343, 372], "slim": [199, 200, 201, 314, 367, 378, 380, 507, 508, 615, 652], "round_multipli": 199, "spars": [199, 213, 343, 596, 653], "model_slim_ffn2": 199, "perman": [199, 569, 652], "obtain": [199, 201, 210, 215, 218, 221, 342, 539, 571, 576, 641, 652, 660, 661, 664], "acceler": [199, 524, 599, 613, 616, 624, 633, 636, 640, 652, 653, 657, 658, 661, 664], "directli": [199, 229, 230, 244, 287, 314, 318, 342, 367, 371, 612, 613, 620, 652, 654, 655, 662], "sprase": 199, "model_slim_mha": 199, "parse_auto_slim_config": [199, 652], "ffn2_sparsiti": [199, 652], "mha_spars": [199, 652], "generate_ffn2_pruning_config": 199, "consecut": [199, 201, 202, 652], "generate_mha_pruning_config": 199, "head": [199, 201, 205, 212, 221, 652, 667], "get_attribut": 201, "get_common_modul": 201, "layer2": [201, 613, 652, 655], "nearest": [201, 262, 303, 396, 536, 546, 658, 663], "print_iter": 201, "recipesearch": 201, "root": [201, 245, 246, 247, 250, 288, 289, 290, 293, 318, 371, 596, 601, 612, 613, 666], "levelwis": 201, "wai": [201, 246, 247, 250, 289, 290, 293, 524, 572, 577, 595, 596, 598, 612, 613, 616, 619, 634, 635, 639, 640, 641, 651, 652, 655, 658, 661, 664, 666], "bert": [201, 230, 241, 244, 245, 262, 284, 287, 288, 303, 574, 596, 599, 612, 614, 621, 644, 647, 648, 652, 663, 667], "recipe_sampl": 201, "bertattent": 201, "dens": [201, 219, 229, 230, 345, 636, 652, 667], "searching_result": 201, "jitbasicsearch": 201, "placeholder_shap": 201, "placeholder_dtyp": 201, "jit": [201, 229, 616, 618, 623, 661, 662], "script": [201, 311, 312, 315, 316, 364, 365, 368, 369, 539, 570, 601, 608, 616, 620, 623, 624, 627, 644, 646, 653], "static_graph": 201, "flatten_static_graph": 201, "target_lay": 201, "linear2linearsearch": 201, "target_op_lut": 201, "lookup": 201, "tabl": [201, 212, 565, 577, 598, 603, 636, 638, 667], "current_pattern": 201, "statu": [201, 562, 569, 595, 643, 646, 647, 648, 650, 652], "selfmhasearch": 201, "classifierheadsearch": 201, "classifi": [201, 221, 245, 288, 318, 371, 596, 599], "classifierheadsearchertf": 201, "squeezer": 202, "postcompressionutil": 202, "librari": [202, 266, 310, 363, 418, 567, 574, 609, 613, 614, 618, 627, 633, 653, 655], "relat": [202, 218, 304, 314, 333, 338, 341, 367, 442, 557, 577, 616, 640, 641, 652, 666], "linearcompress": 202, "root_linear": 202, "target_linear": 202, "while": [202, 213, 221, 343, 350, 428, 539, 575, 576, 596, 602, 608, 614, 616, 621, 633, 635, 652, 654, 655, 658, 661], "hidden": [202, 207, 341, 575], "layer_1": 202, "act_fn": 202, "layer_2": 202, "linearcompressioniter": 202, "linear_pattern": 202, "register_pattern": [203, 341], "basepattern": [203, 205, 207], "unit": [203, 341, 570, 641, 652], "4x1": [203, 229, 230, 337, 613, 652, 667], "is_glob": [203, 341], "local": [203, 229, 230, 341, 509, 539, 565, 594, 626, 630, 635, 642, 643, 652, 660], "keep_mask_lay": 203, "invalid_lay": 203, "max_sparsity_ratio_per_op": [203, 208, 226, 229, 230, 613, 652], "sparsiti": [203, 205, 206, 208, 209, 210, 213, 215, 216, 219, 221, 229, 230, 343, 345, 565, 574, 596, 608, 613, 665, 667], "min_sparsity_ratio_per_op": [203, 226, 229, 230, 613, 652], "target_spars": [203, 226, 229, 230, 613, 652, 654, 666], "pytorchbasepattern": [203, 218], "kerasbasepattern": 203, "get_pattern": [204, 341], "patternmha": 205, "doc": [205, 206, 229, 230, 341, 359, 360, 371, 424, 439, 440, 443, 509, 565, 612, 613, 628, 631, 639], "md": [205, 206, 229, 230, 341, 371, 424], "n": [205, 206, 229, 230, 246, 262, 289, 303, 312, 341, 365, 443, 577, 594, 596, 598, 599, 641, 652, 655, 661, 663], "pytorchpatternninm": 206, "out": [206, 229, 230, 245, 246, 247, 288, 289, 290, 309, 341, 346, 520, 570, 571, 574, 596, 616, 621, 626, 627, 628, 630, 631, 633, 639, 652, 654, 655, 658], "pytorchpatternnxm": 207, "kept": [207, 341], "block_siz": [207, 341, 546, 658], "height": [207, 258, 262, 300, 303, 341, 601, 663, 666], "width": [207, 258, 262, 300, 303, 341, 593, 601, 652, 655, 663, 666], "vertic": [207, 262, 303, 341, 663], "keraspatternnxm": 207, "register_prun": [208, 217, 343], "baseprun": [208, 213, 215, 217], "current_sparsity_ratio": [208, 343], "global_step": [208, 343], "start_step": [208, 226, 229, 230, 343, 613, 652, 654], "end_step": [208, 226, 229, 230, 343, 613, 652, 654], "pruning_frequ": [208, 226, 229, 230, 613, 652], "target_sparsity_ratio": [208, 343], "show": [208, 565, 569, 599, 601, 613, 619, 634, 635, 636, 638, 641, 646, 647, 648, 661, 664, 665], "pytorchbaseprun": [208, 216], "kerasbaseprun": 208, "pytorchbasicprun": 209, "arrang": [209, 210, 215, 216, 246, 247, 250, 289, 290, 293, 596, 652], "proce": [209, 210, 215, 216], "regul": [209, 210, 215, 216], "kerasbasicprun": 209, "pytorchblockmaskprun": 210, "grad": [210, 215], "parse_valid_pruner_typ": 211, "get_prun": [211, 343], "pythonmultiheadattentionprun": 212, "mha_modul": 212, "partial": [212, 652, 655], "qkv": 212, "feedward": 212, "simultan": [212, 616, 640, 651, 654], "qkv_name": 212, "query_layer_nam": 212, "key_layer_nam": 212, "value_layer_nam": 212, "ffn_name": 212, "attention_ffn_nam": 212, "mha_nam": 212, "qkv_modul": 212, "ffn_modul": 212, "mha_compress": 212, "mhacompress": 212, "linear_lay": 212, "independ": [212, 418, 423, 577], "4x": [212, 572, 655], "subsequ": [212, 576, 616, 633], "head_mask": 212, "mha_head_s": 212, "similar": [212, 226, 613, 637, 654, 661, 664, 666], "mha_scor": 212, "lock": [213, 331, 332, 608, 651, 652], "pytorchpatternlockprun": 213, "parent": [213, 214, 219, 337, 343, 345, 662], "pytorchprogressiveprun": 214, "basicprun": [214, 217], "interpol": [214, 262, 303, 612, 652, 663], "fine": [214, 245, 288, 594, 596, 619, 652, 653, 655], "grain": [214, 652, 653, 664], "improv": [214, 539, 570, 593, 594, 613, 616, 633, 634, 636, 652, 653, 655, 657, 658, 664, 665, 667], "ad": [214, 245, 288, 311, 350, 364, 388, 428, 576, 577, 598, 614, 616, 621, 624, 628, 631, 641, 652, 658, 662], "retrain": [215, 600], "pytorchretrainfreeprun": 215, "pruner_class": [215, 216], "fast": [215, 229, 230, 574, 652, 653, 658], "retrainfreeprun": [215, 217], "effect": [215, 574, 575, 652, 653], "2204": 215, "09656": 215, "sparsegptprun": [216, 217], "most": [216, 229, 230, 318, 371, 598, 613, 614, 652, 655, 658, 661, 664, 667], "sparsegpt": [216, 217, 652], "massiv": [216, 652], "One": [216, 577, 594, 596, 601, 608, 638, 652, 653, 664], "2301": [216, 652], "00774": [216, 652], "opt": [217, 574, 611, 621, 652, 661, 664, 667], "least": [217, 344, 570, 613, 652, 664], "templat": [217, 344, 613, 652], "tree": [217, 344, 360, 440, 641], "nlp": [217, 229, 230, 344, 621, 637, 652, 655], "huggingface_model": [217, 344, 637], "classif": [217, 245, 262, 288, 303, 318, 344, 371, 599, 603, 612, 622, 636, 644, 647, 648, 652, 653], "pytorch_prun": [217, 310, 363], "eager": [217, 344, 423, 601, 608, 655, 657, 662], "config_file_path": [217, 344], "pruner_info": [217, 344], "pruning_class": 217, "avail": [217, 229, 230, 376, 578, 580, 584, 587, 590, 594, 602, 604, 606, 608, 626, 630, 635, 640, 641, 642, 646, 647, 648, 652, 664, 667], "regular": [218, 311, 342, 364], "register_reg": 218, "regulariz": 218, "get_reg_typ": 218, "get_reg": 218, "basereg": 218, "grouplasso": 218, "coeff": 218, "lasso": [218, 328, 608, 652], "reg_term": 218, "register_schedul": [219, 345], "get_schedul": [219, 345], "pruningschedul": 219, "gradual": [219, 345, 652], "oneshotschedul": [219, 345], "iterativeschedul": [219, 345], "get_tf_criterion": 220, "get_sparsity_ratio": 221, "elementwise_over_matmul_gemm_conv": 221, "elementwise_over_al": 221, "blockwise_over_matmul_gemm_conv": 221, "get_sparsity_ratio_tf": 221, "check_config": [221, 342], "prune_config": [221, 342], "everyth": [221, 342, 621], "reset_none_to_default": 221, "update_param": 221, "process_weight_config": 221, "global_config": [221, 327, 328, 330, 331, 332], "local_config": [221, 229, 230, 327, 328, 330, 331, 332], "default_config": 221, "pruners_info": 221, "process_yaml_config": 221, "check_key_valid": 221, "template_config": 221, "user_config": 221, "process_and_check_config": [221, 342], "process_config": [221, 342], "parse_last_linear": 221, "often": [221, 595, 599, 638, 651, 652], "might": [221, 571, 594, 635, 664], "caus": [221, 576, 595, 617, 636, 638, 652, 658], "drop": [221, 314, 342, 367, 570, 613, 614, 627, 652, 658, 661, 667], "parse_last_linear_tf": 221, "parse_to_prun": [221, 342], "parse_to_prune_tf": 221, "generate_pruner_config": 221, "dotdict": [221, 226, 230, 382, 565], "get_lay": 221, "collect_layer_input": 221, "layer_idx": 221, "layer_input": 221, "previou": [221, 576, 577, 613, 652, 659, 661, 662, 664, 665, 667], "prune_wanda": 223, "use_vari": 223, "low_mem_usag": 223, "dsnot": 223, "sij": 223, "wij": 223, "xj": 223, "2306": [223, 658], "11695": 223, "recurs": [224, 565], "wrappedgpt": 225, "layer_id": 225, "gpt": [225, 574, 611, 637, 652, 661, 667], "prunerv2": 226, "pruning_typ": [226, 229, 230, 613, 652], "pruning_scop": [226, 229, 230, 613, 652], "sparsity_decay_typ": [226, 229, 230, 613, 652], "pruning_op_typ": [226, 229, 230, 613, 652], "reg_typ": 226, "criterion_reduce_typ": 226, "resume_from_pruned_checkpoint": 226, "cfg_fname": 226, "parser": 226, "quantization_conf": 226, "pruning_conf": 226, "graph_optimization_conf": [226, 309], "mixedprecision_conf": 226, "benchmark_conf": 226, "nasconfig": [226, 230, 322, 324, 572], "approach": [226, 229, 230, 321, 322, 324, 571, 572, 593, 596, 599, 608, 613, 621, 633, 636, 644, 646, 647, 648, 652, 653, 654, 656, 658, 664, 666], "search_algorithm": [226, 230, 310, 323, 363, 572], "na": [226, 230, 310, 363, 376, 608, 667], "procedur": [226, 572, 652, 664], "deep_get": [227, 382, 509], "dot": [227, 509, 614, 655], "person": [227, 509, 569, 653], "john": [227, 509], "deep_set": [227, 382], "sex": [227, 569], "male": 227, "notat": [227, 230, 565], "pythonic_config": 228, "random_se": [229, 230, 350, 428, 613, 666], "1978": [229, 230], "default_workspac": [229, 230], "directori": [229, 230, 246, 247, 289, 290, 380, 507, 509, 560, 562, 564, 565, 596, 601, 604, 626, 628, 630, 631, 637, 639, 662], "histori": [229, 230, 564, 565, 633, 637, 664], "nc_workspac": [229, 230, 636, 637], "datetim": [229, 230], "now": [229, 230, 262, 303, 571, 572, 577, 596, 601, 624, 654, 663, 664], "strftime": [229, 230], "d_": [229, 230], "resum": [229, 230, 233, 234, 276, 277, 351, 354, 355, 356, 425, 428, 429, 430, 431, 433, 434, 435, 436], "flag": [229, 230, 312, 365, 598], "visual": [229, 230, 574, 624, 633, 660, 662, 664, 665], "displai": [229, 230, 359, 360, 439, 440, 509, 565, 633, 636], "2022": [229, 230, 574, 610, 652, 658, 661, 667], "workspace_path": [229, 230], "accuracycriterion": [229, 230, 613, 664], "accuracy_criterion": [229, 230, 382, 613, 637, 650, 654, 664, 666], "warmup": [229, 230, 592, 613, 654], "inter_num_of_thread": [229, 230, 418, 423, 613, 654], "intra_num_of_thread": [229, 230, 418, 423, 613, 654], "benchmark": [229, 230, 265, 310, 347, 363, 382, 565, 574, 582, 615, 616, 620, 624, 627, 633, 636, 664, 665, 666, 667], "onnxrt_trt_ep": [229, 230, 614, 655], "onnxrt_cuda_ep": [229, 230, 614, 655], "inter": [229, 230], "intra": [229, 230], "quantizationconfig": 229, "post_training_static_qu": [229, 596, 613, 654, 664], "calibration_sampling_s": [229, 230, 613, 638], "op_type_dict": [229, 230, 577, 654, 655, 658, 664], "op_name_dict": [229, 230, 598, 613, 636, 638, 655, 664], "strategy_kwarg": [229, 230, 660, 664], "quant_level": [229, 230, 636, 658, 661, 664], "posttrainingquantconfig": [229, 230, 424, 571, 574, 577, 595, 598, 603, 606, 612, 613, 615, 635, 636, 637, 638, 655, 656, 657, 658, 660, 661, 664], "quantizationawaretrainingconfig": [229, 230, 554, 571, 600, 603, 613, 655, 657, 664], "cv": [229, 230, 652], "object_detect": [229, 230, 314, 367], "recommendation_system": [229, 230], "overrid": [229, 230, 565, 594], "quantiztaion": [229, 230], "smooth_quant_arg": [229, 230, 655, 661], "gemm_to_matmul": [229, 230, 655], "graph_optimization_level": [229, 230, 654, 655], "disable_al": [229, 230, 654], "enable_bas": [229, 230], "enable_extend": [229, 230], "enable_al": [229, 230], "first_conv_or_matmul_quant": [229, 230, 655], "last_conv_or_matmul_quant": [229, 230, 655], "pre_post_process_quant": [229, 230, 655], "postprocess": [229, 230, 256, 259, 262, 266, 303, 310, 363, 371, 424, 557, 575, 613, 662, 663], "dedic": [229, 230], "quant_format": [229, 230, 308, 603, 636], "constraint": [229, 230, 309, 346, 613, 652, 660, 664, 666], "conv1": [229, 230, 655, 666], "tuning_strategi": [229, 230], "guarante": [229, 230, 613], "models": [229, 230, 382, 613, 650, 654], "footprint": [229, 230, 309, 333, 338, 346, 382, 600, 613, 650, 652, 654, 656], "earli": [229, 230, 613, 655, 664, 666], "stop": [229, 230, 613, 664, 665, 666], "excluded_precis": [229, 230, 657], "exclud": [229, 230, 575, 593, 657], "conserv": [229, 230, 363, 432], "use_distributed_tun": 229, "weightpruningconfig": [229, 230, 613, 651, 652], "pruning_config": [229, 230, 613, 652], "exp": [229, 230, 613, 652], "link": [229, 230, 245, 288, 371, 395, 424, 593, 596, 603, 626, 630, 633, 658, 667], "90": [229, 230, 656, 666, 667], "magnitude_progress": [229, 230], "snip_progress": [229, 230], "snip_momentum_progress": [229, 230], "feasibl": [229, 230], "situat": [229, 230, 601, 652], "unstructur": [229, 230, 337, 608, 652, 667], "8x1": [229, 230], "channelx1": [229, 230, 652], "1xchannel": [229, 230, 652], "itrex": [229, 230, 661], "start": [229, 230, 262, 303, 314, 367, 429, 609, 638, 653, 663, 664, 665, 668], "togeth": [229, 230, 262, 303, 599, 609, 620, 653, 662, 663], "sort": [229, 230, 353, 388, 433, 598, 636, 658, 664], "sinc": [229, 230, 309, 311, 333, 338, 346, 364, 599, 603, 609, 612, 627, 633, 638, 651, 658, 659], "lead": [229, 230, 594, 599, 613, 614, 638, 652, 658, 661], "increas": [229, 230, 388, 597, 608, 616, 633, 638, 658, 664], "cube": [229, 230, 652], "update_config": [229, 230], "knowledgedistillationlossconfig": [229, 230, 599, 600, 613, 651], "hyperparamet": [229, 230, 359, 660, 661, 664], "entropi": [229, 230, 593, 664], "groundtruth": [229, 230, 314, 367], "label": [229, 230, 233, 234, 245, 247, 248, 249, 250, 253, 258, 262, 267, 276, 277, 288, 290, 291, 292, 293, 296, 300, 303, 311, 313, 318, 364, 366, 371, 372, 424, 504, 554, 571, 595, 596, 598, 612, 613, 655, 663], "sum": [229, 230, 318, 371, 598, 599], "distillationconfig": [229, 230, 554, 599, 600, 613, 651], "prepare_compress": [229, 230, 554, 571, 599, 600, 613, 651, 652, 655], "criterion_conf": [229, 230], "d_conf": [229, 230, 600, 613, 651], "compression_manag": [229, 230, 554, 571, 599, 600, 613, 651, 652, 655], "featur": [229, 230, 245, 246, 258, 262, 288, 289, 300, 303, 570, 574, 592, 595, 597, 599, 613, 614, 615, 616, 620, 621, 624, 633, 635, 639, 652, 653, 659, 663], "distil_loss": [229, 230, 613], "ni_workload_nam": 230, "onnxrt_dnnl_ep": [230, 614, 655], "onnxrt_dml_ep": [230, 655], "tuningcriterion": [230, 613, 650, 660, 664], "tuning_criterion": [230, 613, 650, 660, 664], "npu": [230, 655], "xpu": [230, 539, 624, 655], "ptq": [230, 424, 571, 598, 601, 608, 613, 638, 655, 661, 662, 664], "meet": [230, 236, 347, 349, 425, 427, 571, 576, 650, 653, 654, 655, 658, 662, 664], "mse_v2": [230, 310, 352, 363, 432], "hawq_v2": [230, 363, 432], "docstr": [230, 443], "workload": [230, 562, 565, 635, 653], "insight": [230, 562, 574, 598, 653, 659, 664, 665], "copi": [230, 342, 565, 594, 595, 639], "deepcopi": [230, 594], "model_origin": [230, 424, 657], "qat_op_name_dict": 230, "low_memory_usag": 230, "hpoconfig": 230, "xgb": 230, "bo": 230, "intermediatelayersknowledgedistillationlossconfig": [230, 599], "relationship": [230, 635], "student_layer_nam": 230, "student_layer_output_process": 230, "teacher_layer_nam": 230, "teacher_layer_output_process": 230, "desir": [230, 258, 262, 300, 303, 576, 577, 652, 661, 663], "serv": [230, 380, 507, 539, 641, 646, 647, 648], "numer": [230, 318, 371, 388, 577, 614, 653, 655, 658], "abbrevi": 230, "l1": 230, "selfknowledgedistillationlossconfig": [230, 599, 613], "student1_layer_name1": 230, "teacher_layer_name1": 230, "student2_layer_name1": 230, "student1_layer_name2": 230, "teacher_layer_name2": 230, "student2_layer_name2": 230, "soft": 230, "hard": [230, 595, 598], "resblock": 230, "deepst": 230, "02": [230, 667], "mixedprecisionconfig": [230, 372, 443, 613, 614], "mixedprecis": [230, 319, 613], "won": [230, 655, 658], "work": [230, 309, 346, 539, 573, 576, 594, 595, 599, 628, 631, 639, 657, 658, 659, 661, 662], "mix_precis": [230, 363, 443, 613, 614], "converted_model": [230, 372, 613, 614], "exportconfig": 230, "14": [230, 307, 308, 603, 609, 648, 667], "dynamic_ax": [230, 308, 603], "qlinear": [230, 247, 254, 290, 297, 318, 371, 575, 623], "ax": [230, 308], "onnxqlinear2qdqconfig": 230, "onnxqlinear2qdq": 230, "torch2onnxconfig": [230, 603], "torch2onnx": [230, 305, 310, 363], "qdq_op_fp32_bia": 230, "qdq_op_int32_bia": 230, "qdq_op_fp32_bias_qdq": 230, "resnet50": [230, 574, 598, 601, 603, 614, 616, 620, 652, 655, 660, 667], "int8_onnx_config": [230, 603], "randn": [230, 603], "224": [230, 258, 300, 574, 596, 601, 603, 606, 613, 616, 635, 663, 666], "batch_siz": [230, 235, 237, 242, 243, 244, 245, 246, 265, 278, 280, 285, 286, 287, 288, 289, 308, 504, 572, 595, 596, 601, 603, 607, 613, 616, 655], "tf2onnxconfig": [230, 603], "tf2onnx": [230, 305, 310, 363], "output_graph": 230, "dyna": [230, 310, 323, 363, 572, 608, 654], "sigopt": [231, 232, 274, 275, 310, 363, 653], "tpe": [231, 232, 274, 275, 310, 363], "sigopttunestrategi": [233, 276], "q_dataload": [233, 234, 276, 277, 350, 351, 353, 354, 355, 356, 425, 428, 429, 430, 431, 433, 434, 435, 436, 607, 664], "eval_metr": [233, 234, 372, 424, 425, 428, 429, 430, 431, 433, 434, 435, 436, 554, 612, 635, 655], "q_hook": [233, 234, 276, 277, 350, 351, 353, 354, 355, 356, 425, 428, 429, 430, 431, 433, 434, 435, 436], "mandatori": [233, 234, 276, 277, 424, 613, 666], "yield": [233, 234, 243, 265, 276, 277, 286, 350, 372, 424, 428, 443, 554, 595, 655, 664], "well": [233, 234, 276, 277, 372, 424, 554, 572, 574, 594, 596, 652, 655, 659, 661, 666], "taken": [233, 234, 276, 277, 372, 424, 554, 655], "reserv": [233, 234, 276, 277], "abl": [233, 234, 276, 277, 372, 424, 554, 624, 633, 655], "tuner": [233, 234, 276, 277, 309, 346, 372, 424, 554, 655], "scalar": [233, 234, 276, 277, 372, 424, 554, 612, 655, 664], "pseudo": [233, 234, 276, 277, 424, 554, 658, 662], "someth": [233, 234, 247, 276, 277, 290, 424, 554], "fefin": [234, 277], "tpetunestrategi": [234, 277], "basedatalod": [235, 278, 504], "basedataload": [235, 240, 242, 278, 283, 285, 504], "last_batch": [235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595], "rollov": [235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595], "collate_fn": [235, 237, 238, 242, 244, 265, 278, 280, 281, 285, 287, 504, 595, 596], "batch_sampl": [235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595], "num_work": [235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595, 613, 655], "pin_memori": [235, 237, 242, 244, 265, 278, 280, 285, 287, 504, 595], "_generate_dataload": [235, 278, 504], "check_dataload": 236, "default_col": [237, 280], "outer": [237, 280], "defaultdataload": [237, 244, 280, 287], "style": [238, 252, 281, 295, 443, 594, 596, 607], "drop_last": [238, 243, 281, 286], "iterablefetch": [238, 281], "indexfetch": [238, 281], "base_dataload": [239, 282, 299, 310], "default_dataload": [239, 282, 299, 310], "fetcher": [239, 282, 299, 310], "mxnet_dataload": [239, 282, 299, 310], "onnxrt_dataload": [239, 282, 299, 310, 417], "pytorch_dataload": [239, 282, 299, 310], "tensorflow_dataload": [239, 282, 299, 310, 422], "mxnetdataload": [240, 283], "onnxrtbertdataload": [241, 284], "variant": [241, 284], "onnxrtdataload": [241, 284, 417], "pytorchdataload": [242, 285], "data_sourc": [243, 286, 557], "__iter__": [243, 247, 286, 290, 595, 596, 613], "matter": [243, 286, 657], "iterablesampl": [243, 286], "squential": [243, 286], "your": [243, 245, 286, 288, 539, 570, 594, 595, 596, 598, 601, 610, 613, 616, 619, 620, 621, 626, 627, 628, 630, 631, 633, 635, 639, 641, 646, 647, 648, 652, 653, 660, 662, 664, 665], "clear": [243, 286, 575, 605, 612, 613], "iterabledataset": [243, 247, 286, 290], "try": [243, 286, 571, 598, 636, 652, 655, 661, 664], "indexdataset": [243, 286], "__getitem__": [243, 247, 262, 286, 290, 303, 595, 596, 613], "__len__": [243, 247, 286, 290, 596], "batchsampl": [243, 286], "tfdatadataload": [244, 287], "tensorflow1": [244, 287], "coupl": [244, 287], "satisfi": [244, 287, 598, 609, 639], "tf1": [244, 287, 615], "although": [244, 287, 660], "tensorflowbertdataload": [244, 287], "tensorflowmodelzoobertdataload": [244, 287], "zoo": [244, 262, 287, 303, 574, 602, 606, 667], "tensorflowdataload": [244, 287, 422], "pytorchbertdataset": [245, 288], "model_typ": [245, 288, 565, 596], "tensordataset": [245, 288, 596], "repo": [245, 288, 568, 570, 596, 602, 626, 628, 630, 631, 668], "easi": [245, 288, 346, 603, 613, 636, 640, 653, 655, 658, 660], "squad": [245, 262, 288, 303, 315, 316, 318, 368, 369, 371, 596, 612, 652, 663, 667], "distilbert": [245, 288, 574, 596, 614, 653, 667], "xlnet": [245, 288, 596, 667], "xlm": [245, 288, 596, 667], "101": [245, 288, 318, 371, 612, 642, 661, 667], "2043": [245, 288], "2001": [245, 288], "onnxrtbertdataset": [245, 288], "data_dir": [245, 288, 596], "model_name_or_path": [245, 288, 596, 613, 621, 622, 637, 644, 647, 648, 656], "max_seq_length": [245, 262, 288, 303, 523, 596, 663], "do_lower_cas": [245, 261, 262, 288, 302, 303, 596, 663], "mrpc": [245, 288, 318, 371, 596, 612, 621, 644, 647, 648, 652, 664, 667], "dynamic_length": [245, 288, 596], "shortcut": [245, 288, 596], "longer": [245, 262, 288, 303, 596, 663], "shorter": [245, 262, 288, 303, 596, 663], "lowercas": [245, 288, 596], "choic": [245, 288, 575, 596, 612, 639, 661], "qqp": [245, 288, 596, 612, 667], "qnli": [245, 288, 596, 612, 667], "rte": [245, 288, 596, 612, 667], "st": [245, 288, 596, 612], "cola": [245, 288, 596, 612, 667], "mnli": [245, 288, 596, 612, 667], "wnli": [245, 288, 596, 612], "mobilebert": [245, 288, 596, 599, 667], "roberta": [245, 288, 596, 667], "uncas": [245, 262, 288, 303, 596, 663, 667], "load_and_cache_exampl": [245, 288], "convert_examples_to_featur": [245, 262, 288, 303], "max_length": [245, 288], "label_list": [245, 288, 318, 371], "output_mod": [245, 288], "pad_token": [245, 288], "pad_token_segment_id": [245, 288], "mask_padding_with_zero": [245, 288], "inputfeatur": [245, 262, 288, 303], "properti": [245, 288, 442, 610], "vocabulari": [245, 261, 262, 288, 302, 303, 663], "attention_mask": [245, 288, 613], "usual": [245, 288, 576, 598, 599, 638, 651, 652, 655, 656, 661], "NOT": [245, 288, 605], "token_type_id": [245, 288, 613], "segment": [245, 288, 312, 314, 365, 367, 570], "portion": [245, 288], "regress": [245, 288, 570, 598], "seq_length": [245, 288], "tensorflowbertdataset": [245, 288], "label_fil": [245, 262, 288, 303, 596, 663], "tfrecord": [245, 246, 247, 288, 289, 290, 596], "guid": [245, 288, 571, 574, 594, 596, 599, 609, 616, 624, 633, 668], "parsedecodebert": [245, 288], "tensorflowmodelzoobertdataset": [245, 246, 288, 289], "num_cor": [245, 246, 250, 288, 289, 293, 596], "28": [245, 246, 250, 288, 289, 293, 596, 667], "coco": [246, 253, 257, 289, 296, 314, 318, 367, 371, 612, 652], "parsedecodecoco": [246, 289], "cocorecorddataset": [246, 289], "interleav": [246, 289, 596], "parallel": [246, 289, 418, 423, 539, 596, 613, 640, 643, 664], "cocoraw": [246, 289, 596], "img_dir": [246, 289, 596], "val2017": [246, 289, 596], "anno_dir": [246, 289, 596], "annot": [246, 289, 314, 367, 443, 576, 577, 596, 612, 652, 664], "instances_val2017": [246, 289, 596], "jpg": [246, 250, 252, 289, 293, 295, 574, 596], "imag": [246, 247, 250, 252, 258, 262, 289, 290, 293, 295, 300, 303, 314, 367, 596, 601, 603, 652, 654, 661, 662, 663, 667], "coconpi": [246, 289, 596], "npy_dir": [246, 289, 596], "npy": [246, 289, 596], "tensorflowdataset": [247, 290], "pytorchdataset": [247, 290], "mxnetdataset": [247, 290], "onnxrtqldataset": [247, 290], "onnxrtitdataset": [247, 290], "IT": [247, 254, 290, 297, 653], "pytorchmxnetwrapdataset": [247, 290], "datafunc": [247, 290], "pytorchmxnetwrapfunct": [247, 262, 290, 303], "framework_dataset": [247, 290], "convent": [247, 290, 314, 367, 570, 599], "imageclassifi": [247, 290], "tensorflow_itex": [247, 250, 252, 254, 290, 293, 295, 297, 595, 654], "onnxrt_qdq": [247, 254, 290, 297, 654], "onnxrt_qlinearop": [247, 254, 262, 290, 297, 303, 654], "onnxrt_integerop": [247, 254, 262, 290, 297, 303, 654], "pytorch_ipex": [247, 254, 290, 297, 613, 654, 666], "pytorch_fx": [247, 254, 290, 297, 613, 654], "dataset_registri": [247, 290], "dataset_typ": [247, 290], "dataset_format": [247, 290], "data_format": [247, 258, 290, 300], "raw_imag": [247, 290], "overwrit": [247, 290, 626, 630], "download_url": [247, 290], "filenam": [247, 290, 509, 565, 596, 639], "md5": [247, 290], "address": [247, 290, 569, 594, 614, 635, 638, 641, 653], "gen_bar_updat": [247, 290], "check_integr": [247, 290], "fpath": [247, 290], "checksum": [247, 290], "calculate_md5": [247, 290], "chunk_siz": [247, 290], "cifar10": [247, 290, 596], "cifar100": [247, 290, 596], "databas": [247, 290, 641], "www": [247, 290, 596, 667], "toronto": [247, 290, 596], "kriz": [247, 290, 596], "cifar": [247, 290, 596, 667], "tar": [247, 290, 596, 598, 628, 631], "gz": [247, 290, 596, 598, 628, 631], "manual": [247, 290, 596, 616, 622, 624, 627, 641, 646, 647, 648, 652], "subset": [247, 250, 290, 293, 596, 638], "internet": [247, 290, 596, 635], "again": [247, 290, 596, 636, 638, 657], "pytorchcifar10": [247, 290], "mxnetcifar10": [247, 290], "tensorflowcifar10": [247, 290], "pytorchcifar100": [247, 290], "mxnetcifar100": [247, 290], "tensorflowcifar100": [247, 290], "mnist": [247, 290, 596, 601], "nation": [247, 290, 569], "institut": [247, 290], "standard": [247, 262, 290, 303, 524, 570, 576, 594, 598, 603, 612, 663, 664], "technologi": [247, 290, 611, 613], "fashionmnist": [247, 290, 596], "npz": [247, 290, 596], "idx1": [247, 290, 596], "ubyt": [247, 290, 596], "idx3": [247, 290, 596], "t10k": [247, 290, 596], "pytorchmnist": [247, 290], "mxnetmnist": [247, 290], "tensorflowmnist": [247, 290], "pytorchfashionmnist": [247, 290], "mxnetfashionmnist": [247, 290], "tensorflowfashionmnist": [247, 290], "imagefold": [247, 290, 596, 601, 613], "expect": [247, 290, 569, 570, 604, 611, 633, 655, 658, 664], "subfold": [247, 290, 636], "belong": [247, 290, 376, 655], "class_1": [247, 290, 596], "xxx": [247, 290, 596, 613], "png": [247, 290, 596], "xxy": [247, 290, 596], "xxz": [247, 290, 596], "class_n": [247, 290, 596], "123": [247, 290, 596, 663], "nsdf3": [247, 290, 596], "asd932_": [247, 290, 596], "categori": [247, 290, 313, 366, 592, 596, 623], "mxnetimagefold": [247, 290], "tensorflowtfrecorddataset": [247, 290], "tensorflowimagerecord": [247, 290], "imagenet": [247, 250, 258, 290, 293, 300, 572, 598, 613, 622, 638, 652, 662, 663, 666, 667], "000": [247, 290, 574, 596], "099": [247, 290, 596], "tensorflowvocrecord": [247, 290], "pascal": [247, 290], "voc": [247, 290, 318, 371], "2012": [247, 290], "00000": [247, 290], "00004": [247, 290], "00001": [247, 290], "00003": [247, 290], "dummydataset": [248, 249, 291, 292, 504], "127": [248, 249, 291, 292, 504, 596, 655, 661, 667], "stand_norm": [248, 249, 291, 292, 504, 596], "dummy_v2": [249, 292, 504, 596], "sparse_dummy_v2": [249, 292, 596], "label_shap": [249, 292, 504, 596], "sparsedummydataset": [249, 292], "dense_shap": [249, 292, 596], "sparse_ratio": [249, 292, 596], "imagenetraw": [250, 293, 596], "data_path": [250, 293, 596], "image_list": [250, 293, 596], "img1": [250, 293, 596], "img2": [250, 293, 596], "imgx": [250, 293, 596], "val_map": [250, 293, 596], "txt": [250, 293, 596, 598, 609, 635, 637, 638, 640, 641], "pytorchimagenetraw": [250, 293], "mxnetimagenetraw": [250, 293], "tensorflowimagenetraw": [250, 293], "inteltensorflow": [250, 252, 293, 295, 609], "tensorflowimagenetdataset": [250, 293], "onnxrtimagenetdataset": [250, 293], "bert_dataset": [251, 256, 294, 299, 310, 363], "coco_dataset": [251, 256, 294, 299, 310, 363], "dummy_dataset": [251, 256, 294, 299, 310, 363], "dummy_dataset_v2": [251, 256, 294, 299, 310, 363], "imagenet_dataset": [251, 256, 294, 299, 310, 363], "style_transfer_dataset": [251, 256, 294, 299, 310, 363], "styletransferdataset": [252, 295], "content_fold": [252, 295, 596], "style_fold": [252, 295, 596], "crop_ratio": [252, 295, 596], "resize_shap": [252, 295, 596], "image_format": [252, 295, 596], "holder": [252, 295, 596], "labelbalancecocorecordfilt": [253, 296], "balanc": [253, 296, 658, 661], "labelbalancecocorawfilt": [253, 296], "tensorflowfilt": [254, 297], "onnxrtqlfilt": [254, 297], "onnxrtitfilt": [254, 297], "pytorchfilt": [254, 297], "mxnetfilt": [254, 297], "filter_registri": [254, 297], "filter_typ": [254, 297], "__call__": [254, 297], "coco_filt": [255, 256, 298, 299, 310, 363], "imagenet_transform": [256, 259, 299, 301, 310, 363], "parsedecodecocotransform": 257, "quantizedinput": [258, 300, 663], "labelshift": [258, 300, 663], "label_shift": [258, 300, 663], "parsedecodeimagenet": [258, 300, 663], "proto": [258, 262, 300, 303, 663], "parsedecodeimagenettransform": [258, 300], "tensorflowtransposelastchannel": 258, "tensorflowshiftrescal": 258, "rescal": [258, 262, 303, 663], "tensorflowresizecropimagenettransform": [258, 300], "random_crop": [258, 300, 663], "resize_sid": [258, 300, 663], "resize_method": [258, 300], "bilinear": [258, 262, 300, 303, 663], "random_flip_left_right": [258, 300, 663], "mean_valu": [258, 300, 663], "channels_last": [258, 300, 616], "subpixel": [258, 300], "rgb": [258, 300], "seri": [258, 300, 574, 609, 613, 663], "applic": [258, 300, 577, 603, 616, 633, 635, 641, 642, 646, 647, 653, 658, 661, 662, 663, 665], "crop": [258, 262, 300, 303, 596, 663], "left": [258, 262, 300, 303, 627, 633, 661, 663], "std": [258, 262, 300, 303, 613, 663], "bilinearimagenettransform": [258, 300], "central_fract": [258, 300, 663], "875": [258, 300, 663], "fraction": [258, 300, 663], "onnxbilinearimagenettransform": [258, 300], "onnxresizecropimagenettransform": [258, 300], "std_valu": [258, 300], "229": [258, 300, 613], "225": [258, 300, 613], "resizewithaspectratio": [258, 300], "87": [258, 300, 667], "inter_pol": [258, 300], "cv2": [258, 300], "inter_area": [258, 300], "aspect": [258, 262, 300, 303, 663], "postprocess_cl": [260, 270, 613], "user_postprocess": [260, 270], "convert_to_unicod": [261, 302], "unicod": [261, 302], "assum": [261, 302, 314, 325, 367, 575, 605, 633], "load_vocab": [261, 302], "vocab_fil": [261, 262, 302, 303, 663], "convert_by_vocab": [261, 302], "vocab": [261, 302], "whitespace_token": [261, 302], "whitespac": [261, 302, 316, 369], "clean": [261, 302, 613], "piec": [261, 302, 311, 364, 612, 658], "fulltoken": [261, 302], "tokenzi": [261, 302], "basictoken": [261, 302], "punctuat": [261, 302, 311, 316, 364, 369], "lower": [261, 262, 302, 303, 316, 369, 429, 600, 652, 653, 655, 661, 663, 664], "wordpiecetoken": [261, 302], "unk_token": [261, 302], "unk": [261, 302], "max_input_chars_per_word": [261, 302], "wordpiec": [261, 262, 302, 303, 663], "concat_gener": [262, 303], "inc": [262, 303, 569, 576, 616, 623, 633, 635, 640, 653, 654, 659, 664], "tensorflowtransform": [262, 303], "mxnettransform": [262, 303], "pytorchtransform": [262, 303], "onnxrtqltransform": [262, 303], "onnxrtittransform": [262, 303], "transform_registri": [262, 303], "transform_typ": [262, 303], "basetransform": [262, 303], "tensorflowwrapfunct": [262, 303], "transform_func": [262, 303], "pytorchmxnettransform": [262, 303], "get_torchvision_map": [262, 303], "torchvis": [262, 303, 602, 606, 616, 622, 636], "composetransform": [262, 303], "transform_list": [262, 303, 663], "compos": [262, 303, 557, 663], "croptoboundingbox": [262, 303, 663], "offset_height": [262, 303, 663], "offset_width": [262, 303, 663], "target_height": [262, 303, 663], "target_width": [262, 303, 663], "box": [262, 303, 314, 318, 367, 371, 571, 612, 616, 627, 633, 662, 663, 664], "coordin": [262, 303, 350, 428, 640, 663, 664], "top": [262, 303, 309, 318, 333, 338, 346, 371, 570, 612, 633, 636, 638, 663], "corner": [262, 303, 570, 575, 577, 663], "horizont": [262, 303, 663], "mxnetcroptoboundingbox": [262, 303], "onnxrtcroptoboundingbox": [262, 303], "tensorflowcroptoboundingbox": [262, 303], "resizewithratio": [262, 303, 663], "min_dim": [262, 303, 663], "800": [262, 303, 663], "max_dim": [262, 303, 663], "1365": [262, 303, 663], "constant_valu": [262, 303], "longest": [262, 303, 663], "side": [262, 303, 596, 627, 663], "exce": [262, 303, 658, 663], "tensorflowresizewithratio": [262, 303], "permut": [262, 303, 663], "tensorflowtranspos": [262, 303], "mxnettranspos": [262, 303], "pytorchtranspos": [262, 303], "randomverticalflip": [262, 303, 663], "tensorflowrandomverticalflip": [262, 303], "randomhorizontalflip": [262, 303, 613, 663], "tensorflowrandomhorizontalflip": [262, 303], "toarrai": [262, 303, 663], "pil": [262, 303, 663], "casttftransform": [262, 303], "castonnxtransform": [262, 303], "castpytorchtransform": [262, 303], "centercroptftransform": [262, 303], "center": [262, 303, 573, 574, 609, 663, 664], "paddedcentercroptransform": [262, 303], "crop_pad": [262, 303], "resizetftransform": [262, 303], "bicub": [262, 303, 663], "resizepytorchtransform": [262, 303], "randomcroptftransform": [262, 303], "randomresizedcroppytorchtransform": [262, 303], "08": [262, 303, 663, 667], "randomresizedcropmxnettransform": [262, 303], "randomresizedcroptftransform": [262, 303], "normalizetftransform": [262, 303], "deviat": [262, 303, 598, 663], "broadcast": [262, 303, 601, 663], "rescalekeraspretraintransform": [262, 303], "rescaletftransform": [262, 303], "rescaletransform": [262, 303], "alignimagechanneltransform": [262, 303], "must": [262, 303, 314, 367, 539, 570, 571, 576, 592, 595, 609, 655, 663], "pytorchalignimagechannel": [262, 303], "tondarraytransform": [262, 303], "resizemxnettransform": [262, 303], "resizetransform": [262, 303], "cropresizetftransform": [262, 303], "boundari": [262, 303, 663], "area": [262, 303, 314, 367, 612, 663], "pytorchcropresizetransform": [262, 303], "mxnetcropresizetransform": [262, 303], "cropresizetransform": [262, 303], "centercroptransform": [262, 303], "mxnetnormalizetransform": [262, 303], "pytorchnormalizetransform": [262, 303], "normalizetransform": [262, 303], "randomcroptransform": [262, 303], "randomresizedcroptransform": [262, 303], "get_final_text": [262, 303], "pred_text": [262, 303], "orig_text": [262, 303], "project": [262, 303, 568, 569, 570, 639, 653, 660, 664, 668], "squadexampl": [262, 303], "qas_id": [262, 303], "question_text": [262, 303], "doc_token": [262, 303], "orig_answer_text": [262, 303], "start_posit": [262, 303], "end_posit": [262, 303], "is_imposs": [262, 303], "answer": [262, 303, 315, 316, 368, 369, 569, 638, 652, 663, 667], "unique_id": [262, 303], "example_index": [262, 303], "doc_span_index": [262, 303], "token_to_orig_map": [262, 303], "token_is_max_context": [262, 303], "input_mask": [262, 303, 613], "segment_id": [262, 303, 613], "read_squad_exampl": [262, 303], "input_fil": [262, 303], "doc_strid": [262, 303, 663], "max_query_length": [262, 303, 663], "output_fn": [262, 303], "inputbatch": [262, 303], "collecttransform": [262, 303], "10833": [262, 303], "tfsquadv1posttransform": [262, 303], "n_best_siz": [262, 303, 663], "384": [262, 303, 663], "64": [262, 303, 572, 658, 661, 663, 667], "max_answer_length": [262, 303, 663], "30": [262, 303, 602, 606, 608, 663, 667], "nbest_predict": [262, 303, 663], "question": [262, 303, 315, 316, 368, 369, 569, 570, 574, 575, 609, 616, 640, 652, 661, 663, 667], "anoth": [262, 303, 311, 320, 364, 565, 598, 599, 626, 630, 663, 664], "long": [262, 303, 594, 604, 658, 663], "document": [262, 303, 443, 576, 577, 582, 601, 611, 614, 618, 628, 631, 632, 639, 640, 642, 652, 659, 663, 665], "chunk": [262, 303, 663], "tfmodelzoocollecttransform": [262, 303], "tfsquadv1modelzooposttransform": [262, 303], "squadv1": [262, 303, 663], "parsedecodevoctransform": [262, 303], "conf_fname_or_obj": [263, 272, 304, 309, 319, 320, 321, 322, 324, 333, 338, 346], "unnecessari": [263, 613], "setter": 265, "calib_dataload": [265, 347, 424, 447, 460, 463, 571, 574, 595, 596, 598, 606, 607, 612, 613, 635, 636, 655, 656, 657, 658], "reason": [265, 569, 576, 595, 638, 658, 662, 664], "know": [265, 594, 601, 659], "metric_cl": [267, 371, 424, 613], "user_metr": [267, 371, 424], "recommend": [267, 371, 539, 575, 596, 605, 624, 627, 632, 634, 652, 654, 664], "set_backend": 268, "tensorflowimagefold": 290, "qlinear2qdq": [305, 310, 363], "qlinearop": [306, 598, 608, 624, 655, 667], "check_model": 306, "onnx_qlinear_to_qdq": 306, "input_name_to_nod": 306, "tf_to_fp32_onnx": 307, "tf_to_int8_onnx": 307, "int8_model": [307, 308, 575], "get_node_map": 308, "fp32_onnx_path": 308, "module_node_map": 308, "get_quantizable_onnx_op": 308, "quantize_nod": 308, "dynamic_quant_export": 308, "pt_fp32_model": 308, "pt_int8_model": 308, "weight_typ": 308, "s8": 308, "static_quant_export": 308, "_quantiz": [308, 391], "torch_to_fp32_onnx": 308, "do_constant_fold": 308, "torch_to_int8_onnx": 308, "across": [309, 319, 346, 372, 597, 613, 640, 643, 652, 656, 661, 664], "variou": [309, 319, 346, 372, 577, 608, 616, 643, 652, 654, 656], "dl": [309, 319, 333, 338, 346, 372, 598, 607, 620, 633, 653, 667], "bring": [309, 346, 627, 640, 661], "vari": [309, 333, 338, 346, 638, 652, 661, 667], "roc": [309, 318, 333, 338, 346, 371], "flexibl": [309, 333, 338, 346, 574, 599, 640, 652, 658], "techniqu": [310, 363, 567, 574, 608, 613, 616, 635, 651, 652, 653, 654, 655, 665, 666, 667], "bleu": [310, 312, 317, 363, 365, 370, 612, 652], "bleu_util": [310, 317, 363, 370], "coco_label_map": [310, 317, 363, 370], "coco_tool": [310, 317, 363, 370], "evaluate_squad": [310, 317, 363, 370], "f1": [310, 315, 317, 318, 363, 368, 370, 371, 601, 612, 613, 636, 660, 667], "basic_na": [310, 323, 363], "nas_util": [310, 323, 363], "pruner_legaci": [310, 363], "gradient_sensit": [310, 329, 363], "group_lasso": [310, 329, 363], "pruning_recip": [310, 363], "tile_pattern": [310, 334, 335], "prune_util": [310, 339, 363], "tuning_sampl": [310, 352, 358, 363, 432, 438], "tuning_spac": [310, 352, 358, 359, 361, 363, 432, 438, 439, 441], "tuning_struct": [310, 352, 358, 359, 360, 363, 432, 438, 439, 440], "auto_mixed_precis": [310, 352, 363, 432], "graph_optim": [310, 363], "mixed_precis": [310, 363, 372, 613], "model_convers": [310, 363], "pruning_v2": [310, 363], "unicoderegex": [311, 364], "hoc": [311, 364], "hack": [311, 364], "recogn": [311, 364, 664], "nondigit_punct_r": [311, 364], "compil": [311, 364, 613], "express": [311, 364, 569], "preced": [311, 364, 661, 664], "digit": [311, 364, 565, 653], "punct_nondigit_r": [311, 364], "symbol_r": [311, 364], "bleu_token": [311, 364], "mose": [311, 364], "smt": [311, 364], "mosesdecod": [311, 364], "mteval": [311, 364], "v14": [311, 364], "pl": [311, 364], "l954": [311, 364], "l983": [311, 364], "bilingu": [311, 364], "understudi": [311, 364], "qualiti": [311, 364, 594], "machin": [311, 364, 603, 609, 619, 633, 635, 641, 653, 661, 662], "translat": [311, 312, 364, 365, 652, 664], "natur": [311, 364, 603], "approxim": [311, 312, 364, 365, 576, 612, 658], "glue": [311, 318, 364, 371, 596, 612, 613, 622], "word": [311, 364, 594, 612, 652, 658, 667], "ngram": [311, 364, 612], "breviti": [311, 312, 364, 365, 612], "doe": [311, 364, 442, 594, 595, 596, 612, 613, 658, 659, 663], "beam": [311, 364, 612], "tensor2tensor": [312, 365], "bleu_hook": [312, 365], "compute_bleu": [312, 365], "reference_corpu": [312, 365], "translation_corpu": [312, 365], "max_ord": [312, 365], "use_bp": [312, 365], "against": [312, 365], "gram": [312, 365], "bleu_scor": [312, 365], "third": [314, 367, 570, 610], "parti": [314, 367, 570, 610, 655], "pycocotool": [314, 367, 604, 609], "noth": [314, 367, 664], "thu": [314, 367, 539, 613, 652, 655], "cannot": [314, 367, 571, 594, 604, 658, 662], "jonathanhuang": [314, 367], "image_id": [314, 367, 612], "invok": [314, 367, 539, 576], "groundtruth_dict": [314, 367], "exportgroundtruthtococo": [314, 367], "groundtruth_boxes_list": [314, 367], "groundtruth_classes_list": [314, 367], "max_num_class": [314, 367], "output_path": [314, 367], "detections_list": [314, 367], "exportdetectionstococo": [314, 367], "detection_boxes_list": [314, 367], "detection_scores_list": [314, 367], "detection_classes_list": [314, 367], "cocowrapp": [314, 367], "loadannot": [314, 367], "cocoevalwrapp": [314, 367], "agnostic_mod": [314, 367], "computemetr": [314, 367], "detection_typ": [314, 367], "bbox": [314, 367, 571, 612], "hold": [314, 350, 367, 428, 596], "iou_typ": [314, 367], "iou_thr": [314, 318, 367, 371, 612], "map_point": [314, 318, 367, 371, 612], "cocoev": [314, 367], "mscoco": [314, 367], "Then": [314, 367, 576, 598, 626, 628, 630, 631, 638, 661, 664], "exportsingleimagegroundtruthtococo": [314, 367], "next_annotation_id": [314, 367], "category_id_set": [314, 367], "groundtruth_box": [314, 367], "groundtruth_class": [314, 367], "groundtruth_mask": [314, 367], "groundtruth_is_crowd": [314, 367], "ingest": [314, 367], "here": [314, 367, 443, 576, 596, 601, 602, 603, 605, 606, 611, 612, 621, 628, 631, 633, 636, 639, 641, 655, 659, 660, 661, 667], "exportsingleimagedetectionstococo": [314, 367], "uniqu": [314, 347, 367, 655], "assign": [314, 367, 565, 601, 654, 664], "num_gt_box": [314, 367], "num_detect": [314, 318, 367, 371, 612, 613, 666], "image_height": [314, 367], "image_width": [314, 367], "detection_mask": [314, 367], "crowd": [314, 367], "insid": [314, 367, 539, 599, 600, 634, 652, 656, 664], "exportsingleimagedetectionboxestococo": [314, 367], "detection_box": [314, 367, 613, 666], "detection_scor": [314, 367, 613, 666], "detection_class": [314, 367, 613, 666], "exporsingleimagedetectionboxestococo": [314, 367], "exportsingleimagedetectionmaskstococo": [314, 367], "allenai": [315, 316, 368, 369], "bi": [315, 316, 368, 369], "att": [315, 316, 368, 369], "flow": [315, 316, 368, 369, 571, 572, 613], "f1_score": [315, 316, 368, 369], "ground_truth": [315, 316, 368, 369], "ground": [315, 316, 368, 369], "truth": [315, 316, 368, 369], "metric_max_over_ground_truth": [315, 316, 368, 369], "metric_fn": [315, 316, 368, 369], "exact_match_scor": [315, 368], "exact": [315, 368], "articl": [315, 316, 368, 369], "paragraph": [315, 316, 368, 369], "qa": [315, 316, 368, 369, 574], "normalize_answ": [316, 369], "newlin": [316, 369, 565], "tab": [316, 369, 633, 662], "harmon": [316, 318, 369, 371], "recal": [316, 318, 369, 371], "answer_start": [316, 369], "177": [316, 369, 667], "denver": [316, 369], "bronco": [316, 369], "nfl": [316, 369], "afc": [316, 369], "super": [316, 369, 572], "bowl": [316, 369], "50": [316, 369, 572, 576, 638, 652, 661, 667], "56be4db0acb8001400a502ec": [316, 369], "percentag": [316, 369, 388, 593, 658, 666], "tensorflowmetr": [318, 371], "maintain": [318, 371, 539, 569, 570, 594, 615, 616, 628, 631, 635, 640, 641, 652, 658, 659], "pytorchmetr": [318, 371], "mxnetmetr": [318, 371], "onnxrtqlmetr": [318, 371], "onnxrtitmetr": [318, 371], "metric_registri": [318, 371], "metric_typ": [318, 371], "decorator_metr": [318, 371], "basemetr": [318, 371, 424], "single_output": [318, 371], "hvd": [318, 371, 601], "wrappytorchmetr": [318, 371], "wrapmxnetmetr": [318, 371], "wraponnxrtmetr": [318, 371], "proport": [318, 371], "pred_list": [318, 371], "pytorchloss": [318, 371], "mae": [318, 371, 612], "compare_label": [318, 371, 424, 612], "rmse": [318, 371, 612, 664], "tensorflowtopk": [318, 371], "k": [318, 371, 424, 612, 635, 652], "among": [318, 371, 627, 661], "outcom": [318, 371], "num_correct": [318, 371], "num_sampl": [318, 371], "generaltopk": [318, 371], "cocomapv2": [318, 371, 612], "anno_path": [318, 371, 612], "map_kei": [318, 371], "detectionboxes_precis": [318, 371], "output_index_map": [318, 371, 612], "tensorflowmap": [318, 371], "tensorflowcocomap": [318, 371], "tensorflowvocmap": [318, 371], "squadf1": [318, 371, 612], "miou": [318, 371], "num_class": [318, 371], "21": [318, 371, 621, 622, 644, 647, 648, 653, 661, 667], "iou": [318, 371], "intersect": [318, 371, 575, 612], "union": [318, 371, 387, 388, 390, 394, 401, 554, 612, 644], "onnxrtglu": [318, 371], "dlrm": [318, 371], "modelconvers": 320, "typic": [320, 347, 572, 574, 600, 602, 606, 638, 652, 667], "basicna": 321, "model_build": [321, 324], "conf_fnam": 321, "nasbas": [324, 572], "nas_registri": 325, "nas_method": 325, "create_search_space_pool": 325, "idx": [325, 596], "find_pareto_front": 325, "pareto": [325, 572], "front": [325, 572], "n_point": 325, "n_metric": 325, "n_pareto_point": 325, "gradientsensitivityprun": 327, "pytorchmodel": [327, 328, 330, 331, 332, 381], "overwritten": [327, 328, 330, 331, 332, 621], "grouplassoprun": 328, "legaci": 329, "basicmagnitudeprun": 330, "patternlockprun": [331, 343], "pruner_registri": 332, "clase": 332, "pruningconf": [333, 338], "tfpruningcallback": [333, 338], "input_model": [333, 338, 615, 636, 637, 638, 662], "pure": [333, 338, 652], "pattern_registri": 336, "pattern_typ": 336, "patternbas": 336, "mask_shap": [336, 337], "is_contigu": 336, "tile": [337, 594], "tilepatternbas": 337, "tilepattern_1x1": 337, "1x1": [337, 599, 613, 652], "tilepattern_2x2": 337, "2x2": [337, 661], "tilepattern_1x16": 337, "1x16": 337, "tilepattern_4x1": 337, "tilepattern_1x2": 337, "1x2": [337, 661], "patternnxm": 341, "patternninm": 341, "reset_non_value_to_default": 342, "parse_not_to_prun": 342, "update_frequency_on_step": [343, 654], "max_sparsity_ratio_per_lay": [343, 654], "magnitudeprun": 343, "snipprun": 343, "snipmomentumprun": 343, "moreoev": 343, "quantconf": 346, "separ": [347, 569, 594, 607, 610, 641, 643, 651, 654], "opt_model": [347, 613], "fulli": [347, 613, 641, 655, 661], "train_func": [347, 554, 601, 613, 655], "automixedprecisiontunestrategi": [348, 426], "basictunestrategi": [349, 427], "polici": [349, 353, 425, 427, 433, 569, 574, 666, 668], "bayesiantunestrategi": [350, 428], "acq_max": [350, 428], "ac": [350, 428], "gp": [350, 428], "y_max": [350, 428], "n_warmup": [350, 428], "10000": [350, 428, 652], "n_iter": [350, 428], "acquisit": [350, 428], "gaussian": [350, 428, 664], "relev": [350, 428, 576, 577, 594, 638, 652], "acq": [350, 428], "randomst": [350, 428], "scipi": [350, 428], "x_max": [350, 428], "targetspac": [350, 428], "pbound": [350, 428], "9527": [350, 428, 613, 666], "bayesianoptim": [350, 428], "exhaustivetunestrategi": [351, 430], "msetunestrategi": [353, 433], "mse_v2tunestrategi": [354, 434], "revert": [354, 362, 434, 442, 664], "randomtunestrategi": [355, 435], "strategy_registri": [356, 436, 664], "tunestrategi": [356, 436, 664], "tuningsamplerregistri": 359, "tuningsampl": [359, 439], "tuningord": [359, 439], "tuningspac": [359, 360, 439, 440], "tuning_order_lst": [359, 439], "initial_op_tuning_cfg": [359, 439], "modelwisetuningsampl": [359, 439], "tuning_items_prior": [359, 439], "op_dtype_dict": [359, 439], "optuningconfig": [359, 360, 361, 439, 440, 441], "optypewisetuningsampl": [359, 439], "opwisetuningsampl": [359, 439], "fallbacktuningsampl": [359, 439], "op_dtyp": [359, 439], "skip_first": [359, 439], "smoothquantsampl": [359, 439], "tuningitem": [360, 440], "item_typ": [360, 440], "pattern_to_intern": [360, 440], "default_dtyp": [360, 440], "pattern_to_path": [360, 440], "quant_mode_from_pattern": [360, 440], "internal_pattern": [360, 440], "initial_tuning_cfg_with_quant_mod": [360, 440], "op_name_typ": [360, 440], "step1": [360, 440], "step2": [360, 440], "complet": [360, 440, 575, 576, 652, 655, 664, 666, 667], "step3": [360, 440], "step4": [360, 440], "step5": [360, 440], "op_quant_mod": [361, 441], "ordereddefaultdict": [362, 442], "extract_data_typ": [362, 442], "reverted_data_typ": [362, 442], "signed_flag": [362, 442], "get_adaptor_nam": [362, 442], "experiment": [363, 572, 596, 600, 601, 603, 609, 613, 652, 654, 655, 659, 663], "base_model": [363, 374], "keras_model": [363, 374], "mxnet_model": [363, 374], "nets_factori": [363, 374, 505], "onnx_model": [363, 374, 384, 385, 387, 388, 390, 399, 417, 636], "tensorflow_model": [363, 374, 422, 638], "torch_model": [363, 374], "collect_layer_histogram": [363, 558], "create_obj_from_config": [363, 558], "kl_diverg": [363, 558], "load_huggingfac": [363, 558, 613], "neural_insights_util": [363, 558], "weights_detail": [363, 558], "sub_class": [371, 424], "register_customer_metr": 371, "topk": [371, 424, 601, 612, 613, 635, 655], "frozen": [372, 380, 424, 507, 615], "savedmodel": [372, 380, 424, 507, 667], "onnx_ml_pb2": [372, 615], "hybirdblock": [372, 424], "basemodel": [373, 460, 463, 507], "plai": [373, 507, 653, 658, 661], "role": [373, 507, 658, 661], "kerasmodel": [375, 507], "get_model_fwk_nam": 376, "fwk": 376, "mxnetmodel": 377, "net": [378, 508], "tfslimnetsfactori": [378, 508], "get_model_typ": [380, 507], "validate_graph_nod": [380, 507], "validate_and_inference_input_output": [380, 507], "graph_sess": [380, 507], "graph_def_sess": [380, 507], "frozen_pb_sess": [380, 507], "load_saved_model": [380, 507], "saved_model_tag": [380, 507], "signatur": [380, 507], "metagraphdef": [380, 507], "keras_sess": [380, 507], "slim_sess": [380, 507], "checkpoint_sess": [380, 507], "estimator_sess": [380, 507], "saved_model_sess": [380, 507], "tensorflowbasemodel": [380, 422, 507], "tensorflowsavedmodelmodel": [380, 507], "tensorflowllmmodel": [380, 507], "exceed": [380, 507], "2gb": [380, 507], "tensorflowqatmodel": [380, 507], "tensorflowcheckpointmodel": [380, 507], "tensorflowmodel": [380, 507], "pytorchbasemodel": 381, "pytorchfxmodel": 381, "ipexmodel": 381, "driven": [382, 574, 613, 633, 650, 662], "objective_registri": 382, "objective_custom_registri": 382, "obj_cl": 382, "eural_compressor": 382, "objective_cl": 382, "user_object": 382, "__class__": 382, "__name__": 382, "objective_cfg": 382, "usr_cfg": 382, "user_obj_cfg": 382, "easili": [382, 575, 617, 621, 633, 650, 661], "peak": [382, 650], "multiobject": 382, "metric_criterion": 382, "metric_weight": 382, "obj_criterion": 382, "obj_weight": 382, "is_measur": 382, "calibrationdataread": [384, 385, 387, 388, 391, 393, 394, 395], "pathlib": [385, 387, 388, 390, 393, 394], "weight_dtyp": [387, 388, 390, 396, 461], "weight_bit": [387, 388, 390, 394, 396, 576], "weight_group_s": [387, 388, 390, 396], "weight_sym": [387, 388, 390, 396, 461], "91": [387, 658, 661, 667], "apply_awq_on_model": 387, "quant_config": [387, 388, 390, 393, 401, 451, 460, 463, 509, 549, 553], "calibration_data_read": [387, 388, 393, 394], "nnx": 387, "stabil": [388, 658], "apply_gptq_on_model": 388, "apply_rtn_on_model": 390, "nodeproto": 391, "data_read": 391, "reader": 391, "smooth_quant_entri": [393, 594], "smoohquantconfig": [393, 396], "rtn_quantize_entri": 393, "rtnconfig": [393, 394, 396, 401, 544, 546, 553], "gptq_quantize_entri": 393, "gptqconfig": [393, 394, 396, 546], "awq_quantize_entri": 393, "awqconfig": [393, 396], "model_input": 394, "base_tun": [394, 545], "expand": 394, "eatch": 394, "eval": [394, 571, 594, 595, 598, 616, 655, 662], "l139": 395, "act_dtyp": [396, 461], "get_default_rtn_config": [396, 546], "get_default_gptq_config": [396, 546], "get_default_awq_config": 396, "fusedconv": 396, "calib_it": 396, "auto_alpha_arg": [396, 461, 661], "alpha_min": [396, 661], "alpha_max": [396, 661], "alpha_step": [396, 661], "attn_method": 396, "get_default_sq_config": [396, 461], "register_algo": [401, 509, 553, 594], "algos_map": [401, 509, 553], "example_algo": [401, 509, 553], "get_qrange_for_qtyp": 401, "parserfactori": 403, "onnxrtparserfactori": 405, "onnxprofilingpars": 407, "respons": [407, 408, 412, 646, 647, 648, 655], "profilingpars": 408, "profilingresult": 409, "total_execution_tim": 409, "accelerator_execution_tim": 409, "cpu_execution_tim": 409, "op_run": 409, "op_defin": 409, "tensorflowparserfactori": 410, "tensorflowprofilingpars": 412, "profilerfactori": [413, 415, 420], "create_onnx_config": 418, "ort": 418, "sessionopt": 418, "delete_assign": 423, "create_tf_config": 423, "tf_modul": 423, "configproto": 423, "set_eager_execut": 423, "entir": [424, 554, 571, 576, 577, 593, 640, 652], "autotunestrategi": 425, "conservativetunestrategi": 429, "o0": [429, 664], "who": [429, 569], "hawq_v2tunestrategi": 431, "made": [431, 575, 655, 659, 664], "impact": [431, 652, 659, 664], "tunestrategymeta": 436, "metaclass": 436, "lowerbitssampl": 439, "blockfallbacktuningsampl": 439, "op_block_lst": 439, "target_dtyp": 439, "alpha_list": 439, "weightonlyquantsampl": 439, "quantopt": 442, "quant_typ": 442, "quant_opt": 442, "preprocess_user_cfg": 442, "op_user_cfg": 442, "op_user_cfg_modifi": 442, "build_slave_faker_model": 442, "slave": [442, 664], "virtual": [442, 653], "classregist": 442, "fun": 443, "attribute1": 443, "module_debug_level1": 443, "debug": [443, 561, 598, 626, 630, 634, 664, 665], "function1": 443, "param1": 443, "param2": 443, "parameter1": 443, "parameter2": 443, "function2": 443, "pep": [443, 594], "484": [443, 667], "output_model": [443, 613, 636, 638, 662], "function3": 443, "section": [443, 577, 594, 598, 599, 600, 633, 636, 639, 652, 654, 658, 666], "restructuredtext": 443, "liter": 443, "generator1": 443, "example_gener": 443, "exampleclass": 443, "param3": 443, "public": [443, 569, 628, 631], "attr1": 443, "attr2": 443, "attr5": 443, "api_doc_exampl": 444, "smoothquantconfig": [447, 461], "calib_iter": [447, 451, 460, 463, 576], "scaler": 448, "kerasqueri": 451, "kerasconfigconvert": 451, "staticquantconfig": [451, 460, 461, 509], "static_quantize_entri": 460, "weight_granular": 461, "per_tensor": [461, 576, 577, 605, 655, 666], "act_sym": 461, "act_granular": 461, "base_config": [461, 463, 549], "get_all_registered_config": 461, "get_default_static_quant_config": 461, "record_max_info": 461, "weight_clip": 461, "default_sq_alpha_arg": 461, "quantize_model": 463, "dummydatasetv2": 504, "itex_instal": 509, "instal": [509, 601, 604, 606, 616, 618, 621, 624, 628, 631, 633, 634, 636, 637, 638, 668], "combine_histogram": [509, 565], "old_hist": [509, 565], "old": [509, 565, 613, 659], "get_all_fp32_data": [509, 565], "get_tensor_histogram": [509, 565], "scale_info": [509, 565], "dequantize_weight": [509, 565], "weight_tensor": [509, 565], "min_filter_tensor": [509, 565], "max_filter_tensor": [509, 565], "dump_data_to_loc": [509, 565], "pkl": [509, 565, 637], "load_data_from_pkl": [509, 565], "cpuinfo": [509, 565], "statist": [509, 521, 565, 566], "header": [509, 521, 565, 604], "field_nam": [509, 521, 565], "output_handl": [509, 521, 565], "printer": [509, 521, 565], "captureoutputtofil": [509, 565], "tmp_file_path": [509, 565], "stream": [509, 565, 667], "sy": [509, 565, 594, 619], "stderr": [509, 565], "captur": [509, 565], "lazyimport": [509, 565], "lazi": [509, 565], "till": [509, 565, 664], "static_quant": 520, "run_fn": [520, 523, 545, 549], "carri": [520, 652], "warm": 521, "dump_model_op_stat": 521, "get_quantizable_ops_recurs": 521, "use_full_rang": [522, 536, 546], "use_auto_scal": 522, "use_mse_search": [522, 536, 546], "use_layer_wis": [523, 546], "run_arg": [523, 545, 549], "register_acceler": 524, "ellipsi": 524, "cuda_acceler": 524, "cpu_acceler": 524, "hqqmoduleconfig": 526, "immut": 526, "constructor": 526, "quant_api": 528, "device_typ": 539, "_dtype": 539, "cache_en": 539, "manag": [539, 554, 557, 613, 616, 617, 627], "region": [539, 661], "chosen": [539, 576, 593], "enter": [539, 627, 633, 641], "half": [539, 614, 624], "hpu": 539, "float8_e4m3fn": 539, "autocastmodel": 539, "affect": [539, 661], "dataparallel": 539, "distributeddataparallel": 539, "torch_dtyp": [539, 577], "rtn_entri": 544, "configs_map": 544, "use_sym": 546, "use_double_qu": 546, "double_quant_dtyp": 546, "double_quant_bit": 546, "double_quant_use_sym": 546, "double_quant_group_s": 546, "act_ord": 546, "static_group": [546, 658], "get_default_hqq_config": 546, "hqqconfig": 546, "hqq": 546, "loop": [554, 571, 572, 576, 577, 605, 643, 660, 664], "compressionmanag": 554, "deal": 554, "pruningconfig": 554, "orchestr": [554, 574, 608, 665], "on_train_begin": [554, 571, 599, 600, 613, 651, 652, 655], "train_loop": [554, 613, 651], "on_epoch_begin": [554, 557, 599, 600, 613, 651], "on_step_begin": [554, 557, 599, 600, 613, 651, 652], "on_after_compute_loss": [554, 599, 600, 613, 651], "on_before_optimizer_step": [554, 599, 600, 613, 651, 652], "on_step_end": [554, 557, 599, 600, 613, 651], "on_epoch_end": [554, 557, 599, 600, 613, 651], "on_train_end": [554, 599, 600, 613, 651, 652, 655], "path_to_sav": 554, "top1": [554, 612, 635, 652, 655, 667], "callbacks_list": 554, "layerhistogramcollector": 555, "layer_tensor": 555, "include_lay": 555, "get_func_from_config": 557, "func_dict": 557, "get_preprocess": 557, "get_metr": 557, "get_postprocess": 557, "get_algorithm": 557, "create_dataset": 557, "cfg_preprocess": 557, "cfg_filter": 557, "create_dataload": 557, "dataloader_cfg": 557, "create_eval_func": 557, "postprocess_cfg": 557, "baselin": [557, 660, 661, 662], "create_train_func": 557, "train_cfg": 557, "Their": 557, "auxiliari": 558, "optimizedmodel": 560, "from_pretrain": [560, 613], "save_for_huggingface_upstream": [560, 613], "saved_dir": [560, 658], "msg": [561, 642, 646, 647], "fatal": 561, "warn": [561, 594], "alia": [561, 565, 618, 623], "register_neural_insights_workload": 562, "workload_loc": [562, 565], "workload_mod": 562, "workload_nam": 562, "uuid": 562, "update_neural_insights_workload": 562, "workload_uuid": 562, "update_neural_insights_workload_accuracy_data": 562, "baseline_accuraci": 562, "optimized_accuraci": 562, "get_model_path": 562, "is_int8_model": 564, "load_weight_onli": 564, "checkpoint_dir": 564, "history_cfg": 564, "best_configur": 564, "best_model_weight": 564, "snapshot": [564, 637], "recover_model_from_json": 564, "json_file_path": 564, "cfg_from_fil": 565, "yaml_fil": [565, 596, 601], "time_limit": 565, "get_siz": 565, "seen": [565, 575], "compute_spars": 565, "fault_tolerant_fil": 565, "equal_dict": 565, "d2": 565, "compare_kei": 565, "ignore_kei": 565, "ignor": [565, 593, 596, 658, 661, 664], "get_tuning_histori": 565, "tuning_history_path": 565, "offlin": [565, 569, 613, 655, 661], "str2arrai": 565, "global_st": 565, "show_memory_info": 565, "hint": 565, "dump_class_attr": 565, "compare_object": 565, "obj1": 565, "obj2": 565, "ignore_attr": 565, "comparison": [565, 658, 659, 662], "alias_param": 565, "param_nam": 565, "param_alia": 565, "alias": [565, 594], "print_tabl": 565, "column_map": 565, "table_entri": 565, "titl": [565, 610, 634, 664], "insert_newlin": 565, "prettyt": 565, "column": [565, 658, 661], "handler": [565, 664], "row": [565, 598, 636, 661], "decim": 565, "get_tensors_info": 565, "get_weights_detail": 565, "weightdetail": 565, "dump_tabl": 565, "file_typ": 565, "csv": [565, 572, 636, 637], "dump_table_to_csv": 565, "get_number_of_socket": 565, "platform": [565, 574, 608, 616, 624, 643, 653, 655], "opentri": 565, "activation_min": 565, "activation_max": 565, "print_op_list": 565, "get_op_list": 565, "minmax_file_path": 565, "input_model_tensor": 565, "optimized_model_tensor": 565, "activation_min_max": 565, "calculate_ms": 565, "mse_metric_gap": 565, "fp32_tensor": 565, "dequantize_tensor": 565, "euclidean": [565, 599], "distanc": [565, 599], "check_key_exist": 565, "weightsdetail": 566, "input_tensor_data": 566, "optimized_tensor_data": 566, "weightsstatist": 566, "welcom": [568, 569, 570, 574, 635, 642, 668], "interest": [569, 574, 635, 662], "foster": 569, "particip": [569, 643], "commun": [569, 635], "harass": 569, "experi": [569, 616, 638, 660, 661, 664], "everyon": 569, "regardless": 569, "ag": 569, "bodi": 569, "ethnic": 569, "characterist": 569, "gender": 569, "educ": 569, "socio": 569, "econom": 569, "race": 569, "religion": 569, "sexual": 569, "orient": 569, "contribut": [569, 574, 652], "inclus": 569, "Being": 569, "viewpoint": 569, "gracefulli": 569, "focus": [569, 575], "empathi": 569, "toward": [569, 599], "member": [569, 575], "unaccept": 569, "imageri": 569, "unwelcom": 569, "troll": 569, "insult": 569, "derogatori": 569, "polit": 569, "attack": 569, "privat": 569, "publish": [569, 610, 611, 614, 634, 661], "electron": 569, "explicit": 569, "permiss": 569, "inappropri": 569, "profession": 569, "clarifi": 569, "appropri": [569, 593, 661], "fair": 569, "action": [569, 628, 631], "edit": 569, "reject": 569, "commit": [569, 570], "wiki": 569, "ban": 569, "temporarili": 569, "deem": 569, "threaten": 569, "offens": 569, "harm": 569, "mail": 569, "social": [569, 653], "media": [569, 653], "account": [569, 660, 664], "appoint": 569, "onlin": [569, 660], "event": [569, 662], "abus": 569, "report": [569, 570, 574, 643, 660], "contact": [569, 659, 660], "complaint": 569, "review": [569, 570, 574, 653], "investig": [569, 594, 638], "circumst": [569, 654], "oblig": [569, 639], "confidenti": [569, 635], "regard": [569, 657], "incid": 569, "good": [569, 655, 664], "faith": 569, "repercuss": 569, "leadership": 569, "faq": [569, 574], "page": [569, 570, 635, 638, 639], "send": [570, 576], "view": [570, 574, 602, 624, 633, 639, 659], "star": 570, "repositori": [570, 628, 631], "button": [570, 608, 627, 633], "fork": [570, 628, 631], "clone": [570, 598, 609, 626, 630, 635, 637, 638, 640, 641], "pc": 570, "git": [570, 598, 604, 609, 635, 637, 638, 640, 641], "modif": [570, 575, 605, 621, 640], "checkout": 570, "my": 570, "push": [570, 652, 658, 661], "cover": [570, 603, 607, 653], "would": [570, 613, 637, 652, 655, 661], "adopt": [570, 616, 652, 653, 661], "certif": [570, 635], "agre": 570, "pr": [570, 595, 612, 628, 631, 659], "At": [570, 576, 639, 643, 664], "approv": 570, "solv": [570, 655, 659], "licens": 570, "azur": [570, 574, 653], "devop": 570, "ci": 570, "cloud": [570, 574, 643, 653], "deploi": [570, 599, 613, 639, 643, 658, 664], "e16": 570, "v5": 570, "scan": [570, 574], "pylint": 570, "bandit": 570, "copyright": [570, 610], "docstyl": 570, "spellcheck": 570, "dco": 570, "pytest": 570, "No": [570, 594, 604, 613, 641, 642, 653], "failur": [570, 571], "fault": 570, "coverag": 570, "runtim": [570, 574, 575, 576, 578, 595, 598, 602, 605, 608, 614, 618, 623, 624, 654, 658, 659, 664], "submit": [570, 640, 643, 653], "bug": [570, 574], "intend": 570, "safe": 570, "collabor": [570, 574, 618, 624], "adher": 570, "toolkit": [571, 609, 616, 624, 653, 665], "tracer": 571, "resolv": [571, 573], "floatfunct": 571, "cat": [571, 603, 619, 646, 647, 648], "done": [571, 599, 600, 617, 633, 642, 646, 647, 652, 655], "10004": [571, 572, 575, 595, 599, 600, 601, 605, 608, 614, 651, 654, 656, 658, 666], "neural_compressor": [571, 572, 574, 577, 592, 594, 595, 596, 598, 599, 600, 601, 603, 606, 607, 612, 613, 614, 615, 635, 636, 650, 651, 652, 654, 655, 656, 657, 659, 660, 661, 663, 664, 666], "conduct": [571, 613, 621, 633, 664, 665], "imper": 571, "therefor": [571, 613, 636, 638, 652, 655, 656, 659, 661], "lot": [571, 638, 661], "As": [571, 576, 595, 599, 612, 613, 627, 638, 652, 658, 664], "successfulli": [571, 601, 642, 646, 647, 648, 653], "suggest": [571, 594, 660], "traceabl": 571, "proxi": 571, "tutori": [571, 624, 653, 665], "prototyp": 571, "html": [571, 574, 576, 593, 601, 608, 628, 631, 634, 636, 642, 646, 655], "highlight": 571, "untrac": 571, "ssd": [571, 603, 667], "resnet34": [571, 667], "r34": 571, "bboxes_labels_scor": 571, "prob": 571, "45": [571, 667], "max_output": 571, "zip": [571, 642, 646, 647], "dbox": 571, "dlabel": 571, "dscore": 571, "decode_singl": 571, "autom": [572, 616, 633, 634, 653, 661], "artifici": 572, "ann": 572, "par": [572, 643], "outperform": 572, "propos": [572, 575, 599, 614, 658, 661], "potenti": [572, 598], "lie": [572, 593], "predictor": 572, "shown": [572, 595, 598, 599, 612, 613, 627, 636, 638, 650, 651, 652, 656, 661, 664], "figur": [572, 626, 627, 630, 656], "popul": 572, "inner": 572, "evolutionari": 572, "until": [572, 576, 664], "conclud": 572, "met": [572, 605, 655, 662], "yet": [572, 628, 631, 634, 641, 655], "simplest": [572, 593, 619], "launcher": [572, 574, 599, 600, 624, 665], "agent": 572, "nsga2": 572, "supernet": 572, "ofa_mbv3_d234_e346_k357_w1": 572, "acc": [572, 643, 652, 662, 667], "mac": [572, 634], "num_ev": 572, "250": [572, 652], "results_csv_path": 572, "search_result": 572, "dataset_path": 572, "ilsvrc2012": 572, "aim": [572, 574, 611, 616, 652, 661, 664, 665], "mobilenetv3": 572, "lt": [572, 596, 667], "wmt": 572, "en": 572, "de": 572, "guidelin": [573, 574], "mainstream": [574, 665], "workflow": [574, 576, 577, 598, 599, 603, 609, 614, 628, 631, 635, 662, 665], "particular": [574, 652, 658], "wide": [574, 602, 614, 652, 655, 667], "hardwar": [574, 575, 599, 608, 613, 633, 652, 653, 654], "xeon": [574, 609, 610, 611, 614, 653, 655, 657, 667], "scalabl": [574, 609, 611, 614, 653, 655, 657], "processor": [574, 611, 614, 641, 653, 655, 657], "flex": [574, 609], "amd": [574, 609, 667], "arm": [574, 608, 609, 667], "nvidia": [574, 593, 608, 609, 667], "llama2": 574, "falcon": [574, 611, 652, 661, 667], "j": [574, 611, 637, 652, 661, 667], "bloom": [574, 652, 661, 667], "broad": [574, 608, 622, 665], "stabl": [574, 609, 652, 653], "diffus": [574, 653], "vision": [574, 603, 620, 661], "coder": [574, 608, 617, 618, 621, 624, 627, 640, 644, 653], "marketplac": [574, 634, 653], "googl": [574, 594, 614, 653], "amazon": [574, 616, 624], "web": [574, 635, 641, 646, 647, 648, 662], "servic": [574, 633, 640, 653], "softwar": [574, 610, 652, 653, 659], "alibaba": [574, 623, 630, 631, 653], "tencent": [574, 653], "taco": [574, 653], "oliv": [574, 653], "ai": [574, 616, 653, 657, 665], "ecosystem": [574, 653], "lightn": [574, 623], "pip": [574, 598, 601, 604, 606, 609, 618, 621, 626, 628, 630, 631, 635, 636, 637, 638, 659], "wget": [574, 598, 604, 606, 635, 638], "googleapi": [574, 606, 635, 638], "v1_6": [574, 606, 635, 638], "mobilenet_v1_1": [574, 606, 635, 646], "0_224_frozen": [574, 606, 635, 646], "overview": [574, 664], "jupyterlab": [574, 616, 622, 624, 626, 630, 665], "studio": [574, 624, 633, 643, 665], "topic": 574, "int4": [574, 611, 655, 667], "fp8": [574, 653], "innov": [574, 624, 653], "blog": [574, 653], "oct": [574, 653], "emnlp": [574, 653], "teq": [574, 653, 656, 658], "sep": [574, 653], "neurip": [574, 653], "quala": [574, 653], "minilm": [574, 653, 667], "releas": [574, 609, 622, 624, 626, 630, 632, 644, 647, 648, 668], "legal": [574, 668], "request": [574, 641, 642, 643, 646, 647, 648, 655], "ask": [574, 609], "email": 574, "research": [574, 610, 661, 667], "idea": [574, 635, 652, 661, 664], "discord": 574, "join": [574, 636, 641, 646, 647], "technic": 574, "discuss": 574, "wechat": [574, 653], "img": 574, "bridg": [575, 576, 608], "vanilla": [575, 576, 608], "abcadaptor": 575, "__init__": [575, 594, 595, 596, 612, 664], "query_fw_cap": [575, 577], "query_fused_pattern": 575, "he": 575, "besid": [575, 599, 638, 658], "describ": [575, 577, 594, 598, 605, 635, 662], "past": [575, 658], "mainten": 575, "difficult": [575, 661], "abil": [575, 576, 596, 605, 661], "fragment": 575, "scenario": [575, 592, 599, 613, 652, 658], "granular": [575, 576, 577, 605, 608, 619, 655, 661, 666], "semant": [575, 605], "mla": [575, 614, 655], "becom": [575, 603, 652, 658], "explor": 575, "inspect_tensor": 575, "op_list": [575, 662], "iteration_list": 575, "inspect_typ": 575, "save_to_disk": 575, "quantization_cfg": 575, "set_tensor": 575, "tensor_dict": 575, "diagnosis_help": 575, "fw": 576, "outlin": [576, 577], "instruct": [576, 577, 599, 609, 614, 628, 631, 635, 636, 637, 638, 652, 653, 654, 655, 661, 667], "extend": [576, 577], "accommod": [576, 577], "incorpor": [576, 577, 600, 652, 664], "diagram": [576, 577, 598, 664], "illustr": [576, 577, 600, 664], "sequencediagram": [576, 577, 643], "autonumb": [576, 577], "query_framework_cap": 576, "opwis": 576, "optypewis": 576, "travers": [576, 577, 658, 664], "\u2776": 576, "\u2777": 576, "\u2778": 576, "\u2779": 576, "\u277a": 576, "\u277b": 576, "\u277c": 576, "These": [576, 608, 636], "chapter": 576, "node_op": 576, "confirm": 576, "int8_conv_config": 576, "optype_wise_": 576, "tuning_cfg_to_fw": 576, "Its": [576, 593, 652], "dispatch": [576, 608, 640, 643], "is_perchannel": 576, "is_asymmetr": 576, "convert_bf16": 576, "somewhat": 576, "distort": 576, "line": [576, 594, 601, 608, 616, 621, 622, 641, 662], "let": [577, 605, 621, 652, 654, 666], "overal": [577, 641, 666], "drive": 577, "uint4": 577, "kullback": [577, 599], "leibler": [577, 599], "pytorch_cpu": 577, "1_11_capabl": 577, "cap_s8_1_11": 577, "cap_s8_1_11_conv1d": 577, "per_channel_symmetr": 577, "addition": [577, 601, 652, 664], "per_tensor_symmetr": 577, "due": [577, 603, 652, 655, 661, 662], "nativ": 577, "with_arg": 577, "qscheme": 577, "quant_min": 577, "quant_max": 577, "linux": [592, 604, 609, 627, 633], "x86_64": 592, "aarch64": 592, "prove": [593, 658, 661], "benefici": 593, "uniform": [593, 658], "\u03b2": 593, "\u03b1": 593, "fundament": [593, 613], "primari": [593, 664], "focu": [593, 664], "essenti": [593, 604], "remaind": 593, "enhanc": [593, 616, 652, 653, 657], "resolut": 593, "extrem": 593, "still": [593, 613, 639, 653, 655, 657], "retain": 593, "noteworthi": 593, "vanhouck": 593, "vincent": 593, "andrew": 593, "senior": 593, "mark": 593, "mao": 593, "speed": [593, 613, 624, 652, 653, 655, 664], "2011": 593, "szymon": 593, "migacz": 593, "2017": 593, "mckinstri": 593, "jeffrei": 593, "l": [593, 599, 662, 664], "discov": [593, 662], "1809": 593, "04191": 593, "2018": 593, "mostli": 594, "overli": 594, "argu": 594, "decis": [594, 612], "subprocess": [594, 595], "popen": 594, "pipe": 594, "sub_modul": 594, "namespac": 594, "pollut": 594, "long_str": 594, "extran": 594, "pager": 594, "getenv": 594, "readabl": 594, "seem": 594, "worth": [594, 652], "4f": 594, "65421": 594, "sentenc": 594, "eval_result": 594, "declar": [594, 634], "typealia": 594, "_lossandgradi": 594, "complextfmap": 594, "xx_func": 594, "ordereddict": 594, "plug": [594, 653], "pylanc": 594, "cheeseshopaddress": 594, "chees": 594, "shop": 594, "outofcheeseerror": 594, "crbug": 594, "192795": 594, "cpufreq": [594, 619], "deprec": [594, 628, 631, 659, 663], "facilit": [594, 616], "__all__": 594, "get_all_config_set_from_config_registri": 594, "algorithm_entri": 594, "autotun": 594, "static_qu": 594, "snippet": [594, 608], "rtn_algo_entri": 594, "vscode": [594, 632, 634], "settings_recommend": 594, "encount": 595, "consum": 595, "previous": 595, "lack": [595, 604], "faster": [595, 597, 603, 653, 664, 667], "Of": 595, "evenli": 595, "divid": [595, 643, 661, 664], "discard": 595, "throw": 595, "awai": 595, "draw": [595, 660, 664], "pin": [595, 626, 630], "reshuffl": 595, "manner": [595, 599, 615], "newdataload": 595, "customis": [595, 596, 612], "ensp": [596, 663], "imagerecord": [596, 601, 666], "image_nam": 596, "cocorecord": 596, "gt": [596, 661, 663], "int64": 596, "offer": 596, "style_transf": 596, "content": [596, 641, 642, 646, 647, 648], "tfrecorddataset": 596, "labelbal": 596, "300": [596, 652, 667], "16": [596, 609, 646, 658, 667], "helloworld": [596, 614, 663], "aid": 597, "deploy": [597, 616, 633, 653, 656, 661], "infrastructur": 597, "diagnos": 598, "gui": [598, 608, 638, 652], "termin": [598, 626, 627, 630, 636], "repeat": [598, 664], "durat": [598, 642, 646, 647, 660], "cd": [598, 601, 609, 635, 637, 638, 640, 641, 646, 647, 648], "setup": [598, 605, 609, 628, 631, 635, 637, 638, 640, 641, 652], "ilsvr2012": 598, "caff": 598, "berkeleyvis": 598, "caffe_ilsvrc12": 598, "xvzf": 598, "image_recognit": [598, 638, 662], "resnet50_torchvis": 598, "ptq_static": [598, 637], "resnet50_v1": [598, 601, 613], "dataset_loc": [598, 638, 646, 662], "label_path": 598, "quantiti": 598, "vec": 598, "frac": [598, 661], "sigma": 598, "var": 598, "happen": 598, "dispers": [598, 636], "v0": [598, 638, 661, 662], "cg": [598, 638, 662], "conv0": [598, 638, 662], "expens": [599, 613, 664], "mobil": [599, 613, 667], "produc": 599, "logit": 599, "softmax": 599, "kd": 599, "patient": 599, "compact": [599, 613, 619, 652], "agnost": 599, "resourc": [599, 640, 643, 664], "convolut": [599, 653], "ia": 599, "attach": [599, 613, 661], "shallow": 599, "deepest": 599, "deeper": 599, "10006": [599, 600], "student_output": [599, 600], "student_loss": [599, 600], "training_func_for_nc": [599, 600], "distil_loss_conf": 599, "accordingli": [599, 624, 661], "promis": [600, 613, 652], "huge": [600, 638, 652, 656], "heavi": 600, "light": 600, "booster": 600, "degrad": [600, 652, 664], "novel": [600, 616, 627, 633], "comb": 600, "distillation_criterion": [600, 613, 651], "q_conf": 600, "horovod": 601, "program": [601, 610, 616, 633], "enable_eager_execut": 601, "yaml_file_path": 601, "pre_process": 601, "simpli": [601, 615, 616, 618, 621, 633, 641], "evaluation_result": 601, "evaluation_time_cost": 601, "partit": [601, 652], "distributedsampl": 601, "train_sampl": 601, "train_dataset": [601, 655], "num_replica": 601, "rank": 601, "train_load": 601, "train_kwarg": 601, "adadelta": 601, "distributedoptim": 601, "named_paramet": 601, "broadcast_paramet": 601, "root_rank": 601, "broadcast_optimizer_st": 601, "set_epoch": 601, "batch_idx": 601, "nll_loss": 601, "log_interv": 601, "0f": 601, "tloss": 601, "6f": 601, "dry_run": 601, "test_func": 601, "host": [601, 641, 643, 646, 647, 648], "num_of_process": 601, "002": 601, "ssh": [601, 633], "prompt": 601, "readm": [601, 646], "exactli": [601, 617], "recognit": [601, 603, 652, 662], "resizecropimagenet": [601, 663], "realiz": [601, 650, 657, 660], "tow": 601, "node1": [601, 646, 647], "node2": [601, 646, 647], "TO": [601, 618, 638], "your_node1_nam": 601, "your_node2_nam": 601, "resnet50_fp32_pretrained_model": 601, "nc_resnet50_v1": 601, "resnet": [601, 667], "varieti": [602, 654, 664], "demonstr": [602, 616, 646, 647, 648, 662], "speedup": [602, 608, 655], "2x": [602, 608], "vnni": [602, 608, 654, 655], "exchang": 603, "hope": 603, "inc_model": [603, 615], "fp32_onnx_config": 603, "verifi": [603, 611], "vgg16": [603, 667], "mobilenet": [603, 660, 667], "rcnn": 603, "torchscript": [603, 656, 661], "unsupport": [603, 613, 652], "add_relu": 603, "conv1d_relu": 603, "conv2d_relu": 603, "group_norm": 603, "hardswish": 603, "instance_norm": 603, "layer_norm": 603, "leaky_relu": 603, "sigmoid": 603, "toolchain": [604, 653], "bare": 604, "metal": 604, "sudo": [604, 619], "apt": [604, 609, 619, 627], "python3": 604, "dev": [604, 626, 630], "distutil": 604, "libgl1": 604, "mesa": 604, "glx": 604, "libglib2": 604, "ln": 604, "sf": 604, "usr": 604, "incompat": 604, "88": [604, 660, 667], "80": [604, 656, 662, 667], "pyobject": 604, "reinstal": 604, "libgl": 604, "yum": [604, 609], "opencv": [604, 609, 627], "conda": [604, 609, 619, 627, 646, 647, 648, 659], "13": [604, 609, 635, 659, 661], "pend": [604, 642], "sqlalchemi": 604, "27": [604, 667], "alemb": 604, "forg": [604, 609], "quick": [605, 614, 652, 665, 666], "friendli": [605, 613, 653, 661, 665, 666], "dive": [605, 665], "purpos": [605, 614, 633, 635, 654, 655], "syntax": 605, "go": [605, 628, 631, 639, 654, 658, 663], "up1": 605, "up2": 605, "valid_mixed_precis": 605, "addn": 605, "grappler_optim": 605, "constfold": 605, "arithmet": 605, "debug_stripp": 605, "major": [607, 638, 655, 661], "concept": [607, 660, 665], "rather": [607, 658], "custom_metr": 607, "420": 608, "geomean": 608, "upload": [608, 628, 631], "click": [608, 616, 617, 624, 627, 633, 638, 653, 662], "qintegerop": [608, 655], "plan": 608, "oneapi": [609, 653, 665], "analyt": [609, 653, 665], "success": [609, 635], "11": [609, 612, 614, 635, 661, 664, 667], "frequent": 609, "pypi": [609, 628, 631], "nightli": 609, "headless": [609, 627], "fastai": 609, "esri": 609, "consolid": 609, "latest": [609, 653, 659], "eas": [609, 618, 653], "along": [609, 652, 658], "streamlin": [609, 640, 653], "scienc": 609, "websit": 609, "anaconda": [609, 640, 641], "suit": [609, 634, 662], "formerli": 609, "skylak": 609, "cascad": 609, "lake": [609, 614, 653], "cooper": [609, 614, 653], "ic": [609, 653], "sapphir": [609, 611], "rapid": [609, 611], "hbm": 609, "arctic": 609, "sound": 609, "pont": 609, "vecchio": 609, "cento": [609, 667], "ubuntu": 609, "22": [609, 667], "04": [609, 667], "maco": 609, "ventura": 609, "fortensorflow": 609, "forpytorch": 609, "12": [609, 635, 667], "tf_enable_onednn_opt": 609, "onednn": [609, 614, 655], "newer": 609, "subject": 610, "accompani": [610, 664], "wish": 610, "bibtex": 610, "author": 610, "feng": 610, "tian": 610, "hanwen": 610, "haihao": [610, 652], "shen": [610, 652], "suyu": 610, "chen": 610, "howpublish": 610, "year": 610, "logo": 610, "atom": 610, "phi": 610, "pentium": 610, "vtune": 610, "corpor": 610, "subsidiari": 610, "brand": 610, "claim": 610, "sq": [611, 661], "woq": 611, "4th": [611, 653, 655], "gen": [611, 614, 653, 655, 657], "codenam": [611, 614], "quickli": [611, 664, 665], "eleutherai": [611, 637, 661, 667], "6b": [611, 637, 661, 667], "facebook": [611, 639, 661, 667], "3b": [611, 661], "30b": [611, 661, 667], "llama": [611, 652, 653, 656, 658, 661, 667], "7b": [611, 661, 667], "13b": [611, 661, 667], "70b": [611, 667], "tiiuae": [611, 661, 667], "40b": 611, "soon": 611, "popularli": 612, "industri": [612, 653], "label_map": 612, "ap": 612, "curv": 612, "turn": [612, 627, 656], "target_boxes_num": 612, "str_label": 612, "int_label": 612, "inturn": 612, "cocomap": 612, "vocmap": 612, "categor": 612, "multiclass": 612, "multilabel": 612, "newmetr": 612, "reset": 612, "reflect": [612, 663], "new_metr": 612, "deliv": [613, 653, 659], "conveni": [613, 640], "upgrad": 613, "veri": [613, 634, 638, 655, 658, 664, 665], "comprehens": [613, 665], "resort": 613, "automodelforsequenceclassif": 613, "autotoken": 613, "val_dataset": [613, 655], "val_dataload": [613, 655], "worker": [613, 643, 646, 647, 648, 655], "ping_memori": [613, 655], "formul": 613, "effort": 613, "onnxrt_integ": [613, 666], "onnxrt_qlinear": [613, 666], "image_tensor": [613, 666], "post_training_dynamic_qu": [613, 654, 664], "1000": [613, 642, 666], "2000": 613, "sampling_s": [613, 666], "model_wis": [613, 666], "op_dict": 613, "op_wis": [613, 662, 666], "sigopt_api_token": [613, 660, 664], "sigopt_project_id": [613, 660, 664], "sigopt_experiment_nam": [613, 660, 664], "demo": 613, "600": 613, "training_arg": 613, "emul": [613, 655], "trainer": [613, 624], "briefli": [613, 661], "pruning_func": 613, "train_dataload": [613, 652, 655], "n_gpu": 613, "gradient_accumulation_step": 613, "clip_grad_norm_": 613, "max_grad_norm": 613, "start_epoch": [613, 654, 666], "end_epoch": [613, 654, 666], "newli": [613, 652], "on_after_optimizer_step": [613, 652], "layer3": [613, 652], "0004": 613, "randomresizedcrop": [613, 663], "totensor": [613, 663], "485": 613, "456": [613, 667], "406": [613, 667], "nepoch": 613, "cnt": 613, "loss_sum": 613, "iter_bar": 613, "desc": 613, "teacher_logit": 613, "train_fun": 613, "training_func": 613, "recent": [613, 614], "growth": [613, 614, 652], "significantli": [613, 614, 636, 638, 652, 664], "bandwidth": [613, 614, 658], "exit_polici": [613, 666], "determinist": 613, "meaning": [613, 651], "reli": [613, 661], "prune_conf": 613, "quantization_aware_training_conf": 613, "aforement": 613, "inset": 613, "p_conf": [613, 651], "ssd_mobilenet_v1": 613, "benchmarkconf": 613, "sixteen": 614, "launch": [614, 634, 639], "3rd": [614, 653, 655, 657], "boost": [614, 617, 633, 652, 653], "x86": 614, "avx512": [614, 655], "vcvtne2ps2bf16": 614, "vcvtneps2bf16": 614, "vdpbf16p": 614, "fbgemm": [614, 655], "tensorrtexecutionprovid": [614, 655], "cudaexecutionprovid": [614, 655], "dnnlexecutionprovid": [614, 655], "avx512_bf16": 614, "plu": 614, "resnet18": [614, 618, 667], "persist": 615, "brought": [615, 617, 624, 655], "tf2": 615, "h5": 615, "hybridblock": 615, "0000": 615, "saved_result": [615, 637, 658], "simplifi": [616, 627, 633, 652, 653], "acquir": 616, "analysi": [616, 633, 652, 660], "heurist": [616, 633], "great": 616, "autocast": 616, "my_model": 616, "no_grad": 616, "memory_format": 616, "112": 616, "plugin": [616, 634], "aw": [616, 624, 643, 653, 667], "sagemak": [616, 624], "neural_cod": [616, 618, 620, 621, 622, 624], "bench": 616, "superbench": 616, "enjoi": [617, 621, 624], "reload": [617, 634, 636, 639], "modern": [618, 658], "democrat": [618, 653], "programm": [618, 624, 633], "nano_bf16_channels_last": 618, "nano_bf16_ipex_channels_last": 618, "nano_bf16_ipex": 618, "nano_bf16": 618, "nano_fp32_channels_last": 618, "nano_fp32_ipex_channels_last": 618, "nano_fp32_ipex": 618, "nano_gpu_to_cpu": 618, "nano_int8": 618, "nano_jit_bf16_channels_last": 618, "nano_jit_bf16_ipex_channels_last": 618, "nano_jit_bf16_ipex": 618, "nano_jit_bf16": 618, "nano_jit_fp32_channels_last": 618, "nano_jit_fp32_ipex_channels_last": 618, "nano_jit_fp32_ipex": 618, "nano_jit_fp32": 618, "nano_onnxruntime_fp32": 618, "nano_onnxruntime_int8_qlinear": 618, "openvino": 618, "nano_openvino_fp32": 618, "nano_openvino_int8": 618, "bc": [619, 627], "conda_prefix": 619, "echo": 619, "tradit": [619, 652], "libjemalloc": 619, "libiomp5": 619, "home": 619, "lib": 619, "ld_preload": 619, "malloc_conf": 619, "oversize_threshold": 619, "background_thread": 619, "metadata_thp": 619, "dirty_decay_m": 619, "9000000000": 619, "muzzy_decay_m": 619, "kmp_affin": 619, "kmp_blocktim": 619, "dnnl_primitive_cache_capac": 619, "governor": 619, "scaling_governor": 619, "powersav": 619, "tee": 619, "pytorch_jit_script": [620, 623], "pytorch_channels_last": [620, 623], "run_bench": 620, "patch": [620, 633], "patch_path": 620, "your_patch_path": 620, "sweep": 620, "sweep_object": 620, "bench_config": 620, "bench_featur": 620, "sai": 621, "run_glu": [621, 622, 644, 647, 648], "requisit": 621, "task_nam": [621, 622, 644, 647, 648], "do_ev": [621, 622, 637, 644, 647, 648], "itself": [621, 652], "run_glue_optim": 621, "static_ipex": 621, "auto_qu": 622, "v4": [622, 644, 647, 648, 667], "albert": [622, 667], "sst2": 622, "alexnet": [622, 667], "pytorch_amp": 623, "optimize_for_infer": 623, "pytorch_jit_trac": 623, "pytorch_jit_script_ofi": 623, "pytorch_jit_trace_ofi": 623, "torchdynamo": 623, "pytorch_torchdynamo_jit_script": 623, "pytorch_torchdynamo_jit_trac": 623, "pytorch_torchdynamo_jit_script_ofi": 623, "pytorch_torchdynamo_jit_trace_ofi": 623, "pytorch_inc_bf16": 623, "pytorch_inc_static_quant_fx": 623, "pytorch_inc_static_quant_ipex": 623, "pytorch_inc_static_quant_ipex_xpu": 623, "pytorch_inc_dynamic_qu": 623, "pytorch_ipex_fp32": 623, "pytorch_ipex_bf16": 623, "pytorch_ipex_int8_static_qu": 623, "pytorch_ipex_int8_dynamic_qu": 623, "blade": 623, "disc": 623, "pytorch_aliblad": 623, "pytorch_lightning_bf16_cpu": 623, "tensorflow_amp": 623, "keras_amp": 623, "tensorflow_inc": 623, "keras_inc": 623, "onnx_inc_static_quant_qlinear": 623, "onnx_inc_static_quant_qdq": 623, "onnx_inc_dynamic_qu": 623, "optimum": [623, 624, 636, 658], "pytorch_inc_huggingface_optimum_stat": 623, "pytorch_inc_huggingface_optimum_dynam": 623, "intel_extension_for_transform": 623, "bigdl": [623, 624], "nano": [623, 624], "nano_": 623, "inc_auto": 623, "delight": 624, "announc": 624, "500": [624, 642, 667], "jupyt": [624, 626, 627, 630], "isa": 624, "adjust": [624, 655, 661], "delta": 624, "acc_delta": 624, "int8_acc": 624, "fp32_acc": 624, "ext": [626, 628, 630, 631, 632], "lab": [626, 627, 628, 630, 631], "nodej": [626, 630], "jlpm": [626, 630], "yarn": [626, 630], "npm": [626, 627, 630], "lieu": [626, 630], "labextens": [626, 627, 630], "typescript": [626, 630], "watch": [626, 630, 639], "immedi": [626, 630, 652], "refresh": [626, 630], "browser": [626, 630, 635, 639], "wait": [626, 630, 633, 643], "rebuilt": [626, 630], "easier": [626, 630, 633, 635, 653], "symlink": [626, 630], "down": 627, "finish": [627, 643], "blank": 627, "cell": 627, "gain": [627, 651, 653], "mkl": 627, "jemalloc": 627, "pip3": 627, "pyproject": [628, 631], "toml": [628, 631], "twine": [628, 631], "whl": [628, 631], "dist": [628, 631], "sdist": [628, 631], "bdist_wheel": [628, 631], "frontend": [628, 631, 641, 648], "login": [628, 631, 660], "cut": [628, 631], "admin_github_token": [628, 631], "pypi_token": [628, 631], "npm_token": [628, 631], "secret": [628, 631], "panel": [628, 631, 633], "draft": [628, 631], "changelog": [628, 631, 632], "pkg": [628, 631], "bot": [628, 631], "pick": [628, 631, 634], "feedstock": [628, 631], "hatch": 631, "notabl": 632, "daili": 633, "advantag": [633, 652, 654, 664], "remot": 633, "server": [633, 635, 638, 641, 646, 647, 648], "re": [633, 639, 658], "market": 633, "uninstal": 633, "fill": [633, 660, 663, 664], "upper": 633, "sidebar": 633, "hover": 633, "track": [633, 660], "argpars": 633, "pop": [633, 643], "diff": 633, "manifest": 634, "palett": 634, "registercommand": 634, "amodio": 634, "tsl": 634, "matcher": 634, "dbaeumer": 634, "eslint": [634, 639], "press": 634, "f5": 634, "ctrl": 634, "hello": 634, "world": 634, "breakpoint": 634, "consol": [634, 639], "relaunch": 634, "toolbar": 634, "node_modul": 634, "viewlet": 634, "dropdown": 634, "runner": [634, 639], "startup": 634, "bundl": 634, "neural_insight": [635, 637, 638], "tl": 635, "ui": 635, "5000": 635, "338174d13706855fc6924cec7b3a8ae8": 635, "listen": 635, "firewal": 635, "8080": 635, "cert": 635, "path_to_cert": 635, "crt": 635, "path_to_private_kei": 635, "encrypt": 635, "expos": 635, "forfeit": 635, "client": [635, 641, 648], "extern": 635, "threat": 635, "diagnost": 635, "skill": 635, "feel": [635, 639], "layoutlmv3": [636, 667], "seqev": 636, "sentencepiec": 636, "timm": 636, "fvcore": 636, "pillow": 636, "einop": 636, "textdist": 636, "setuptool": 636, "cli": 636, "hypjudi": 636, "finetun": [636, 652, 658, 667], "funsd": [636, 667], "calib_dataset": 636, "incdataset": 636, "eval_dataset": 636, "poor": [636, 662], "9049": 636, "2989": 636, "66": [636, 667], "9631": 636, "glob": 636, "panda": 636, "pd": 636, "set_opt": 636, "max_row": 636, "max_column": 636, "getmtim": 636, "activations_t": 636, "weights_tabl": [636, 637], "read_csv": 636, "nweight": 636, "descend": 636, "sorted_data": 636, "sort_valu": 636, "ascend": 636, "evid": 636, "tip": 636, "8981": 636, "7502": 636, "run_clm": 637, "wikitext": [637, 667], "dataset_config_nam": 637, "do_train": 637, "inspect_sav": 637, "inspect_result": 637, "quan": 637, "model_summari": 637, "incept": [638, 667], "v3": [638, 667], "inception_v3": [638, 662], "inceptionv3_fp32_pretrained_model": [638, 662], "bash": [638, 662], "prepare_dataset": 638, "sh": [638, 662], "raw_dir": 638, "img_raw": 638, "delet": [638, 652], "run_tun": 638, "nc_inception_v3": 638, "highest": [638, 644, 664], "satisfactori": 638, "webpag": 638, "spike": 638, "bottom": 638, "chart": [638, 655, 660, 662], "concentr": 638, "But": 638, "bigger": 638, "bootstrap": 639, "localhost": [639, 641, 646, 647], "3000": 639, "lint": 639, "interact": [639, 660], "correctli": 639, "hash": [639, 642], "readi": [639, 652], "aren": 639, "transit": 639, "webpack": 639, "babel": 639, "tweak": 639, "ever": 639, "curat": 639, "suitabl": 639, "middl": [639, 661], "shouldn": 639, "understand": [639, 655, 662, 665], "wouldn": 639, "couldn": 639, "troubleshoot": 639, "effortlessli": 640, "grpc": [640, 641, 645, 646, 647, 649], "queue": 640, "seamlessli": [640, 652, 664], "mpi": [640, 641, 664], "neural_solut": [640, 641, 646, 647, 648], "task_monitor_port": [641, 646, 647, 648], "22222": [641, 646, 647, 648], "result_monitor_port": [641, 646, 647, 648], "33333": [641, 646, 647, 648], "restful_api_port": [641, 646, 647, 648], "hostfil": [641, 643, 646, 647, 648], "grpc_api_port": [641, 646, 647, 648], "api_typ": [641, 646, 647, 648], "conda_env": [641, 646, 647, 648], "upload_path": [641, 646, 647, 648], "8000": [641, 646, 647, 648], "monitor": [641, 646, 647, 648], "3333": [641, 646, 647, 648], "2222": [641, 646, 647, 648], "ns_workspac": [641, 646, 647, 648], "hf_model": [641, 645, 647, 648], "curl": [641, 642, 646, 647], "task_id": [641, 646, 647, 648], "usernam": 641, "db": [641, 643], "serve_log": [641, 646, 647, 648], "frontend_grpc": 641, "task_log": 641, "task_bdf0bd1b2cc14bc19bce12d4f9b333c7": 641, "task_workspac": 641, "bdf0bd1b2cc14bc19bce12d4f9b333c7": 641, "aliv": 641, "properli": 641, "commonli": [641, 652], "hostnam": 641, "breakdown": 641, "ip": 641, "hous": 641, "host1": [641, 646, 647], "host2": [641, 646, 647], "query_id": 641, "oaa": 642, "host_ip": 642, "task_request": [642, 646, 647, 648], "tuning_info": [642, 646], "optimization_result": [642, 646], "result_path": [642, 646, 647], "closur": 642, "404": [642, 652, 667], "health": 642, "healthi": 642, "quantized_model": [642, 646, 647], "400": [642, 667], "alloc": 643, "incom": 643, "taskmonitor": 643, "cluster": [643, 646, 647, 664], "tasklaunch": 643, "resultmonitor": 643, "receiv": [643, 660], "p1": 643, "notif": 643, "p2": 643, "p3": 643, "mpirun": [643, 664], "perf": 643, "p4": 643, "four": [643, 662, 667], "classdiagram": 643, "taskdb": 643, "get_statu": 643, "update_statu": 643, "task_collect": 643, "append_task": 643, "get_all_pending_task": 643, "update_task_statu": 643, "task_db": 643, "wait_new_task": 643, "schedule_task": 643, "dispatch_task": 643, "launch_task": 643, "query_task_statu": 643, "node_list": 643, "reserve_resourc": 643, "get_node_statu": 643, "gcp": [643, 653], "script_url": [644, 646, 647, 648], "archiv": 644, "tf_example1": [645, 646, 647], "hf_models_grpc": [645, 648], "00173": 646, "01024": 646, "task_request_distribut": 646, "custom_models_optim": 646, "7602cd63d4c849e7a686a8165a77f69d": [646, 647], "151": [646, 667], "8617": 646, "17": [646, 667], "8213": [646, 667], "number_of_socket": [646, 647], "number_of_thread": [646, 647], "cdf419910f9b4d2a8320d0e420ac1d0a": 647, "optimized_result": 647, "58": [647, 667], "3162": 647, "6488": [647, 667], "06": [648, 666, 667], "34": [648, 667], "55": [648, 667], "d3e10a49326449fb9d0d62f2bfc1cb43": 648, "fastapi": 649, "multi_object": 650, "benefit": 651, "instanti": 651, "neuron": 652, "art": 652, "grown": 652, "unpreced": 652, "increasingli": 652, "crucial": 652, "stand": [652, 664], "shrink": 652, "contextu": 652, "scene": 652, "haven": 652, "color": [652, 656], "lowest": [652, 664], "emsp": 652, "downstream": 652, "prone": 652, "co": 652, "discourag": 652, "penal": 652, "parameter": 652, "lightweight": 652, "perceptron": 652, "mlp": 652, "valuabl": [652, 662], "basi": 652, "billion": 652, "dolli": [652, 661, 667], "mpt": [652, 661, 667], "lm": [652, 667], "lamini": [652, 661], "mention": [652, 658], "tend": 652, "exemplifi": 652, "complement": 652, "fortieth": 652, "miss": [652, 655], "pruner2": 652, "few": [652, 653, 661, 664], "lm_head": 652, "yourself": 652, "uncertain": 652, "auto_config": 652, "quit": 652, "straightforward": [652, 658, 661], "pruning_pattern": 652, "pruning_start": 652, "pruning_end": 652, "sparse_gpt": 652, "embed_out": 652, "card": 652, "hesit": 652, "causal": 652, "clm": 652, "sst": [652, 667], "25": [652, 667], "63": [652, 667], "24": [652, 664, 667], "35": [652, 667], "flan": 652, "t5": [652, 667], "english": 652, "romanian": 652, "381": 652, "yolov5": 652, "75": [652, 667], "2x1": [652, 667], "801": 652, "7895": 652, "signific": [652, 653, 656, 661], "reduct": [652, 656, 666], "namhoon": 652, "lee": 652, "thalaiyasingam": 652, "ajanthan": 652, "philip": 652, "torr": 652, "2019": 652, "zafrir": 652, "ofir": 652, "ariel": 652, "larei": 652, "boudoukh": 652, "mosh": 652, "wasserblat": 652, "2111": 652, "05754": 652, "2021": 652, "kwon": 652, "kim": 652, "mahonei": 652, "hassoun": 652, "keutzer": 652, "gholami": 652, "pp": 652, "24101": 652, "24116": 652, "frantar": [652, 658], "alistarh": 652, "medium": 653, "aug": 653, "juli": 653, "onnxcommunitymeetup2023": 653, "chatbot": 653, "june": 653, "msft": 653, "netflix": 653, "apr": 653, "mlperf": [653, 667], "5x": 653, "\u96c6\u6210\u82f1\u7279\u5c14": 653, "\u817e\u8baf\u4e91taco": 653, "kit\u4e3aai\u5e94\u7528\u5e26\u6765\u9ad8\u6548\u5f02\u6784\u52a0\u901f\u670d\u52a1": 653, "mar": 653, "heterogen": 653, "jan": 653, "busi": 653, "amx": 653, "journei": 653, "dec": 653, "mleffici": 653, "deepen": 653, "foundat": 653, "intellig": 653, "vmware": 653, "applianc": 653, "bitnami": 653, "nov": 653, "sota": 653, "twitter": 653, "linkedin": 653, "zone": 653, "land": 653, "pat": 653, "keynot": 653, "intelon": 653, "chines": 653, "purif": 653, "sacrif": 653, "jun": 653, "partner": 653, "feb": 653, "joint": 653, "bilibili": 653, "gestalt": 653, "ml": 653, "doubl": 653, "abound": 653, "lpot": [653, 659], "nextplatform": 653, "cern": 653, "gan": 653, "3dgan": 653, "iml": 653, "workshop": 653, "asplo": 653, "18": [653, 667], "highli": [653, 658], "intelcaff": 653, "aris": 654, "henc": 654, "onnxrt_qoper": 654, "quant_aware_train": 654, "weight_compress": [654, 666], "initial_spars": [654, 666], "prune_typ": [654, 666], "basic_magnitud": [654, 666], "update_frequ": 654, "prune_domain": 654, "tile_pattern_1x1": 654, "invent": 655, "cost": [655, 658], "theoret": [655, 658], "zeropoint": 655, "255": [655, 661], "overflow": 655, "unseen": 655, "peopl": 655, "mimic": 655, "fact": 655, "ultim": 655, "pain": 655, "lossi": 655, "philosophi": 655, "neither": 655, "nor": 655, "val_load": 655, "avg": 655, "themselv": 655, "dmlexecutionprovid": 655, "meanwhil": 656, "substanti": 656, "pose": 656, "challeng": 656, "greatli": [656, 658], "constrain": 656, "grei": 656, "blue": 656, "rectangl": 656, "w8a8": [656, 658], "10005": 656, "rtn_arg": [656, 658], "ouput_dir": 656, "fp32_model_path": 656, "int8_model_path": 656, "ON": 657, "forc": 657, "postposttrainingquantconfig": 657, "bf16wrapper": 657, "retrac": 657, "preval": 658, "grow": 658, "demand": 658, "trade": 658, "bottleneck": 658, "roughli": 658, "speak": 658, "capac": [658, 660], "flop": 658, "famou": 658, "approx": 658, "bmm": 658, "100x": 658, "excel": 658, "stai": [658, 661], "quantif": [658, 661], "think": 658, "intuit": [658, 661], "uniformli": 658, "qlora": 658, "invers": 658, "restor": 658, "protect": 658, "inspir": 658, "c_": 658, "normalfloat": 658, "e2m1": 658, "bnb": 658, "805": 658, "awq_arg": 658, "gptq_arg": 658, "mitig": 658, "date": 658, "sym_full_rang": 658, "qweight_config_path": 658, "gptq_config_path": 658, "gptq_config": 658, "use_full_length": 658, "compressed_model": 658, "omit": 658, "rtn_g32asym": 658, "gptq_g32asym": 658, "gptq_g32asym_disable_last_matmul": 658, "gptq_g128asym": 658, "awq_g32asym": 658, "xiao": [658, 661], "guangxuan": [658, 661], "2211": [658, 661], "10438": [658, 661], "wei": [658, 661], "xiui": [658, 661], "suppress": [658, 661], "2209": [658, 661], "13325": [658, 661], "lin": 658, "ji": 658, "00978": 658, "elia": 658, "dettmer": 658, "tim": 658, "2305": 658, "14314": 658, "site": 659, "sed": 659, "your_script": 659, "backbon": 660, "sigopt_experiment_id": 660, "nc": [660, 664], "suffici": 660, "ordinari": 660, "latenc": [660, 664], "8266": 660, "8372": 660, "2132": 660, "83": [660, 661, 667], "7495": 660, "8299": 660, "8294": 660, "85": [660, 661, 667], "0837": 660, "8291": 660, "4469": 660, "gigant": 661, "systemat": 661, "migrat": [661, 665], "difficulti": 661, "mathemat": 661, "allevi": 661, "coarsest": 661, "finer": [661, 664], "matric": 661, "similarli": 661, "finest": 661, "consumpt": 661, "suppos": 661, "6839": 661, "4741": 661, "7451": 661, "9301": 661, "1742": 661, "6835": 661, "q_min": 661, "q_max": 661, "q_x": 661, "clamp_": 661, "round_": 661, "w_q": 661, "00296431384049356": 661, "59": [661, 667], "172": [661, 667], "192": 661, "w_dq": 661, "2220": 661, "1510": 661, "2420": 661, "2570": 661, "0500": 661, "1890": 661, "mseloss": 661, "1983354538679123": 661, "6848": 661, "4743": 661, "7440": 661, "9308": 661, "1749": 661, "385297635664756e": 661, "07": [661, 666, 667], "quantize_per_channel": 661, "x_tmp": 661, "detach": 661, "keepdim": 661, "dequantize_per_channel": 661, "0029": [661, 667], "0036": 661, "162": [661, 667], "48": [661, 667], "72": [661, 667], "93": [661, 667], "207": 661, "139": [661, 667], "6837": 661, "4734": 661, "1751": 661, "6821": 661, "637690492221736e": 661, "6376e": 661, "3852e": 661, "cdot": 661, "quantize_per_tensor_absmax": 661, "n_bit": 661, "div_": 661, "0806": 661, "7589": 661, "6038": 661, "3815": 661, "5040": 661, "7174": 661, "5444": 661, "5826": 661, "7772": 661, "5555": 661, "3740": 661, "3253": 661, "0698": 661, "1381": 661, "5972": [661, 667], "0086": 661, "0737": 661, "8298": 661, "6883": 661, "2991": 661, "1601": 661, "6506": 661, "8246": 661, "3924": 661, "3845": 661, "8768": 661, "w_scale": 661, "x_q": 661, "x_scale": 661, "84": [661, 667], "120": 661, "0059755356051027775": 661, "89": [661, 667], "119": 661, "57": [661, 667], "006533813662827015": 661, "y_q": 661, "17509": 661, "7608": 661, "4055": 661, "16599": 661, "21020": 661, "10016": 661, "9860": 661, "22444": 661, "y_dq": 661, "6836": 661, "2970": 661, "1583": 661, "6481": 661, "8207": 661, "3911": 661, "3850": 661, "8763": 661, "though": 661, "simplic": 661, "fp1": 661, "fp2": 661, "subsect": [661, 666], "x1": [661, 664], "x2": [661, 664], "herebi": 661, "optdecoderlay": 661, "blockwis": 661, "overhead": 661, "hardtanh": 661, "t5norm": 661, "llamanorm": 661, "groupnorm": 661, "lambada": 661, "openai": [661, 667], "sweet": 661, "spot": 661, "bigscienc": [661, 667], "560m": 661, "354": 661, "3542": 661, "1b7": 661, "4634": 661, "4936": 661, "518": 661, "5185": 661, "7b1": [661, 667], "5764": [661, 667], "5977": 661, "bloomz": [661, 667], "3947": 661, "3930": 661, "4828": 661, "4906": 661, "5018": 661, "4980": 661, "5593": [661, 667], "5552": 661, "125m": 661, "379": 661, "3757": 661, "350m": 661, "4516": 661, "4533": 661, "5789": 661, "5742": 661, "6365": 661, "6404": 661, "6769": [661, 667], "6804": [661, 667], "6872": 661, "6814": 661, "7149": 661, "7128": 661, "66b": 661, "7398": 661, "7326": 661, "7361": [661, 667], "7357": 661, "7627": [661, 667], "7590": 661, "7759": [661, 667], "7840": 661, "65b": 661, "7908": 661, "7957": 661, "7392": [661, 667], "7335": [661, 667], "chat": [661, 667], "7058": [661, 667], "6994": 661, "7677": [661, 667], "7615": [661, 667], "6831": [661, 667], "mbzuai": 661, "124m": 661, "3804": 661, "3887": 661, "774m": 661, "5048": 661, "5057": 661, "5b": 661, "5443": [661, 667], "5436": 661, "mosaicml": [661, 667], "655": [661, 667], "6499": 661, "stabilityai": 661, "stablelm": 661, "4172": 661, "4149": 661, "togethercomput": 661, "redpajama": 661, "incit": 661, "6542": 661, "6735": 661, "6718": 661, "6740": [661, 667], "6569": 661, "6621": 661, "7143": 661, "7221": 661, "6895": 661, "6953": [661, 667], "databrick": [661, 667], "6866": [661, 667], "6297": 661, "6247": 661, "6437": [661, 667], "6392": 661, "7332": 661, "7632": 661, "asterisk": 661, "consider": 661, "arang": 661, "tolist": 661, "default_alpha": 661, "step_siz": 661, "shared_criterion": 661, "do_blockwis": 661, "jason": 661, "emerg": 661, "transact": 661, "yvinec": 661, "edouard": 661, "proceed": 661, "cvf": 661, "winter": 661, "instrument": 662, "writer": 662, "_pre_eval_hook": 662, "_post_eval_hook": 662, "submodul": 662, "whitelist": 662, "_recordingobserv": 662, "output_tensors_dict": 662, "current_it": 662, "get_tensor_valu": 662, "_observer_forward_hook": 662, "activation_post_process": 662, "_add_observer_": 662, "named_children": 662, "leaf": 662, "add_modul": 662, "register_forward_hook": 662, "dump_tim": 662, "summarywrit": 662, "_acc": 662, "tune_": 662, "add_graph": 662, "get_observer_dict": 662, "observer_dict": 662, "is_quant": 662, "add_histogram": 662, "shell": 662, "bind_al": 662, "logdir_spec": 662, "tune_0_acc0": 662, "tune_1": 662, "tune_1_acc0": 662, "79": [662, 667], "baseline_acc_0": 662, "776": 662, "tune_1_acc_0": 662, "095": 662, "runs_v3": 662, "run_tuning_dump_tensor": 662, "inceptionv3": 662, "run_quant": 662, "topologi": 662, "nc_inceptionv3": 662, "inceptionv3_dump_tensor": 662, "eightbit": 662, "disappear": 662, "centercrop": 663, "randomcrop": 663, "cropres": 663, "decodeimag": 663, "jpeg": 663, "encodejp": 663, "alignimagechannel": 663, "68": [663, 667], "116": 663, "78": [663, 667], "103": 663, "94": [663, 667], "017": 663, "bilinearimagenet": [663, 666], "topilimag": 663, "padding_mod": 663, "border": 663, "pixel": 663, "edg": 663, "colorjitt": 663, "bright": 663, "satur": 663, "hue": 663, "jitter": 663, "tondarrai": 663, "o1": 664, "human": 664, "aggress": 664, "classic": 664, "flowchart": 664, "htmllabel": 664, "td": 664, "classdef": 664, "itemstyl": 664, "cce5ff": 664, "stroke": 664, "99ccff": 664, "s1": 664, "s2": 664, "s3": 664, "s4": 664, "s5": 664, "s6": 664, "s7": 664, "nbsp": 664, "subgraphstyl": 664, "ffffff": 664, "attempt": 664, "post_training_auto_qu": 664, "increment": 664, "ii": 664, "spent": 664, "hawq_v2_loss": 664, "model_loss": 664, "black": 664, "compli": 664, "posterior": 664, "short": 664, "loglevel": 664, "endlessli": 664, "perspect": 664, "smbo": 664, "appl": 664, "surrog": 664, "densiti": 664, "parzen": 664, "greatest": 664, "hour": 664, "dai": 664, "next_tune_cfg": 664, "overridden": 664, "replic": 664, "replica": 664, "fed": 664, "synchron": 664, "number_of_process": 664, "run_cmd": 664, "abctunestrategi": 664, "familiar": 665, "notebook": 665, "introduct": 665, "organ": 666, "logic": 666, "mobilenet_v1": 666, "40": [666, 667], "beta_1": 666, "beta_2": 666, "epsilon": 666, "sparsecategoricalcrossentropi": 666, "sum_over_batch_s": 666, "from_logit": 666, "54": [666, 667], "19": [666, 667], "09": 667, "1x": 667, "platinum": 667, "8480": 667, "8ghz": 667, "56": 667, "ht": 667, "turbo": 667, "256gb": 667, "16x16gb": 667, "ddr5": 667, "4800": 667, "mt": 667, "bio": 667, "3a14": 667, "tel2p1": 667, "microcod": 667, "0x2b0001b0": 667, "gcc": 667, "20210514": 667, "red": 667, "hat": 667, "visit": 667, "1s4c14ins1bsthroughput": 667, "sec": 667, "74": 667, "2914": 667, "621": 667, "69x": 667, "76": 667, "23": 667, "46": 667, "2160": 667, "545": 667, "47": 667, "96x": 667, "resnet101": 667, "77": 667, "37": 667, "1508": 667, "428": 667, "53x": 667, "70": 667, "44": 667, "69": 667, "3290": 667, "1229": 667, "68x": 667, "38": 667, "73": 667, "2404": 667, "1048": 667, "49": 667, "29x": 667, "71": 667, "1669": 667, "33x": 667, "1073": 667, "245": 667, "38x": 667, "374": 667, "52": 667, "18x": 667, "96": 667, "5478": 667, "1756": 667, "12x": 667, "4133": 667, "1748": 667, "36x": 667, "1534": 667, "236": 667, "62": 667, "49x": 667, "vgg19": 667, "1377": 667, "197": 667, "resnetv2": 667, "39": 667, "1125": 667, "656": 667, "71x": 667, "709": 667, "367": 667, "00": 667, "93x": 667, "152": 667, "03": 667, "497": 667, "265": 667, "87x": 667, "densenet": 667, "121": 667, "557": 667, "67": 667, "61": 667, "22x": 667, "161": 667, "29": 667, "353": 667, "235": 667, "50x": 667, "169": 667, "65": 667, "41": 667, "435": 667, "385": 667, "13x": 667, "efficientnet": 667, "b0": 667, "786": 667, "723": 667, "09x": 667, "130": 667, "23x": 667, "1291": 667, "683": 667, "89x": 667, "61x": 667, "1295": 667, "453": 667, "85x": 667, "242": 667, "31x": 667, "cnn": 667, "80x": 667, "43": 667, "81x": 667, "166": 667, "07x": 667, "16x": 667, "26": 667, "173": 667, "yolov3": 667, "82": 667, "230": 667, "92": 667, "36": 667, "37x": 667, "58x": 667, "86": 667, "416": 667, "35x": 667, "88x": 667, "51": 667, "17x": 667, "75552": 667, "50803": 667, "1s56c1ins1bsthroughput": 667, "60": 667, "64x": 667, "1673": 667, "653": 667, "56x": 667, "1170": 667, "329": 667, "55x": 667, "977": 667, "335": 667, "91x": 667, "resnest50": 667, "81": 667, "10x": 667, "resnext101_32x8d": 667, "562": 667, "109": 667, "efficientnet_b0": 667, "696": 667, "667": 667, "04x": 667, "efficientnet_b3": 667, "508": 667, "397": 667, "28x": 667, "efficientnet_b7": 667, "234": 667, "149": 667, "57x": 667, "peleenet": 667, "858": 667, "588": 667, "46x": 667, "se_resnext50_32x4d": 667, "739": 667, "283": 667, "yolo": 667, "141": 667, "99x": 667, "174": 667, "camembert": 667, "395": 667, "171": 667, "30x": 667, "53": 667, "795": 667, "341": 667, "744": 667, "343": 667, "163": 667, "funnel": 667, "182": 667, "65x": 667, "399": 667, "21x": 667, "407": 667, "412": 667, "stsb": 667, "413": 667, "39x": 667, "409": 667, "75x": 667, "401": 667, "70x": 667, "76x": 667, "reform": 667, "crime": 667, "punish": 667, "446": 667, "398": 667, "lvwerra": 667, "pegasu": 667, "samsum": 667, "102": 667, "770": 667, "450": 667, "14x": 667, "whisper": 667, "25x": 667, "abeja": 667, "neox": 667, "japanes": 667, "90x": 667, "1646": 667, "657": 667, "1098": 667, "322": 667, "41x": 667, "568": 667, "19x": 667, "1383": 667, "761": 667, "82x": 667, "32x": 667, "5701": 667, "1593": 667, "2090": 667, "685": 667, "05x": 667, "resnext101_32x16d_wsl": 667, "556": 667, "01x": 667, "86x": 667, "558": 667, "11x": 667, "lambada_openai": 667, "hellaswag": 667, "winogrand": 667, "piqa": 667, "word_perplex": 667, "4954": 667, "6409": 667, "7541": 667, "6434": 667, "8816": 667, "gptqw4g128asym": 667, "679": 667, "4895": 667, "6433": 667, "7476": 667, "6399": 667, "9945": 667, "0999": 667, "gptqw4g32asym": 667, "6829": 667, "4923": 667, "6401": 667, "7486": 667, "6410": 667, "9963": 667, "0141": 667, "gptqw4g128sym": 667, "4907": 667, "6361": 667, "7443": 667, "6390": 667, "9932": 667, "1498": 667, "gptqw4g32sym": 667, "6911": 667, "4899": 667, "6448": 667, "7497": 667, "6439": 667, "0008": 667, "0927": 667, "5049": 667, "6543": 667, "7628": 667, "6497": 667, "2862": 667, "4984": 667, "6535": 667, "7568": 667, "6473": 667, "9962": 667, "4193": 667, "6885": 667, "4973": 667, "753": 667, "6455": 667, "9935": 667, "4607": 667, "decapoda": 667, "5642": 667, "6709": 667, "7835": 667, "6887": 667, "4202": 667, "7244": 667, "5603": 667, "6614": 667, "6824": 667, "9909": 667, "5881": 667, "5911": 667, "7009": 667, "7878": 667, "7106": 667, "212": 667, "7518": 667, "5843": 667, "6961": 667, "7911": 667, "4319": 667, "7572": 667, "5898": 667, "7056": 667, "7894": 667, "7105": 667, "9998": 667, "3429": 667, "7596": 667, "5841": 667, "6977": 667, "7905": 667, "7080": 667, "4916": 667, "6266": 667, "7277": 667, "8096": 667, "7350": 667, "2384": 667, "778": 667, "624": 667, "7269": 667, "8047": 667, "7334": 667, "9979": 667, "4237": 667, "7706": 667, "6239": 667, "7285": 667, "8058": 667, "7322": 667, "4697": 667, "7836": 667, "6195": 667, "7337": 667, "9983": 667, "5604": 667, "5732": 667, "648": 667, "7715": 667, "6746": 667, "7107": 667, "6982": 667, "5637": 667, "6527": 667, "7704": 667, "6713": 667, "9950": 667, "9702": 667, "5682": 667, "6575": 667, "7758": 667, "6742": 667, "9994": 667, "9317": 667, "567": 667, "6902": 667, "7353": 667, "6622": 667, "7829": 667, "6862": 667, "9942": 667, "9635": 667, "7246": 667, "5617": 667, "6756": 667, "7797": 667, "6854": 667, "9931": 667, "2799": 667, "7312": 667, "6059": 667, "7103": 667, "7077": 667, "2213": 667, "7273": 667, "6018": 667, "7088": 667, "7742": 667, "7030": 667, "9934": 667, "2538": 667, "083": 667, "7283": 667, "6053": 667, "7024": 667, "7764": 667, "7031": 667, "1889": 667, "727": 667, "5997": 667, "7018": 667, "9916": 667, "2504": 667, "7122": 667, "8984": 667, "5933": 667, "689": 667, "7851": 667, "7075": 667, "1556": 667, "448": 667, "7675": 667, "5934": 667, "7856": 667, "7111": 667, "9984": 667, "1514": 667, "927": 667, "7566": 667, "5899": 667, "7032": 667, "9953": 667, "1374": 667, "728": 667, "4628": 667, "6456": 667, "6029": 667, "6438": 667, "5799": 667, "4542": 667, "6004": 667, "9957": 667, "0626": 667, "4789": 667, "6134": 667, "7432": 667, "5525": 667, "4731": 667, "6504": 667, "7617": 667, "6094": 667, "7828": 667, "5098": 667, "7622": 667, "6505": 667, "3242": 667, "6878": 667, "5058": 667, "6393": 667, "7633": 667, "6491": 667, "9978": 667, "5514": 667, "6864": 667, "5084": 667, "6519": 667, "6509": 667, "0006": 667, "4728": 667, "6876": 667, "5045": 667, "6474": 667, "9952": 667, "6379": 667, "5282": 667, "614": 667, "7448": 667, "6312": 667, "6377": 667, "5228": 667, "5991": 667, "6261": 667, "9919": 667, "4096": 667, "neo": 667, "6224": 667, "4271": 667, "577": 667, "722": 667, "5871": 667, "9359": 667, "6123": 667, "4227": 667, "5738": 667, "7203": 667, "5823": 667, "9917": 667, "3377": 667, "615": 667, "4259": 667, "5714": 667, "7247": 667, "9951": 667, "2083": 667, "6154": 667, "4208": 667, "5777": 667, "7198": 667, "5834": 667, "9937": 667, "3121": 667, "20b": 667, "7233": 667, "5359": 667, "7753": 667, "195": 667, "7186": 667, "5328": 667, "7699": 667, "6687": 667, "9922": 667, "3463": 667, "7268": 667, "533": 667, "659": 667, "6726": 667, "2897": 667, "5718": 667, "6859": 667, "7927": 667, "6890": 667, "9324": 667, "7006": 667, "5655": 667, "6803": 667, "7965": 667, "6857": 667, "1515": 667, "5752": 667, "6748": 667, "7845": 667, "6724": 667, "5951": 667, "6472": 667, "5716": 667, "6685": 667, "784": 667, "6678": 667, "8539": 667, "6918": 667, "5819": 667, "678": 667, "6861": 667, "8863": 667, "5765": 667, "6827": 667, "7873": 667, "6832": 667, "9958": 667, "1451": 667, "storywrit": 667, "693": 667, "5477": 667, "663": 667, "6719": 667, "9125": 667, "6661": 667, "7813": 667, "6693": 667, "9961": 667, "1137": 667, "rw": 667, "6604": 667, "5419": 667, "6598": 667, "6594": 667, "7616": 667, "6484": 667, "5369": 667, "7807": 667, "6559": 667, "9947": 667, "9411": 667, "6571": 667, "5398": 667, "6582": 667, "6579": 667, "8809": 667, "652": 667, "535": 667, "7682": 667, "6532": 667, "9906": 667, "0048": 667, "5177": 667, "6669": 667, "7824": 667, "5053": 667, "6301": 667, "5142": 667, "6654": 667, "6483": 667, "9933": 667, "8146": 667, "517": 667, "9941": 667, "1566": 667, "724": 667, "1567": 667, "716": 667, "1414": 667, "718": 667, "97x": 667, "1459": 667, "721": 667, "02x": 667, "1582": 667, "752": 667, "7139": 667, "4289": 667, "66x": 667, "4080": 667, "7236": 667, "4299": 667, "6842": 667, "4496": 667, "52x": 667, "591": 667, "178": 667, "183": 667, "590": 667, "179": 667, "42x": 667, "5703": 667, "2578": 667, "5610": 667, "2603": 667, "shufflenet": 667, "6689": 667, "3690": 667, "5692": 667, "3758": 667, "51x": 667, "googlenet": 667, "1792": 667, "1111": 667, "1821": 667, "1104": 667, "squeezenet": 667, "9472": 667, "5582": 667, "9861": 667, "5566": 667, "77x": 667, "caffenet": 667, "3348": 667, "1141": 667, "3509": 667, "1142": 667, "2426": 667, "987": 667, "2208": 667, "1016": 667, "zfnet": 667, "930": 667, "532": 667, "919": 667, "417": 667, "1880": 667, "1159": 667, "62x": 667, "1798": 667, "1151": 667, "2890": 667, "1380": 667, "2548": 667, "1362": 667, "507": 667, "94x": 667, "1286": 667, "904": 667, "1121": 667, "856": 667, "829": 667, "1044": 667, "790": 667, "849": 667, "627": 667, "79x": 667, "yolov4": 667, "duc": 667, "tini": 667, "1119": 667, "ultra": 667, "8537": 667, "1934": 667, "emot": 667, "ferplu": 667, "3568": 667, "arcfac": 667, "494": 667, "244": 667, "226": 667, "392": 667, "223": 667, "integerop": 667, "473": 667, "548": 667, "964": 667, "540": 667, "394": 667, "602": 667, "487": 667, "222": 667, "20x": 667, "189": 667, "146": 667, "125": 667, "bidaf": 667, "2757": 667, "2277": 667, "gpt2": 667, "360": 667, "213": 667, "490": 667, "304": 667, "214": 667, "347": 667, "272": 667, "216": 667, "26x": 667, "489": 667, "27x": 667, "l12": 667, "h384": 667, "1054": 667, "585": 667, "1072": 667, "890": 667, "746": 667, "268": 667, "211": 667, "l6": 667, "1958": 667, "1130": 667, "73x": 667, "electra": 667, "discrimin": 667, "1797": 667, "1077": 667, "67x": 667, "1930": 667, "1139": 667, "mini": 667, "5510": 667, "3334": 667, "5627": 667, "3365": 667, "108": 667, "110": 667, "bart": 667, "15x": 667, "deberta": 667, "168": 667, "145": 667, "spanbert": 667, "63x": 667, "multilingu": 667, "113": 667, "159": 667, "40x": 667, "distilgpt2": 667, "layoutlm": 667, "layoutlmv2": 667, "codebert": 667, "47x": 667, "fcn": 667, "perplex": 667, "2788": 667, "7002": 667, "4124": 667, "9921": 667, "3950": 667, "5711": 667, "9892": 667, "9163": 667, "7240": 667, "9902": 667, "0438": 667, "7634": 667, "1186": 667, "9944": 667, "1276": 667, "7543": 667, "6181": 667, "rtnw4g32asym": 667, "6496": 667, "9967": 667, "7964": 667, "6612": 667, "rtnw4g32sym": 667, "7941": 667, "7243": 667, "9971": 667, "taskdataset": 667, "accuracyspars": 667, "ratiospars": 667, "commentsbalancedor": 667, "unbalanc": 667, "answeringsquad": 667, "87f1": 667, "momentumunbalanc": 667, "momentumbalanc": 667, "90f1": 667, "59f1": 667, "23f1": 667, "classificationmrpc": 667, "52f1": 667, "26f1": 667, "classificationsst": 667, "61accuraci": 667, "recognitionimagenet": 667, "95top1": 667, "v5s6": 667, "detectioncoco": 667, "ap0": 667, "6ap0": 667, "393": 667, "584": 667, "34f1": 667, "lassounbalanc": 667, "classificationmnli": 667, "mm": 667, "allbalanc": 667, "32accuraci": 667, "sensitivitybalanc": 667, "classificationqqp": 667, "classificationqnli": 667, "54accuraci": 667, "em": 667, "mobilenetv2": 667, "wideresnet40": 667, "9522": 667, "8178": 667, "0213": 667, "8235": 667, "027": 667, "5494": 667, "7153": 667, "5540": 667, "0046": 667, "5523": 667, "vgg": 667, "bn": 667, "7022": 667, "7415": 667, "7025": 667, "0003": 667, "6739": 667, "7399": 667, "6845": 667, "0106": 667, "blendcnn": 667, "7034": 667, "8382": 667, "bilstm": 667, "8314": 667, "9403": 667, "9048": 667, "0734": 667, "7323": 667, "8256": 667, "8084": 667, "8814": 667, "7442": 667, "8371": 667, "0119": 667, "0115": 667, "tinybert": 667, "8018": 667, "8044": 667, "8363": 667, "8411": 667, "8025": 667, "8074": 667, "0007": 667, "0030": 667, "8626": 667, "9091": 667, "8782": 667, "8684": 667, "8259": 667, "0058": 667, "distilroberta": 667, "6057": 667, "6187": 667, "0130": 667, "c6i": 667, "2xlarg": 667, "c6a": 667, "c6g": 667, "a100cuda": 667, "executionprovid": 667}, "objects": {"": [[0, 0, 0, "-", "block_mask"], [363, 0, 0, "-", "neural_compressor"]], "neural_compressor": [[2, 0, 0, "-", "adaptor"], [174, 0, 0, "-", "algorithm"], [177, 0, 0, "-", "benchmark"], [180, 0, 0, "-", "common"], [195, 0, 0, "-", "compression"], [228, 0, 0, "-", "conf"], [230, 0, 0, "-", "config"], [231, 0, 0, "-", "contrib"], [256, 0, 0, "-", "data"], [310, 0, 0, "-", "experimental"], [370, 0, 0, "-", "metric"], [372, 0, 0, "-", "mix_precision"], [374, 0, 0, "-", "model"], [382, 0, 0, "-", "objective"], [392, 0, 0, "-", "onnxrt"], [402, 0, 0, "-", "profiling"], [424, 0, 0, "-", "quantization"], [432, 0, 0, "-", "strategy"], [444, 0, 0, "-", "template"], [459, 0, 0, "-", "tensorflow"], [543, 0, 0, "-", "torch"], [554, 0, 0, "-", "training"], [558, 0, 0, "-", "utils"], [567, 0, 0, "-", "version"]], "neural_compressor.adaptor": [[1, 0, 0, "-", "adaptor"], [3, 0, 0, "-", "keras"], [7, 0, 0, "-", "keras_utils"], [11, 0, 0, "-", "mxnet"], [12, 0, 0, "-", "mxnet_utils"], [14, 0, 0, "-", "onnxrt"], [17, 0, 0, "-", "ox_utils"], [45, 0, 0, "-", "pytorch"], [46, 0, 0, "-", "query"], [47, 0, 0, "-", "tensorflow"], [111, 0, 0, "-", "tf_utils"], [158, 0, 0, "-", "torch_utils"]], "neural_compressor.adaptor.adaptor": [[1, 1, 1, "", "Adaptor"], [1, 2, 1, "", "adaptor_registry"]], "neural_compressor.adaptor.keras": [[3, 1, 1, "", "KerasAdaptor"]], "neural_compressor.adaptor.keras_utils": [[4, 0, 0, "-", "conv2d"], [5, 0, 0, "-", "dense"], [6, 0, 0, "-", "depthwise_conv2d"], [8, 0, 0, "-", "pool2d"], [9, 0, 0, "-", "quantizer"], [10, 0, 0, "-", "separable_conv2d"]], "neural_compressor.adaptor.mxnet": [[11, 1, 1, "", "MXNetQuery"], [11, 1, 1, "", "MxNetAdaptor"]], "neural_compressor.adaptor.mxnet_utils": [[13, 0, 0, "-", "util"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, 1, 1, "", "CalibCollector"], [13, 1, 1, "", "CalibData"], [13, 1, 1, "", "CollectorBase"], [13, 1, 1, "", "DataIterLoader"], [13, 1, 1, "", "DataLoaderWrap"], [13, 1, 1, "", "NameCollector"], [13, 1, 1, "", "OpType"], [13, 1, 1, "", "TensorCollector"], [13, 2, 1, "", "amp_convert"], [13, 2, 1, "", "calib_model"], [13, 2, 1, "", "check_mx_version"], [13, 2, 1, "", "combine_capabilities"], [13, 2, 1, "", "create_data_example"], [13, 2, 1, "", "distribute_calib_tensors"], [13, 2, 1, "", "ensure_list"], [13, 2, 1, "", "fuse"], [13, 2, 1, "", "get_framework_name"], [13, 2, 1, "", "is_model_quantized"], [13, 2, 1, "", "isiterable"], [13, 2, 1, "", "make_module"], [13, 2, 1, "", "make_nc_model"], [13, 2, 1, "", "make_symbol_block"], [13, 2, 1, "", "ndarray_to_device"], [13, 2, 1, "", "parse_tune_config"], [13, 2, 1, "", "prepare_dataloader"], [13, 2, 1, "", "prepare_model"], [13, 2, 1, "", "prepare_model_data"], [13, 2, 1, "", "quantize_sym_model"], [13, 2, 1, "", "query_quantizable_nodes"], [13, 2, 1, "", "run_forward"]], "neural_compressor.adaptor.onnxrt": [[14, 1, 1, "", "ONNXRTQuery"], [14, 1, 1, "", "ONNXRT_IntegerOpsAdaptor"], [14, 1, 1, "", "ONNXRT_QDQAdaptor"], [14, 1, 1, "", "ONNXRT_QLinearOpsAdaptor"], [14, 1, 1, "", "ONNXRT_WeightOnlyAdaptor"], [14, 1, 1, "", "ONNXRUNTIMEAdaptor"]], "neural_compressor.adaptor.ox_utils": [[15, 0, 0, "-", "calibration"], [16, 0, 0, "-", "calibrator"], [29, 0, 0, "-", "operators"], [41, 0, 0, "-", "quantizer"], [42, 0, 0, "-", "smooth_quant"], [43, 0, 0, "-", "util"], [44, 0, 0, "-", "weight_only"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, 1, 1, "", "ONNXRTAugment"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, 1, 1, "", "CalibratorBase"], [16, 1, 1, "", "HistogramCollector"], [16, 1, 1, "", "KLCalibrator"], [16, 1, 1, "", "MinMaxCalibrator"], [16, 1, 1, "", "PercentileCalibrator"], [16, 2, 1, "", "calib_registry"], [16, 2, 1, "", "smooth_distribution"]], "neural_compressor.adaptor.ox_utils.operators": [[18, 0, 0, "-", "activation"], [19, 0, 0, "-", "argmax"], [20, 0, 0, "-", "attention"], [21, 0, 0, "-", "binary_op"], [22, 0, 0, "-", "concat"], [23, 0, 0, "-", "conv"], [24, 0, 0, "-", "direct_q8"], [25, 0, 0, "-", "embed_layernorm"], [26, 0, 0, "-", "gather"], [27, 0, 0, "-", "gavgpool"], [28, 0, 0, "-", "gemm"], [30, 0, 0, "-", "lstm"], [31, 0, 0, "-", "matmul"], [32, 0, 0, "-", "maxpool"], [33, 0, 0, "-", "norm"], [34, 0, 0, "-", "ops"], [35, 0, 0, "-", "pad"], [36, 0, 0, "-", "pooling"], [37, 0, 0, "-", "reduce"], [38, 0, 0, "-", "resize"], [39, 0, 0, "-", "split"], [40, 0, 0, "-", "unary_op"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, 1, 1, "", "ActivationOperator"], [18, 1, 1, "", "Float16ActivationOperator"], [18, 1, 1, "", "QActivationOperator"], [18, 1, 1, "", "RemovableActivationOperator"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, 1, 1, "", "ArgMaxOperator"], [19, 1, 1, "", "QArgMaxOperator"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, 1, 1, "", "AttentionOperator"], [20, 1, 1, "", "QAttentionOperator"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, 1, 1, "", "BinaryDirect8BitOperator"], [21, 1, 1, "", "BinaryOperator"], [21, 1, 1, "", "Float16BinaryOperator"], [21, 1, 1, "", "QBinaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, 1, 1, "", "ConcatOperator"], [22, 1, 1, "", "QConcatOperator"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, 1, 1, "", "ConvOperator"], [23, 1, 1, "", "QConvOperator"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, 1, 1, "", "Direct8BitOperator"], [24, 1, 1, "", "QDirectOperator"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, 1, 1, "", "EmbedLayerNormalizationOperator"], [25, 1, 1, "", "QEmbedLayerNormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, 1, 1, "", "GatherOperator"], [26, 1, 1, "", "QGatherOperator"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, 1, 1, "", "GlobalAveragePoolOperator"], [27, 1, 1, "", "QGlobalAveragePoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, 1, 1, "", "GemmOperator"], [28, 1, 1, "", "QGemmOperator"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, 1, 1, "", "LSTMOperator"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, 1, 1, "", "FusedMatMulOperator"], [31, 1, 1, "", "MatMulOperator"], [31, 1, 1, "", "QMatMulOperator"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, 1, 1, "", "MaxPoolOperator"], [32, 1, 1, "", "QMaxPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, 1, 1, "", "BatchNormalizationOperator"], [33, 1, 1, "", "NormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, 1, 1, "", "Operator"], [34, 1, 1, "", "QOperator"], [34, 2, 1, "", "op_registry"], [34, 2, 1, "", "qop_registry"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, 1, 1, "", "PadOperator"], [35, 1, 1, "", "QPadOperator"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, 1, 1, "", "PoolOperator"], [36, 1, 1, "", "QPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, 1, 1, "", "ReduceMinMaxOperator"], [37, 1, 1, "", "ReduceOperator"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, 1, 1, "", "QResizeOperator"], [38, 1, 1, "", "ResizeOperator"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, 1, 1, "", "QSplitOperator"], [39, 1, 1, "", "SplitOperator"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, 1, 1, "", "UnaryDirect8BitOperator"], [40, 1, 1, "", "UnaryOperator"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, 1, 1, "", "Quantizer"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, 1, 1, "", "ORTSmoothQuant"], [42, 2, 1, "", "get_quant_dequant_output"], [42, 2, 1, "", "make_sub_graph"], [42, 2, 1, "", "quant_dequant_data"]], "neural_compressor.adaptor.ox_utils.util": [[43, 1, 1, "", "QuantFormat"], [43, 1, 1, "", "QuantType"], [43, 1, 1, "", "QuantizationMode"], [43, 1, 1, "", "QuantizedInitializer"], [43, 1, 1, "", "QuantizedValue"], [43, 1, 1, "", "QuantizedValueType"], [43, 1, 1, "", "ValueInfo"], [43, 2, 1, "", "attribute_to_kwarg"], [43, 2, 1, "", "calculate_scale_zp"], [43, 2, 1, "", "cast_tensor"], [43, 2, 1, "", "collate_preds"], [43, 2, 1, "", "dequantize_data"], [43, 2, 1, "", "dequantize_data_with_scale_zero"], [43, 2, 1, "", "dtype_to_name"], [43, 2, 1, "", "find_by_name"], [43, 2, 1, "", "float_to_bfloat16"], [43, 2, 1, "", "float_to_float16"], [43, 2, 1, "", "get_node_original_name"], [43, 2, 1, "", "infer_shapes"], [43, 2, 1, "", "is_B_transposed"], [43, 2, 1, "", "make_dquant_node"], [43, 2, 1, "", "make_quant_node"], [43, 2, 1, "", "quantize_data"], [43, 2, 1, "", "quantize_data_per_channel"], [43, 2, 1, "", "quantize_data_with_scale_zero"], [43, 2, 1, "", "quantize_nparray"], [43, 2, 1, "", "remove_init_from_model_input"], [43, 2, 1, "", "simple_progress_bar"], [43, 2, 1, "", "split_shared_bias"], [43, 2, 1, "", "to_numpy"], [43, 2, 1, "", "trt_env_setup"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, 2, 1, "", "apply_awq_clip"], [44, 2, 1, "", "apply_awq_scale"], [44, 2, 1, "", "awq_quantize"], [44, 2, 1, "", "get_blob_size"], [44, 2, 1, "", "get_weight_scale"], [44, 2, 1, "", "gptq"], [44, 2, 1, "", "gptq_quantize"], [44, 2, 1, "", "make_matmul_weight_only_node"], [44, 2, 1, "", "pad_tensor"], [44, 2, 1, "", "prepare_inputs"], [44, 2, 1, "", "qdq_tensor"], [44, 2, 1, "", "quant_tensor"], [44, 2, 1, "", "rtn_quantize"]], "neural_compressor.adaptor.pytorch": [[45, 1, 1, "", "PyTorchAdaptor"], [45, 1, 1, "", "PyTorchWeightOnlyAdaptor"], [45, 1, 1, "", "PyTorch_FXAdaptor"], [45, 1, 1, "", "PyTorch_IPEXAdaptor"], [45, 1, 1, "", "TemplateAdaptor"], [45, 2, 1, "", "get_ops_recursively"]], "neural_compressor.adaptor.query": [[46, 1, 1, "", "QueryBackendCapability"]], "neural_compressor.adaptor.tensorflow": [[47, 1, 1, "", "TensorFlowAdaptor"], [47, 1, 1, "", "TensorflowQuery"], [47, 1, 1, "", "Tensorflow_ITEXAdaptor"]], "neural_compressor.adaptor.tf_utils": [[48, 0, 0, "-", "graph_converter"], [49, 0, 0, "-", "graph_converter_without_calib"], [87, 0, 0, "-", "graph_rewriter"], [110, 0, 0, "-", "graph_util"], [112, 0, 0, "-", "quantize_graph"], [139, 0, 0, "-", "quantize_graph_common"], [140, 0, 0, "-", "smooth_quant_calibration"], [141, 0, 0, "-", "smooth_quant_scaler"], [142, 0, 0, "-", "tf2onnx_converter"], [145, 0, 0, "-", "transform_graph"], [148, 0, 0, "-", "util"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, 1, 1, "", "GraphConverter"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, 1, 1, "", "GraphConverterWithoutCalib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[52, 0, 0, "-", "bf16"], [76, 0, 0, "-", "generic"], [86, 0, 0, "-", "graph_base"], [95, 0, 0, "-", "int8"], [101, 0, 0, "-", "onnx"], [106, 0, 0, "-", "qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[50, 0, 0, "-", "bf16_convert"], [51, 0, 0, "-", "dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, 1, 1, "", "BF16Convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, 1, 1, "", "DequantizeCastOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[53, 0, 0, "-", "convert_add_to_biasadd"], [54, 0, 0, "-", "convert_layout"], [55, 0, 0, "-", "convert_leakyrelu"], [56, 0, 0, "-", "convert_nan_to_random"], [57, 0, 0, "-", "convert_placeholder_to_const"], [58, 0, 0, "-", "dilated_contraction"], [59, 0, 0, "-", "dummy_biasadd"], [60, 0, 0, "-", "expanddims_optimizer"], [61, 0, 0, "-", "fetch_weight_from_reshape"], [62, 0, 0, "-", "fold_batch_norm"], [63, 0, 0, "-", "fold_constant"], [64, 0, 0, "-", "fuse_biasadd_add"], [65, 0, 0, "-", "fuse_column_wise_mul"], [66, 0, 0, "-", "fuse_conv_with_math"], [67, 0, 0, "-", "fuse_decomposed_bn"], [68, 0, 0, "-", "fuse_decomposed_in"], [69, 0, 0, "-", "fuse_gelu"], [70, 0, 0, "-", "fuse_layer_norm"], [71, 0, 0, "-", "fuse_pad_with_conv"], [72, 0, 0, "-", "fuse_pad_with_fp32_conv"], [73, 0, 0, "-", "fuse_reshape_transpose"], [74, 0, 0, "-", "graph_cse_optimizer"], [75, 0, 0, "-", "grappler_pass"], [77, 0, 0, "-", "insert_print_node"], [78, 0, 0, "-", "move_squeeze_after_relu"], [79, 0, 0, "-", "pre_optimize"], [80, 0, 0, "-", "remove_training_nodes"], [81, 0, 0, "-", "rename_batch_norm"], [82, 0, 0, "-", "split_shared_input"], [83, 0, 0, "-", "strip_equivalent_nodes"], [84, 0, 0, "-", "strip_unused_nodes"], [85, 0, 0, "-", "switch_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, 1, 1, "", "ConvertAddToBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, 1, 1, "", "ConvertLayoutOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, 1, 1, "", "ConvertLeakyReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, 1, 1, "", "ConvertNanToRandom"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, 1, 1, "", "ConvertPlaceholderToConst"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, 1, 1, "", "DilatedContraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, 1, 1, "", "InjectDummyBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, 1, 1, "", "ExpandDimsOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, 1, 1, "", "FetchWeightFromReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, 1, 1, "", "FoldBatchNormNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, 1, 1, "", "GraphFoldConstantOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, 1, 1, "", "FuseBiasAddAndAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, 1, 1, "", "FuseColumnWiseMulOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, 1, 1, "", "FuseConvWithMathOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, 1, 1, "", "FuseDecomposedBNOptimizer"], [67, 2, 1, "", "bypass_reshape"], [67, 2, 1, "", "get_const_dim_count"], [67, 2, 1, "", "node_from_map"], [67, 2, 1, "", "node_name_from_input"], [67, 2, 1, "", "valid_reshape_inputs"], [67, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, 1, 1, "", "FuseDecomposedINOptimizer"], [68, 2, 1, "", "bypass_reshape"], [68, 2, 1, "", "get_const_dim_count"], [68, 2, 1, "", "node_from_map"], [68, 2, 1, "", "node_name_from_input"], [68, 2, 1, "", "valid_reshape_inputs"], [68, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, 1, 1, "", "FuseGeluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, 1, 1, "", "FuseLayerNormOptimizer"], [70, 2, 1, "", "node_from_map"], [70, 2, 1, "", "node_name_from_input"], [70, 2, 1, "", "values_from_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, 1, 1, "", "FusePadWithConv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, 1, 1, "", "FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, 1, 1, "", "FuseTransposeReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, 1, 1, "", "GraphCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, 1, 1, "", "GrapplerOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, 1, 1, "", "InsertPrintMinMaxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, 1, 1, "", "MoveSqueezeAfterReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, 1, 1, "", "PreOptimization"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, 1, 1, "", "RemoveTrainingNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, 1, 1, "", "RenameBatchNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, 1, 1, "", "SplitSharedInputOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, 1, 1, "", "StripEquivalentNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, 1, 1, "", "StripUnusedNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, 1, 1, "", "SwitchOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, 1, 1, "", "GraphRewriterBase"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[88, 0, 0, "-", "freeze_fake_quant"], [89, 0, 0, "-", "freeze_value"], [90, 0, 0, "-", "freeze_value_without_calib"], [91, 0, 0, "-", "fuse_conv_redundant_dequantize"], [92, 0, 0, "-", "fuse_conv_requantize"], [93, 0, 0, "-", "fuse_matmul_redundant_dequantize"], [94, 0, 0, "-", "fuse_matmul_requantize"], [96, 0, 0, "-", "meta_op_optimizer"], [97, 0, 0, "-", "post_hostconst_converter"], [98, 0, 0, "-", "post_quantized_op_cse"], [99, 0, 0, "-", "rnn_convert"], [100, 0, 0, "-", "scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, 1, 1, "", "FreezeFakeQuantOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, 1, 1, "", "FreezeValueTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, 1, 1, "", "FreezeValueWithoutCalibTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, 1, 1, "", "FuseConvRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, 1, 1, "", "FuseConvRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, 1, 1, "", "FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, 1, 1, "", "FuseMatMulRequantizeDequantizeNewAPITransformer"], [94, 1, 1, "", "FuseMatMulRequantizeDequantizeTransformer"], [94, 1, 1, "", "FuseMatMulRequantizeNewAPITransformer"], [94, 1, 1, "", "FuseMatMulRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, 1, 1, "", "MetaInfoChangingMemOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, 1, 1, "", "PostHostConstConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, 1, 1, "", "PostCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, 1, 1, "", "QuantizedRNNConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, 1, 1, "", "ScaleProPagationTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[102, 0, 0, "-", "onnx_graph"], [103, 0, 0, "-", "onnx_node"], [104, 0, 0, "-", "onnx_schema"], [105, 0, 0, "-", "tf2onnx_utils"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, 1, 1, "", "OnnxGraph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, 1, 1, "", "OnnxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, 1, 1, "", "OnnxOpSchema"], [104, 2, 1, "", "get_max_supported_opset_version"], [104, 2, 1, "", "get_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, 1, 1, "", "SeqType"], [105, 2, 1, "", "add_port_to_name"], [105, 2, 1, "", "are_shapes_equal"], [105, 2, 1, "", "assert_error"], [105, 2, 1, "", "compute_const_folding_using_tf"], [105, 2, 1, "", "convert_tensorflow_tensor_to_onnx"], [105, 2, 1, "", "find_opset"], [105, 2, 1, "", "get_index_from_strided_slice_of_shape"], [105, 2, 1, "", "get_subgraphs_from_onnx"], [105, 2, 1, "", "get_tensorflow_node_attr"], [105, 2, 1, "", "get_tensorflow_node_shape_attr"], [105, 2, 1, "", "get_tensorflow_tensor_data"], [105, 2, 1, "", "get_tensorflow_tensor_shape"], [105, 2, 1, "", "infer_onnx_shape_dtype"], [105, 2, 1, "", "initialize_name_counter"], [105, 2, 1, "", "is_list_or_tuple"], [105, 2, 1, "", "is_onnx_domain"], [105, 2, 1, "", "make_onnx_inputs_outputs"], [105, 2, 1, "", "make_onnx_shape"], [105, 2, 1, "", "map_numpy_to_onnx_dtype"], [105, 2, 1, "", "map_onnx_to_numpy_type"], [105, 2, 1, "", "map_tensorflow_dtype"], [105, 2, 1, "", "read_tensorflow_node_attrs"], [105, 2, 1, "", "save_protobuf"], [105, 2, 1, "", "set_name"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[107, 0, 0, "-", "insert_qdq_pattern"], [108, 0, 0, "-", "merge_duplicated_qdq"], [109, 0, 0, "-", "share_qdq_y_pattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, 1, 1, "", "GenerateGraphWithQDQPattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, 1, 1, "", "MergeDuplicatedQDQOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, 1, 1, "", "ShareQDQForItexYPatternOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, 1, 1, "", "GraphAnalyzer"], [110, 1, 1, "", "GraphRewriterHelper"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[114, 0, 0, "-", "qat"], [130, 0, 0, "-", "qdq"], [132, 0, 0, "-", "quantize_graph_base"], [133, 0, 0, "-", "quantize_graph_bn"], [134, 0, 0, "-", "quantize_graph_concatv2"], [135, 0, 0, "-", "quantize_graph_conv"], [136, 0, 0, "-", "quantize_graph_for_intel_cpu"], [137, 0, 0, "-", "quantize_graph_matmul"], [138, 0, 0, "-", "quantize_graph_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[113, 0, 0, "-", "fake_quantize"], [115, 0, 0, "-", "quantize_config"], [116, 0, 0, "-", "quantize_helper"], [117, 0, 0, "-", "quantize_layers"], [122, 0, 0, "-", "quantize_wrapper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, 1, 1, "", "FakeQuantize"], [113, 1, 1, "", "FakeQuantizeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, 1, 1, "", "QuantizeConfig"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, 2, 1, "", "init_quantize_config"], [116, 2, 1, "", "qat_clone_function"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[118, 0, 0, "-", "optimize_layer"], [119, 0, 0, "-", "quantize_layer_add"], [120, 0, 0, "-", "quantize_layer_base"], [121, 0, 0, "-", "quantize_layer_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, 2, 1, "", "config_quantizable_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, 1, 1, "", "QuantizeLayerAdd"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, 1, 1, "", "QuantizeLayerBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, 1, 1, "", "QuantizeLayerBatchNormalization"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, 1, 1, "", "QuantizeWrapper"], [122, 1, 1, "", "QuantizeWrapperBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[123, 0, 0, "-", "fuse_qdq_bn"], [124, 0, 0, "-", "fuse_qdq_concatv2"], [125, 0, 0, "-", "fuse_qdq_conv"], [126, 0, 0, "-", "fuse_qdq_deconv"], [127, 0, 0, "-", "fuse_qdq_in"], [128, 0, 0, "-", "fuse_qdq_matmul"], [129, 0, 0, "-", "fuse_qdq_pooling"], [131, 0, 0, "-", "optimize_qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, 1, 1, "", "FuseNodeStartWithDeconv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, 1, 1, "", "FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, 1, 1, "", "OptimizeQDQGraph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, 1, 1, "", "QuantizeGraphBase"], [132, 1, 1, "", "QuantizeNodeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, 1, 1, "", "FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, 1, 1, "", "FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, 1, 1, "", "FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, 1, 1, "", "QuantizeGraphForIntel"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, 1, 1, "", "FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, 1, 1, "", "FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, 1, 1, "", "QuantizeGraphHelper"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, 1, 1, "", "SmoothQuantCalibration"], [140, 1, 1, "", "SmoothQuantCalibrationLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, 1, 1, "", "SmoothQuantScaler"], [141, 1, 1, "", "SmoothQuantScalerLLM"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, 1, 1, "", "TensorflowQDQToOnnxQDQConverter"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[143, 0, 0, "-", "bias_correction"], [144, 0, 0, "-", "graph_transform_base"], [146, 0, 0, "-", "insert_logging"], [147, 0, 0, "-", "rerange_quantized_concat"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, 1, 1, "", "BiasCorrection"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, 1, 1, "", "GraphTransformBase"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, 1, 1, "", "InsertLogging"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, 1, 1, "", "RerangeQuantizedConcat"]], "neural_compressor.adaptor.tf_utils.util": [[148, 2, 1, "", "apply_inlining"], [148, 2, 1, "", "collate_tf_preds"], [148, 2, 1, "", "construct_function_from_graph_def"], [148, 2, 1, "", "disable_random"], [148, 2, 1, "", "fix_ref_type_of_graph_def"], [148, 2, 1, "", "generate_feed_dict"], [148, 2, 1, "", "get_estimator_graph"], [148, 2, 1, "", "get_graph_def"], [148, 2, 1, "", "get_input_output_node_names"], [148, 2, 1, "", "get_model_input_shape"], [148, 2, 1, "", "get_tensor_by_name"], [148, 2, 1, "", "get_tensor_val_from_graph_node"], [148, 2, 1, "", "get_weight_from_input_tensor"], [148, 2, 1, "", "int8_node_name_reverse"], [148, 2, 1, "", "is_ckpt_format"], [148, 2, 1, "", "is_saved_model_format"], [148, 2, 1, "", "iterator_sess_run"], [148, 2, 1, "", "parse_saved_model"], [148, 2, 1, "", "read_graph"], [148, 2, 1, "", "reconstruct_saved_model"], [148, 2, 1, "", "strip_equivalent_nodes"], [148, 2, 1, "", "strip_unused_nodes"], [148, 2, 1, "", "tf_diagnosis_helper"], [148, 2, 1, "", "version1_eq_version2"], [148, 2, 1, "", "version1_gt_version2"], [148, 2, 1, "", "version1_gte_version2"], [148, 2, 1, "", "version1_lt_version2"], [148, 2, 1, "", "version1_lte_version2"], [148, 2, 1, "", "write_graph"]], "neural_compressor.adaptor.torch_utils": [[151, 0, 0, "-", "autoround"], [154, 0, 0, "-", "awq"], [155, 0, 0, "-", "bf16_convert"], [156, 0, 0, "-", "gptq"], [157, 0, 0, "-", "hawq_metric"], [159, 0, 0, "-", "layer_wise_quant"], [164, 0, 0, "-", "mixed_precision"], [165, 0, 0, "-", "model_wrapper"], [166, 0, 0, "-", "pattern_detector"], [167, 0, 0, "-", "smooth_quant"], [168, 0, 0, "-", "symbolic_trace"], [169, 0, 0, "-", "teq"], [170, 0, 0, "-", "util"], [171, 0, 0, "-", "weight_only"]], "neural_compressor.adaptor.torch_utils.autoround": [[149, 0, 0, "-", "autoround"], [150, 0, 0, "-", "export"], [152, 0, 0, "-", "model_wrapper"], [153, 0, 0, "-", "sign_sgd"]], "neural_compressor.adaptor.torch_utils.autoround.autoround": [[149, 1, 1, "", "AutoAdamRound"], [149, 1, 1, "", "AutoOPTRound"], [149, 1, 1, "", "AutoRound"], [149, 1, 1, "", "SaveInputs"], [149, 1, 1, "", "WrapperMultiblock"], [149, 2, 1, "", "block_forward"], [149, 2, 1, "", "check_is_cpu"], [149, 2, 1, "", "collect_minmax_scale"], [149, 2, 1, "", "collect_round_v"], [149, 2, 1, "", "get_batch_dim"], [149, 2, 1, "", "get_block_names"], [149, 2, 1, "", "get_dataloader"], [149, 2, 1, "", "get_module"], [149, 2, 1, "", "get_scale_shape"], [149, 2, 1, "", "get_tokenizer_function"], [149, 2, 1, "", "move_input_to_device"], [149, 2, 1, "", "quant_weight"], [149, 2, 1, "", "quant_weight_actor"], [149, 2, 1, "", "quant_weight_asym"], [149, 2, 1, "", "quant_weight_sym"], [149, 2, 1, "", "quant_weight_w_scale"], [149, 2, 1, "", "round_ste"], [149, 2, 1, "", "sampling_inputs"], [149, 2, 1, "", "set_module"], [149, 2, 1, "", "unwrapper_block"], [149, 2, 1, "", "wrapper_block"]], "neural_compressor.adaptor.torch_utils.autoround.export": [[150, 2, 1, "", "export_compressed_model"]], "neural_compressor.adaptor.torch_utils.autoround.sign_sgd": [[153, 1, 1, "", "SGD"], [153, 2, 1, "", "sgd"]], "neural_compressor.adaptor.torch_utils.awq": [[154, 1, 1, "", "ActAwareWeightQuant"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[155, 1, 1, "", "BF16ModuleWrapper"], [155, 2, 1, "", "Convert"], [155, 2, 1, "", "bf16_symbolic_trace"]], "neural_compressor.adaptor.torch_utils.gptq": [[156, 1, 1, "", "GPTQ"], [156, 1, 1, "", "GPTQuantizer"], [156, 2, 1, "", "find_layers"], [156, 2, 1, "", "find_layers_name"], [156, 2, 1, "", "is_leaf"], [156, 2, 1, "", "log_quantizable_layers_per_transformer"], [156, 2, 1, "", "quantize"], [156, 2, 1, "", "trace_gptq_target_blocks"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[157, 1, 1, "", "HessianTrace"], [157, 1, 1, "", "Node_collector"], [157, 2, 1, "", "compare_weights"], [157, 2, 1, "", "hawq_top"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[160, 0, 0, "-", "modified_pickle"], [161, 0, 0, "-", "quantize"], [162, 0, 0, "-", "torch_load"], [163, 0, 0, "-", "utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[160, 3, 1, "", "PickleError"], [160, 3, 1, "", "PicklingError"], [160, 3, 1, "", "UnpicklingError"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[161, 1, 1, "", "LayerWiseQuant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[162, 2, 1, "", "load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[163, 2, 1, "", "dowload_hf_model"], [163, 2, 1, "", "get_children"], [163, 2, 1, "", "get_module"], [163, 2, 1, "", "get_named_children"], [163, 2, 1, "", "get_super_module_by_name"], [163, 2, 1, "", "load_empty_model"], [163, 2, 1, "", "load_layer_wise_quantized_model"], [163, 2, 1, "", "load_tensor"], [163, 2, 1, "", "load_tensor_from_shard"], [163, 2, 1, "", "update_module"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[164, 2, 1, "", "ipex_mixed_precision"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[165, 1, 1, "", "FakeAffineTensorQuantFunction"], [165, 1, 1, "", "MulLinear"], [165, 1, 1, "", "TEQLinearFakeQuant"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[166, 1, 1, "", "TransformerBasedModelBlockPatternDetector"]], "neural_compressor.adaptor.torch_utils.smooth_quant": [[167, 1, 1, "", "TorchSmoothQuant"], [167, 2, 1, "", "get_module"], [167, 2, 1, "", "set_module"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[168, 2, 1, "", "symbolic_trace"], [168, 2, 1, "", "trace_and_fuse_sub_graph"]], "neural_compressor.adaptor.torch_utils.teq": [[169, 1, 1, "", "TEQuantizer"]], "neural_compressor.adaptor.torch_utils.util": [[170, 2, 1, "", "append_attr"], [170, 2, 1, "", "auto_copy"], [170, 2, 1, "", "calculate_quant_min_max"], [170, 2, 1, "", "calibration"], [170, 2, 1, "", "check_cfg_and_qconfig"], [170, 2, 1, "", "collate_torch_preds"], [170, 2, 1, "", "collect_weight_info"], [170, 2, 1, "", "fetch_module"], [170, 2, 1, "", "forward_wrapper"], [170, 2, 1, "", "generate_activation_observer"], [170, 2, 1, "", "get_absorb_layers"], [170, 2, 1, "", "get_block_prefix"], [170, 2, 1, "", "get_depth"], [170, 2, 1, "", "get_dict_at_depth"], [170, 2, 1, "", "get_element_under_depth"], [170, 2, 1, "", "get_embedding_contiguous"], [170, 2, 1, "", "get_example_input"], [170, 2, 1, "", "get_fallback_order"], [170, 2, 1, "", "get_hidden_states"], [170, 2, 1, "", "get_module_input_output"], [170, 2, 1, "", "get_mse_order_per_fp32"], [170, 2, 1, "", "get_mse_order_per_int8"], [170, 2, 1, "", "get_op_type_by_name"], [170, 2, 1, "", "get_quantizable_ops_from_cfgs"], [170, 2, 1, "", "get_torch_version"], [170, 2, 1, "", "input2tuple"], [170, 2, 1, "", "is_fused_module"], [170, 2, 1, "", "match_datatype_pattern"], [170, 2, 1, "", "move_input_device"], [170, 2, 1, "", "paser_cfgs"], [170, 2, 1, "", "set_module"], [170, 2, 1, "", "simple_inference"], [170, 2, 1, "", "update_sq_scale"]], "neural_compressor.adaptor.torch_utils.weight_only": [[171, 2, 1, "", "awq_quantize"], [171, 2, 1, "", "gptq_quantize"], [171, 2, 1, "", "qdq_weight_actor"], [171, 2, 1, "", "qdq_weight_asym"], [171, 2, 1, "", "qdq_weight_sym"], [171, 2, 1, "", "quant_weight"], [171, 2, 1, "", "quant_weight_w_scale"], [171, 2, 1, "", "quantize_4bit"], [171, 2, 1, "", "rtn_quantize"], [171, 2, 1, "", "search_clip"], [171, 2, 1, "", "teq_quantize"]], "neural_compressor.algorithm": [[172, 0, 0, "-", "algorithm"], [173, 0, 0, "-", "fast_bias_correction"], [175, 0, 0, "-", "smooth_quant"], [176, 0, 0, "-", "weight_correction"]], "neural_compressor.algorithm.algorithm": [[172, 1, 1, "", "ALGORITHMS"], [172, 1, 1, "", "Algorithm"], [172, 1, 1, "", "AlgorithmScheduler"], [172, 2, 1, "", "algorithm_registry"]], "neural_compressor.algorithm.fast_bias_correction": [[173, 1, 1, "", "FastBiasCorrection"]], "neural_compressor.algorithm.smooth_quant": [[175, 1, 1, "", "SmoothQuant"]], "neural_compressor.algorithm.weight_correction": [[176, 1, 1, "", "WeightCorrection"]], "neural_compressor.benchmark": [[177, 2, 1, "", "benchmark_with_raw_cmd"], [177, 2, 1, "", "call_one"], [177, 2, 1, "", "config_instance"], [177, 2, 1, "", "fit"], [177, 2, 1, "", "generate_prefix"], [177, 2, 1, "", "get_architecture"], [177, 2, 1, "", "get_bounded_threads"], [177, 2, 1, "", "get_core_ids"], [177, 2, 1, "", "get_physical_ids"], [177, 2, 1, "", "get_threads"], [177, 2, 1, "", "get_threads_per_core"], [177, 2, 1, "", "profile"], [177, 2, 1, "", "run_instance"], [177, 2, 1, "", "set_all_env_var"], [177, 2, 1, "", "set_env_var"], [177, 2, 1, "", "summary_benchmark"]], "neural_compressor.common": [[178, 0, 0, "-", "base_config"], [179, 0, 0, "-", "base_tuning"], [181, 0, 0, "-", "tuning_param"], [183, 0, 0, "-", "utils"]], "neural_compressor.common.base_config": [[178, 1, 1, "", "BaseConfig"], [178, 1, 1, "", "ComposableConfig"], [178, 2, 1, "", "register_config"], [178, 2, 1, "", "register_supported_configs_for_fwk"]], "neural_compressor.common.base_tuning": [[179, 1, 1, "", "Evaluator"], [179, 1, 1, "", "SequentialSampler"], [179, 1, 1, "", "TuningConfig"]], "neural_compressor.common.tuning_param": [[181, 1, 1, "", "ParamLevel"], [181, 1, 1, "", "TuningParam"]], "neural_compressor.common.utils": [[182, 0, 0, "-", "constants"], [184, 0, 0, "-", "logger"], [185, 0, 0, "-", "utility"]], "neural_compressor.common.utils.logger": [[184, 1, 1, "", "Logger"], [184, 1, 1, "", "TuningLogger"]], "neural_compressor.common.utils.utility": [[185, 2, 1, "", "dump_elapsed_time"], [185, 2, 1, "", "set_random_seed"], [185, 2, 1, "", "set_resume_from"], [185, 2, 1, "", "set_tensorboard"], [185, 2, 1, "", "set_workspace"]], "neural_compressor.compression": [[186, 0, 0, "-", "callbacks"], [188, 0, 0, "-", "distillation"], [191, 0, 0, "-", "hpo"], [198, 0, 0, "-", "pruner"]], "neural_compressor.compression.callbacks": [[186, 1, 1, "", "BaseCallbacks"], [186, 1, 1, "", "DistillationCallbacks"], [186, 1, 1, "", "PruningCallbacks"], [186, 1, 1, "", "QuantizationAwareTrainingCallbacks"]], "neural_compressor.compression.callbacks.DistillationCallbacks": [[186, 4, 1, "", "_epoch_ran"], [186, 4, 1, "", "best_model"], [186, 4, 1, "", "best_score"], [186, 4, 1, "", "eval_frequency"]], "neural_compressor.compression.distillation": [[187, 0, 0, "-", "criterions"], [189, 0, 0, "-", "optimizers"], [190, 0, 0, "-", "utility"]], "neural_compressor.compression.distillation.criterions": [[187, 1, 1, "", "Criterions"], [187, 1, 1, "", "IntermediateLayersKnowledgeDistillationLoss"], [187, 1, 1, "", "KnowledgeDistillationFramework"], [187, 1, 1, "", "KnowledgeDistillationLoss"], [187, 1, 1, "", "PyTorchCriterions"], [187, 1, 1, "", "PyTorchCrossEntropyLoss"], [187, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLoss"], [187, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"], [187, 1, 1, "", "PyTorchKnowledgeDistillationLoss"], [187, 1, 1, "", "PyTorchKnowledgeDistillationLossWrapper"], [187, 1, 1, "", "PyTorchSelfKnowledgeDistillationLoss"], [187, 1, 1, "", "PyTorchSelfKnowledgeDistillationLossWrapper"], [187, 1, 1, "", "SelfKnowledgeDistillationLoss"], [187, 1, 1, "", "TensorFlowCrossEntropyLoss"], [187, 1, 1, "", "TensorFlowSparseCategoricalCrossentropy"], [187, 1, 1, "", "TensorflowCriterions"], [187, 1, 1, "", "TensorflowKnowledgeDistillationLoss"], [187, 1, 1, "", "TensorflowKnowledgeDistillationLossExternal"], [187, 1, 1, "", "TensorflowKnowledgeDistillationLossWrapper"], [187, 2, 1, "", "criterion_registry"]], "neural_compressor.compression.distillation.optimizers": [[189, 1, 1, "", "Optimizers"], [189, 1, 1, "", "PyTorchOptimizers"], [189, 1, 1, "", "PyTorchSGD"], [189, 1, 1, "", "TensorFlowAdam"], [189, 1, 1, "", "TensorFlowAdamW"], [189, 1, 1, "", "TensorFlowSGD"], [189, 1, 1, "", "TensorflowOptimizers"], [189, 2, 1, "", "optimizer_registry"]], "neural_compressor.compression.distillation.utility": [[190, 2, 1, "", "get_activation"], [190, 2, 1, "", "record_output"]], "neural_compressor.compression.hpo": [[192, 0, 0, "-", "sa_optimizer"], [193, 0, 0, "-", "search_algorithms"], [194, 0, 0, "-", "search_space"]], "neural_compressor.compression.hpo.search_algorithms": [[193, 1, 1, "", "BayesianOptimizationSearcher"], [193, 1, 1, "", "GridSearcher"], [193, 1, 1, "", "RandomSearcher"], [193, 1, 1, "", "Searcher"], [193, 1, 1, "", "XgbSearcher"], [193, 2, 1, "", "register_searcher"]], "neural_compressor.compression.hpo.search_space": [[194, 1, 1, "", "BaseSearchSpace"], [194, 1, 1, "", "ContinuousSearchSpace"], [194, 1, 1, "", "DiscreteSearchSpace"], [194, 1, 1, "", "SearchSpace"], [194, 2, 1, "", "register_searchspace"]], "neural_compressor.compression.pruner": [[196, 0, 0, "-", "criteria"], [197, 0, 0, "-", "dsnot"], [200, 0, 0, "-", "model_slim"], [204, 0, 0, "-", "patterns"], [198, 2, 1, "", "prepare_pruning"], [211, 0, 0, "-", "pruners"], [217, 0, 0, "-", "pruning"], [218, 0, 0, "-", "regs"], [198, 2, 1, "", "save"], [219, 0, 0, "-", "schedulers"], [220, 0, 0, "-", "tf_criteria"], [221, 0, 0, "-", "utils"], [222, 0, 0, "-", "wanda"]], "neural_compressor.compression.pruner.criteria": [[196, 1, 1, "", "BlockMaskCriterion"], [196, 1, 1, "", "GradientCriterion"], [196, 1, 1, "", "MagnitudeCriterion"], [196, 1, 1, "", "PruningCriterion"], [196, 1, 1, "", "RetrainFreeCriterion"], [196, 1, 1, "", "SnipCriterion"], [196, 1, 1, "", "SnipMomentumCriterion"], [196, 2, 1, "", "get_criterion"], [196, 2, 1, "", "register_criterion"]], "neural_compressor.compression.pruner.criteria.BlockMaskCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.GradientCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.MagnitudeCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.PruningCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.SnipCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion": [[196, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.dsnot": [[197, 2, 1, "", "DSnoT"], [197, 2, 1, "", "return_reorder_indice"]], "neural_compressor.compression.pruner.model_slim": [[199, 0, 0, "-", "auto_slim"], [201, 0, 0, "-", "pattern_analyzer"], [202, 0, 0, "-", "weight_slim"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[199, 2, 1, "", "generate_ffn2_pruning_config"], [199, 2, 1, "", "generate_mha_pruning_config"], [199, 2, 1, "", "model_slim"], [199, 2, 1, "", "model_slim_ffn2"], [199, 2, 1, "", "model_slim_mha"], [199, 2, 1, "", "parse_auto_slim_config"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[201, 1, 1, "", "ClassifierHeadSearcher"], [201, 1, 1, "", "ClassifierHeadSearcherTF"], [201, 1, 1, "", "JitBasicSearcher"], [201, 1, 1, "", "Linear2LinearSearcher"], [201, 1, 1, "", "RecipeSearcher"], [201, 1, 1, "", "SelfMHASearcher"], [201, 2, 1, "", "get_attributes"], [201, 2, 1, "", "get_common_module"], [201, 2, 1, "", "print_iterables"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher": [[201, 4, 1, "", "device"], [201, 4, 1, "", "flatten_static_graph"], [201, 4, 1, "", "model"], [201, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF": [[201, 4, 1, "", "device"], [201, 4, 1, "", "flatten_static_graph"], [201, 4, 1, "", "model"], [201, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher": [[201, 4, 1, "", "device"], [201, 4, 1, "", "flatten_static_graph"], [201, 4, 1, "", "model"], [201, 4, 1, "", "searching_results"], [201, 4, 1, "", "static_graph"], [201, 4, 1, "", "target_layers"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher": [[201, 4, 1, "", "current_pattern"], [201, 4, 1, "", "device"], [201, 4, 1, "", "flatten_static_graph"], [201, 4, 1, "", "model"], [201, 4, 1, "", "searching_results"], [201, 4, 1, "", "static_graph"], [201, 4, 1, "", "target_layers"], [201, 4, 1, "", "target_op_lut"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher": [[201, 4, 1, "", "model"], [201, 4, 1, "", "recipe"], [201, 4, 1, "", "searching_results"], [201, 4, 1, "", "targets"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher": [[201, 4, 1, "", "device"], [201, 4, 1, "", "flatten_static_graph"], [201, 4, 1, "", "model"], [201, 4, 1, "", "static_graph"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[202, 1, 1, "", "LinearCompression"], [202, 1, 1, "", "LinearCompressionIterator"], [202, 1, 1, "", "PostCompressionUtils"]], "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression": [[202, 4, 1, "", "device"], [202, 4, 1, "", "layer_1"], [202, 4, 1, "", "layer_2"]], "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator": [[202, 4, 1, "", "linear_patterns"]], "neural_compressor.compression.pruner.patterns": [[203, 0, 0, "-", "base"], [204, 2, 1, "", "get_pattern"], [205, 0, 0, "-", "mha"], [206, 0, 0, "-", "ninm"], [207, 0, 0, "-", "nxm"]], "neural_compressor.compression.pruner.patterns.base": [[203, 1, 1, "", "BasePattern"], [203, 1, 1, "", "KerasBasePattern"], [203, 1, 1, "", "PytorchBasePattern"], [203, 2, 1, "", "register_pattern"]], "neural_compressor.compression.pruner.patterns.base.BasePattern": [[203, 4, 1, "", "config"], [203, 4, 1, "", "invalid_layers"], [203, 4, 1, "", "is_global"], [203, 4, 1, "", "keep_mask_layers"], [203, 4, 1, "", "max_sparsity_ratio_per_op"], [203, 4, 1, "", "min_sparsity_ratio_per_op"], [203, 4, 1, "", "modules"], [203, 4, 1, "", "pattern"], [203, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.base.KerasBasePattern": [[203, 4, 1, "", "config"], [203, 4, 1, "", "invalid_layers"], [203, 4, 1, "", "is_global"], [203, 4, 1, "", "keep_mask_layers"], [203, 4, 1, "", "max_sparsity_ratio_per_op"], [203, 4, 1, "", "min_sparsity_ratio_per_op"], [203, 4, 1, "", "modules"], [203, 4, 1, "", "pattern"], [203, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern": [[203, 4, 1, "", "config"], [203, 4, 1, "", "invalid_layers"], [203, 4, 1, "", "is_global"], [203, 4, 1, "", "keep_mask_layers"], [203, 4, 1, "", "max_sparsity_ratio_per_op"], [203, 4, 1, "", "min_sparsity_ratio_per_op"], [203, 4, 1, "", "modules"], [203, 4, 1, "", "pattern"], [203, 4, 1, "", "target_sparsity"]], "neural_compressor.compression.pruner.patterns.mha": [[205, 1, 1, "", "PatternMHA"]], "neural_compressor.compression.pruner.patterns.mha.PatternMHA": [[205, 4, 1, "", "M"], [205, 4, 1, "", "N"]], "neural_compressor.compression.pruner.patterns.ninm": [[206, 1, 1, "", "PytorchPatternNInM"]], "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM": [[206, 4, 1, "", "M"], [206, 4, 1, "", "N"]], "neural_compressor.compression.pruner.patterns.nxm": [[207, 1, 1, "", "KerasPatternNxM"], [207, 1, 1, "", "PytorchPatternNxM"]], "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM": [[207, 4, 1, "", "block_size"]], "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM": [[207, 4, 1, "", "block_size"]], "neural_compressor.compression.pruner.pruners": [[208, 0, 0, "-", "base"], [209, 0, 0, "-", "basic"], [210, 0, 0, "-", "block_mask"], [211, 2, 1, "", "get_pruner"], [212, 0, 0, "-", "mha"], [211, 2, 1, "", "parse_valid_pruner_types"], [213, 0, 0, "-", "pattern_lock"], [214, 0, 0, "-", "progressive"], [215, 0, 0, "-", "retrain_free"], [216, 0, 0, "-", "sparse_gpt"]], "neural_compressor.compression.pruner.pruners.base": [[208, 1, 1, "", "BasePruner"], [208, 1, 1, "", "KerasBasePruner"], [208, 1, 1, "", "PytorchBasePruner"], [208, 2, 1, "", "register_pruner"]], "neural_compressor.compression.pruner.pruners.base.BasePruner": [[208, 4, 1, "", "config"], [208, 4, 1, "", "current_sparsity_ratio"], [208, 4, 1, "", "end_step"], [208, 4, 1, "", "global_step"], [208, 4, 1, "", "masks"], [208, 4, 1, "", "max_sparsity_ratio_per_op"], [208, 4, 1, "", "modules"], [208, 4, 1, "", "pattern"], [208, 4, 1, "", "pruning_frequency"], [208, 4, 1, "", "scheduler"], [208, 4, 1, "", "scores"], [208, 4, 1, "", "start_step"], [208, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.base.KerasBasePruner": [[208, 4, 1, "", "config"], [208, 4, 1, "", "current_sparsity_ratio"], [208, 4, 1, "", "end_step"], [208, 4, 1, "", "global_step"], [208, 4, 1, "", "masks"], [208, 4, 1, "", "max_sparsity_ratio_per_op"], [208, 4, 1, "", "modules"], [208, 4, 1, "", "pattern"], [208, 4, 1, "", "pruning_frequency"], [208, 4, 1, "", "scheduler"], [208, 4, 1, "", "scores"], [208, 4, 1, "", "start_step"], [208, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner": [[208, 4, 1, "", "config"], [208, 4, 1, "", "current_sparsity_ratio"], [208, 4, 1, "", "end_step"], [208, 4, 1, "", "global_step"], [208, 4, 1, "", "masks"], [208, 4, 1, "", "max_sparsity_ratio_per_op"], [208, 4, 1, "", "modules"], [208, 4, 1, "", "pattern"], [208, 4, 1, "", "pruning_frequency"], [208, 4, 1, "", "scheduler"], [208, 4, 1, "", "scores"], [208, 4, 1, "", "start_step"], [208, 4, 1, "", "target_sparsity_ratio"]], "neural_compressor.compression.pruner.pruners.basic": [[209, 1, 1, "", "KerasBasicPruner"], [209, 1, 1, "", "PytorchBasicPruner"]], "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner": [[209, 4, 1, "", "criterion"], [209, 4, 1, "", "pattern"], [209, 4, 1, "", "reg"], [209, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner": [[209, 4, 1, "", "criterion"], [209, 4, 1, "", "pattern"], [209, 4, 1, "", "reg"], [209, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.block_mask": [[210, 1, 1, "", "PytorchBlockMaskPruner"]], "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner": [[210, 4, 1, "", "criterion"], [210, 4, 1, "", "pattern"], [210, 4, 1, "", "reg"], [210, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.mha": [[212, 1, 1, "", "PythonMultiheadAttentionPruner"]], "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner": [[212, 4, 1, "", "head_masks"], [212, 4, 1, "", "linear_layers"], [212, 4, 1, "", "mha_compressions"], [212, 4, 1, "", "mha_scores"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[213, 1, 1, "", "PytorchPatternLockPruner"]], "neural_compressor.compression.pruner.pruners.progressive": [[214, 1, 1, "", "PytorchProgressivePruner"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[215, 1, 1, "", "PytorchRetrainFreePruner"]], "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner": [[215, 4, 1, "", "criterion"], [215, 4, 1, "", "pattern"], [215, 4, 1, "", "reg"], [215, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[216, 1, 1, "", "SparseGPTPruner"]], "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner": [[216, 4, 1, "", "criterion"], [216, 4, 1, "", "pattern"], [216, 4, 1, "", "reg"], [216, 4, 1, "", "scheduler"]], "neural_compressor.compression.pruner.pruning": [[217, 1, 1, "", "BasePruning"], [217, 1, 1, "", "BasicPruning"], [217, 1, 1, "", "RetrainFreePruning"], [217, 1, 1, "", "SparseGPTPruning"], [217, 2, 1, "", "register_pruning"]], "neural_compressor.compression.pruner.pruning.BasePruning": [[217, 4, 1, "", "config_file_path"], [217, 4, 1, "", "model"], [217, 4, 1, "", "pruner_info"], [217, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.pruning.BasicPruning": [[217, 4, 1, "", "config_file_path"], [217, 4, 1, "", "model"], [217, 4, 1, "", "pruner_info"], [217, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.pruning.RetrainFreePruning": [[217, 4, 1, "", "config_file_path"], [217, 4, 1, "", "model"], [217, 4, 1, "", "pruner_info"], [217, 4, 1, "", "pruners"]], "neural_compressor.compression.pruner.regs": [[218, 1, 1, "", "BaseReg"], [218, 1, 1, "", "GroupLasso"], [218, 2, 1, "", "get_reg"], [218, 2, 1, "", "get_reg_type"], [218, 2, 1, "", "register_reg"]], "neural_compressor.compression.pruner.regs.GroupLasso": [[218, 4, 1, "", "alpha"], [218, 4, 1, "", "reg_terms"]], "neural_compressor.compression.pruner.schedulers": [[219, 1, 1, "", "IterativeScheduler"], [219, 1, 1, "", "OneshotScheduler"], [219, 1, 1, "", "PruningScheduler"], [219, 2, 1, "", "get_scheduler"], [219, 2, 1, "", "register_scheduler"]], "neural_compressor.compression.pruner.schedulers.PruningScheduler": [[219, 4, 1, "", "config"]], "neural_compressor.compression.pruner.tf_criteria": [[220, 1, 1, "", "MagnitudeCriterion"], [220, 1, 1, "", "PruningCriterion"], [220, 2, 1, "", "get_tf_criterion"], [220, 2, 1, "", "register_criterion"]], "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion": [[220, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.tf_criteria.PruningCriterion": [[220, 4, 1, "", "scores"]], "neural_compressor.compression.pruner.utils": [[221, 2, 1, "", "check_config"], [221, 2, 1, "", "check_key_validity"], [221, 2, 1, "", "collect_layer_inputs"], [221, 2, 1, "", "generate_pruner_config"], [221, 2, 1, "", "get_layers"], [221, 2, 1, "", "get_sparsity_ratio"], [221, 2, 1, "", "get_sparsity_ratio_tf"], [221, 2, 1, "", "parse_last_linear"], [221, 2, 1, "", "parse_last_linear_tf"], [221, 2, 1, "", "parse_to_prune"], [221, 2, 1, "", "parse_to_prune_tf"], [221, 2, 1, "", "process_and_check_config"], [221, 2, 1, "", "process_config"], [221, 2, 1, "", "process_weight_config"], [221, 2, 1, "", "process_yaml_config"], [221, 2, 1, "", "reset_none_to_default"], [221, 2, 1, "", "update_params"]], "neural_compressor.compression.pruner.wanda": [[223, 0, 0, "-", "prune"], [224, 0, 0, "-", "utils"], [225, 0, 0, "-", "wrapper"]], "neural_compressor.compression.pruner.wanda.prune": [[223, 2, 1, "", "prune_wanda"]], "neural_compressor.compression.pruner.wanda.utils": [[224, 2, 1, "", "find_layers"]], "neural_compressor.compression.pruner.wanda.wrapper": [[225, 1, 1, "", "WrappedGPT"]], "neural_compressor.conf": [[226, 0, 0, "-", "config"], [227, 0, 0, "-", "dotdict"], [229, 0, 0, "-", "pythonic_config"]], "neural_compressor.conf.config": [[226, 1, 1, "", "Benchmark_Conf"], [226, 1, 1, "", "Conf"], [226, 1, 1, "", "Distillation_Conf"], [226, 1, 1, "", "Graph_Optimization_Conf"], [226, 1, 1, "", "MixedPrecision_Conf"], [226, 1, 1, "", "NASConfig"], [226, 1, 1, "", "PrunerV2"], [226, 1, 1, "", "Pruning_Conf"], [226, 1, 1, "", "Quantization_Conf"]], "neural_compressor.conf.dotdict": [[227, 1, 1, "", "DotDict"], [227, 2, 1, "", "deep_get"], [227, 2, 1, "", "deep_set"]], "neural_compressor.conf.pythonic_config": [[229, 1, 1, "", "AccuracyCriterion"], [229, 1, 1, "", "BenchmarkConfig"], [229, 1, 1, "", "DistillationConfig"], [229, 1, 1, "", "KnowledgeDistillationLossConfig"], [229, 1, 1, "", "Options"], [229, 1, 1, "", "QuantizationConfig"], [229, 1, 1, "", "WeightPruningConfig"]], "neural_compressor.config": [[230, 1, 1, "", "AccuracyCriterion"], [230, 1, 1, "", "BenchmarkConfig"], [230, 1, 1, "", "DistillationConfig"], [230, 1, 1, "", "DotDict"], [230, 1, 1, "", "ExportConfig"], [230, 1, 1, "", "HPOConfig"], [230, 1, 1, "", "IntermediateLayersKnowledgeDistillationLossConfig"], [230, 1, 1, "", "Keras"], [230, 1, 1, "", "KnowledgeDistillationLossConfig"], [230, 1, 1, "", "MXNet"], [230, 1, 1, "", "MixedPrecisionConfig"], [230, 1, 1, "", "NASConfig"], [230, 1, 1, "", "ONNX"], [230, 1, 1, "", "ONNXQlinear2QDQConfig"], [230, 1, 1, "", "Options"], [230, 1, 1, "", "PostTrainingQuantConfig"], [230, 1, 1, "", "PyTorch"], [230, 1, 1, "", "QuantizationAwareTrainingConfig"], [230, 1, 1, "", "SelfKnowledgeDistillationLossConfig"], [230, 1, 1, "", "TF2ONNXConfig"], [230, 1, 1, "", "TensorFlow"], [230, 1, 1, "", "Torch2ONNXConfig"], [230, 1, 1, "", "TuningCriterion"], [230, 1, 1, "", "WeightPruningConfig"]], "neural_compressor.contrib": [[232, 0, 0, "-", "strategy"]], "neural_compressor.contrib.strategy": [[233, 0, 0, "-", "sigopt"], [234, 0, 0, "-", "tpe"]], "neural_compressor.contrib.strategy.sigopt": [[233, 1, 1, "", "SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[234, 1, 1, "", "TpeTuneStrategy"]], "neural_compressor.data": [[239, 0, 0, "-", "dataloaders"], [251, 0, 0, "-", "datasets"], [255, 0, 0, "-", "filters"], [259, 0, 0, "-", "transforms"]], "neural_compressor.data.dataloaders": [[235, 0, 0, "-", "base_dataloader"], [236, 0, 0, "-", "dataloader"], [237, 0, 0, "-", "default_dataloader"], [238, 0, 0, "-", "fetcher"], [240, 0, 0, "-", "mxnet_dataloader"], [241, 0, 0, "-", "onnxrt_dataloader"], [242, 0, 0, "-", "pytorch_dataloader"], [243, 0, 0, "-", "sampler"], [244, 0, 0, "-", "tensorflow_dataloader"]], "neural_compressor.data.dataloaders.base_dataloader": [[235, 1, 1, "", "BaseDataLoader"]], "neural_compressor.data.dataloaders.dataloader": [[236, 1, 1, "", "DataLoader"], [236, 2, 1, "", "check_dataloader"]], "neural_compressor.data.dataloaders.default_dataloader": [[237, 1, 1, "", "DefaultDataLoader"], [237, 2, 1, "", "default_collate"]], "neural_compressor.data.dataloaders.fetcher": [[238, 1, 1, "", "Fetcher"], [238, 1, 1, "", "IndexFetcher"], [238, 1, 1, "", "IterableFetcher"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[240, 1, 1, "", "MXNetDataLoader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[241, 1, 1, "", "ONNXRTBertDataLoader"], [241, 1, 1, "", "ONNXRTDataLoader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[242, 1, 1, "", "PyTorchDataLoader"]], "neural_compressor.data.dataloaders.sampler": [[243, 1, 1, "", "BatchSampler"], [243, 1, 1, "", "IterableSampler"], [243, 1, 1, "", "Sampler"], [243, 1, 1, "", "SequentialSampler"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[244, 1, 1, "", "TFDataDataLoader"], [244, 1, 1, "", "TensorflowBertDataLoader"], [244, 1, 1, "", "TensorflowDataLoader"], [244, 1, 1, "", "TensorflowModelZooBertDataLoader"]], "neural_compressor.data.datasets": [[245, 0, 0, "-", "bert_dataset"], [246, 0, 0, "-", "coco_dataset"], [247, 0, 0, "-", "dataset"], [248, 0, 0, "-", "dummy_dataset"], [249, 0, 0, "-", "dummy_dataset_v2"], [250, 0, 0, "-", "imagenet_dataset"], [252, 0, 0, "-", "style_transfer_dataset"]], "neural_compressor.data.datasets.bert_dataset": [[245, 1, 1, "", "InputFeatures"], [245, 1, 1, "", "ONNXRTBertDataset"], [245, 1, 1, "", "ParseDecodeBert"], [245, 1, 1, "", "PytorchBertDataset"], [245, 1, 1, "", "TensorflowBertDataset"], [245, 1, 1, "", "TensorflowModelZooBertDataset"], [245, 2, 1, "", "convert_examples_to_features"], [245, 2, 1, "", "load_and_cache_examples"]], "neural_compressor.data.datasets.coco_dataset": [[246, 1, 1, "", "COCONpy"], [246, 1, 1, "", "COCORaw"], [246, 1, 1, "", "COCORecordDataset"], [246, 1, 1, "", "ParseDecodeCoco"]], "neural_compressor.data.datasets.dataset": [[247, 1, 1, "", "CIFAR10"], [247, 1, 1, "", "CIFAR100"], [247, 1, 1, "", "Dataset"], [247, 1, 1, "", "Datasets"], [247, 1, 1, "", "FashionMNIST"], [247, 1, 1, "", "ImageFolder"], [247, 1, 1, "", "IterableDataset"], [247, 1, 1, "", "MNIST"], [247, 1, 1, "", "MXNetCIFAR10"], [247, 1, 1, "", "MXNetCIFAR100"], [247, 1, 1, "", "MXNetDatasets"], [247, 1, 1, "", "MXNetFashionMNIST"], [247, 1, 1, "", "MXNetImageFolder"], [247, 1, 1, "", "MXNetMNIST"], [247, 1, 1, "", "ONNXRTITDatasets"], [247, 1, 1, "", "ONNXRTQLDatasets"], [247, 1, 1, "", "PyTorchDatasets"], [247, 1, 1, "", "PytorchCIFAR10"], [247, 1, 1, "", "PytorchCIFAR100"], [247, 1, 1, "", "PytorchFashionMNIST"], [247, 1, 1, "", "PytorchMNIST"], [247, 1, 1, "", "PytorchMxnetWrapDataset"], [247, 1, 1, "", "PytorchMxnetWrapFunction"], [247, 1, 1, "", "Tensorflow"], [247, 1, 1, "", "TensorflowCIFAR10"], [247, 1, 1, "", "TensorflowCIFAR100"], [247, 1, 1, "", "TensorflowDatasets"], [247, 1, 1, "", "TensorflowFashionMNIST"], [247, 1, 1, "", "TensorflowImageRecord"], [247, 1, 1, "", "TensorflowMNIST"], [247, 1, 1, "", "TensorflowTFRecordDataset"], [247, 1, 1, "", "TensorflowVOCRecord"], [247, 2, 1, "", "calculate_md5"], [247, 2, 1, "", "check_integrity"], [247, 2, 1, "", "dataset_registry"], [247, 2, 1, "", "download_url"], [247, 5, 1, "", "framework_datasets"], [247, 2, 1, "", "gen_bar_updater"]], "neural_compressor.data.datasets.dummy_dataset": [[248, 1, 1, "", "DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[249, 1, 1, "", "DummyDataset"], [249, 1, 1, "", "SparseDummyDataset"]], "neural_compressor.data.datasets.imagenet_dataset": [[250, 1, 1, "", "ImagenetRaw"], [250, 1, 1, "", "MXNetImagenetRaw"], [250, 1, 1, "", "ONNXRTImagenetDataset"], [250, 1, 1, "", "PytorchImagenetRaw"], [250, 1, 1, "", "TensorflowImagenetDataset"], [250, 1, 1, "", "TensorflowImagenetRaw"]], "neural_compressor.data.datasets.style_transfer_dataset": [[252, 1, 1, "", "StyleTransferDataset"]], "neural_compressor.data.filters": [[253, 0, 0, "-", "coco_filter"], [254, 0, 0, "-", "filter"]], "neural_compressor.data.filters.coco_filter": [[253, 1, 1, "", "LabelBalanceCOCORawFilter"], [253, 1, 1, "", "LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.filter": [[254, 1, 1, "", "FILTERS"], [254, 1, 1, "", "Filter"], [254, 1, 1, "", "MXNetFilters"], [254, 1, 1, "", "ONNXRTITFilters"], [254, 1, 1, "", "ONNXRTQLFilters"], [254, 1, 1, "", "PyTorchFilters"], [254, 1, 1, "", "TensorflowFilters"], [254, 2, 1, "", "filter_registry"]], "neural_compressor.data.transforms": [[257, 0, 0, "-", "coco_transform"], [258, 0, 0, "-", "imagenet_transform"], [260, 0, 0, "-", "postprocess"], [261, 0, 0, "-", "tokenization"], [262, 0, 0, "-", "transform"]], "neural_compressor.data.transforms.coco_transform": [[257, 1, 1, "", "ParseDecodeCocoTransform"]], "neural_compressor.data.transforms.imagenet_transform": [[258, 1, 1, "", "BilinearImagenetTransform"], [258, 1, 1, "", "LabelShift"], [258, 1, 1, "", "ONNXResizeCropImagenetTransform"], [258, 1, 1, "", "OnnxBilinearImagenetTransform"], [258, 1, 1, "", "ParseDecodeImagenet"], [258, 1, 1, "", "ParseDecodeImagenetTransform"], [258, 1, 1, "", "QuantizedInput"], [258, 1, 1, "", "ResizeWithAspectRatio"], [258, 1, 1, "", "TensorflowResizeCropImagenetTransform"], [258, 1, 1, "", "TensorflowShiftRescale"], [258, 1, 1, "", "TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.postprocess": [[260, 1, 1, "", "Postprocess"]], "neural_compressor.data.transforms.tokenization": [[261, 1, 1, "", "BasicTokenizer"], [261, 1, 1, "", "FullTokenizer"], [261, 1, 1, "", "WordpieceTokenizer"], [261, 2, 1, "", "convert_by_vocab"], [261, 2, 1, "", "convert_to_unicode"], [261, 2, 1, "", "load_vocab"], [261, 2, 1, "", "whitespace_tokenize"]], "neural_compressor.data.transforms.transform": [[262, 1, 1, "", "AlignImageChannelTransform"], [262, 1, 1, "", "BaseTransform"], [262, 1, 1, "", "CastONNXTransform"], [262, 1, 1, "", "CastPyTorchTransform"], [262, 1, 1, "", "CastTFTransform"], [262, 1, 1, "", "CenterCropTFTransform"], [262, 1, 1, "", "CenterCropTransform"], [262, 1, 1, "", "CollectTransform"], [262, 1, 1, "", "ComposeTransform"], [262, 1, 1, "", "CropResizeTFTransform"], [262, 1, 1, "", "CropResizeTransform"], [262, 1, 1, "", "CropToBoundingBox"], [262, 1, 1, "", "InputFeatures"], [262, 1, 1, "", "MXNetCropResizeTransform"], [262, 1, 1, "", "MXNetCropToBoundingBox"], [262, 1, 1, "", "MXNetNormalizeTransform"], [262, 1, 1, "", "MXNetTransforms"], [262, 1, 1, "", "MXNetTranspose"], [262, 1, 1, "", "NormalizeTFTransform"], [262, 1, 1, "", "NormalizeTransform"], [262, 1, 1, "", "ONNXRTCropToBoundingBox"], [262, 1, 1, "", "ONNXRTITTransforms"], [262, 1, 1, "", "ONNXRTQLTransforms"], [262, 1, 1, "", "PaddedCenterCropTransform"], [262, 1, 1, "", "ParseDecodeVocTransform"], [262, 1, 1, "", "PyTorchAlignImageChannel"], [262, 1, 1, "", "PyTorchCropResizeTransform"], [262, 1, 1, "", "PyTorchNormalizeTransform"], [262, 1, 1, "", "PyTorchTransforms"], [262, 1, 1, "", "PyTorchTranspose"], [262, 1, 1, "", "PytorchMxnetTransform"], [262, 1, 1, "", "PytorchMxnetWrapFunction"], [262, 1, 1, "", "RandomCropTFTransform"], [262, 1, 1, "", "RandomCropTransform"], [262, 1, 1, "", "RandomHorizontalFlip"], [262, 1, 1, "", "RandomResizedCropMXNetTransform"], [262, 1, 1, "", "RandomResizedCropPytorchTransform"], [262, 1, 1, "", "RandomResizedCropTFTransform"], [262, 1, 1, "", "RandomResizedCropTransform"], [262, 1, 1, "", "RandomVerticalFlip"], [262, 1, 1, "", "RescaleKerasPretrainTransform"], [262, 1, 1, "", "RescaleTFTransform"], [262, 1, 1, "", "RescaleTransform"], [262, 1, 1, "", "ResizeMXNetTransform"], [262, 1, 1, "", "ResizePytorchTransform"], [262, 1, 1, "", "ResizeTFTransform"], [262, 1, 1, "", "ResizeTransform"], [262, 1, 1, "", "ResizeWithRatio"], [262, 1, 1, "", "SquadExample"], [262, 1, 1, "", "TFModelZooCollectTransform"], [262, 1, 1, "", "TFSquadV1ModelZooPostTransform"], [262, 1, 1, "", "TFSquadV1PostTransform"], [262, 1, 1, "", "TRANSFORMS"], [262, 1, 1, "", "TensorflowCropToBoundingBox"], [262, 1, 1, "", "TensorflowRandomHorizontalFlip"], [262, 1, 1, "", "TensorflowRandomVerticalFlip"], [262, 1, 1, "", "TensorflowResizeWithRatio"], [262, 1, 1, "", "TensorflowTransform"], [262, 1, 1, "", "TensorflowTransforms"], [262, 1, 1, "", "TensorflowTranspose"], [262, 1, 1, "", "TensorflowWrapFunction"], [262, 1, 1, "", "ToArray"], [262, 1, 1, "", "ToNDArrayTransform"], [262, 1, 1, "", "Transforms"], [262, 1, 1, "", "Transpose"], [262, 2, 1, "", "convert_examples_to_features"], [262, 2, 1, "", "get_final_text"], [262, 2, 1, "", "get_torchvision_map"], [262, 2, 1, "", "read_squad_examples"], [262, 2, 1, "", "transform_registry"]], "neural_compressor.experimental": [[263, 0, 0, "-", "benchmark"], [266, 0, 0, "-", "common"], [272, 0, 0, "-", "component"], [273, 0, 0, "-", "compression"], [274, 0, 0, "-", "contrib"], [299, 0, 0, "-", "data"], [304, 0, 0, "-", "distillation"], [305, 0, 0, "-", "export"], [309, 0, 0, "-", "graph_optimization"], [317, 0, 0, "-", "metric"], [319, 0, 0, "-", "mixed_precision"], [320, 0, 0, "-", "model_conversion"], [323, 0, 0, "-", "nas"], [329, 0, 0, "-", "pruner_legacy"], [333, 0, 0, "-", "pruning"], [334, 0, 0, "-", "pruning_recipes"], [338, 0, 0, "-", "pruning_v2"], [339, 0, 0, "-", "pytorch_pruner"], [346, 0, 0, "-", "quantization"], [347, 0, 0, "-", "scheduler"], [352, 0, 0, "-", "strategy"]], "neural_compressor.experimental.benchmark": [[263, 1, 1, "", "Benchmark"], [263, 2, 1, "", "get_architecture"], [263, 2, 1, "", "get_bounded_threads"], [263, 2, 1, "", "get_core_ids"], [263, 2, 1, "", "get_physical_ids"], [263, 2, 1, "", "get_threads"], [263, 2, 1, "", "get_threads_per_core"], [263, 2, 1, "", "set_all_env_var"], [263, 2, 1, "", "set_env_var"]], "neural_compressor.experimental.common": [[264, 0, 0, "-", "criterion"], [265, 0, 0, "-", "dataloader"], [267, 0, 0, "-", "metric"], [268, 0, 0, "-", "model"], [269, 0, 0, "-", "optimizer"], [270, 0, 0, "-", "postprocess"], [271, 0, 0, "-", "torch_utils"]], "neural_compressor.experimental.common.criterion": [[264, 1, 1, "", "Criterions"], [264, 1, 1, "", "IntermediateLayersKnowledgeDistillationLoss"], [264, 1, 1, "", "KnowledgeDistillationFramework"], [264, 1, 1, "", "KnowledgeDistillationLoss"], [264, 1, 1, "", "PyTorchCriterions"], [264, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLoss"], [264, 1, 1, "", "PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"], [264, 1, 1, "", "PyTorchKnowledgeDistillationLoss"], [264, 1, 1, "", "PyTorchKnowledgeDistillationLossWrapper"], [264, 1, 1, "", "SelfKnowledgeDistillationLoss"], [264, 1, 1, "", "TensorflowCriterions"], [264, 1, 1, "", "TensorflowKnowledgeDistillationLossExternal"], [264, 2, 1, "", "criterion_registry"]], "neural_compressor.experimental.common.dataloader": [[265, 1, 1, "", "DataLoader"]], "neural_compressor.experimental.common.metric": [[267, 1, 1, "", "Metric"]], "neural_compressor.experimental.common.model": [[268, 1, 1, "", "Model"], [268, 2, 1, "", "set_backend"]], "neural_compressor.experimental.common.optimizer": [[269, 1, 1, "", "Optimizers"], [269, 1, 1, "", "PyTorchOptimizers"], [269, 1, 1, "", "PyTorchSGD"], [269, 1, 1, "", "TensorFlowAdamW"], [269, 1, 1, "", "TensorFlowSGD"], [269, 1, 1, "", "TensorflowOptimizers"], [269, 2, 1, "", "optimizer_registry"]], "neural_compressor.experimental.common.postprocess": [[270, 1, 1, "", "Postprocess"]], "neural_compressor.experimental.common.torch_utils": [[271, 2, 1, "", "get_activation"], [271, 2, 1, "", "record_output"]], "neural_compressor.experimental.component": [[272, 1, 1, "", "Component"]], "neural_compressor.experimental.contrib": [[275, 0, 0, "-", "strategy"]], "neural_compressor.experimental.contrib.strategy": [[276, 0, 0, "-", "sigopt"], [277, 0, 0, "-", "tpe"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[276, 1, 1, "", "SigOptTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.tpe": [[277, 1, 1, "", "TpeTuneStrategy"]], "neural_compressor.experimental.data": [[282, 0, 0, "-", "dataloaders"], [294, 0, 0, "-", "datasets"], [298, 0, 0, "-", "filters"], [301, 0, 0, "-", "transforms"]], "neural_compressor.experimental.data.dataloaders": [[278, 0, 0, "-", "base_dataloader"], [279, 0, 0, "-", "dataloader"], [280, 0, 0, "-", "default_dataloader"], [281, 0, 0, "-", "fetcher"], [283, 0, 0, "-", "mxnet_dataloader"], [284, 0, 0, "-", "onnxrt_dataloader"], [285, 0, 0, "-", "pytorch_dataloader"], [286, 0, 0, "-", "sampler"], [287, 0, 0, "-", "tensorflow_dataloader"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[278, 1, 1, "", "BaseDataLoader"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[280, 1, 1, "", "DefaultDataLoader"], [280, 2, 1, "", "default_collate"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[281, 1, 1, "", "Fetcher"], [281, 1, 1, "", "IndexFetcher"], [281, 1, 1, "", "IterableFetcher"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[283, 1, 1, "", "MXNetDataLoader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[284, 1, 1, "", "ONNXRTBertDataLoader"], [284, 1, 1, "", "ONNXRTDataLoader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[285, 1, 1, "", "PyTorchDataLoader"]], "neural_compressor.experimental.data.dataloaders.sampler": [[286, 1, 1, "", "BatchSampler"], [286, 1, 1, "", "IterableSampler"], [286, 1, 1, "", "Sampler"], [286, 1, 1, "", "SequentialSampler"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[287, 1, 1, "", "TFDataDataLoader"], [287, 1, 1, "", "TensorflowBertDataLoader"], [287, 1, 1, "", "TensorflowDataLoader"], [287, 1, 1, "", "TensorflowModelZooBertDataLoader"]], "neural_compressor.experimental.data.datasets": [[288, 0, 0, "-", "bert_dataset"], [289, 0, 0, "-", "coco_dataset"], [290, 0, 0, "-", "dataset"], [291, 0, 0, "-", "dummy_dataset"], [292, 0, 0, "-", "dummy_dataset_v2"], [293, 0, 0, "-", "imagenet_dataset"], [295, 0, 0, "-", "style_transfer_dataset"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[288, 1, 1, "", "InputFeatures"], [288, 1, 1, "", "ONNXRTBertDataset"], [288, 1, 1, "", "ParseDecodeBert"], [288, 1, 1, "", "PytorchBertDataset"], [288, 1, 1, "", "TensorflowBertDataset"], [288, 1, 1, "", "TensorflowModelZooBertDataset"], [288, 2, 1, "", "convert_examples_to_features"], [288, 2, 1, "", "load_and_cache_examples"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[289, 1, 1, "", "COCONpy"], [289, 1, 1, "", "COCORaw"], [289, 1, 1, "", "COCORecordDataset"], [289, 1, 1, "", "ParseDecodeCoco"]], "neural_compressor.experimental.data.datasets.dataset": [[290, 1, 1, "", "CIFAR10"], [290, 1, 1, "", "CIFAR100"], [290, 1, 1, "", "Dataset"], [290, 1, 1, "", "Datasets"], [290, 1, 1, "", "FashionMNIST"], [290, 1, 1, "", "ImageFolder"], [290, 1, 1, "", "IterableDataset"], [290, 1, 1, "", "MNIST"], [290, 1, 1, "", "MXNetCIFAR10"], [290, 1, 1, "", "MXNetCIFAR100"], [290, 1, 1, "", "MXNetDatasets"], [290, 1, 1, "", "MXNetFashionMNIST"], [290, 1, 1, "", "MXNetImageFolder"], [290, 1, 1, "", "MXNetMNIST"], [290, 1, 1, "", "ONNXRTITDatasets"], [290, 1, 1, "", "ONNXRTQLDatasets"], [290, 1, 1, "", "PyTorchDatasets"], [290, 1, 1, "", "PytorchCIFAR10"], [290, 1, 1, "", "PytorchCIFAR100"], [290, 1, 1, "", "PytorchFashionMNIST"], [290, 1, 1, "", "PytorchMNIST"], [290, 1, 1, "", "PytorchMxnetWrapDataset"], [290, 1, 1, "", "PytorchMxnetWrapFunction"], [290, 1, 1, "", "TensorflowCIFAR10"], [290, 1, 1, "", "TensorflowCIFAR100"], [290, 1, 1, "", "TensorflowDatasets"], [290, 1, 1, "", "TensorflowFashionMNIST"], [290, 1, 1, "", "TensorflowImageFolder"], [290, 1, 1, "", "TensorflowImageRecord"], [290, 1, 1, "", "TensorflowMNIST"], [290, 1, 1, "", "TensorflowTFRecordDataset"], [290, 1, 1, "", "TensorflowVOCRecord"], [290, 2, 1, "", "calculate_md5"], [290, 2, 1, "", "check_integrity"], [290, 2, 1, "", "dataset_registry"], [290, 2, 1, "", "download_url"], [290, 5, 1, "", "framework_datasets"], [290, 2, 1, "", "gen_bar_updater"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[291, 1, 1, "", "DummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[292, 1, 1, "", "DummyDataset"], [292, 1, 1, "", "SparseDummyDataset"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[293, 1, 1, "", "ImagenetRaw"], [293, 1, 1, "", "MXNetImagenetRaw"], [293, 1, 1, "", "ONNXRTImagenetDataset"], [293, 1, 1, "", "PytorchImagenetRaw"], [293, 1, 1, "", "TensorflowImagenetDataset"], [293, 1, 1, "", "TensorflowImagenetRaw"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[295, 1, 1, "", "StyleTransferDataset"]], "neural_compressor.experimental.data.filters": [[296, 0, 0, "-", "coco_filter"], [297, 0, 0, "-", "filter"]], "neural_compressor.experimental.data.filters.coco_filter": [[296, 1, 1, "", "LabelBalanceCOCORawFilter"], [296, 1, 1, "", "LabelBalanceCOCORecordFilter"]], "neural_compressor.experimental.data.filters.filter": [[297, 1, 1, "", "FILTERS"], [297, 1, 1, "", "Filter"], [297, 1, 1, "", "MXNetFilters"], [297, 1, 1, "", "ONNXRTITFilters"], [297, 1, 1, "", "ONNXRTQLFilters"], [297, 1, 1, "", "PyTorchFilters"], [297, 1, 1, "", "TensorflowFilters"], [297, 2, 1, "", "filter_registry"]], "neural_compressor.experimental.data.transforms": [[300, 0, 0, "-", "imagenet_transform"], [302, 0, 0, "-", "tokenization"], [303, 0, 0, "-", "transform"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[300, 1, 1, "", "BilinearImagenetTransform"], [300, 1, 1, "", "LabelShift"], [300, 1, 1, "", "ONNXResizeCropImagenetTransform"], [300, 1, 1, "", "OnnxBilinearImagenetTransform"], [300, 1, 1, "", "ParseDecodeImagenet"], [300, 1, 1, "", "ParseDecodeImagenetTransform"], [300, 1, 1, "", "QuantizedInput"], [300, 1, 1, "", "ResizeWithAspectRatio"], [300, 1, 1, "", "TensorflowResizeCropImagenetTransform"]], "neural_compressor.experimental.data.transforms.tokenization": [[302, 1, 1, "", "BasicTokenizer"], [302, 1, 1, "", "FullTokenizer"], [302, 1, 1, "", "WordpieceTokenizer"], [302, 2, 1, "", "convert_by_vocab"], [302, 2, 1, "", "convert_to_unicode"], [302, 2, 1, "", "load_vocab"], [302, 2, 1, "", "whitespace_tokenize"]], "neural_compressor.experimental.data.transforms.transform": [[303, 1, 1, "", "AlignImageChannelTransform"], [303, 1, 1, "", "BaseTransform"], [303, 1, 1, "", "CastONNXTransform"], [303, 1, 1, "", "CastPyTorchTransform"], [303, 1, 1, "", "CastTFTransform"], [303, 1, 1, "", "CenterCropTFTransform"], [303, 1, 1, "", "CenterCropTransform"], [303, 1, 1, "", "CollectTransform"], [303, 1, 1, "", "ComposeTransform"], [303, 1, 1, "", "CropResizeTFTransform"], [303, 1, 1, "", "CropResizeTransform"], [303, 1, 1, "", "CropToBoundingBox"], [303, 1, 1, "", "InputFeatures"], [303, 1, 1, "", "MXNetCropResizeTransform"], [303, 1, 1, "", "MXNetCropToBoundingBox"], [303, 1, 1, "", "MXNetNormalizeTransform"], [303, 1, 1, "", "MXNetTransforms"], [303, 1, 1, "", "MXNetTranspose"], [303, 1, 1, "", "NormalizeTFTransform"], [303, 1, 1, "", "NormalizeTransform"], [303, 1, 1, "", "ONNXRTCropToBoundingBox"], [303, 1, 1, "", "ONNXRTITTransforms"], [303, 1, 1, "", "ONNXRTQLTransforms"], [303, 1, 1, "", "PaddedCenterCropTransform"], [303, 1, 1, "", "ParseDecodeVocTransform"], [303, 1, 1, "", "PyTorchAlignImageChannel"], [303, 1, 1, "", "PyTorchCropResizeTransform"], [303, 1, 1, "", "PyTorchNormalizeTransform"], [303, 1, 1, "", "PyTorchTransforms"], [303, 1, 1, "", "PyTorchTranspose"], [303, 1, 1, "", "PytorchMxnetTransform"], [303, 1, 1, "", "PytorchMxnetWrapFunction"], [303, 1, 1, "", "RandomCropTFTransform"], [303, 1, 1, "", "RandomCropTransform"], [303, 1, 1, "", "RandomHorizontalFlip"], [303, 1, 1, "", "RandomResizedCropMXNetTransform"], [303, 1, 1, "", "RandomResizedCropPytorchTransform"], [303, 1, 1, "", "RandomResizedCropTFTransform"], [303, 1, 1, "", "RandomResizedCropTransform"], [303, 1, 1, "", "RandomVerticalFlip"], [303, 1, 1, "", "RescaleKerasPretrainTransform"], [303, 1, 1, "", "RescaleTFTransform"], [303, 1, 1, "", "RescaleTransform"], [303, 1, 1, "", "ResizeMXNetTransform"], [303, 1, 1, "", "ResizePytorchTransform"], [303, 1, 1, "", "ResizeTFTransform"], [303, 1, 1, "", "ResizeTransform"], [303, 1, 1, "", "ResizeWithRatio"], [303, 1, 1, "", "SquadExample"], [303, 1, 1, "", "TFModelZooCollectTransform"], [303, 1, 1, "", "TFSquadV1ModelZooPostTransform"], [303, 1, 1, "", "TFSquadV1PostTransform"], [303, 1, 1, "", "TRANSFORMS"], [303, 1, 1, "", "TensorflowCropToBoundingBox"], [303, 1, 1, "", "TensorflowRandomHorizontalFlip"], [303, 1, 1, "", "TensorflowRandomVerticalFlip"], [303, 1, 1, "", "TensorflowResizeWithRatio"], [303, 1, 1, "", "TensorflowTransform"], [303, 1, 1, "", "TensorflowTransforms"], [303, 1, 1, "", "TensorflowTranspose"], [303, 1, 1, "", "TensorflowWrapFunction"], [303, 1, 1, "", "ToArray"], [303, 1, 1, "", "ToNDArrayTransform"], [303, 1, 1, "", "Transforms"], [303, 1, 1, "", "Transpose"], [303, 2, 1, "", "convert_examples_to_features"], [303, 2, 1, "", "get_final_text"], [303, 2, 1, "", "get_torchvision_map"], [303, 2, 1, "", "read_squad_examples"], [303, 2, 1, "", "transform_registry"]], "neural_compressor.experimental.distillation": [[304, 1, 1, "", "Distillation"]], "neural_compressor.experimental.distillation.Distillation": [[304, 4, 1, "", "_epoch_ran"], [304, 4, 1, "", "best_model"], [304, 4, 1, "", "best_score"], [304, 4, 1, "", "eval_frequency"]], "neural_compressor.experimental.export": [[306, 0, 0, "-", "qlinear2qdq"], [307, 0, 0, "-", "tf2onnx"], [308, 0, 0, "-", "torch2onnx"]], "neural_compressor.experimental.export.qlinear2qdq": [[306, 2, 1, "", "check_model"], [306, 2, 1, "", "onnx_qlinear_to_qdq"]], "neural_compressor.experimental.export.tf2onnx": [[307, 2, 1, "", "tf_to_fp32_onnx"], [307, 2, 1, "", "tf_to_int8_onnx"]], "neural_compressor.experimental.export.torch2onnx": [[308, 2, 1, "", "dynamic_quant_export"], [308, 2, 1, "", "get_node_mapping"], [308, 2, 1, "", "get_quantizable_onnx_ops"], [308, 2, 1, "", "static_quant_export"], [308, 2, 1, "", "torch_to_fp32_onnx"], [308, 2, 1, "", "torch_to_int8_onnx"]], "neural_compressor.experimental.graph_optimization": [[309, 1, 1, "", "Graph_Optimization"]], "neural_compressor.experimental.metric": [[311, 0, 0, "-", "bleu"], [312, 0, 0, "-", "bleu_util"], [313, 0, 0, "-", "coco_label_map"], [314, 0, 0, "-", "coco_tools"], [315, 0, 0, "-", "evaluate_squad"], [316, 0, 0, "-", "f1"], [318, 0, 0, "-", "metric"]], "neural_compressor.experimental.metric.bleu": [[311, 1, 1, "", "BLEU"], [311, 1, 1, "", "UnicodeRegex"], [311, 2, 1, "", "bleu_tokenize"]], "neural_compressor.experimental.metric.bleu.BLEU": [[311, 4, 1, "", "labels"], [311, 4, 1, "", "predictions"]], "neural_compressor.experimental.metric.bleu.UnicodeRegex": [[311, 4, 1, "", "nondigit_punct_re"], [311, 4, 1, "", "punct_nondigit_re"], [311, 4, 1, "", "symbol_re"]], "neural_compressor.experimental.metric.bleu_util": [[312, 2, 1, "", "compute_bleu"]], "neural_compressor.experimental.metric.coco_tools": [[314, 1, 1, "", "COCOEvalWrapper"], [314, 1, 1, "", "COCOWrapper"], [314, 2, 1, "", "ExportSingleImageDetectionBoxesToCoco"], [314, 2, 1, "", "ExportSingleImageDetectionMasksToCoco"], [314, 2, 1, "", "ExportSingleImageGroundtruthToCoco"]], "neural_compressor.experimental.metric.coco_tools.COCOWrapper": [[314, 4, 1, "", "dataset"], [314, 4, 1, "", "detection_type"]], "neural_compressor.experimental.metric.evaluate_squad": [[315, 2, 1, "", "evaluate"], [315, 2, 1, "", "exact_match_score"], [315, 2, 1, "", "f1_score"], [315, 2, 1, "", "metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.f1": [[316, 2, 1, "", "evaluate"], [316, 2, 1, "", "f1_score"], [316, 2, 1, "", "metric_max_over_ground_truths"], [316, 2, 1, "", "normalize_answer"]], "neural_compressor.experimental.metric.metric": [[318, 1, 1, "", "Accuracy"], [318, 1, 1, "", "BaseMetric"], [318, 1, 1, "", "COCOmAPv2"], [318, 1, 1, "", "F1"], [318, 1, 1, "", "GeneralTopK"], [318, 1, 1, "", "Loss"], [318, 1, 1, "", "MAE"], [318, 1, 1, "", "METRICS"], [318, 1, 1, "", "MSE"], [318, 1, 1, "", "MXNetMetrics"], [318, 1, 1, "", "ONNXRTGLUE"], [318, 1, 1, "", "ONNXRTITMetrics"], [318, 1, 1, "", "ONNXRTQLMetrics"], [318, 1, 1, "", "PyTorchLoss"], [318, 1, 1, "", "PyTorchMetrics"], [318, 1, 1, "", "RMSE"], [318, 1, 1, "", "ROC"], [318, 1, 1, "", "SquadF1"], [318, 1, 1, "", "TensorflowCOCOMAP"], [318, 1, 1, "", "TensorflowMAP"], [318, 1, 1, "", "TensorflowMetrics"], [318, 1, 1, "", "TensorflowTopK"], [318, 1, 1, "", "TensorflowVOCMAP"], [318, 1, 1, "", "WrapMXNetMetric"], [318, 1, 1, "", "WrapONNXRTMetric"], [318, 1, 1, "", "WrapPyTorchMetric"], [318, 1, 1, "", "mIOU"], [318, 2, 1, "", "metric_registry"]], "neural_compressor.experimental.metric.metric.Accuracy": [[318, 4, 1, "", "label_list"], [318, 4, 1, "", "pred_list"], [318, 4, 1, "", "sample"]], "neural_compressor.experimental.metric.metric.GeneralTopK": [[318, 4, 1, "", "k"], [318, 4, 1, "", "num_correct"], [318, 4, 1, "", "num_sample"]], "neural_compressor.experimental.metric.metric.Loss": [[318, 4, 1, "", "sample"], [318, 4, 1, "", "sum"]], "neural_compressor.experimental.metric.metric.MAE": [[318, 4, 1, "", "compare_label"], [318, 4, 1, "", "label_list"], [318, 4, 1, "", "pred_list"]], "neural_compressor.experimental.metric.metric.METRICS": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.MSE": [[318, 4, 1, "", "compare_label"], [318, 4, 1, "", "label_list"], [318, 4, 1, "", "pred_list"]], "neural_compressor.experimental.metric.metric.MXNetMetrics": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.ONNXRTITMetrics": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.PyTorchMetrics": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.RMSE": [[318, 4, 1, "", "mse"]], "neural_compressor.experimental.metric.metric.TensorflowMetrics": [[318, 4, 1, "", "metrics"]], "neural_compressor.experimental.metric.metric.TensorflowTopK": [[318, 4, 1, "", "k"], [318, 4, 1, "", "num_correct"], [318, 4, 1, "", "num_sample"]], "neural_compressor.experimental.mixed_precision": [[319, 1, 1, "", "MixedPrecision"]], "neural_compressor.experimental.model_conversion": [[320, 1, 1, "", "ModelConversion"]], "neural_compressor.experimental.nas": [[321, 0, 0, "-", "basic_nas"], [322, 0, 0, "-", "dynas"], [324, 0, 0, "-", "nas"], [325, 0, 0, "-", "nas_utils"], [326, 0, 0, "-", "search_algorithms"]], "neural_compressor.experimental.nas.basic_nas": [[321, 1, 1, "", "BasicNAS"]], "neural_compressor.experimental.nas.dynas": [[322, 1, 1, "", "DyNAS"]], "neural_compressor.experimental.nas.nas": [[324, 1, 1, "", "NAS"], [324, 1, 1, "", "NASBase"]], "neural_compressor.experimental.nas.nas_utils": [[325, 2, 1, "", "create_search_space_pool"], [325, 2, 1, "", "find_pareto_front"], [325, 2, 1, "", "nas_registry"]], "neural_compressor.experimental.nas.search_algorithms": [[326, 1, 1, "", "BayesianOptimizationSearcher"], [326, 1, 1, "", "GridSearcher"], [326, 1, 1, "", "RandomSearcher"], [326, 1, 1, "", "Searcher"]], "neural_compressor.experimental.pruner_legacy": [[327, 0, 0, "-", "gradient_sensitivity"], [328, 0, 0, "-", "group_lasso"], [330, 0, 0, "-", "magnitude"], [331, 0, 0, "-", "pattern_lock"], [332, 0, 0, "-", "pruner"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[327, 1, 1, "", "GradientSensitivityPruner"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[328, 1, 1, "", "GroupLassoPruner"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[330, 1, 1, "", "BasicMagnitudePruner"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[331, 1, 1, "", "PatternLockPruner"]], "neural_compressor.experimental.pruner_legacy.pruner": [[332, 1, 1, "", "Pruner"], [332, 2, 1, "", "pruner_registry"]], "neural_compressor.experimental.pruning": [[333, 1, 1, "", "Pruning"], [333, 1, 1, "", "TfPruningCallback"]], "neural_compressor.experimental.pruning.Pruning": [[333, 4, 1, "", "conf"], [333, 4, 1, "", "pruners"]], "neural_compressor.experimental.pruning_recipes": [[335, 0, 0, "-", "patterns"]], "neural_compressor.experimental.pruning_recipes.patterns": [[336, 0, 0, "-", "pattern"], [337, 0, 0, "-", "tile_pattern"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[336, 1, 1, "", "PATTERNS"], [336, 1, 1, "", "PatternBase"], [336, 2, 1, "", "pattern_registry"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS": [[336, 4, 1, "", "patterns"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[337, 1, 1, "", "TilePatternBase"], [337, 1, 1, "", "TilePattern_1x1"], [337, 1, 1, "", "TilePattern_1x16"], [337, 1, 1, "", "TilePattern_1x2"], [337, 1, 1, "", "TilePattern_2x2"], [337, 1, 1, "", "TilePattern_4x1"]], "neural_compressor.experimental.pruning_v2": [[338, 1, 1, "", "Pruning"], [338, 1, 1, "", "TfPruningCallback"]], "neural_compressor.experimental.pruning_v2.Pruning": [[338, 4, 1, "", "conf"], [338, 4, 1, "", "pruners"]], "neural_compressor.experimental.pytorch_pruner": [[340, 0, 0, "-", "logger"], [341, 0, 0, "-", "patterns"], [342, 0, 0, "-", "prune_utils"], [343, 0, 0, "-", "pruner"], [344, 0, 0, "-", "pruning"], [345, 0, 0, "-", "scheduler"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[341, 1, 1, "", "Pattern"], [341, 1, 1, "", "PatternNInM"], [341, 1, 1, "", "PatternNxM"], [341, 2, 1, "", "get_pattern"], [341, 2, 1, "", "register_pattern"]], "neural_compressor.experimental.pytorch_pruner.patterns.Pattern": [[341, 4, 1, "", "is_global"], [341, 4, 1, "", "pattern"]], "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM": [[341, 4, 1, "", "M"], [341, 4, 1, "", "N"]], "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM": [[341, 4, 1, "", "block_size"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[342, 2, 1, "", "check_config"], [342, 2, 1, "", "parse_not_to_prune"], [342, 2, 1, "", "parse_to_prune"], [342, 2, 1, "", "process_and_check_config"], [342, 2, 1, "", "process_config"], [342, 2, 1, "", "reset_non_value_to_default"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[343, 1, 1, "", "MagnitudePruner"], [343, 1, 1, "", "PatternLockPruner"], [343, 1, 1, "", "Pruner"], [343, 1, 1, "", "SnipMomentumPruner"], [343, 1, 1, "", "SnipPruner"], [343, 2, 1, "", "get_pruner"], [343, 2, 1, "", "register_pruners"]], "neural_compressor.experimental.pytorch_pruner.pruner.Pruner": [[343, 4, 1, "", "config"], [343, 4, 1, "", "current_sparsity_ratio"], [343, 4, 1, "", "end_step"], [343, 4, 1, "", "global_step"], [343, 4, 1, "", "masks"], [343, 4, 1, "", "max_sparsity_ratio_per_layer"], [343, 4, 1, "", "modules"], [343, 4, 1, "", "pattern"], [343, 4, 1, "", "scheduler"], [343, 4, 1, "", "scores"], [343, 4, 1, "", "start_step"], [343, 4, 1, "", "target_sparsity_ratio"], [343, 4, 1, "", "update_frequency_on_step"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[344, 1, 1, "", "Pruning"]], "neural_compressor.experimental.pytorch_pruner.pruning.Pruning": [[344, 4, 1, "", "config_file_path"], [344, 4, 1, "", "model"], [344, 4, 1, "", "pruner_info"], [344, 4, 1, "", "pruners"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[345, 1, 1, "", "IterativeScheduler"], [345, 1, 1, "", "OneshotScheduler"], [345, 1, 1, "", "Scheduler"], [345, 2, 1, "", "get_scheduler"], [345, 2, 1, "", "register_scheduler"]], "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler": [[345, 4, 1, "", "config"]], "neural_compressor.experimental.quantization": [[346, 1, 1, "", "Quantization"]], "neural_compressor.experimental.scheduler": [[347, 1, 1, "", "Scheduler"]], "neural_compressor.experimental.strategy": [[348, 0, 0, "-", "auto_mixed_precision"], [349, 0, 0, "-", "basic"], [350, 0, 0, "-", "bayesian"], [351, 0, 0, "-", "exhaustive"], [353, 0, 0, "-", "mse"], [354, 0, 0, "-", "mse_v2"], [355, 0, 0, "-", "random"], [356, 0, 0, "-", "strategy"], [358, 0, 0, "-", "utils"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[348, 1, 1, "", "AutoMixedPrecisionTuneStrategy"]], "neural_compressor.experimental.strategy.basic": [[349, 1, 1, "", "BasicTuneStrategy"]], "neural_compressor.experimental.strategy.bayesian": [[350, 1, 1, "", "BayesianOptimization"], [350, 1, 1, "", "BayesianTuneStrategy"], [350, 1, 1, "", "TargetSpace"], [350, 2, 1, "", "acq_max"]], "neural_compressor.experimental.strategy.exhaustive": [[351, 1, 1, "", "ExhaustiveTuneStrategy"]], "neural_compressor.experimental.strategy.mse": [[353, 1, 1, "", "MSETuneStrategy"]], "neural_compressor.experimental.strategy.mse_v2": [[354, 1, 1, "", "MSE_V2TuneStrategy"]], "neural_compressor.experimental.strategy.random": [[355, 1, 1, "", "RandomTuneStrategy"]], "neural_compressor.experimental.strategy.strategy": [[356, 1, 1, "", "TuneStrategy"], [356, 2, 1, "", "strategy_registry"]], "neural_compressor.experimental.strategy.utils": [[357, 0, 0, "-", "constant"], [359, 0, 0, "-", "tuning_sampler"], [360, 0, 0, "-", "tuning_space"], [361, 0, 0, "-", "tuning_structs"], [362, 0, 0, "-", "utility"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[359, 1, 1, "", "FallbackTuningSampler"], [359, 1, 1, "", "ModelWiseTuningSampler"], [359, 1, 1, "", "OpTypeWiseTuningSampler"], [359, 1, 1, "", "OpWiseTuningSampler"], [359, 1, 1, "", "SmoothQuantSampler"], [359, 1, 1, "", "TuningOrder"], [359, 1, 1, "", "TuningSampler"], [359, 1, 1, "", "TuningSamplerRegistry"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[360, 1, 1, "", "TuningItem"], [360, 1, 1, "", "TuningSpace"], [360, 2, 1, "", "initial_tuning_cfg_with_quant_mode"], [360, 2, 1, "", "pattern_to_internal"], [360, 2, 1, "", "pattern_to_path"], [360, 2, 1, "", "quant_mode_from_pattern"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[361, 1, 1, "", "OpTuningConfig"]], "neural_compressor.experimental.strategy.utils.utility": [[362, 1, 1, "", "OrderedDefaultDict"], [362, 2, 1, "", "extract_data_type"], [362, 2, 1, "", "get_adaptor_name"], [362, 2, 1, "", "reverted_data_type"]], "neural_compressor.metric": [[364, 0, 0, "-", "bleu"], [365, 0, 0, "-", "bleu_util"], [366, 0, 0, "-", "coco_label_map"], [367, 0, 0, "-", "coco_tools"], [368, 0, 0, "-", "evaluate_squad"], [369, 0, 0, "-", "f1"], [371, 0, 0, "-", "metric"]], "neural_compressor.metric.bleu": [[364, 1, 1, "", "BLEU"], [364, 1, 1, "", "UnicodeRegex"], [364, 2, 1, "", "bleu_tokenize"]], "neural_compressor.metric.bleu.BLEU": [[364, 4, 1, "", "labels"], [364, 4, 1, "", "predictions"]], "neural_compressor.metric.bleu.UnicodeRegex": [[364, 4, 1, "", "nondigit_punct_re"], [364, 4, 1, "", "punct_nondigit_re"], [364, 4, 1, "", "symbol_re"]], "neural_compressor.metric.bleu_util": [[365, 2, 1, "", "compute_bleu"]], "neural_compressor.metric.coco_tools": [[367, 1, 1, "", "COCOEvalWrapper"], [367, 1, 1, "", "COCOWrapper"], [367, 2, 1, "", "ExportSingleImageDetectionBoxesToCoco"], [367, 2, 1, "", "ExportSingleImageDetectionMasksToCoco"], [367, 2, 1, "", "ExportSingleImageGroundtruthToCoco"]], "neural_compressor.metric.coco_tools.COCOWrapper": [[367, 4, 1, "", "dataset"], [367, 4, 1, "", "detection_type"]], "neural_compressor.metric.evaluate_squad": [[368, 2, 1, "", "evaluate"], [368, 2, 1, "", "exact_match_score"], [368, 2, 1, "", "f1_score"], [368, 2, 1, "", "metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[369, 2, 1, "", "evaluate"], [369, 2, 1, "", "f1_score"], [369, 2, 1, "", "metric_max_over_ground_truths"], [369, 2, 1, "", "normalize_answer"]], "neural_compressor.metric.metric": [[371, 1, 1, "", "Accuracy"], [371, 1, 1, "", "BaseMetric"], [371, 1, 1, "", "COCOmAPv2"], [371, 1, 1, "", "F1"], [371, 1, 1, "", "GeneralTopK"], [371, 1, 1, "", "Loss"], [371, 1, 1, "", "MAE"], [371, 1, 1, "", "METRICS"], [371, 1, 1, "", "MSE"], [371, 1, 1, "", "MXNetMetrics"], [371, 1, 1, "", "Metric"], [371, 1, 1, "", "ONNXRTGLUE"], [371, 1, 1, "", "ONNXRTITMetrics"], [371, 1, 1, "", "ONNXRTQLMetrics"], [371, 1, 1, "", "PyTorchLoss"], [371, 1, 1, "", "PyTorchMetrics"], [371, 1, 1, "", "RMSE"], [371, 1, 1, "", "ROC"], [371, 1, 1, "", "SquadF1"], [371, 1, 1, "", "TensorflowCOCOMAP"], [371, 1, 1, "", "TensorflowMAP"], [371, 1, 1, "", "TensorflowMetrics"], [371, 1, 1, "", "TensorflowTopK"], [371, 1, 1, "", "TensorflowVOCMAP"], [371, 1, 1, "", "WrapMXNetMetric"], [371, 1, 1, "", "WrapONNXRTMetric"], [371, 1, 1, "", "WrapPyTorchMetric"], [371, 1, 1, "", "mIOU"], [371, 2, 1, "", "metric_registry"], [371, 2, 1, "", "register_customer_metric"]], "neural_compressor.metric.metric.Accuracy": [[371, 4, 1, "", "label_list"], [371, 4, 1, "", "pred_list"], [371, 4, 1, "", "sample"]], "neural_compressor.metric.metric.GeneralTopK": [[371, 4, 1, "", "k"], [371, 4, 1, "", "num_correct"], [371, 4, 1, "", "num_sample"]], "neural_compressor.metric.metric.Loss": [[371, 4, 1, "", "sample"], [371, 4, 1, "", "sum"]], "neural_compressor.metric.metric.MAE": [[371, 4, 1, "", "compare_label"], [371, 4, 1, "", "label_list"], [371, 4, 1, "", "pred_list"]], "neural_compressor.metric.metric.METRICS": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.MSE": [[371, 4, 1, "", "compare_label"], [371, 4, 1, "", "label_list"], [371, 4, 1, "", "pred_list"]], "neural_compressor.metric.metric.MXNetMetrics": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTITMetrics": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.ONNXRTQLMetrics": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.PyTorchMetrics": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.RMSE": [[371, 4, 1, "", "mse"]], "neural_compressor.metric.metric.TensorflowMetrics": [[371, 4, 1, "", "metrics"]], "neural_compressor.metric.metric.TensorflowTopK": [[371, 4, 1, "", "k"], [371, 4, 1, "", "num_correct"], [371, 4, 1, "", "num_sample"]], "neural_compressor.mix_precision": [[372, 2, 1, "", "fit"]], "neural_compressor.model": [[373, 0, 0, "-", "base_model"], [375, 0, 0, "-", "keras_model"], [376, 0, 0, "-", "model"], [377, 0, 0, "-", "mxnet_model"], [378, 0, 0, "-", "nets_factory"], [379, 0, 0, "-", "onnx_model"], [380, 0, 0, "-", "tensorflow_model"], [381, 0, 0, "-", "torch_model"]], "neural_compressor.model.base_model": [[373, 1, 1, "", "BaseModel"]], "neural_compressor.model.keras_model": [[375, 1, 1, "", "KerasModel"]], "neural_compressor.model.model": [[376, 1, 1, "", "Model"], [376, 2, 1, "", "get_model_fwk_name"]], "neural_compressor.model.mxnet_model": [[377, 1, 1, "", "MXNetModel"]], "neural_compressor.model.nets_factory": [[378, 1, 1, "", "TFSlimNetsFactory"]], "neural_compressor.model.onnx_model": [[379, 1, 1, "", "ONNXModel"]], "neural_compressor.model.tensorflow_model": [[380, 1, 1, "", "TensorflowBaseModel"], [380, 1, 1, "", "TensorflowCheckpointModel"], [380, 1, 1, "", "TensorflowLLMModel"], [380, 1, 1, "", "TensorflowModel"], [380, 1, 1, "", "TensorflowQATModel"], [380, 1, 1, "", "TensorflowSavedModelModel"], [380, 2, 1, "", "checkpoint_session"], [380, 2, 1, "", "estimator_session"], [380, 2, 1, "", "frozen_pb_session"], [380, 2, 1, "", "get_model_type"], [380, 2, 1, "", "graph_def_session"], [380, 2, 1, "", "graph_session"], [380, 2, 1, "", "keras_session"], [380, 2, 1, "", "load_saved_model"], [380, 2, 1, "", "saved_model_session"], [380, 2, 1, "", "slim_session"], [380, 2, 1, "", "validate_and_inference_input_output"], [380, 2, 1, "", "validate_graph_node"]], "neural_compressor.model.torch_model": [[381, 1, 1, "", "IPEXModel"], [381, 1, 1, "", "PyTorchBaseModel"], [381, 1, 1, "", "PyTorchFXModel"], [381, 1, 1, "", "PyTorchModel"]], "neural_compressor.objective": [[382, 1, 1, "", "Accuracy"], [382, 1, 1, "", "Footprint"], [382, 1, 1, "", "ModelSize"], [382, 1, 1, "", "MultiObjective"], [382, 1, 1, "", "Objective"], [382, 1, 1, "", "Performance"], [382, 2, 1, "", "objective_custom_registry"], [382, 2, 1, "", "objective_registry"]], "neural_compressor.onnxrt": [[383, 0, 0, "-", "algorithms"], [397, 0, 0, "-", "quantization"], [399, 0, 0, "-", "utils"]], "neural_compressor.onnxrt.algorithms": [[386, 0, 0, "-", "smoother"], [389, 0, 0, "-", "weight_only"]], "neural_compressor.onnxrt.algorithms.smoother": [[384, 0, 0, "-", "calibrator"], [385, 0, 0, "-", "core"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[384, 1, 1, "", "Calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[385, 1, 1, "", "Smoother"]], "neural_compressor.onnxrt.algorithms.weight_only": [[387, 0, 0, "-", "awq"], [388, 0, 0, "-", "gptq"], [390, 0, 0, "-", "rtn"], [391, 0, 0, "-", "utility"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[387, 2, 1, "", "apply_awq_on_model"], [387, 2, 1, "", "awq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[388, 2, 1, "", "apply_gptq_on_model"], [388, 2, 1, "", "gptq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[390, 2, 1, "", "apply_rtn_on_model"], [390, 2, 1, "", "rtn_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[391, 2, 1, "", "make_matmul_weight_only_node"], [391, 2, 1, "", "pad_tensor"], [391, 2, 1, "", "prepare_inputs"], [391, 2, 1, "", "qdq_tensor"], [391, 2, 1, "", "quant_tensor"]], "neural_compressor.onnxrt.quantization": [[393, 0, 0, "-", "algorithm_entry"], [394, 0, 0, "-", "autotune"], [395, 0, 0, "-", "calibrate"], [396, 0, 0, "-", "config"], [398, 0, 0, "-", "quantize"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[393, 2, 1, "", "awq_quantize_entry"], [393, 2, 1, "", "gptq_quantize_entry"], [393, 2, 1, "", "rtn_quantize_entry"], [393, 2, 1, "", "smooth_quant_entry"]], "neural_compressor.onnxrt.quantization.autotune": [[394, 2, 1, "", "autotune"]], "neural_compressor.onnxrt.quantization.calibrate": [[395, 1, 1, "", "CalibrationDataReader"]], "neural_compressor.onnxrt.quantization.config": [[396, 1, 1, "", "AWQConfig"], [396, 1, 1, "", "GPTQConfig"], [396, 1, 1, "", "RTNConfig"], [396, 1, 1, "", "SmoohQuantConfig"], [396, 2, 1, "", "get_default_awq_config"], [396, 2, 1, "", "get_default_gptq_config"], [396, 2, 1, "", "get_default_rtn_config"], [396, 2, 1, "", "get_default_sq_config"]], "neural_compressor.onnxrt.utils": [[400, 0, 0, "-", "onnx_model"], [401, 0, 0, "-", "utility"]], "neural_compressor.onnxrt.utils.onnx_model": [[400, 1, 1, "", "ONNXModel"]], "neural_compressor.onnxrt.utils.utility": [[401, 2, 1, "", "find_by_name"], [401, 2, 1, "", "get_qrange_for_qType"], [401, 2, 1, "", "is_B_transposed"], [401, 2, 1, "", "quantize_data"], [401, 2, 1, "", "register_algo"], [401, 2, 1, "", "simple_progress_bar"]], "neural_compressor.profiling": [[404, 0, 0, "-", "parser"], [414, 0, 0, "-", "profiler"]], "neural_compressor.profiling.parser": [[403, 0, 0, "-", "factory"], [406, 0, 0, "-", "onnx_parser"], [408, 0, 0, "-", "parser"], [409, 0, 0, "-", "result"], [411, 0, 0, "-", "tensorflow_parser"]], "neural_compressor.profiling.parser.factory": [[403, 1, 1, "", "ParserFactory"]], "neural_compressor.profiling.parser.onnx_parser": [[405, 0, 0, "-", "factory"], [407, 0, 0, "-", "parser"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[405, 1, 1, "", "OnnxrtParserFactory"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[407, 1, 1, "", "OnnxProfilingParser"]], "neural_compressor.profiling.parser.parser": [[408, 1, 1, "", "ProfilingParser"]], "neural_compressor.profiling.parser.result": [[409, 1, 1, "", "ProfilingResult"]], "neural_compressor.profiling.parser.tensorflow_parser": [[410, 0, 0, "-", "factory"], [412, 0, 0, "-", "parser"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[410, 1, 1, "", "TensorFlowParserFactory"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[412, 1, 1, "", "TensorFlowProfilingParser"]], "neural_compressor.profiling.profiler": [[413, 0, 0, "-", "factory"], [416, 0, 0, "-", "onnxrt_profiler"], [419, 0, 0, "-", "profiler"], [421, 0, 0, "-", "tensorflow_profiler"]], "neural_compressor.profiling.profiler.factory": [[413, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[415, 0, 0, "-", "factory"], [417, 0, 0, "-", "profiler"], [418, 0, 0, "-", "utils"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[415, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[417, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[418, 2, 1, "", "create_onnx_config"]], "neural_compressor.profiling.profiler.profiler": [[419, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[420, 0, 0, "-", "factory"], [422, 0, 0, "-", "profiler"], [423, 0, 0, "-", "utils"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[420, 1, 1, "", "ProfilerFactory"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[422, 1, 1, "", "Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[423, 2, 1, "", "create_tf_config"], [423, 2, 1, "", "delete_assign"], [423, 2, 1, "", "set_eager_execution"]], "neural_compressor.quantization": [[424, 2, 1, "", "fit"]], "neural_compressor.strategy": [[425, 0, 0, "-", "auto"], [426, 0, 0, "-", "auto_mixed_precision"], [427, 0, 0, "-", "basic"], [428, 0, 0, "-", "bayesian"], [429, 0, 0, "-", "conservative"], [430, 0, 0, "-", "exhaustive"], [431, 0, 0, "-", "hawq_v2"], [433, 0, 0, "-", "mse"], [434, 0, 0, "-", "mse_v2"], [435, 0, 0, "-", "random"], [436, 0, 0, "-", "strategy"], [438, 0, 0, "-", "utils"]], "neural_compressor.strategy.auto": [[425, 1, 1, "", "AutoTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[426, 1, 1, "", "AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.basic": [[427, 1, 1, "", "BasicTuneStrategy"]], "neural_compressor.strategy.bayesian": [[428, 1, 1, "", "BayesianOptimization"], [428, 1, 1, "", "BayesianTuneStrategy"], [428, 1, 1, "", "TargetSpace"], [428, 2, 1, "", "acq_max"]], "neural_compressor.strategy.conservative": [[429, 1, 1, "", "ConservativeTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[430, 1, 1, "", "ExhaustiveTuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[431, 1, 1, "", "HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.mse": [[433, 1, 1, "", "MSETuneStrategy"]], "neural_compressor.strategy.mse_v2": [[434, 1, 1, "", "MSE_V2TuneStrategy"]], "neural_compressor.strategy.random": [[435, 1, 1, "", "RandomTuneStrategy"]], "neural_compressor.strategy.strategy": [[436, 1, 1, "", "TuneStrategy"], [436, 1, 1, "", "TuneStrategyMeta"], [436, 2, 1, "", "strategy_registry"]], "neural_compressor.strategy.utils": [[437, 0, 0, "-", "constant"], [439, 0, 0, "-", "tuning_sampler"], [440, 0, 0, "-", "tuning_space"], [441, 0, 0, "-", "tuning_structs"], [442, 0, 0, "-", "utility"]], "neural_compressor.strategy.utils.tuning_sampler": [[439, 1, 1, "", "BlockFallbackTuningSampler"], [439, 1, 1, "", "FallbackTuningSampler"], [439, 1, 1, "", "LowerBitsSampler"], [439, 1, 1, "", "ModelWiseTuningSampler"], [439, 1, 1, "", "OpTypeWiseTuningSampler"], [439, 1, 1, "", "OpWiseTuningSampler"], [439, 1, 1, "", "SmoothQuantSampler"], [439, 1, 1, "", "TuningOrder"], [439, 1, 1, "", "TuningSampler"], [439, 1, 1, "", "WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_space": [[440, 1, 1, "", "TuningItem"], [440, 1, 1, "", "TuningSpace"], [440, 2, 1, "", "initial_tuning_cfg_with_quant_mode"], [440, 2, 1, "", "pattern_to_internal"], [440, 2, 1, "", "pattern_to_path"], [440, 2, 1, "", "quant_mode_from_pattern"]], "neural_compressor.strategy.utils.tuning_structs": [[441, 1, 1, "", "OpTuningConfig"]], "neural_compressor.strategy.utils.utility": [[442, 1, 1, "", "ClassRegister"], [442, 1, 1, "", "OrderedDefaultDict"], [442, 1, 1, "", "QuantOptions"], [442, 1, 1, "", "QuantType"], [442, 2, 1, "", "build_slave_faker_model"], [442, 2, 1, "", "extract_data_type"], [442, 2, 1, "", "get_adaptor_name"], [442, 2, 1, "", "preprocess_user_cfg"], [442, 2, 1, "", "reverted_data_type"]], "neural_compressor.template": [[443, 0, 0, "-", "api_doc_example"]], "neural_compressor.template.api_doc_example": [[443, 1, 1, "", "ExampleClass"], [443, 4, 1, "", "attribute1"], [443, 2, 1, "", "function1"], [443, 2, 1, "", "function2"], [443, 2, 1, "", "function3"], [443, 2, 1, "", "generator1"], [443, 5, 1, "", "module_debug_level1"]], "neural_compressor.template.api_doc_example.ExampleClass": [[443, 4, 1, "", "attr1"], [443, 4, 1, "", "attr2"], [443, 4, 1, "", "attr5"]], "neural_compressor.tensorflow": [[445, 0, 0, "-", "algorithms"], [462, 0, 0, "-", "quantization"], [505, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.algorithms": [[448, 0, 0, "-", "smoother"], [450, 0, 0, "-", "static_quant"]], "neural_compressor.tensorflow.algorithms.smoother": [[446, 0, 0, "-", "calibration"], [447, 0, 0, "-", "core"], [449, 0, 0, "-", "scaler"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[446, 1, 1, "", "SmoothQuantCalibration"], [446, 1, 1, "", "SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[447, 1, 1, "", "SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[449, 1, 1, "", "SmoothQuantScaler"], [449, 1, 1, "", "SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.static_quant": [[451, 0, 0, "-", "keras"], [455, 0, 0, "-", "keras_utils"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[451, 1, 1, "", "KerasAdaptor"], [451, 1, 1, "", "KerasConfigConverter"], [451, 1, 1, "", "KerasQuery"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils": [[452, 0, 0, "-", "conv2d"], [453, 0, 0, "-", "dense"], [454, 0, 0, "-", "depthwise_conv2d"], [456, 0, 0, "-", "pool2d"], [457, 0, 0, "-", "quantizer"], [458, 0, 0, "-", "separable_conv2d"]], "neural_compressor.tensorflow.quantization": [[460, 0, 0, "-", "algorithm_entry"], [461, 0, 0, "-", "config"], [463, 0, 0, "-", "quantize"], [500, 0, 0, "-", "utils"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[460, 2, 1, "", "static_quantize_entry"]], "neural_compressor.tensorflow.quantization.config": [[461, 1, 1, "", "SmoothQuantConfig"], [461, 1, 1, "", "StaticQuantConfig"], [461, 2, 1, "", "get_all_registered_configs"], [461, 2, 1, "", "get_default_sq_config"], [461, 2, 1, "", "get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.quantize": [[463, 2, 1, "", "quantize_model"]], "neural_compressor.tensorflow.quantization.utils": [[498, 0, 0, "-", "graph_rewriter"], [499, 0, 0, "-", "graph_util"], [501, 0, 0, "-", "quantize_graph_common"], [502, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[487, 0, 0, "-", "generic"], [497, 0, 0, "-", "graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[464, 0, 0, "-", "convert_add_to_biasadd"], [465, 0, 0, "-", "convert_layout"], [466, 0, 0, "-", "convert_leakyrelu"], [467, 0, 0, "-", "convert_nan_to_random"], [468, 0, 0, "-", "convert_placeholder_to_const"], [469, 0, 0, "-", "dilated_contraction"], [470, 0, 0, "-", "dummy_biasadd"], [471, 0, 0, "-", "expanddims_optimizer"], [472, 0, 0, "-", "fetch_weight_from_reshape"], [473, 0, 0, "-", "fold_batch_norm"], [474, 0, 0, "-", "fold_constant"], [475, 0, 0, "-", "fuse_biasadd_add"], [476, 0, 0, "-", "fuse_column_wise_mul"], [477, 0, 0, "-", "fuse_conv_with_math"], [478, 0, 0, "-", "fuse_decomposed_bn"], [479, 0, 0, "-", "fuse_decomposed_in"], [480, 0, 0, "-", "fuse_gelu"], [481, 0, 0, "-", "fuse_layer_norm"], [482, 0, 0, "-", "fuse_pad_with_conv"], [483, 0, 0, "-", "fuse_pad_with_fp32_conv"], [484, 0, 0, "-", "fuse_reshape_transpose"], [485, 0, 0, "-", "graph_cse_optimizer"], [486, 0, 0, "-", "grappler_pass"], [488, 0, 0, "-", "insert_print_node"], [489, 0, 0, "-", "move_squeeze_after_relu"], [490, 0, 0, "-", "pre_optimize"], [491, 0, 0, "-", "remove_training_nodes"], [492, 0, 0, "-", "rename_batch_norm"], [493, 0, 0, "-", "split_shared_input"], [494, 0, 0, "-", "strip_equivalent_nodes"], [495, 0, 0, "-", "strip_unused_nodes"], [496, 0, 0, "-", "switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[464, 1, 1, "", "ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[465, 1, 1, "", "ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[466, 1, 1, "", "ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[467, 1, 1, "", "ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[468, 1, 1, "", "ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[469, 1, 1, "", "DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[470, 1, 1, "", "InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[471, 1, 1, "", "ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[472, 1, 1, "", "FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[473, 1, 1, "", "FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[474, 1, 1, "", "GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[475, 1, 1, "", "FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[476, 1, 1, "", "FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[477, 1, 1, "", "FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[478, 1, 1, "", "FuseDecomposedBNOptimizer"], [478, 2, 1, "", "bypass_reshape"], [478, 2, 1, "", "get_const_dim_count"], [478, 2, 1, "", "node_from_map"], [478, 2, 1, "", "node_name_from_input"], [478, 2, 1, "", "valid_reshape_inputs"], [478, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[479, 1, 1, "", "FuseDecomposedINOptimizer"], [479, 2, 1, "", "bypass_reshape"], [479, 2, 1, "", "get_const_dim_count"], [479, 2, 1, "", "node_from_map"], [479, 2, 1, "", "node_name_from_input"], [479, 2, 1, "", "valid_reshape_inputs"], [479, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[480, 1, 1, "", "FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[481, 1, 1, "", "FuseLayerNormOptimizer"], [481, 2, 1, "", "node_from_map"], [481, 2, 1, "", "node_name_from_input"], [481, 2, 1, "", "values_from_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[482, 1, 1, "", "FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[483, 1, 1, "", "FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[484, 1, 1, "", "FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[485, 1, 1, "", "GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[486, 1, 1, "", "GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[488, 1, 1, "", "InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[489, 1, 1, "", "MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[490, 1, 1, "", "PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[491, 1, 1, "", "RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[492, 1, 1, "", "RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[493, 1, 1, "", "SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[494, 1, 1, "", "StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[495, 1, 1, "", "StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[496, 1, 1, "", "SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[497, 1, 1, "", "GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[499, 1, 1, "", "GraphAnalyzer"], [499, 1, 1, "", "GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[501, 1, 1, "", "QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.utility": [[502, 2, 1, "", "apply_inlining"], [502, 2, 1, "", "collate_tf_preds"], [502, 2, 1, "", "construct_function_from_graph_def"], [502, 2, 1, "", "disable_random"], [502, 2, 1, "", "fix_ref_type_of_graph_def"], [502, 2, 1, "", "generate_feed_dict"], [502, 2, 1, "", "get_graph_def"], [502, 2, 1, "", "get_input_output_node_names"], [502, 2, 1, "", "get_model_input_shape"], [502, 2, 1, "", "get_tensor_by_name"], [502, 2, 1, "", "get_tensor_val_from_graph_node"], [502, 2, 1, "", "get_weight_from_input_tensor"], [502, 2, 1, "", "int8_node_name_reverse"], [502, 2, 1, "", "is_ckpt_format"], [502, 2, 1, "", "is_saved_model_format"], [502, 2, 1, "", "iterator_sess_run"], [502, 2, 1, "", "parse_saved_model"], [502, 2, 1, "", "read_graph"], [502, 2, 1, "", "reconstruct_saved_model"], [502, 2, 1, "", "strip_equivalent_nodes"], [502, 2, 1, "", "strip_unused_nodes"], [502, 2, 1, "", "tf_diagnosis_helper"], [502, 2, 1, "", "write_graph"]], "neural_compressor.tensorflow.utils": [[503, 0, 0, "-", "constants"], [504, 0, 0, "-", "data"], [506, 0, 0, "-", "model"], [507, 0, 0, "-", "model_wrappers"], [508, 0, 0, "-", "nets_factory"], [509, 0, 0, "-", "utility"]], "neural_compressor.tensorflow.utils.data": [[504, 1, 1, "", "BaseDataLoader"], [504, 1, 1, "", "DummyDataset"], [504, 1, 1, "", "DummyDatasetV2"]], "neural_compressor.tensorflow.utils.model": [[506, 1, 1, "", "Model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[507, 1, 1, "", "BaseModel"], [507, 1, 1, "", "KerasModel"], [507, 1, 1, "", "TensorflowBaseModel"], [507, 1, 1, "", "TensorflowCheckpointModel"], [507, 1, 1, "", "TensorflowLLMModel"], [507, 1, 1, "", "TensorflowModel"], [507, 1, 1, "", "TensorflowQATModel"], [507, 1, 1, "", "TensorflowSavedModelModel"], [507, 2, 1, "", "checkpoint_session"], [507, 2, 1, "", "estimator_session"], [507, 2, 1, "", "frozen_pb_session"], [507, 2, 1, "", "get_model_type"], [507, 2, 1, "", "graph_def_session"], [507, 2, 1, "", "graph_session"], [507, 2, 1, "", "keras_session"], [507, 2, 1, "", "load_saved_model"], [507, 2, 1, "", "saved_model_session"], [507, 2, 1, "", "slim_session"], [507, 2, 1, "", "validate_and_inference_input_output"], [507, 2, 1, "", "validate_graph_node"]], "neural_compressor.tensorflow.utils.nets_factory": [[508, 1, 1, "", "TFSlimNetsFactory"]], "neural_compressor.tensorflow.utils.utility": [[509, 1, 1, "", "CaptureOutputToFile"], [509, 1, 1, "", "CpuInfo"], [509, 2, 1, "", "Dequantize"], [509, 1, 1, "", "LazyImport"], [509, 1, 1, "", "Statistics"], [509, 2, 1, "", "combine_histogram"], [509, 2, 1, "", "deep_get"], [509, 2, 1, "", "dequantize_weight"], [509, 2, 1, "", "disable_random"], [509, 2, 1, "", "dump_data_to_local"], [509, 2, 1, "", "dump_elapsed_time"], [509, 2, 1, "", "get_all_fp32_data"], [509, 2, 1, "", "get_tensor_histogram"], [509, 2, 1, "", "itex_installed"], [509, 2, 1, "", "load_data_from_pkl"], [509, 2, 1, "", "register_algo"], [509, 2, 1, "", "singleton"], [509, 2, 1, "", "version1_eq_version2"], [509, 2, 1, "", "version1_gt_version2"], [509, 2, 1, "", "version1_gte_version2"], [509, 2, 1, "", "version1_lt_version2"], [509, 2, 1, "", "version1_lte_version2"]], "neural_compressor.torch": [[514, 0, 0, "-", "algorithms"], [542, 0, 0, "-", "amp"], [547, 0, 0, "-", "quantization"], [552, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms": [[511, 0, 0, "-", "habana_fp8"], [515, 0, 0, "-", "layer_wise"], [519, 0, 0, "-", "static_quant"], [534, 0, 0, "-", "weight_only"]], "neural_compressor.torch.algorithms.habana_fp8": [[510, 0, 0, "-", "fp8_quant"], [512, 0, 0, "-", "modules"], [513, 0, 0, "-", "observer"]], "neural_compressor.torch.algorithms.layer_wise": [[516, 0, 0, "-", "load"], [517, 0, 0, "-", "modified_pickle"], [518, 0, 0, "-", "utils"]], "neural_compressor.torch.algorithms.layer_wise.load": [[516, 2, 1, "", "load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[517, 3, 1, "", "PickleError"], [517, 3, 1, "", "PicklingError"], [517, 3, 1, "", "UnpicklingError"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[518, 2, 1, "", "dowload_hf_model"], [518, 2, 1, "", "get_children"], [518, 2, 1, "", "get_module"], [518, 2, 1, "", "get_named_children"], [518, 2, 1, "", "get_super_module_by_name"], [518, 2, 1, "", "load_empty_model"], [518, 2, 1, "", "load_layer_wise_quantized_model"], [518, 2, 1, "", "load_tensor"], [518, 2, 1, "", "load_tensor_from_shard"], [518, 2, 1, "", "update_module"]], "neural_compressor.torch.algorithms.static_quant": [[520, 0, 0, "-", "static_quant"], [521, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[520, 2, 1, "", "static_quantize"]], "neural_compressor.torch.algorithms.static_quant.utility": [[521, 1, 1, "", "Statistics"], [521, 1, 1, "", "TransformerBasedModelBlockPatternDetector"], [521, 2, 1, "", "dump_model_op_stats"], [521, 2, 1, "", "get_depth"], [521, 2, 1, "", "get_dict_at_depth"], [521, 2, 1, "", "get_element_under_depth"], [521, 2, 1, "", "get_quantizable_ops_from_cfgs"], [521, 2, 1, "", "get_quantizable_ops_recursively"], [521, 2, 1, "", "paser_cfgs"], [521, 2, 1, "", "simple_inference"]], "neural_compressor.torch.algorithms.weight_only": [[522, 0, 0, "-", "awq"], [523, 0, 0, "-", "gptq"], [528, 0, 0, "-", "hqq"], [535, 0, 0, "-", "modules"], [536, 0, 0, "-", "rtn"], [537, 0, 0, "-", "teq"], [538, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.weight_only.awq": [[522, 1, 1, "", "ActAwareWeightQuant"], [522, 2, 1, "", "awq_quantize"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[523, 1, 1, "", "GPTQ"], [523, 1, 1, "", "GPTQuantizer"], [523, 2, 1, "", "find_layers"], [523, 2, 1, "", "find_layers_name"], [523, 2, 1, "", "gptq_quantize"], [523, 2, 1, "", "is_leaf"], [523, 2, 1, "", "log_quantizable_layers_per_transformer"], [523, 2, 1, "", "quantize"], [523, 2, 1, "", "trace_gptq_target_blocks"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[524, 0, 0, "-", "auto_accelerator"], [525, 0, 0, "-", "bitpack"], [526, 0, 0, "-", "config"], [527, 0, 0, "-", "core"], [529, 0, 0, "-", "optimizer"], [530, 0, 0, "-", "qtensor"], [531, 0, 0, "-", "quant_api"], [532, 0, 0, "-", "quantizer"], [533, 0, 0, "-", "utility"]], "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator": [[524, 1, 1, "", "Auto_Accelerator"], [524, 1, 1, "", "CPU_Accelerator"], [524, 1, 1, "", "CUDA_Accelerator"], [524, 2, 1, "", "register_accelerator"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[526, 1, 1, "", "HQQModuleConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[533, 2, 1, "", "dump_elapsed_time"]], "neural_compressor.torch.algorithms.weight_only.modules": [[535, 1, 1, "", "FakeAffineTensorQuantFunction"], [535, 1, 1, "", "MulLinear"], [535, 1, 1, "", "TEQLinearFakeQuant"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[536, 2, 1, "", "rtn_quantize"]], "neural_compressor.torch.algorithms.weight_only.teq": [[537, 1, 1, "", "TEQuantizer"], [537, 2, 1, "", "teq_quantize"]], "neural_compressor.torch.algorithms.weight_only.utility": [[538, 2, 1, "", "calibration"], [538, 2, 1, "", "fetch_module"], [538, 2, 1, "", "get_absorb_layers"], [538, 2, 1, "", "get_block_prefix"], [538, 2, 1, "", "get_example_input"], [538, 2, 1, "", "get_hidden_states"], [538, 2, 1, "", "get_module"], [538, 2, 1, "", "get_module_input_output"], [538, 2, 1, "", "qdq_weight_actor"], [538, 2, 1, "", "qdq_weight_asym"], [538, 2, 1, "", "qdq_weight_sym"], [538, 2, 1, "", "quant_tensor"], [538, 2, 1, "", "quant_weight_w_scale"], [538, 2, 1, "", "quantize_4bit"], [538, 2, 1, "", "search_clip"], [538, 2, 1, "", "set_module"]], "neural_compressor.torch.amp": [[539, 0, 0, "-", "autocast"], [541, 0, 0, "-", "fp8"]], "neural_compressor.torch.amp.autocast": [[539, 1, 1, "", "autocast"]], "neural_compressor.torch.amp.fp8": [[540, 0, 0, "-", "functions"]], "neural_compressor.torch.quantization": [[544, 0, 0, "-", "algorithm_entry"], [545, 0, 0, "-", "autotune"], [546, 0, 0, "-", "config"], [548, 0, 0, "-", "modules"], [549, 0, 0, "-", "quantize"]], "neural_compressor.torch.quantization.algorithm_entry": [[544, 2, 1, "", "rtn_entry"]], "neural_compressor.torch.quantization.autotune": [[545, 2, 1, "", "autotune"]], "neural_compressor.torch.quantization.config": [[546, 1, 1, "", "GPTQConfig"], [546, 1, 1, "", "RTNConfig"], [546, 2, 1, "", "get_default_gptq_config"], [546, 2, 1, "", "get_default_hqq_config"], [546, 2, 1, "", "get_default_rtn_config"]], "neural_compressor.torch.quantization.quantize": [[549, 2, 1, "", "quantize"]], "neural_compressor.torch.utils": [[550, 0, 0, "-", "constants"], [551, 0, 0, "-", "environ"], [553, 0, 0, "-", "utility"]], "neural_compressor.torch.utils.utility": [[553, 2, 1, "", "fetch_module"], [553, 2, 1, "", "register_algo"], [553, 2, 1, "", "set_module"]], "neural_compressor.training": [[554, 1, 1, "", "CallBacks"], [554, 1, 1, "", "CompressionManager"], [554, 2, 1, "", "fit"], [554, 2, 1, "", "prepare_compression"]], "neural_compressor.utils": [[555, 0, 0, "-", "collect_layer_histogram"], [556, 0, 0, "-", "constant"], [557, 0, 0, "-", "create_obj_from_config"], [559, 0, 0, "-", "kl_divergence"], [560, 0, 0, "-", "load_huggingface"], [561, 0, 0, "-", "logger"], [562, 0, 0, "-", "neural_insights_utils"], [563, 0, 0, "-", "options"], [564, 0, 0, "-", "pytorch"], [565, 0, 0, "-", "utility"], [566, 0, 0, "-", "weights_details"]], "neural_compressor.utils.collect_layer_histogram": [[555, 1, 1, "", "LayerHistogramCollector"]], "neural_compressor.utils.create_obj_from_config": [[557, 2, 1, "", "create_dataloader"], [557, 2, 1, "", "create_dataset"], [557, 2, 1, "", "create_eval_func"], [557, 2, 1, "", "create_train_func"], [557, 2, 1, "", "get_algorithm"], [557, 2, 1, "", "get_func_from_config"], [557, 2, 1, "", "get_metrics"], [557, 2, 1, "", "get_postprocess"], [557, 2, 1, "", "get_preprocess"]], "neural_compressor.utils.kl_divergence": [[559, 1, 1, "", "KL_Divergence"]], "neural_compressor.utils.load_huggingface": [[560, 1, 1, "", "OptimizedModel"], [560, 2, 1, "", "export_compressed_model"], [560, 2, 1, "", "save_for_huggingface_upstream"]], "neural_compressor.utils.logger": [[561, 1, 1, "", "Logger"], [561, 2, 1, "", "debug"], [561, 2, 1, "", "error"], [561, 2, 1, "", "fatal"], [561, 2, 1, "", "info"], [561, 2, 1, "", "log"], [561, 2, 1, "", "warn"], [561, 2, 1, "", "warning"]], "neural_compressor.utils.neural_insights_utils": [[562, 2, 1, "", "get_model_path"], [562, 2, 1, "", "register_neural_insights_workload"], [562, 2, 1, "", "update_neural_insights_workload"], [562, 2, 1, "", "update_neural_insights_workload_accuracy_data"]], "neural_compressor.utils.options": [[563, 1, 1, "", "onnxrt"]], "neural_compressor.utils.pytorch": [[564, 2, 1, "", "is_int8_model"], [564, 2, 1, "", "load"], [564, 2, 1, "", "load_weight_only"], [564, 2, 1, "", "recover_model_from_json"]], "neural_compressor.utils.utility": [[565, 1, 1, "", "CaptureOutputToFile"], [565, 1, 1, "", "CpuInfo"], [565, 2, 1, "", "Dequantize"], [565, 1, 1, "", "DotDict"], [565, 1, 1, "", "GLOBAL_STATE"], [565, 1, 1, "", "LazyImport"], [565, 1, 1, "", "MODE"], [565, 1, 1, "", "OpEntry"], [565, 1, 1, "", "Statistics"], [565, 2, 1, "", "alias_param"], [565, 2, 1, "", "calculate_mse"], [565, 2, 1, "", "check_key_exist"], [565, 2, 1, "", "combine_histogram"], [565, 2, 1, "", "compare_objects"], [565, 2, 1, "", "compute_sparsity"], [565, 2, 1, "", "dequantize_weight"], [565, 2, 1, "", "dump_class_attrs"], [565, 2, 1, "", "dump_data_to_local"], [565, 2, 1, "", "dump_elapsed_time"], [565, 2, 1, "", "dump_table"], [565, 2, 1, "", "dump_table_to_csv"], [565, 2, 1, "", "equal_dicts"], [565, 2, 1, "", "fault_tolerant_file"], [565, 2, 1, "", "get_all_fp32_data"], [565, 2, 1, "", "get_number_of_sockets"], [565, 2, 1, "", "get_op_list"], [565, 2, 1, "", "get_size"], [565, 2, 1, "", "get_tensor_histogram"], [565, 2, 1, "", "get_tensors_info"], [565, 2, 1, "", "get_tuning_history"], [565, 2, 1, "", "get_weights_details"], [565, 2, 1, "", "load_data_from_pkl"], [565, 2, 1, "", "mse_metric_gap"], [565, 2, 1, "", "print_op_list"], [565, 2, 1, "", "print_table"], [565, 2, 1, "", "recover"], [565, 2, 1, "", "set_random_seed"], [565, 2, 1, "", "set_resume_from"], [565, 2, 1, "", "set_tensorboard"], [565, 2, 1, "", "set_workspace"], [565, 2, 1, "", "show_memory_info"], [565, 2, 1, "", "singleton"], [565, 2, 1, "", "str2array"], [565, 2, 1, "", "time_limit"], [565, 2, 1, "", "version1_eq_version2"], [565, 2, 1, "", "version1_gt_version2"], [565, 2, 1, "", "version1_gte_version2"], [565, 2, 1, "", "version1_lt_version2"], [565, 2, 1, "", "version1_lte_version2"]], "neural_compressor.utils.weights_details": [[566, 1, 1, "", "WeightsDetails"], [566, 1, 1, "", "WeightsStatistics"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:function", "3": "py:exception", "4": "py:attribute", "5": "py:data"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "function", "Python function"], "3": ["py", "exception", "Python exception"], "4": ["py", "attribute", "Python attribute"], "5": ["py", "data", "Python data"]}, "titleterms": {"block_mask": [0, 210], "neural_compressor": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567], "adaptor": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 575, 576, 578], "modul": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 175, 176, 177, 178, 179, 181, 184, 185, 186, 187, 189, 190, 193, 194, 196, 197, 199, 201, 202, 203, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 253, 254, 257, 258, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 271, 272, 276, 277, 278, 280, 281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 300, 302, 303, 304, 306, 307, 308, 309, 311, 312, 314, 315, 316, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 330, 331, 332, 333, 336, 337, 338, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 362, 364, 365, 367, 368, 369, 371, 372, 373, 375, 376, 377, 378, 379, 380, 381, 382, 384, 385, 387, 388, 390, 391, 393, 394, 395, 396, 400, 401, 403, 405, 407, 408, 409, 410, 412, 413, 415, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 439, 440, 441, 442, 443, 446, 447, 449, 451, 460, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 501, 502, 504, 506, 507, 508, 509, 512, 516, 517, 518, 520, 521, 522, 523, 524, 525, 526, 527, 530, 531, 533, 535, 536, 537, 538, 539, 544, 545, 546, 548, 549, 553, 554, 555, 557, 559, 560, 561, 562, 563, 564, 565, 566], "content": [1, 2, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 184, 185, 186, 187, 189, 190, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 276, 277, 278, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 308, 309, 310, 311, 312, 314, 315, 316, 317, 318, 319, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 359, 360, 361, 362, 364, 365, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 390, 391, 392, 393, 394, 395, 396, 397, 399, 400, 401, 403, 405, 407, 408, 409, 410, 412, 413, 415, 417, 418, 419, 420, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 439, 440, 441, 442, 443, 446, 447, 449, 451, 460, 461, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 501, 502, 504, 506, 507, 508, 509, 516, 517, 518, 520, 521, 522, 523, 524, 525, 526, 527, 530, 531, 533, 535, 536, 537, 538, 539, 544, 545, 546, 549, 553, 554, 555, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 574, 643], "class": [1, 3, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 109, 110, 113, 115, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 149, 153, 154, 155, 156, 157, 161, 165, 166, 167, 169, 172, 173, 174, 175, 176, 178, 179, 180, 181, 184, 186, 187, 189, 193, 194, 196, 201, 202, 203, 205, 206, 207, 208, 209, 210, 212, 213, 214, 215, 216, 217, 218, 219, 220, 225, 226, 227, 229, 230, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 272, 276, 277, 278, 280, 281, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 309, 310, 311, 314, 317, 318, 319, 320, 321, 322, 324, 326, 327, 328, 330, 331, 332, 333, 334, 335, 336, 337, 338, 341, 343, 344, 345, 346, 347, 348, 349, 350, 351, 353, 354, 355, 356, 359, 360, 361, 362, 364, 367, 370, 371, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 392, 395, 396, 397, 399, 400, 403, 405, 407, 408, 409, 410, 412, 413, 415, 417, 419, 420, 422, 425, 426, 427, 428, 429, 430, 431, 433, 434, 435, 436, 439, 440, 441, 442, 443, 446, 447, 449, 451, 461, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 499, 501, 504, 506, 507, 508, 509, 521, 522, 523, 524, 525, 526, 527, 530, 535, 537, 538, 539, 546, 554, 555, 558, 559, 560, 561, 563, 565, 566, 575, 643], "function": [1, 13, 16, 34, 42, 43, 44, 45, 67, 68, 70, 104, 105, 116, 118, 148, 149, 150, 153, 155, 156, 157, 162, 163, 164, 167, 168, 170, 171, 172, 174, 177, 178, 179, 180, 185, 187, 189, 190, 193, 194, 196, 197, 198, 199, 201, 203, 204, 208, 211, 217, 218, 219, 220, 221, 223, 224, 227, 236, 237, 245, 247, 251, 254, 255, 256, 259, 261, 262, 263, 264, 266, 268, 269, 271, 280, 288, 290, 294, 297, 298, 299, 301, 302, 303, 306, 307, 308, 311, 312, 314, 315, 316, 317, 318, 325, 332, 336, 341, 342, 343, 345, 350, 356, 360, 362, 364, 365, 367, 368, 369, 370, 371, 372, 376, 380, 382, 383, 387, 388, 390, 391, 392, 393, 394, 396, 397, 401, 418, 423, 424, 428, 436, 440, 442, 443, 460, 461, 463, 478, 479, 481, 502, 507, 509, 516, 518, 520, 521, 522, 523, 524, 531, 533, 536, 537, 538, 540, 544, 545, 546, 549, 553, 554, 557, 558, 560, 561, 562, 564, 565, 601], "subpackag": [2, 17, 87, 111, 112, 114, 158, 195, 198, 231, 256, 274, 299, 310, 334, 352, 363, 432, 498, 514], "submodul": [2, 12, 17, 29, 52, 76, 87, 95, 101, 106, 111, 112, 114, 117, 130, 145, 151, 158, 159, 174, 183, 188, 191, 195, 198, 200, 204, 211, 222, 228, 232, 239, 251, 255, 259, 266, 275, 282, 294, 298, 301, 305, 310, 317, 323, 329, 335, 339, 352, 358, 363, 370, 374, 386, 399, 404, 406, 411, 414, 416, 421, 432, 438, 444, 448, 487, 498, 500, 505, 515, 528, 534, 547, 558], "packag": [2, 29, 174, 180, 198, 204, 211, 239, 251, 255, 256, 259, 266, 282, 294, 298, 299, 301, 310, 317, 329, 334, 335, 352, 370, 374, 383, 386, 392, 397, 399, 432, 558, 626, 628, 630, 631], "kera": [3, 451], "keras_util": [4, 5, 6, 7, 8, 9, 10, 452, 453, 454, 455, 456, 457, 458], "conv2d": [4, 452], "dens": [5, 453], "depthwise_conv2d": [6, 454], "pool2d": [8, 456], "quantiz": [9, 41, 161, 346, 393, 394, 395, 396, 397, 398, 424, 457, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 532, 544, 545, 546, 547, 548, 549, 571, 574, 576, 577, 589, 593, 598, 600, 603, 606, 609, 611, 613, 614, 622, 633, 635, 636, 637, 638, 646, 647, 648, 654, 655, 656, 657, 658, 661, 667], "separable_conv2d": [10, 458], "mxnet": [11, 596, 612, 655, 663], "mxnet_util": [12, 13], "util": [13, 43, 148, 163, 170, 182, 183, 184, 185, 190, 221, 224, 357, 358, 359, 360, 361, 362, 391, 399, 400, 401, 418, 423, 437, 438, 439, 440, 441, 442, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 518, 521, 533, 538, 550, 551, 552, 553, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 580], "onnxrt": [14, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 596, 612, 663], "ox_util": [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], "calibr": [15, 16, 384, 395, 446, 576, 593], "oper": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 576, 577], "activ": [18, 636], "argmax": 19, "attent": 20, "binary_op": 21, "concat": 22, "conv": 23, "direct_q8": 24, "embed_layernorm": 25, "gather": 26, "gavgpool": 27, "gemm": 28, "lstm": 30, "matmul": [31, 661], "maxpool": 32, "norm": 33, "op": [34, 603], "pad": 35, "pool": 36, "reduc": 37, "resiz": 38, "split": [39, 639], "unary_op": 40, "smooth_quant": [42, 167, 175], "weight_onli": [44, 171, 387, 388, 389, 390, 391, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538], "pytorch": [45, 564, 596, 601, 603, 612, 637, 655, 656, 657, 662, 663, 667], "queri": [46, 575, 641, 646, 647, 648], "tensorflow": [47, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 596, 601, 603, 612, 655, 657, 662, 663, 667], "tf_util": [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148], "graph_convert": 48, "graph_converter_without_calib": 49, "graph_rewrit": [50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498], "bf16": [50, 51, 52, 614], "bf16_convert": [50, 155], "dequantize_cast_optim": 51, "gener": [53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 576], "convert_add_to_biasadd": [53, 464], "convert_layout": [54, 465], "convert_leakyrelu": [55, 466], "convert_nan_to_random": [56, 467], "convert_placeholder_to_const": [57, 468], "dilated_contract": [58, 469], "dummy_biasadd": [59, 470], "expanddims_optim": [60, 471], "fetch_weight_from_reshap": [61, 472], "fold_batch_norm": [62, 473], "fold_const": [63, 474], "fuse_biasadd_add": [64, 475], "fuse_column_wise_mul": [65, 476], "fuse_conv_with_math": [66, 477], "fuse_decomposed_bn": [67, 478], "fuse_decomposed_in": [68, 479], "fuse_gelu": [69, 480], "fuse_layer_norm": [70, 481], "fuse_pad_with_conv": [71, 482], "fuse_pad_with_fp32_conv": [72, 483], "fuse_reshape_transpos": [73, 484], "graph_cse_optim": [74, 485], "grappler_pass": [75, 486], "insert_print_nod": [77, 488], "move_squeeze_after_relu": [78, 489], "pre_optim": [79, 490], "remove_training_nod": [80, 491], "rename_batch_norm": [81, 492], "split_shared_input": [82, 493], "strip_equivalent_nod": [83, 494], "strip_unused_nod": [84, 495], "switch_optim": [85, 496], "graph_bas": [86, 497], "int8": [88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 603, 667], "freeze_fake_qu": 88, "freeze_valu": 89, "freeze_value_without_calib": 90, "fuse_conv_redundant_dequant": 91, "fuse_conv_requant": 92, "fuse_matmul_redundant_dequant": 93, "fuse_matmul_requant": 94, "meta_op_optim": 96, "post_hostconst_convert": 97, "post_quantized_op_cs": 98, "rnn_convert": 99, "scale_propag": 100, "onnx": [101, 102, 103, 104, 105, 579, 609, 655, 656, 667], "onnx_graph": 102, "onnx_nod": 103, "onnx_schema": 104, "tf2onnx_util": 105, "qdq": [106, 107, 108, 109, 123, 124, 125, 126, 127, 128, 129, 130, 131, 667], "insert_qdq_pattern": 107, "merge_duplicated_qdq": 108, "share_qdq_y_pattern": 109, "graph_util": [110, 499], "quantize_graph": [112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138], "qat": [113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 667], "fake_quant": 113, "quantize_config": 115, "quantize_help": 116, "quantize_lay": [117, 118, 119, 120, 121], "optimize_lay": 118, "quantize_layer_add": 119, "quantize_layer_bas": 120, "quantize_layer_bn": 121, "quantize_wrapp": 122, "fuse_qdq_bn": 123, "fuse_qdq_concatv2": 124, "fuse_qdq_conv": 125, "fuse_qdq_deconv": 126, "fuse_qdq_in": 127, "fuse_qdq_matmul": 128, "fuse_qdq_pool": 129, "optimize_qdq": 131, "quantize_graph_bas": 132, "quantize_graph_bn": 133, "quantize_graph_concatv2": 134, "quantize_graph_conv": 135, "quantize_graph_for_intel_cpu": 136, "quantize_graph_matmul": 137, "quantize_graph_pool": 138, "quantize_graph_common": [139, 501], "smooth_quant_calibr": 140, "smooth_quant_scal": 141, "tf2onnx_convert": 142, "transform_graph": [143, 144, 145, 146, 147], "bias_correct": 143, "graph_transform_bas": 144, "insert_log": 146, "rerange_quantized_concat": 147, "torch_util": [149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 271], "autoround": [149, 150, 151, 152, 153], "export": [150, 305, 306, 307, 308, 603, 658], "model_wrapp": [152, 165, 507], "sign_sgd": 153, "awq": [154, 387, 522], "gptq": [156, 388, 523], "hawq_metr": 157, "layer_wise_qu": [159, 160, 161, 162, 163], "modified_pickl": [160, 517], "torch_load": 162, "mixed_precis": [164, 319], "pattern_detector": 166, "symbolic_trac": 168, "teq": [169, 537], "algorithm": [172, 173, 174, 175, 176, 383, 384, 385, 386, 387, 388, 389, 390, 391, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 593, 658, 661, 664], "fast_bias_correct": 173, "weight_correct": 176, "benchmark": [177, 263, 583, 592, 598, 613, 654], "common": [178, 179, 180, 181, 182, 183, 184, 185, 264, 265, 266, 267, 268, 269, 270, 271, 571, 604], "base_config": 178, "attribut": [178, 179, 180, 184, 239, 247, 256, 290, 299, 310, 334, 374, 396, 399, 401, 443, 526, 538, 558, 569], "base_tun": 179, "tuning_param": 181, "constant": [182, 357, 437, 503, 550, 556], "logger": [184, 340, 561, 594], "compress": [186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 273, 584, 658], "callback": 186, "distil": [187, 188, 189, 190, 304, 599, 600, 613, 654, 667], "criterion": [187, 264], "optim": [189, 269, 529, 623, 633, 643, 646, 647, 648, 651, 652, 665], "hpo": [191, 192, 193, 194], "sa_optim": 192, "search_algorithm": [193, 326], "search_spac": 194, "pruner": [196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 332, 343], "criteria": [196, 570, 652, 664], "dsnot": 197, "model_slim": [199, 200, 201, 202], "auto_slim": 199, "pattern_analyz": 201, "weight_slim": 202, "pattern": [203, 204, 205, 206, 207, 335, 336, 337, 341, 652], "base": [203, 208, 609, 642, 665], "mha": [205, 212], "ninm": 206, "nxm": 207, "basic": [209, 349, 427, 572, 664], "pattern_lock": [213, 331], "progress": [214, 639], "retrain_fre": 215, "sparse_gpt": 216, "prune": [217, 223, 333, 344, 613, 652, 654, 667], "reg": 218, "schedul": [219, 345, 347, 652], "tf_criteria": 220, "wanda": [222, 223, 224, 225], "wrapper": 225, "conf": [226, 227, 228, 229], "config": [226, 230, 396, 461, 526, 546, 585, 596, 650], "dotdict": 227, "pythonic_config": 229, "contrib": [231, 232, 233, 234, 274, 275, 276, 277], "strategi": [232, 233, 234, 275, 276, 277, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 590, 660, 664], "sigopt": [233, 276, 660, 664], "tpe": [234, 277, 664], "data": [235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 504, 576, 577, 598, 602, 637], "dataload": [235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 265, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 595, 596], "base_dataload": [235, 278], "default_dataload": [237, 280], "fetcher": [238, 281], "mxnet_dataload": [240, 283], "onnxrt_dataload": [241, 284], "pytorch_dataload": [242, 285], "sampler": [243, 286], "tensorflow_dataload": [244, 287], "dataset": [245, 246, 247, 248, 249, 250, 251, 252, 288, 289, 290, 291, 292, 293, 294, 295, 596, 598, 607, 638], "bert_dataset": [245, 288], "coco_dataset": [246, 289], "dummy_dataset": [248, 291], "dummy_dataset_v2": [249, 292], "imagenet_dataset": [250, 293], "style_transfer_dataset": [252, 295], "filter": [253, 254, 255, 296, 297, 298], "coco_filt": [253, 296], "transform": [257, 258, 259, 260, 261, 262, 300, 301, 302, 303, 607, 663], "coco_transform": 257, "imagenet_transform": [258, 300], "postprocess": [260, 270], "token": [261, 302], "experiment": [263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362], "metric": [267, 311, 312, 313, 314, 315, 316, 317, 318, 364, 365, 366, 367, 368, 369, 370, 371, 607, 612], "model": [268, 373, 374, 375, 376, 377, 378, 379, 380, 381, 506, 576, 587, 603, 606, 609, 611, 613, 615, 622, 636, 637, 638, 646, 647, 648, 652, 656, 658, 661, 667], "compon": 272, "qlinear2qdq": 306, "tf2onnx": 307, "torch2onnx": 308, "graph_optim": 309, "bleu": [311, 364], "bleu_util": [312, 365], "coco_label_map": [313, 366], "coco_tool": [314, 367], "evaluate_squad": [315, 368], "f1": [316, 369], "model_convers": 320, "na": [321, 322, 323, 324, 325, 326, 572, 654], "basic_na": 321, "dyna": 322, "nas_util": 325, "pruner_legaci": [327, 328, 329, 330, 331, 332], "gradient_sensit": 327, "group_lasso": 328, "magnitud": 330, "pruning_recip": [334, 335, 336, 337], "tile_pattern": 337, "pruning_v2": 338, "pytorch_prun": [339, 340, 341, 342, 343, 344, 345], "prune_util": 342, "auto_mixed_precis": [348, 426], "bayesian": [350, 428, 664], "exhaust": [351, 430, 664], "mse": [353, 433, 664], "mse_v2": [354, 434, 664], "random": [355, 435, 664], "tuning_sampl": [359, 439], "tuning_spac": [360, 440], "tuning_struct": [361, 441], "mix_precis": 372, "base_model": 373, "keras_model": 375, "mxnet_model": 377, "nets_factori": [378, 508], "onnx_model": [379, 400], "tensorflow_model": 380, "torch_model": 381, "object": [382, 588, 646, 647, 648, 650], "smoother": [384, 385, 386, 446, 447, 448, 449], "core": [385, 447, 527], "rtn": [390, 536], "algorithm_entri": [393, 460, 544], "autotun": [394, 545], "profil": [402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 598], "parser": [403, 404, 405, 406, 407, 408, 409, 410, 411, 412], "factori": [403, 405, 410, 413, 415, 420], "onnx_pars": [405, 406, 407], "result": [409, 636, 638, 646, 647, 648], "tensorflow_pars": [410, 411, 412], "onnxrt_profil": [415, 416, 417, 418], "tensorflow_profil": [420, 421, 422, 423], "auto": [425, 627, 633, 657, 661, 664], "conserv": [429, 664], "hawq_v2": [431, 664], "templat": [443, 444, 570], "api_doc_exampl": 443, "scaler": 449, "static_qu": [450, 451, 452, 453, 454, 455, 456, 457, 458, 519, 520, 521], "torch": [510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 580, 667], "habana_fp8": [510, 511, 512, 513], "fp8_quant": 510, "observ": 513, "layer_wis": [515, 516, 517, 518], "load": 516, "hqq": [524, 525, 526, 527, 528, 529, 530, 531, 532, 533], "auto_acceler": 524, "bitpack": 525, "qtensor": 530, "quant_api": 531, "amp": [539, 540, 541, 542], "autocast": 539, "fp8": [540, 541], "environ": [551, 609, 619], "train": [554, 571, 591, 601, 613, 652, 655], "collect_layer_histogram": 555, "create_obj_from_config": 557, "kl_diverg": 559, "load_huggingfac": 560, "neural_insights_util": 562, "option": [563, 601, 621], "weights_detail": 566, "version": 567, "intel": [568, 574, 595, 598, 608, 609, 612, 613, 619, 627, 633, 667, 668], "neural": [568, 571, 572, 574, 595, 598, 608, 609, 612, 613, 616, 620, 622, 627, 633, 635, 636, 637, 638, 640, 641, 642, 646, 647, 648, 652, 660, 665, 668], "compressor": [568, 571, 574, 595, 598, 608, 609, 612, 613, 627, 633, 660, 668], "document": [568, 574, 581, 668], "section": [568, 668], "contributor": [569, 570], "coven": [569, 570], "code": [569, 570, 572, 594, 613, 634, 639, 658, 665], "conduct": [569, 570], "our": [569, 661], "pledg": 569, "standard": 569, "respons": [569, 642], "scope": [569, 652], "enforc": 569, "contribut": [570, 626, 630], "guidelin": 570, "creat": [570, 639], "pull": 570, "request": [570, 614, 644], "step": [570, 635, 636, 637, 638], "checklist": 570, "accept": 570, "statu": [570, 641, 642], "check": 570, "overview": [570, 643, 665], "support": [570, 571, 572, 575, 577, 592, 593, 595, 596, 598, 599, 600, 601, 603, 605, 608, 609, 612, 614, 615, 617, 618, 622, 623, 650, 651, 652, 654, 655, 656, 658, 661, 662, 663, 666], "fx": 571, "introduct": [571, 572, 575, 576, 577, 592, 593, 595, 596, 598, 599, 600, 601, 603, 605, 608, 612, 614, 615, 633, 636, 637, 638, 650, 651, 652, 654, 655, 656, 658, 660, 661, 662, 663, 664, 666], "mode": [571, 667], "matrix": [571, 572, 575, 592, 593, 595, 596, 598, 599, 600, 601, 603, 605, 608, 612, 614, 615, 618, 650, 651, 652, 654, 655, 656, 658, 661, 662, 666], "get": [571, 572, 574, 575, 592, 595, 596, 598, 599, 600, 601, 605, 606, 612, 614, 616, 627, 634, 635, 639, 640, 641, 642, 650, 651, 652, 654, 655, 662, 666], "start": [571, 572, 574, 575, 592, 595, 596, 598, 599, 600, 601, 605, 606, 612, 614, 616, 617, 621, 627, 635, 639, 640, 641, 646, 647, 648, 650, 651, 652, 654, 655, 662, 666], "post": [571, 613, 642, 655], "static": [571, 655], "dynam": [571, 572, 655], "awar": [571, 613, 652, 655], "exampl": [571, 572, 575, 581, 592, 595, 596, 598, 599, 600, 601, 602, 603, 612, 613, 614, 615, 618, 622, 635, 636, 637, 638, 640, 645, 646, 647, 648, 650, 651, 652, 655, 656, 658, 661, 662, 667], "note": [571, 659], "detail": 571, "problem": 571, "architectur": [572, 597, 608, 609], "search": [572, 633], "api": [572, 574, 575, 576, 581, 582, 592, 595, 596, 599, 600, 601, 606, 607, 612, 614, 616, 620, 634, 635, 642, 648, 650, 651, 652, 654, 665], "usag": [572, 622, 633, 642, 661, 662, 664], "1": [572, 601, 604, 607, 613, 633, 640, 641, 667], "python": [572, 574, 595, 606, 612, 616, 620, 621, 628, 631, 635, 654, 665], "yaml": [572, 576, 596, 601, 605, 666], "2": [572, 601, 604, 607, 613, 633, 640, 641, 667], "onli": [572, 658], "advanc": [572, 639, 665], "custom": [572, 595, 612, 646, 664], "secur": [573, 601], "polici": [573, 664], "report": 573, "vulner": 573, "instal": [574, 598, 609, 617, 619, 626, 627, 630, 635, 640, 641], "from": [574, 576, 609, 613, 635, 640, 641], "pypi": [574, 622, 635], "select": [574, 627], "public": [574, 594, 653], "event": [574, 653], "addit": 574, "commun": 574, "work": [575, 640, 655], "flow": [575, 655], "background": [575, 594, 633], "ad": 575, "new": [575, 577, 628, 631, 664], "backend": [575, 655], "capabl": [575, 658], "implement": [575, 576], "onnxrtadaptor": 575, "how": [576, 577, 598, 636, 637, 638, 640], "add": [576, 641], "an": [576, 646, 647, 648], "list": [576, 602, 645, 663], "need": 576, "design": [576, 597, 643, 664], "framework": [576, 595, 596, 603, 605, 615, 654, 656, 658, 661], "query_fw_cap": 576, "accord": [576, 577], "tune_cfg": 576, "prepar": [576, 598, 636, 637, 638, 660], "fp32": [576, 603], "graph": 576, "run": [576, 598, 634, 636, 637, 638, 639], "sampl": [576, 606], "iter": 576, "calcul": 576, "rang": 576, "type": [577, 594, 652], "like": 577, "int4": 577, "few": 577, "line": 577, "chang": [577, 607, 632, 634, 659], "defin": [577, 601], "abil": 577, "specif": [577, 596], "invok": 577, "kernel": 577, "tune": [577, 655, 658, 661, 664], "configur": [577, 601, 605, 639, 654, 660, 666], "us": [577, 595, 612, 640, 641, 661], "summari": [577, 636], "runtim": [579, 609, 655, 656, 667], "mix": [586, 613, 614, 657], "precis": [586, 613, 614, 657], "refer": [593, 594, 652, 655, 658, 661], "inc": 594, "convent": 594, "rule": [594, 655], "import": 594, "string": 594, "annot": 594, "comment": 594, "todo": 594, "intern": 594, "interfac": 594, "folder": [594, 634], "structur": 594, "recommend": 594, "v": [594, 634], "set": [594, 598, 619, 633], "json": 594, "build": [595, 604, 612, 639, 640, 641], "file": [596, 605, 666], "user": [596, 601, 607, 654, 658, 665, 666], "workflow": [597, 643], "diagnosi": [598, 635], "featur": [598, 601, 605, 608, 622, 623, 627, 654, 655, 662, 666], "modifi": 598, "script": [598, 639], "see": 598, "do": [598, 616], "paramet": [598, 642], "descript": [598, 642, 644], "suggest": 598, "fallback": 598, "knowledg": [599, 667], "intermedi": 599, "layer": [599, 656, 661], "self": 599, "distribut": [601, 622, 664], "infer": 601, "evalu": 601, "pure": 601, "horovodrun": 601, "execut": 601, "releas": [602, 628, 631, 659], "appendix": 603, "frequent": 604, "ask": 604, "question": 604, "issu": [604, 659], "3": [604, 617, 633], "4": [604, 624, 633, 653], "quick": [606, 621], "valid": [606, 609, 661, 667], "incompat": [607, 659], "between": 607, "v1": 607, "face": [607, 647, 648], "built": [607, 609, 612], "infrastructur": 608, "prerequisit": [609, 640, 641], "binari": 609, "sourc": [609, 635, 637, 638, 640, 641], "ai": 609, "kit": 609, "system": 609, "requir": [609, 626, 630, 636, 637, 638, 646], "hardwar": [609, 614, 667], "cpu": [609, 619, 667], "64": 609, "compat": 609, "processor": 609, "gpu": 609, "": [609, 634, 640], "xe": 609, "multipl": [609, 650, 667], "vendor": 609, "through": [609, 661, 667], "softwar": [609, 614], "legal": 610, "inform": 610, "licens": 610, "citat": 610, "trademark": 610, "llm": 611, "recip": [611, 655], "ipex": [611, 655], "kei": 611, "migrat": 613, "x": 613, "orchestr": [613, 651], "fp16": 614, "dure": [614, 657], "accuraci": [614, 636, 638, 655, 664], "driven": 614, "coder": [616, 620, 622, 633, 665], "what": [616, 634, 640], "we": 616, "offer": 616, "jupyt": [616, 617, 628, 631], "lab": [616, 617], "extens": [616, 626, 627, 630, 633, 634, 643, 667], "launcher": [616, 621], "contact": [616, 640], "aw": 617, "amazon": 617, "sagemak": 617, "For": 617, "studio": 617, "notebook": 617, "instanc": 617, "guid": [617, 665], "bigdl": 618, "nano": 618, "platform": [619, 660], "best": [619, 627], "perform": [619, 660], "mkl": 619, "openmp": 619, "jemalloc": 619, "numa": 619, "control": 619, "variabl": 619, "frequenc": 619, "govern": 619, "enabl": [620, 627, 633], "bench": 620, "superbench": 620, "argument": 621, "v0": 624, "highlight": 624, "other": 624, "changelog": [625, 629], "neural_compressor_ext_lab": [626, 628], "uninstal": [626, 630], "develop": [626, 630], "jupyterlab": 627, "Or": 627, "let": 627, "u": 627, "help": 627, "you": 627, "pre": 627, "requisit": 627, "make": [628, 631, 634, 639], "manual": [628, 631], "npm": [628, 631, 639], "autom": [628, 631], "publish": [628, 631], "conda": [628, 631], "forg": [628, 631], "neural_compressor_ext_lab_alibaba": [630, 631], "log": [632, 641, 642], "unreleas": 632, "vscode": 633, "open": [633, 638], "icon": 633, "5": 633, "welcom": 634, "your": 634, "setup": 634, "up": 634, "straight": 634, "awai": 634, "explor": 634, "test": [634, 639], "go": 634, "further": 634, "insight": [635, 636, 637, 638], "tensor": [635, 661], "dump": [635, 637], "research": 635, "collabor": 635, "debug": [636, 638], "analyz": [636, 638, 639], "weight": [636, 637, 638, 658], "histogram": 638, "react": 639, "app": 639, "avail": 639, "eject": 639, "learn": [639, 640], "more": [639, 640], "bundl": 639, "size": 639, "web": 639, "deploy": [639, 652], "fail": 639, "minifi": 639, "solut": [640, 641, 642, 646, 647, 648], "why": 640, "doe": 640, "method": [640, 641], "pip": [640, 641], "end": [640, 646, 647, 648], "servic": [641, 643, 646, 647, 648], "submit": [641, 642, 646, 647, 648], "task": [641, 642, 644, 646, 647, 648], "stop": [641, 646, 647, 648], "inspect": 641, "manag": [641, 646, 647], "resourc": [641, 646, 647], "node": 641, "state": 641, "cluster": [641, 642], "remov": 641, "url": 642, "endpoint": 642, "task_id": 642, "websocket": 642, "screen": 642, "ping": 642, "download": [642, 646, 647], "doc": 643, "wip": 643, "oaa": 643, "definit": 643, "diagram": 643, "hug": [647, 648], "grpc": 648, "client": 649, "singl": 650, "One": 651, "shot": 651, "network": 652, "sparsiti": 652, "decai": 652, "regular": 652, "larg": 652, "languag": 652, "retrain": 652, "free": 652, "spars": 652, "hyperparamet": 652, "full": 653, "79": 653, "2023": 653, "25": 653, "2022": 653, "35": 653, "2021": 653, "15": [653, 667], "2018": 653, "2020": 653, "style": 654, "access": 654, "fundament": [655, 661], "scheme": 655, "approach": 655, "With": 655, "without": 655, "specifi": 655, "devic": 655, "wise": 656, "lwq": 656, "turn": 657, "off": 657, "woq": [658, 667], "known": 659, "benefit": 660, "comparison": 660, "differ": 660, "smooth": 661, "quant": 661, "per": 661, "channel": 661, "limit": 661, "smoothquant": 661, "enhanc": 661, "alpha": 661, "engin": 661, "fix": 661, "determin": 661, "entir": 661, "each": 661, "block": 661, "tensorboard": 662, "space": 664, "exit": 664, "process": 664, "zero": 665, "topic": 665, "innov": 665, "product": 665, "13": 667, "0": 667, "ptq": 667}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"block_mask": [[0, "module-block_mask"]], "neural_compressor.adaptor.adaptor": [[1, "module-neural_compressor.adaptor.adaptor"]], "Module Contents": [[1, "module-contents"], [3, "module-contents"], [11, "module-contents"], [13, "module-contents"], [14, "module-contents"], [15, "module-contents"], [16, "module-contents"], [18, "module-contents"], [19, "module-contents"], [20, "module-contents"], [21, "module-contents"], [22, "module-contents"], [23, "module-contents"], [24, "module-contents"], [25, "module-contents"], [26, "module-contents"], [27, "module-contents"], [28, "module-contents"], [30, "module-contents"], [31, "module-contents"], [32, "module-contents"], [33, "module-contents"], [34, "module-contents"], [35, "module-contents"], [36, "module-contents"], [37, "module-contents"], [38, "module-contents"], [39, "module-contents"], [40, "module-contents"], [41, "module-contents"], [42, "module-contents"], [43, "module-contents"], [44, "module-contents"], [45, "module-contents"], [46, "module-contents"], [47, "module-contents"], [48, "module-contents"], [49, "module-contents"], [50, "module-contents"], [51, "module-contents"], [53, "module-contents"], [54, "module-contents"], [55, "module-contents"], [56, "module-contents"], [57, "module-contents"], [58, "module-contents"], [59, "module-contents"], [60, "module-contents"], [61, "module-contents"], [62, "module-contents"], [63, "module-contents"], [64, "module-contents"], [65, "module-contents"], [66, "module-contents"], [67, "module-contents"], [68, "module-contents"], [69, "module-contents"], [70, "module-contents"], [71, "module-contents"], [72, "module-contents"], [73, "module-contents"], [74, "module-contents"], [75, "module-contents"], [77, "module-contents"], [78, "module-contents"], [79, "module-contents"], [80, "module-contents"], [81, "module-contents"], [82, "module-contents"], [83, "module-contents"], [84, "module-contents"], [85, "module-contents"], [86, "module-contents"], [88, "module-contents"], [89, "module-contents"], [90, "module-contents"], [91, "module-contents"], [92, "module-contents"], [93, "module-contents"], [94, "module-contents"], [96, "module-contents"], [97, "module-contents"], [98, "module-contents"], [99, "module-contents"], [100, "module-contents"], [102, "module-contents"], [103, "module-contents"], [104, "module-contents"], [105, "module-contents"], [107, "module-contents"], [108, "module-contents"], [109, "module-contents"], [110, "module-contents"], [113, "module-contents"], [115, "module-contents"], [116, "module-contents"], [118, "module-contents"], [119, "module-contents"], [120, "module-contents"], [121, "module-contents"], [122, "module-contents"], [123, "module-contents"], [124, "module-contents"], [125, "module-contents"], [126, "module-contents"], [127, "module-contents"], [128, "module-contents"], [129, "module-contents"], [131, "module-contents"], [132, "module-contents"], [133, "module-contents"], [134, "module-contents"], [135, "module-contents"], [136, "module-contents"], [137, "module-contents"], [138, "module-contents"], [139, "module-contents"], [140, "module-contents"], [141, "module-contents"], [142, "module-contents"], [143, "module-contents"], [144, "module-contents"], [146, "module-contents"], [147, "module-contents"], [148, "module-contents"], [149, "module-contents"], [150, "module-contents"], [153, "module-contents"], [154, "module-contents"], [155, "module-contents"], [156, "module-contents"], [157, "module-contents"], [160, "module-contents"], [161, "module-contents"], [162, "module-contents"], [163, "module-contents"], [164, "module-contents"], [165, "module-contents"], [166, "module-contents"], [167, "module-contents"], [168, "module-contents"], [169, "module-contents"], [170, "module-contents"], [171, "module-contents"], [172, "module-contents"], [173, "module-contents"], [175, "module-contents"], [176, "module-contents"], [177, "module-contents"], [178, "module-contents"], [179, "module-contents"], [181, "module-contents"], [184, "module-contents"], [185, "module-contents"], [186, "module-contents"], [187, "module-contents"], [189, "module-contents"], [190, "module-contents"], [193, "module-contents"], [194, "module-contents"], [196, "module-contents"], [197, "module-contents"], [199, "module-contents"], [201, "module-contents"], [202, "module-contents"], [203, "module-contents"], [205, "module-contents"], [206, "module-contents"], [207, "module-contents"], [208, "module-contents"], [209, "module-contents"], [210, "module-contents"], [212, "module-contents"], [213, "module-contents"], [214, "module-contents"], [215, "module-contents"], [216, "module-contents"], [217, "module-contents"], [218, "module-contents"], [219, "module-contents"], [220, "module-contents"], [221, "module-contents"], [223, "module-contents"], [224, "module-contents"], [225, "module-contents"], [226, "module-contents"], [227, "module-contents"], [229, "module-contents"], [230, "module-contents"], [233, "module-contents"], [234, "module-contents"], [235, "module-contents"], [236, "module-contents"], [237, "module-contents"], [238, "module-contents"], [240, "module-contents"], [241, "module-contents"], [242, "module-contents"], [243, "module-contents"], [244, "module-contents"], [245, "module-contents"], [246, "module-contents"], [247, "module-contents"], [248, "module-contents"], [249, "module-contents"], [250, "module-contents"], [252, "module-contents"], [253, "module-contents"], [254, "module-contents"], [257, "module-contents"], [258, "module-contents"], [260, "module-contents"], [261, "module-contents"], [262, "module-contents"], [263, "module-contents"], [264, "module-contents"], [265, "module-contents"], [267, "module-contents"], [268, "module-contents"], [269, "module-contents"], [270, "module-contents"], [271, "module-contents"], [272, "module-contents"], [276, "module-contents"], [277, "module-contents"], [278, "module-contents"], [280, "module-contents"], [281, "module-contents"], [283, "module-contents"], [284, "module-contents"], [285, "module-contents"], [286, "module-contents"], [287, "module-contents"], [288, "module-contents"], [289, "module-contents"], [290, "module-contents"], [291, "module-contents"], [292, "module-contents"], [293, "module-contents"], [295, "module-contents"], [296, "module-contents"], [297, "module-contents"], [300, "module-contents"], [302, "module-contents"], [303, "module-contents"], [304, "module-contents"], [306, "module-contents"], [307, "module-contents"], [308, "module-contents"], [309, "module-contents"], [311, "module-contents"], [312, "module-contents"], [314, "module-contents"], [315, "module-contents"], [316, "module-contents"], [318, "module-contents"], [319, "module-contents"], [320, "module-contents"], [321, "module-contents"], [322, "module-contents"], [324, "module-contents"], [325, "module-contents"], [326, "module-contents"], [327, "module-contents"], [328, "module-contents"], [330, "module-contents"], [331, "module-contents"], [332, "module-contents"], [333, "module-contents"], [336, "module-contents"], [337, "module-contents"], [338, "module-contents"], [341, "module-contents"], [342, "module-contents"], [343, "module-contents"], [344, "module-contents"], [345, "module-contents"], [346, "module-contents"], [347, "module-contents"], [348, "module-contents"], [349, "module-contents"], [350, "module-contents"], [351, "module-contents"], [353, "module-contents"], [354, "module-contents"], [355, "module-contents"], [356, "module-contents"], [359, "module-contents"], [360, "module-contents"], [361, "module-contents"], [362, "module-contents"], [364, "module-contents"], [365, "module-contents"], [367, "module-contents"], [368, "module-contents"], [369, "module-contents"], [371, "module-contents"], [372, "module-contents"], [373, "module-contents"], [375, "module-contents"], [376, "module-contents"], [377, "module-contents"], [378, "module-contents"], [379, "module-contents"], [380, "module-contents"], [381, "module-contents"], [382, "module-contents"], [384, "module-contents"], [385, "module-contents"], [387, "module-contents"], [388, "module-contents"], [390, "module-contents"], [391, "module-contents"], [393, "module-contents"], [394, "module-contents"], [395, "module-contents"], [396, "module-contents"], [400, "module-contents"], [401, "module-contents"], [403, "module-contents"], [405, "module-contents"], [407, "module-contents"], [408, "module-contents"], [409, "module-contents"], [410, "module-contents"], [412, "module-contents"], [413, "module-contents"], [415, "module-contents"], [417, "module-contents"], [418, "module-contents"], [419, "module-contents"], [420, "module-contents"], [422, "module-contents"], [423, "module-contents"], [424, "module-contents"], [425, "module-contents"], [426, "module-contents"], [427, "module-contents"], [428, "module-contents"], [429, "module-contents"], [430, "module-contents"], [431, "module-contents"], [433, "module-contents"], [434, "module-contents"], [435, "module-contents"], [436, "module-contents"], [439, "module-contents"], [440, "module-contents"], [441, "module-contents"], [442, "module-contents"], [443, "module-contents"], [446, "module-contents"], [447, "module-contents"], [449, "module-contents"], [451, "module-contents"], [460, "module-contents"], [461, "module-contents"], [463, "module-contents"], [464, "module-contents"], [465, "module-contents"], [466, "module-contents"], [467, "module-contents"], [468, "module-contents"], [469, "module-contents"], [470, "module-contents"], [471, "module-contents"], [472, "module-contents"], [473, "module-contents"], [474, "module-contents"], [475, "module-contents"], [476, "module-contents"], [477, "module-contents"], [478, "module-contents"], [479, "module-contents"], [480, "module-contents"], [481, "module-contents"], [482, "module-contents"], [483, "module-contents"], [484, "module-contents"], [485, "module-contents"], [486, "module-contents"], [488, "module-contents"], [489, "module-contents"], [490, "module-contents"], [491, "module-contents"], [492, "module-contents"], [493, "module-contents"], [494, "module-contents"], [495, "module-contents"], [496, "module-contents"], [497, "module-contents"], [499, "module-contents"], [501, "module-contents"], [502, "module-contents"], [504, "module-contents"], [506, "module-contents"], [507, "module-contents"], [508, "module-contents"], [509, "module-contents"], [516, "module-contents"], [517, "module-contents"], [518, "module-contents"], [520, "module-contents"], [521, "module-contents"], [522, "module-contents"], [523, "module-contents"], [524, "module-contents"], [525, "module-contents"], [526, "module-contents"], [527, "module-contents"], [530, "module-contents"], [531, "module-contents"], [533, "module-contents"], [535, "module-contents"], [536, "module-contents"], [537, "module-contents"], [538, "module-contents"], [539, "module-contents"], [544, "module-contents"], [545, "module-contents"], [546, "module-contents"], [549, "module-contents"], [553, "module-contents"], [554, "module-contents"], [555, "module-contents"], [557, "module-contents"], [559, "module-contents"], [560, "module-contents"], [561, "module-contents"], [562, "module-contents"], [563, "module-contents"], [564, "module-contents"], [565, "module-contents"], [566, "module-contents"]], "Classes": [[1, "classes"], [3, "classes"], [11, "classes"], [13, "classes"], [14, "classes"], [15, "classes"], [16, "classes"], [18, "classes"], [19, "classes"], [20, "classes"], [21, "classes"], [22, "classes"], [23, "classes"], [24, "classes"], [25, "classes"], [26, "classes"], [27, "classes"], [28, "classes"], [30, "classes"], [31, "classes"], [32, "classes"], [33, "classes"], [34, "classes"], [35, "classes"], [36, "classes"], [37, "classes"], [38, "classes"], [39, "classes"], [40, "classes"], [41, "classes"], [42, "classes"], [43, "classes"], [45, "classes"], [46, "classes"], [47, "classes"], [48, "classes"], [49, "classes"], [50, "classes"], [51, "classes"], [53, "classes"], [54, "classes"], [55, "classes"], [56, "classes"], [57, "classes"], [58, "classes"], [59, "classes"], [60, "classes"], [61, "classes"], [62, "classes"], [63, "classes"], [64, "classes"], [65, "classes"], [66, "classes"], [67, "classes"], [68, "classes"], [69, "classes"], [70, "classes"], [71, "classes"], [72, "classes"], [73, "classes"], [74, "classes"], [75, "classes"], [77, "classes"], [78, "classes"], [79, "classes"], [80, "classes"], [81, "classes"], [82, "classes"], [83, "classes"], [84, "classes"], [85, "classes"], [86, "classes"], [88, "classes"], [89, "classes"], [90, "classes"], [91, "classes"], [92, "classes"], [93, "classes"], [94, "classes"], [96, "classes"], [97, "classes"], [98, "classes"], [99, "classes"], [100, "classes"], [102, "classes"], [103, "classes"], [104, "classes"], [105, "classes"], [107, "classes"], [108, "classes"], [109, "classes"], [110, "classes"], [113, "classes"], [115, "classes"], [119, "classes"], [120, "classes"], [121, "classes"], [122, "classes"], [123, "classes"], [124, "classes"], [125, "classes"], [126, "classes"], [127, "classes"], [128, "classes"], [129, "classes"], [131, "classes"], [132, "classes"], [133, "classes"], [134, "classes"], [135, "classes"], [136, "classes"], [137, "classes"], [138, "classes"], [139, "classes"], [140, "classes"], [141, "classes"], [142, "classes"], [143, "classes"], [144, "classes"], [146, "classes"], [147, "classes"], [149, "classes"], [153, "classes"], [154, "classes"], [155, "classes"], [156, "classes"], [157, "classes"], [161, "classes"], [165, "classes"], [166, "classes"], [167, "classes"], [169, "classes"], [172, "classes"], [173, "classes"], [174, "classes"], [175, "classes"], [176, "classes"], [178, "classes"], [179, "classes"], [180, "classes"], [181, "classes"], [184, "classes"], [186, "classes"], [187, "classes"], [189, "classes"], [193, "classes"], [194, "classes"], [196, "classes"], [201, "classes"], [202, "classes"], [203, "classes"], [205, "classes"], [206, "classes"], [207, "classes"], [208, "classes"], [209, "classes"], [210, "classes"], [212, "classes"], [213, "classes"], [214, "classes"], [215, "classes"], [216, "classes"], [217, "classes"], [218, "classes"], [219, "classes"], [220, "classes"], [225, "classes"], [226, "classes"], [227, "classes"], [229, "classes"], [230, "classes"], [233, "classes"], [234, "classes"], [235, "classes"], [236, "classes"], [237, "classes"], [238, "classes"], [239, "classes"], [240, "classes"], [241, "classes"], [242, "classes"], [243, "classes"], [244, "classes"], [245, "classes"], [246, "classes"], [247, "classes"], [248, "classes"], [249, "classes"], [250, "classes"], [251, "classes"], [252, "classes"], [253, "classes"], [254, "classes"], [255, "classes"], [256, "classes"], [257, "classes"], [258, "classes"], [259, "classes"], [260, "classes"], [261, "classes"], [262, "classes"], [263, "classes"], [264, "classes"], [265, "classes"], [266, "classes"], [267, "classes"], [268, "classes"], [269, "classes"], [270, "classes"], [272, "classes"], [276, "classes"], [277, "classes"], [278, "classes"], [280, "classes"], [281, "classes"], [283, "classes"], [284, "classes"], [285, "classes"], [286, "classes"], [287, "classes"], [288, "classes"], [289, "classes"], [290, "classes"], [291, "classes"], [292, "classes"], [293, "classes"], [294, "classes"], [295, "classes"], [296, "classes"], [297, "classes"], [298, "classes"], [299, "classes"], [300, "classes"], [301, "classes"], [302, "classes"], [303, "classes"], [304, "classes"], [309, "classes"], [310, "classes"], [311, "classes"], [314, "classes"], [317, "classes"], [318, "classes"], [319, "classes"], [320, "classes"], [321, "classes"], [322, "classes"], [324, "classes"], [326, "classes"], [327, "classes"], [328, "classes"], [330, "classes"], [331, "classes"], [332, "classes"], [333, "classes"], [334, "classes"], [335, "classes"], [336, "classes"], [337, "classes"], [338, "classes"], [341, "classes"], [343, "classes"], [344, "classes"], [345, "classes"], [346, "classes"], [347, "classes"], [348, "classes"], [349, "classes"], [350, "classes"], [351, "classes"], [353, "classes"], [354, "classes"], [355, "classes"], [356, "classes"], [359, "classes"], [360, "classes"], [361, "classes"], [362, "classes"], [364, "classes"], [367, "classes"], [370, "classes"], [371, "classes"], [373, "classes"], [374, "classes"], [375, "classes"], [376, "classes"], [377, "classes"], [378, "classes"], [379, "classes"], [380, "classes"], [381, "classes"], [382, "classes"], [383, "classes"], [384, "classes"], [385, "classes"], [386, "classes"], [392, "classes"], [395, "classes"], [396, "classes"], [397, "classes"], [399, "classes"], [400, "classes"], [403, "classes"], [405, "classes"], [407, "classes"], [408, "classes"], [409, "classes"], [410, "classes"], [412, "classes"], [413, "classes"], [415, "classes"], [417, "classes"], [419, "classes"], [420, "classes"], [422, "classes"], [425, "classes"], [426, "classes"], [427, "classes"], [428, "classes"], [429, "classes"], [430, "classes"], [431, "classes"], [433, "classes"], [434, "classes"], [435, "classes"], [436, "classes"], [439, "classes"], [440, "classes"], [441, "classes"], [442, "classes"], [443, "classes"], [446, "classes"], [447, "classes"], [449, "classes"], [451, "classes"], [461, "classes"], [464, "classes"], [465, "classes"], [466, "classes"], [467, "classes"], [468, "classes"], [469, "classes"], [470, "classes"], [471, "classes"], [472, "classes"], [473, "classes"], [474, "classes"], [475, "classes"], [476, "classes"], [477, "classes"], [478, "classes"], [479, "classes"], [480, "classes"], [481, "classes"], [482, "classes"], [483, "classes"], [484, "classes"], [485, "classes"], [486, "classes"], [488, "classes"], [489, "classes"], [490, "classes"], [491, "classes"], [492, "classes"], [493, "classes"], [494, "classes"], [495, "classes"], [496, "classes"], [497, "classes"], [499, "classes"], [501, "classes"], [504, "classes"], [506, "classes"], [507, "classes"], [508, "classes"], [509, "classes"], [521, "classes"], [522, "classes"], [523, "classes"], [524, "classes"], [525, "classes"], [526, "classes"], [527, "classes"], [530, "classes"], [535, "classes"], [537, "classes"], [538, "classes"], [539, "classes"], [546, "classes"], [554, "classes"], [555, "classes"], [558, "classes"], [559, "classes"], [560, "classes"], [561, "classes"], [563, "classes"], [565, "classes"], [566, "classes"]], "Functions": [[1, "functions"], [13, "functions"], [16, "functions"], [34, "functions"], [42, "functions"], [43, "functions"], [44, "functions"], [45, "functions"], [67, "functions"], [68, "functions"], [70, "functions"], [104, "functions"], [105, "functions"], [116, "functions"], [118, "functions"], [148, "functions"], [149, "functions"], [150, "functions"], [153, "functions"], [155, "functions"], [156, "functions"], [157, "functions"], [162, "functions"], [163, "functions"], [164, "functions"], [167, "functions"], [168, "functions"], [170, "functions"], [171, "functions"], [172, "functions"], [174, "functions"], [177, "functions"], [178, "functions"], [179, "functions"], [180, "functions"], [185, "functions"], [187, "functions"], [189, "functions"], [190, "functions"], [193, "functions"], [194, "functions"], [196, "functions"], [197, "functions"], [198, "functions"], [199, "functions"], [201, "functions"], [203, "functions"], [204, "functions"], [208, "functions"], [211, "functions"], [217, "functions"], [218, "functions"], [219, "functions"], [220, "functions"], [221, "functions"], [223, "functions"], [224, "functions"], [227, "functions"], [236, "functions"], [237, "functions"], [245, "functions"], [247, "functions"], [251, "functions"], [254, "functions"], [255, "functions"], [256, "functions"], [259, "functions"], [261, "functions"], [262, "functions"], [263, "functions"], [264, "functions"], [266, "functions"], [268, "functions"], [269, "functions"], [271, "functions"], [280, "functions"], [288, "functions"], [290, "functions"], [294, "functions"], [297, "functions"], [298, "functions"], [299, "functions"], [301, "functions"], [302, "functions"], [303, "functions"], [306, "functions"], [307, "functions"], [308, "functions"], [311, "functions"], [312, "functions"], [314, "functions"], [315, "functions"], [316, "functions"], [317, "functions"], [318, "functions"], [325, "functions"], [332, "functions"], [336, "functions"], [341, "functions"], [342, "functions"], [343, "functions"], [345, "functions"], [350, "functions"], [356, "functions"], [360, "functions"], [362, "functions"], [364, "functions"], [365, "functions"], [367, "functions"], [368, "functions"], [369, "functions"], [370, "functions"], [371, "functions"], [372, "functions"], [376, "functions"], [380, "functions"], [382, "functions"], [383, "functions"], [387, "functions"], [388, "functions"], [390, "functions"], [391, "functions"], [392, "functions"], [393, "functions"], [394, "functions"], [396, "functions"], [397, "functions"], [401, "functions"], [418, "functions"], [423, "functions"], [424, "functions"], [428, "functions"], [436, "functions"], [440, "functions"], [442, "functions"], [443, "functions"], [460, "functions"], [461, "functions"], [463, "functions"], [478, "functions"], [479, "functions"], [481, "functions"], [502, "functions"], [507, "functions"], [509, "functions"], [516, "functions"], [518, "functions"], [520, "functions"], [521, "functions"], [522, "functions"], [523, "functions"], [524, "functions"], [531, "functions"], [533, "functions"], [536, "functions"], [537, "functions"], [538, "functions"], [544, "functions"], [545, "functions"], [546, "functions"], [549, "functions"], [553, "functions"], [554, "functions"], [557, "functions"], [558, "functions"], [560, "functions"], [561, "functions"], [562, "functions"], [564, "functions"], [565, "functions"]], "neural_compressor.adaptor": [[2, "module-neural_compressor.adaptor"]], "Subpackages": [[2, "subpackages"], [17, "subpackages"], [87, "subpackages"], [111, "subpackages"], [112, "subpackages"], [114, "subpackages"], [158, "subpackages"], [195, "subpackages"], [198, "subpackages"], [231, "subpackages"], [256, "subpackages"], [274, "subpackages"], [299, "subpackages"], [310, "subpackages"], [334, "subpackages"], [352, "subpackages"], [363, "subpackages"], [432, "subpackages"], [498, "subpackages"], [514, "subpackages"]], "Submodules": [[2, "submodules"], [12, "submodules"], [17, "submodules"], [29, "submodules"], [52, "submodules"], [76, "submodules"], [87, "submodules"], [95, "submodules"], [101, "submodules"], [106, "submodules"], [111, "submodules"], [112, "submodules"], [114, "submodules"], [117, "submodules"], [130, "submodules"], [145, "submodules"], [151, "submodules"], [158, "submodules"], [159, "submodules"], [174, "submodules"], [183, "submodules"], [188, "submodules"], [191, "submodules"], [195, "submodules"], [198, "submodules"], [200, "submodules"], [204, "submodules"], [211, "submodules"], [222, "submodules"], [228, "submodules"], [232, "submodules"], [239, "submodules"], [251, "submodules"], [255, "submodules"], [259, "submodules"], [266, "submodules"], [275, "submodules"], [282, "submodules"], [294, "submodules"], [298, "submodules"], [301, "submodules"], [305, "submodules"], [310, "submodules"], [317, "submodules"], [323, "submodules"], [329, "submodules"], [335, "submodules"], [339, "submodules"], [352, "submodules"], [358, "submodules"], [363, "submodules"], [370, "submodules"], [374, "submodules"], [386, "submodules"], [399, "submodules"], [404, "submodules"], [406, "submodules"], [411, "submodules"], [414, "submodules"], [416, "submodules"], [421, "submodules"], [432, "submodules"], [438, "submodules"], [444, "submodules"], [448, "submodules"], [487, "submodules"], [498, "submodules"], [500, "submodules"], [505, "submodules"], [515, "submodules"], [528, "submodules"], [534, "submodules"], [547, "submodules"], [558, "submodules"]], "Package Contents": [[2, "package-contents"], [29, "package-contents"], [174, "package-contents"], [180, "package-contents"], [198, "package-contents"], [204, "package-contents"], [211, "package-contents"], [239, "package-contents"], [251, "package-contents"], [255, "package-contents"], [256, "package-contents"], [259, "package-contents"], [266, "package-contents"], [282, "package-contents"], [294, "package-contents"], [298, "package-contents"], [299, "package-contents"], [301, "package-contents"], [310, "package-contents"], [317, "package-contents"], [329, "package-contents"], [334, "package-contents"], [335, "package-contents"], [352, "package-contents"], [370, "package-contents"], [374, "package-contents"], [383, "package-contents"], [386, "package-contents"], [392, "package-contents"], [397, "package-contents"], [399, "package-contents"], [432, "package-contents"], [558, "package-contents"]], "neural_compressor.adaptor.keras": [[3, "module-neural_compressor.adaptor.keras"]], "neural_compressor.adaptor.keras_utils.conv2d": [[4, "module-neural_compressor.adaptor.keras_utils.conv2d"]], "neural_compressor.adaptor.keras_utils.dense": [[5, "module-neural_compressor.adaptor.keras_utils.dense"]], "neural_compressor.adaptor.keras_utils.depthwise_conv2d": [[6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"]], "neural_compressor.adaptor.keras_utils": [[7, "module-neural_compressor.adaptor.keras_utils"]], "neural_compressor.adaptor.keras_utils.pool2d": [[8, "module-neural_compressor.adaptor.keras_utils.pool2d"]], "neural_compressor.adaptor.keras_utils.quantizer": [[9, "module-neural_compressor.adaptor.keras_utils.quantizer"]], "neural_compressor.adaptor.keras_utils.separable_conv2d": [[10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"]], "neural_compressor.adaptor.mxnet": [[11, "module-neural_compressor.adaptor.mxnet"]], "neural_compressor.adaptor.mxnet_utils": [[12, "module-neural_compressor.adaptor.mxnet_utils"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, "module-neural_compressor.adaptor.mxnet_utils.util"]], "neural_compressor.adaptor.onnxrt": [[14, "module-neural_compressor.adaptor.onnxrt"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, "module-neural_compressor.adaptor.ox_utils.calibration"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, "module-neural_compressor.adaptor.ox_utils.calibrator"]], "neural_compressor.adaptor.ox_utils": [[17, "module-neural_compressor.adaptor.ox_utils"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, "module-neural_compressor.adaptor.ox_utils.operators.activation"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, "module-neural_compressor.adaptor.ox_utils.operators.attention"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, "module-neural_compressor.adaptor.ox_utils.operators.concat"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, "module-neural_compressor.adaptor.ox_utils.operators.conv"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, "module-neural_compressor.adaptor.ox_utils.operators.gather"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"]], "neural_compressor.adaptor.ox_utils.operators": [[29, "module-neural_compressor.adaptor.ox_utils.operators"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, "module-neural_compressor.adaptor.ox_utils.operators.norm"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, "module-neural_compressor.adaptor.ox_utils.operators.ops"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, "module-neural_compressor.adaptor.ox_utils.operators.pad"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, "module-neural_compressor.adaptor.ox_utils.operators.resize"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, "module-neural_compressor.adaptor.ox_utils.operators.split"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, "module-neural_compressor.adaptor.ox_utils.quantizer"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"]], "neural_compressor.adaptor.ox_utils.util": [[43, "module-neural_compressor.adaptor.ox_utils.util"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, "module-neural_compressor.adaptor.ox_utils.weight_only"]], "neural_compressor.adaptor.pytorch": [[45, "module-neural_compressor.adaptor.pytorch"]], "neural_compressor.adaptor.query": [[46, "module-neural_compressor.adaptor.query"]], "neural_compressor.adaptor.tensorflow": [[47, "module-neural_compressor.adaptor.tensorflow"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, "module-neural_compressor.adaptor.tf_utils.graph_converter"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, "module-neural_compressor.adaptor.tf_utils.graph_util"]], "neural_compressor.adaptor.tf_utils": [[111, "module-neural_compressor.adaptor.tf_utils"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[145, "module-neural_compressor.adaptor.tf_utils.transform_graph"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"]], "neural_compressor.adaptor.tf_utils.util": [[148, "module-neural_compressor.adaptor.tf_utils.util"]], "neural_compressor.adaptor.torch_utils.autoround.autoround": [[149, "module-neural_compressor.adaptor.torch_utils.autoround.autoround"]], "neural_compressor.adaptor.torch_utils.autoround.export": [[150, "module-neural_compressor.adaptor.torch_utils.autoround.export"]], "neural_compressor.adaptor.torch_utils.autoround": [[151, "module-neural_compressor.adaptor.torch_utils.autoround"]], "neural_compressor.adaptor.torch_utils.autoround.model_wrapper": [[152, "module-neural_compressor.adaptor.torch_utils.autoround.model_wrapper"]], "neural_compressor.adaptor.torch_utils.autoround.sign_sgd": [[153, "module-neural_compressor.adaptor.torch_utils.autoround.sign_sgd"]], "neural_compressor.adaptor.torch_utils.awq": [[154, "module-neural_compressor.adaptor.torch_utils.awq"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[155, "module-neural_compressor.adaptor.torch_utils.bf16_convert"]], "neural_compressor.adaptor.torch_utils.gptq": [[156, "module-neural_compressor.adaptor.torch_utils.gptq"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[157, "module-neural_compressor.adaptor.torch_utils.hawq_metric"]], "neural_compressor.adaptor.torch_utils": [[158, "module-neural_compressor.adaptor.torch_utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[160, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[161, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[162, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[163, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[164, "module-neural_compressor.adaptor.torch_utils.mixed_precision"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[165, "module-neural_compressor.adaptor.torch_utils.model_wrapper"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[166, "module-neural_compressor.adaptor.torch_utils.pattern_detector"]], "neural_compressor.adaptor.torch_utils.smooth_quant": [[167, "module-neural_compressor.adaptor.torch_utils.smooth_quant"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[168, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"]], "neural_compressor.adaptor.torch_utils.teq": [[169, "module-neural_compressor.adaptor.torch_utils.teq"]], "neural_compressor.adaptor.torch_utils.util": [[170, "module-neural_compressor.adaptor.torch_utils.util"]], "}": [[170, "id3"]], "neural_compressor.adaptor.torch_utils.weight_only": [[171, "module-neural_compressor.adaptor.torch_utils.weight_only"]], "neural_compressor.algorithm.algorithm": [[172, "module-neural_compressor.algorithm.algorithm"]], "neural_compressor.algorithm.fast_bias_correction": [[173, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[174, "module-neural_compressor.algorithm"]], "neural_compressor.algorithm.smooth_quant": [[175, "module-neural_compressor.algorithm.smooth_quant"]], "neural_compressor.algorithm.weight_correction": [[176, "module-neural_compressor.algorithm.weight_correction"]], "neural_compressor.benchmark": [[177, "module-neural_compressor.benchmark"]], "neural_compressor.common.base_config": [[178, "module-neural_compressor.common.base_config"]], "Attributes": [[178, "attributes"], [179, "attributes"], [180, "attributes"], [184, "attributes"], [239, "attributes"], [247, "attributes"], [256, "attributes"], [290, "attributes"], [299, "attributes"], [310, "attributes"], [334, "attributes"], [374, "attributes"], [396, "attributes"], [399, "attributes"], [401, "attributes"], [443, "attributes"], [526, "attributes"], [538, "attributes"], [558, "attributes"]], "neural_compressor.common.base_tuning": [[179, "module-neural_compressor.common.base_tuning"]], "neural_compressor.common": [[180, "module-neural_compressor.common"]], "neural_compressor.common.tuning_param": [[181, "module-neural_compressor.common.tuning_param"]], "neural_compressor.common.utils.constants": [[182, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[183, "module-neural_compressor.common.utils"]], "neural_compressor.common.utils.logger": [[184, "module-neural_compressor.common.utils.logger"]], "neural_compressor.common.utils.utility": [[185, "module-neural_compressor.common.utils.utility"]], "neural_compressor.compression.callbacks": [[186, "module-neural_compressor.compression.callbacks"]], "neural_compressor.compression.distillation.criterions": [[187, "module-neural_compressor.compression.distillation.criterions"]], "neural_compressor.compression.distillation": [[188, "module-neural_compressor.compression.distillation"]], "neural_compressor.compression.distillation.optimizers": [[189, "module-neural_compressor.compression.distillation.optimizers"]], "neural_compressor.compression.distillation.utility": [[190, "module-neural_compressor.compression.distillation.utility"]], "neural_compressor.compression.hpo": [[191, "module-neural_compressor.compression.hpo"]], "neural_compressor.compression.hpo.sa_optimizer": [[192, "module-neural_compressor.compression.hpo.sa_optimizer"]], "neural_compressor.compression.hpo.search_algorithms": [[193, "module-neural_compressor.compression.hpo.search_algorithms"]], "neural_compressor.compression.hpo.search_space": [[194, "module-neural_compressor.compression.hpo.search_space"]], "neural_compressor.compression": [[195, "module-neural_compressor.compression"]], "neural_compressor.compression.pruner.criteria": [[196, "module-neural_compressor.compression.pruner.criteria"]], "neural_compressor.compression.pruner.dsnot": [[197, "module-neural_compressor.compression.pruner.dsnot"]], "neural_compressor.compression.pruner": [[198, "module-neural_compressor.compression.pruner"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[199, "module-neural_compressor.compression.pruner.model_slim.auto_slim"]], "neural_compressor.compression.pruner.model_slim": [[200, "module-neural_compressor.compression.pruner.model_slim"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[201, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[202, "module-neural_compressor.compression.pruner.model_slim.weight_slim"]], "neural_compressor.compression.pruner.patterns.base": [[203, "module-neural_compressor.compression.pruner.patterns.base"]], "neural_compressor.compression.pruner.patterns": [[204, "module-neural_compressor.compression.pruner.patterns"]], "neural_compressor.compression.pruner.patterns.mha": [[205, "module-neural_compressor.compression.pruner.patterns.mha"]], "neural_compressor.compression.pruner.patterns.ninm": [[206, "module-neural_compressor.compression.pruner.patterns.ninm"]], "neural_compressor.compression.pruner.patterns.nxm": [[207, "module-neural_compressor.compression.pruner.patterns.nxm"]], "neural_compressor.compression.pruner.pruners.base": [[208, "module-neural_compressor.compression.pruner.pruners.base"]], "neural_compressor.compression.pruner.pruners.basic": [[209, "module-neural_compressor.compression.pruner.pruners.basic"]], "neural_compressor.compression.pruner.pruners.block_mask": [[210, "module-neural_compressor.compression.pruner.pruners.block_mask"]], "neural_compressor.compression.pruner.pruners": [[211, "module-neural_compressor.compression.pruner.pruners"]], "neural_compressor.compression.pruner.pruners.mha": [[212, "module-neural_compressor.compression.pruner.pruners.mha"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[213, "module-neural_compressor.compression.pruner.pruners.pattern_lock"]], "neural_compressor.compression.pruner.pruners.progressive": [[214, "module-neural_compressor.compression.pruner.pruners.progressive"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[215, "module-neural_compressor.compression.pruner.pruners.retrain_free"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[216, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"]], "neural_compressor.compression.pruner.pruning": [[217, "module-neural_compressor.compression.pruner.pruning"]], "neural_compressor.compression.pruner.regs": [[218, "module-neural_compressor.compression.pruner.regs"]], "neural_compressor.compression.pruner.schedulers": [[219, "module-neural_compressor.compression.pruner.schedulers"]], "neural_compressor.compression.pruner.tf_criteria": [[220, "module-neural_compressor.compression.pruner.tf_criteria"]], "neural_compressor.compression.pruner.utils": [[221, "module-neural_compressor.compression.pruner.utils"]], "neural_compressor.compression.pruner.wanda": [[222, "module-neural_compressor.compression.pruner.wanda"]], "neural_compressor.compression.pruner.wanda.prune": [[223, "module-neural_compressor.compression.pruner.wanda.prune"]], "neural_compressor.compression.pruner.wanda.utils": [[224, "module-neural_compressor.compression.pruner.wanda.utils"]], "neural_compressor.compression.pruner.wanda.wrapper": [[225, "module-neural_compressor.compression.pruner.wanda.wrapper"]], "neural_compressor.conf.config": [[226, "module-neural_compressor.conf.config"]], "neural_compressor.conf.dotdict": [[227, "module-neural_compressor.conf.dotdict"]], "neural_compressor.conf": [[228, "module-neural_compressor.conf"]], "neural_compressor.conf.pythonic_config": [[229, "module-neural_compressor.conf.pythonic_config"]], "neural_compressor.config": [[230, "module-neural_compressor.config"]], "neural_compressor.contrib": [[231, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[232, "module-neural_compressor.contrib.strategy"]], "neural_compressor.contrib.strategy.sigopt": [[233, "module-neural_compressor.contrib.strategy.sigopt"]], "neural_compressor.contrib.strategy.tpe": [[234, "module-neural_compressor.contrib.strategy.tpe"]], "neural_compressor.data.dataloaders.base_dataloader": [[235, "module-neural_compressor.data.dataloaders.base_dataloader"]], "neural_compressor.data.dataloaders.dataloader": [[236, "module-neural_compressor.data.dataloaders.dataloader"]], "neural_compressor.data.dataloaders.default_dataloader": [[237, "module-neural_compressor.data.dataloaders.default_dataloader"]], "neural_compressor.data.dataloaders.fetcher": [[238, "module-neural_compressor.data.dataloaders.fetcher"]], "neural_compressor.data.dataloaders": [[239, "module-neural_compressor.data.dataloaders"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[240, "module-neural_compressor.data.dataloaders.mxnet_dataloader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[241, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[242, "module-neural_compressor.data.dataloaders.pytorch_dataloader"]], "neural_compressor.data.dataloaders.sampler": [[243, "module-neural_compressor.data.dataloaders.sampler"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[244, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"]], "neural_compressor.data.datasets.bert_dataset": [[245, "module-neural_compressor.data.datasets.bert_dataset"]], "neural_compressor.data.datasets.coco_dataset": [[246, "module-neural_compressor.data.datasets.coco_dataset"]], "neural_compressor.data.datasets.dataset": [[247, "module-neural_compressor.data.datasets.dataset"]], "neural_compressor.data.datasets.dummy_dataset": [[248, "module-neural_compressor.data.datasets.dummy_dataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[249, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "neural_compressor.data.datasets.imagenet_dataset": [[250, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[251, "module-neural_compressor.data.datasets"]], "neural_compressor.data.datasets.style_transfer_dataset": [[252, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "neural_compressor.data.filters.coco_filter": [[253, "module-neural_compressor.data.filters.coco_filter"]], "neural_compressor.data.filters.filter": [[254, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[255, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[256, "module-neural_compressor.data"]], "neural_compressor.data.transforms.coco_transform": [[257, "module-neural_compressor.data.transforms.coco_transform"]], "neural_compressor.data.transforms.imagenet_transform": [[258, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[259, "module-neural_compressor.data.transforms"]], "neural_compressor.data.transforms.postprocess": [[260, "module-neural_compressor.data.transforms.postprocess"]], "neural_compressor.data.transforms.tokenization": [[261, "module-neural_compressor.data.transforms.tokenization"]], "neural_compressor.data.transforms.transform": [[262, "module-neural_compressor.data.transforms.transform"]], "neural_compressor.experimental.benchmark": [[263, "module-neural_compressor.experimental.benchmark"]], "neural_compressor.experimental.common.criterion": [[264, "module-neural_compressor.experimental.common.criterion"]], "neural_compressor.experimental.common.dataloader": [[265, "module-neural_compressor.experimental.common.dataloader"]], "neural_compressor.experimental.common": [[266, "module-neural_compressor.experimental.common"]], "neural_compressor.experimental.common.metric": [[267, "module-neural_compressor.experimental.common.metric"]], "neural_compressor.experimental.common.model": [[268, "module-neural_compressor.experimental.common.model"]], "neural_compressor.experimental.common.optimizer": [[269, "module-neural_compressor.experimental.common.optimizer"]], "neural_compressor.experimental.common.postprocess": [[270, "module-neural_compressor.experimental.common.postprocess"]], "neural_compressor.experimental.common.torch_utils": [[271, "module-neural_compressor.experimental.common.torch_utils"]], "neural_compressor.experimental.component": [[272, "module-neural_compressor.experimental.component"]], "neural_compressor.experimental.compression": [[273, "module-neural_compressor.experimental.compression"]], "neural_compressor.experimental.contrib": [[274, "module-neural_compressor.experimental.contrib"]], "neural_compressor.experimental.contrib.strategy": [[275, "module-neural_compressor.experimental.contrib.strategy"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[276, "module-neural_compressor.experimental.contrib.strategy.sigopt"]], "neural_compressor.experimental.contrib.strategy.tpe": [[277, "module-neural_compressor.experimental.contrib.strategy.tpe"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[278, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"]], "neural_compressor.experimental.data.dataloaders.dataloader": [[279, "module-neural_compressor.experimental.data.dataloaders.dataloader"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[280, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[281, "module-neural_compressor.experimental.data.dataloaders.fetcher"]], "neural_compressor.experimental.data.dataloaders": [[282, "module-neural_compressor.experimental.data.dataloaders"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[283, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[284, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[285, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"]], "neural_compressor.experimental.data.dataloaders.sampler": [[286, "module-neural_compressor.experimental.data.dataloaders.sampler"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[287, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[288, "module-neural_compressor.experimental.data.datasets.bert_dataset"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[289, "module-neural_compressor.experimental.data.datasets.coco_dataset"]], "neural_compressor.experimental.data.datasets.dataset": [[290, "module-neural_compressor.experimental.data.datasets.dataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[291, "module-neural_compressor.experimental.data.datasets.dummy_dataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[292, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[293, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"]], "neural_compressor.experimental.data.datasets": [[294, "module-neural_compressor.experimental.data.datasets"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[295, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"]], "neural_compressor.experimental.data.filters.coco_filter": [[296, "module-neural_compressor.experimental.data.filters.coco_filter"]], "neural_compressor.experimental.data.filters.filter": [[297, "module-neural_compressor.experimental.data.filters.filter"]], "neural_compressor.experimental.data.filters": [[298, "module-neural_compressor.experimental.data.filters"]], "neural_compressor.experimental.data": [[299, "module-neural_compressor.experimental.data"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[300, "module-neural_compressor.experimental.data.transforms.imagenet_transform"]], "neural_compressor.experimental.data.transforms": [[301, "module-neural_compressor.experimental.data.transforms"]], "neural_compressor.experimental.data.transforms.tokenization": [[302, "module-neural_compressor.experimental.data.transforms.tokenization"]], "neural_compressor.experimental.data.transforms.transform": [[303, "module-neural_compressor.experimental.data.transforms.transform"]], "neural_compressor.experimental.distillation": [[304, "module-neural_compressor.experimental.distillation"]], "neural_compressor.experimental.export": [[305, "module-neural_compressor.experimental.export"]], "neural_compressor.experimental.export.qlinear2qdq": [[306, "module-neural_compressor.experimental.export.qlinear2qdq"]], "neural_compressor.experimental.export.tf2onnx": [[307, "module-neural_compressor.experimental.export.tf2onnx"]], "neural_compressor.experimental.export.torch2onnx": [[308, "module-neural_compressor.experimental.export.torch2onnx"]], "neural_compressor.experimental.graph_optimization": [[309, "module-neural_compressor.experimental.graph_optimization"]], "neural_compressor.experimental": [[310, "module-neural_compressor.experimental"]], "neural_compressor.experimental.metric.bleu": [[311, "module-neural_compressor.experimental.metric.bleu"]], "neural_compressor.experimental.metric.bleu_util": [[312, "module-neural_compressor.experimental.metric.bleu_util"]], "neural_compressor.experimental.metric.coco_label_map": [[313, "module-neural_compressor.experimental.metric.coco_label_map"]], "neural_compressor.experimental.metric.coco_tools": [[314, "module-neural_compressor.experimental.metric.coco_tools"]], "neural_compressor.experimental.metric.evaluate_squad": [[315, "module-neural_compressor.experimental.metric.evaluate_squad"]], "neural_compressor.experimental.metric.f1": [[316, "module-neural_compressor.experimental.metric.f1"]], "neural_compressor.experimental.metric": [[317, "module-neural_compressor.experimental.metric"]], "neural_compressor.experimental.metric.metric": [[318, "module-neural_compressor.experimental.metric.metric"]], "neural_compressor.experimental.mixed_precision": [[319, "module-neural_compressor.experimental.mixed_precision"]], "neural_compressor.experimental.model_conversion": [[320, "module-neural_compressor.experimental.model_conversion"]], "neural_compressor.experimental.nas.basic_nas": [[321, "module-neural_compressor.experimental.nas.basic_nas"]], "neural_compressor.experimental.nas.dynas": [[322, "module-neural_compressor.experimental.nas.dynas"]], "neural_compressor.experimental.nas": [[323, "module-neural_compressor.experimental.nas"]], "neural_compressor.experimental.nas.nas": [[324, "module-neural_compressor.experimental.nas.nas"]], "neural_compressor.experimental.nas.nas_utils": [[325, "module-neural_compressor.experimental.nas.nas_utils"]], "neural_compressor.experimental.nas.search_algorithms": [[326, "module-neural_compressor.experimental.nas.search_algorithms"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[327, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[328, "module-neural_compressor.experimental.pruner_legacy.group_lasso"]], "neural_compressor.experimental.pruner_legacy": [[329, "module-neural_compressor.experimental.pruner_legacy"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[330, "module-neural_compressor.experimental.pruner_legacy.magnitude"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[331, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"]], "neural_compressor.experimental.pruner_legacy.pruner": [[332, "module-neural_compressor.experimental.pruner_legacy.pruner"]], "neural_compressor.experimental.pruning": [[333, "module-neural_compressor.experimental.pruning"]], "neural_compressor.experimental.pruning_recipes": [[334, "module-neural_compressor.experimental.pruning_recipes"]], "neural_compressor.experimental.pruning_recipes.patterns": [[335, "module-neural_compressor.experimental.pruning_recipes.patterns"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[336, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[337, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"]], "neural_compressor.experimental.pruning_v2": [[338, "module-neural_compressor.experimental.pruning_v2"]], "neural_compressor.experimental.pytorch_pruner": [[339, "module-neural_compressor.experimental.pytorch_pruner"]], "neural_compressor.experimental.pytorch_pruner.logger": [[340, "module-neural_compressor.experimental.pytorch_pruner.logger"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[341, "module-neural_compressor.experimental.pytorch_pruner.patterns"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[342, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[343, "module-neural_compressor.experimental.pytorch_pruner.pruner"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[344, "module-neural_compressor.experimental.pytorch_pruner.pruning"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[345, "module-neural_compressor.experimental.pytorch_pruner.scheduler"]], "neural_compressor.experimental.quantization": [[346, "module-neural_compressor.experimental.quantization"]], "neural_compressor.experimental.scheduler": [[347, "module-neural_compressor.experimental.scheduler"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[348, "module-neural_compressor.experimental.strategy.auto_mixed_precision"]], "neural_compressor.experimental.strategy.basic": [[349, "module-neural_compressor.experimental.strategy.basic"]], "neural_compressor.experimental.strategy.bayesian": [[350, "module-neural_compressor.experimental.strategy.bayesian"]], "neural_compressor.experimental.strategy.exhaustive": [[351, "module-neural_compressor.experimental.strategy.exhaustive"]], "neural_compressor.experimental.strategy": [[352, "module-neural_compressor.experimental.strategy"]], "neural_compressor.experimental.strategy.mse": [[353, "module-neural_compressor.experimental.strategy.mse"]], "neural_compressor.experimental.strategy.mse_v2": [[354, "module-neural_compressor.experimental.strategy.mse_v2"]], "neural_compressor.experimental.strategy.random": [[355, "module-neural_compressor.experimental.strategy.random"]], "neural_compressor.experimental.strategy.strategy": [[356, "module-neural_compressor.experimental.strategy.strategy"]], "neural_compressor.experimental.strategy.utils.constant": [[357, "module-neural_compressor.experimental.strategy.utils.constant"]], "neural_compressor.experimental.strategy.utils": [[358, "module-neural_compressor.experimental.strategy.utils"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[359, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[360, "module-neural_compressor.experimental.strategy.utils.tuning_space"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[361, "module-neural_compressor.experimental.strategy.utils.tuning_structs"]], "neural_compressor.experimental.strategy.utils.utility": [[362, "module-neural_compressor.experimental.strategy.utils.utility"]], "neural_compressor": [[363, "module-neural_compressor"]], "neural_compressor.metric.bleu": [[364, "module-neural_compressor.metric.bleu"]], "neural_compressor.metric.bleu_util": [[365, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[366, "module-neural_compressor.metric.coco_label_map"]], "neural_compressor.metric.coco_tools": [[367, "module-neural_compressor.metric.coco_tools"]], "neural_compressor.metric.evaluate_squad": [[368, "module-neural_compressor.metric.evaluate_squad"]], "neural_compressor.metric.f1": [[369, "module-neural_compressor.metric.f1"]], "neural_compressor.metric": [[370, "module-neural_compressor.metric"]], "neural_compressor.metric.metric": [[371, "module-neural_compressor.metric.metric"]], "neural_compressor.mix_precision": [[372, "module-neural_compressor.mix_precision"]], "neural_compressor.model.base_model": [[373, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[374, "module-neural_compressor.model"]], "neural_compressor.model.keras_model": [[375, "module-neural_compressor.model.keras_model"]], "neural_compressor.model.model": [[376, "module-neural_compressor.model.model"]], "neural_compressor.model.mxnet_model": [[377, "module-neural_compressor.model.mxnet_model"]], "neural_compressor.model.nets_factory": [[378, "module-neural_compressor.model.nets_factory"]], "neural_compressor.model.onnx_model": [[379, "module-neural_compressor.model.onnx_model"]], "neural_compressor.model.tensorflow_model": [[380, "module-neural_compressor.model.tensorflow_model"]], "neural_compressor.model.torch_model": [[381, "module-neural_compressor.model.torch_model"]], "neural_compressor.objective": [[382, "module-neural_compressor.objective"]], "neural_compressor.onnxrt.algorithms": [[383, "module-neural_compressor.onnxrt.algorithms"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[384, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[385, "module-neural_compressor.onnxrt.algorithms.smoother.core"]], "neural_compressor.onnxrt.algorithms.smoother": [[386, "module-neural_compressor.onnxrt.algorithms.smoother"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[387, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[388, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"]], "neural_compressor.onnxrt.algorithms.weight_only": [[389, "module-neural_compressor.onnxrt.algorithms.weight_only"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[390, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[391, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"]], "neural_compressor.onnxrt": [[392, "module-neural_compressor.onnxrt"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[393, "module-neural_compressor.onnxrt.quantization.algorithm_entry"]], "neural_compressor.onnxrt.quantization.autotune": [[394, "module-neural_compressor.onnxrt.quantization.autotune"]], "neural_compressor.onnxrt.quantization.calibrate": [[395, "module-neural_compressor.onnxrt.quantization.calibrate"]], "neural_compressor.onnxrt.quantization.config": [[396, "module-neural_compressor.onnxrt.quantization.config"]], "neural_compressor.onnxrt.quantization": [[397, "module-neural_compressor.onnxrt.quantization"]], "neural_compressor.onnxrt.quantization.quantize": [[398, "module-neural_compressor.onnxrt.quantization.quantize"]], "neural_compressor.onnxrt.utils": [[399, "module-neural_compressor.onnxrt.utils"]], "neural_compressor.onnxrt.utils.onnx_model": [[400, "module-neural_compressor.onnxrt.utils.onnx_model"]], "neural_compressor.onnxrt.utils.utility": [[401, "module-neural_compressor.onnxrt.utils.utility"]], "neural_compressor.profiling": [[402, "module-neural_compressor.profiling"]], "neural_compressor.profiling.parser.factory": [[403, "module-neural_compressor.profiling.parser.factory"]], "neural_compressor.profiling.parser": [[404, "module-neural_compressor.profiling.parser"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[405, "module-neural_compressor.profiling.parser.onnx_parser.factory"]], "neural_compressor.profiling.parser.onnx_parser": [[406, "module-neural_compressor.profiling.parser.onnx_parser"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[407, "module-neural_compressor.profiling.parser.onnx_parser.parser"]], "neural_compressor.profiling.parser.parser": [[408, "module-neural_compressor.profiling.parser.parser"]], "neural_compressor.profiling.parser.result": [[409, "module-neural_compressor.profiling.parser.result"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[410, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"]], "neural_compressor.profiling.parser.tensorflow_parser": [[411, "module-neural_compressor.profiling.parser.tensorflow_parser"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[412, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"]], "neural_compressor.profiling.profiler.factory": [[413, "module-neural_compressor.profiling.profiler.factory"]], "neural_compressor.profiling.profiler": [[414, "module-neural_compressor.profiling.profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[415, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[416, "module-neural_compressor.profiling.profiler.onnxrt_profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[417, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[418, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"]], "neural_compressor.profiling.profiler.profiler": [[419, "module-neural_compressor.profiling.profiler.profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[420, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[421, "module-neural_compressor.profiling.profiler.tensorflow_profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[422, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[423, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"]], "neural_compressor.quantization": [[424, "module-neural_compressor.quantization"]], "neural_compressor.strategy.auto": [[425, "module-neural_compressor.strategy.auto"]], "neural_compressor.strategy.auto_mixed_precision": [[426, "module-neural_compressor.strategy.auto_mixed_precision"]], "neural_compressor.strategy.basic": [[427, "module-neural_compressor.strategy.basic"]], "neural_compressor.strategy.bayesian": [[428, "module-neural_compressor.strategy.bayesian"]], "neural_compressor.strategy.conservative": [[429, "module-neural_compressor.strategy.conservative"]], "neural_compressor.strategy.exhaustive": [[430, "module-neural_compressor.strategy.exhaustive"]], "neural_compressor.strategy.hawq_v2": [[431, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[432, "module-neural_compressor.strategy"]], "neural_compressor.strategy.mse": [[433, "module-neural_compressor.strategy.mse"]], "neural_compressor.strategy.mse_v2": [[434, "module-neural_compressor.strategy.mse_v2"]], "neural_compressor.strategy.random": [[435, "module-neural_compressor.strategy.random"]], "neural_compressor.strategy.strategy": [[436, "module-neural_compressor.strategy.strategy"]], "neural_compressor.strategy.utils.constant": [[437, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[438, "module-neural_compressor.strategy.utils"]], "neural_compressor.strategy.utils.tuning_sampler": [[439, "module-neural_compressor.strategy.utils.tuning_sampler"]], "neural_compressor.strategy.utils.tuning_space": [[440, "module-neural_compressor.strategy.utils.tuning_space"]], "neural_compressor.strategy.utils.tuning_structs": [[441, "module-neural_compressor.strategy.utils.tuning_structs"]], "neural_compressor.strategy.utils.utility": [[442, "module-neural_compressor.strategy.utils.utility"]], "neural_compressor.template.api_doc_example": [[443, "module-neural_compressor.template.api_doc_example"]], "neural_compressor.template": [[444, "module-neural_compressor.template"]], "neural_compressor.tensorflow.algorithms": [[445, "module-neural_compressor.tensorflow.algorithms"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[446, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[447, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[448, "module-neural_compressor.tensorflow.algorithms.smoother"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[449, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[450, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[451, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d": [[452, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense": [[453, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d": [[454, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils": [[455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d": [[456, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer": [[457, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d": [[458, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d"]], "neural_compressor.tensorflow": [[459, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[460, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "neural_compressor.tensorflow.quantization.config": [[461, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[462, "module-neural_compressor.tensorflow.quantization"]], "neural_compressor.tensorflow.quantization.quantize": [[463, "module-neural_compressor.tensorflow.quantization.quantize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[464, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[465, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[466, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[467, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[468, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[469, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[470, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[471, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[472, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[473, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[474, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[499, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[500, "module-neural_compressor.tensorflow.quantization.utils"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[501, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "neural_compressor.tensorflow.quantization.utils.utility": [[502, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "neural_compressor.tensorflow.utils.constants": [[503, "module-neural_compressor.tensorflow.utils.constants"]], "neural_compressor.tensorflow.utils.data": [[504, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[505, "module-neural_compressor.tensorflow.utils"]], "neural_compressor.tensorflow.utils.model": [[506, "module-neural_compressor.tensorflow.utils.model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[507, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "neural_compressor.tensorflow.utils.nets_factory": [[508, "module-neural_compressor.tensorflow.utils.nets_factory"]], "neural_compressor.tensorflow.utils.utility": [[509, "module-neural_compressor.tensorflow.utils.utility"]], "neural_compressor.torch.algorithms.habana_fp8.fp8_quant": [[510, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"]], "neural_compressor.torch.algorithms.habana_fp8": [[511, "module-neural_compressor.torch.algorithms.habana_fp8"]], "neural_compressor.torch.algorithms.habana_fp8.modules": [[512, "module-neural_compressor.torch.algorithms.habana_fp8.modules"]], "neural_compressor.torch.algorithms.habana_fp8.observer": [[513, "module-neural_compressor.torch.algorithms.habana_fp8.observer"]], "neural_compressor.torch.algorithms": [[514, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[515, "module-neural_compressor.torch.algorithms.layer_wise"]], "neural_compressor.torch.algorithms.layer_wise.load": [[516, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[517, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[518, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "neural_compressor.torch.algorithms.static_quant": [[519, "module-neural_compressor.torch.algorithms.static_quant"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[520, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "neural_compressor.torch.algorithms.static_quant.utility": [[521, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "neural_compressor.torch.algorithms.weight_only.awq": [[522, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[523, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator": [[524, "module-neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[525, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[526, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[527, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[528, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[529, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[530, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "neural_compressor.torch.algorithms.weight_only.hqq.quant_api": [[531, "module-neural_compressor.torch.algorithms.weight_only.hqq.quant_api"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[532, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[533, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"]], "neural_compressor.torch.algorithms.weight_only": [[534, "module-neural_compressor.torch.algorithms.weight_only"]], "neural_compressor.torch.algorithms.weight_only.modules": [[535, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[536, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "neural_compressor.torch.algorithms.weight_only.teq": [[537, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "neural_compressor.torch.algorithms.weight_only.utility": [[538, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "neural_compressor.torch.amp.autocast": [[539, "module-neural_compressor.torch.amp.autocast"]], "neural_compressor.torch.amp.fp8.functions": [[540, "module-neural_compressor.torch.amp.fp8.functions"]], "neural_compressor.torch.amp.fp8": [[541, "module-neural_compressor.torch.amp.fp8"]], "neural_compressor.torch.amp": [[542, "module-neural_compressor.torch.amp"]], "neural_compressor.torch": [[543, "module-neural_compressor.torch"]], "neural_compressor.torch.quantization.algorithm_entry": [[544, "module-neural_compressor.torch.quantization.algorithm_entry"]], "neural_compressor.torch.quantization.autotune": [[545, "module-neural_compressor.torch.quantization.autotune"]], "neural_compressor.torch.quantization.config": [[546, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[547, "module-neural_compressor.torch.quantization"]], "neural_compressor.torch.quantization.modules": [[548, "module-neural_compressor.torch.quantization.modules"]], "neural_compressor.torch.quantization.quantize": [[549, "module-neural_compressor.torch.quantization.quantize"]], "neural_compressor.torch.utils.constants": [[550, "module-neural_compressor.torch.utils.constants"]], "neural_compressor.torch.utils.environ": [[551, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[552, "module-neural_compressor.torch.utils"]], "neural_compressor.torch.utils.utility": [[553, "module-neural_compressor.torch.utils.utility"]], "neural_compressor.training": [[554, "module-neural_compressor.training"]], "neural_compressor.utils.collect_layer_histogram": [[555, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[556, "module-neural_compressor.utils.constant"]], "neural_compressor.utils.create_obj_from_config": [[557, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils": [[558, "module-neural_compressor.utils"]], "neural_compressor.utils.kl_divergence": [[559, "module-neural_compressor.utils.kl_divergence"]], "neural_compressor.utils.load_huggingface": [[560, "module-neural_compressor.utils.load_huggingface"]], "neural_compressor.utils.logger": [[561, "module-neural_compressor.utils.logger"]], "neural_compressor.utils.neural_insights_utils": [[562, "module-neural_compressor.utils.neural_insights_utils"]], "neural_compressor.utils.options": [[563, "module-neural_compressor.utils.options"]], "neural_compressor.utils.pytorch": [[564, "module-neural_compressor.utils.pytorch"]], "neural_compressor.utils.utility": [[565, "module-neural_compressor.utils.utility"]], "neural_compressor.utils.weights_details": [[566, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[567, "module-neural_compressor.version"]], "Intel\u00ae Neural Compressor Documentation": [[568, "intel-neural-compressor-documentation"], [668, "intel-neural-compressor-documentation"]], "Sections": [[568, "sections"], [668, "sections"]], "Contributor Covenant Code of Conduct": [[569, "contributor-covenant-code-of-conduct"], [570, "contributor-covenant-code-of-conduct"]], "Our Pledge": [[569, "our-pledge"]], "Our Standards": [[569, "our-standards"]], "Our Responsibilities": [[569, "our-responsibilities"]], "Scope": [[569, "scope"]], "Enforcement": [[569, "enforcement"]], "Attribution": [[569, "attribution"]], "Contribution Guidelines": [[570, "contribution-guidelines"]], "Create Pull Request": [[570, "create-pull-request"]], "Step-by-Step guidelines": [[570, "step-by-step-guidelines"]], "Pull Request Checklist": [[570, "pull-request-checklist"]], "Pull Request Template": [[570, "pull-request-template"]], "Pull Request Acceptance Criteria": [[570, "pull-request-acceptance-criteria"]], "Pull Request Status Checks Overview": [[570, "pull-request-status-checks-overview"]], "Support": [[570, "support"]], "FX": [[571, "fx"]], "Introduction": [[571, "introduction"], [572, "introduction"], [575, "introduction"], [576, "introduction"], [577, "introduction"], [592, "introduction"], [593, "introduction"], [595, "introduction"], [596, "introduction"], [599, "introduction"], [600, "introduction"], [601, "introduction"], [603, "introduction"], [605, "introduction"], [608, "introduction"], [612, "introduction"], [614, "introduction"], [615, "introduction"], [636, "introduction"], [637, "introduction"], [638, "introduction"], [650, "introduction"], [651, "introduction"], [652, "introduction"], [654, "introduction"], [656, "introduction"], [658, "introduction"], [660, "introduction"], [661, "introduction"], [662, "introduction"], [663, "introduction"], [664, "introduction"], [666, "introduction"]], "FX Mode Support Matrix in Neural Compressor": [[571, "fx-mode-support-matrix-in-neural-compressor"]], "Get Started": [[571, "get-started"], [598, "get-started"], [640, "get-started"], [655, "get-started"]], "Post Training Static Quantization": [[571, "post-training-static-quantization"], [655, "post-training-static-quantization"]], "Post Training Dynamic Quantization": [[571, "post-training-dynamic-quantization"], [655, "post-training-dynamic-quantization"]], "Quantization-Aware Training": [[571, "quantization-aware-training"]], "Examples": [[571, "examples"], [572, "examples"], [592, "examples"], [595, "examples"], [596, "examples"], [599, "examples"], [600, "examples"], [601, "examples"], [602, "examples"], [603, "examples"], [613, "examples"], [614, "examples"], [615, "examples"], [651, "examples"], [652, "examples"], [655, "examples"], [656, "examples"], [658, "examples"], [662, "examples"]], "Note": [[571, "note"]], "Details": [[571, "details"]], "Common Problem": [[571, "common-problem"]], "Dynamic Quantization": [[571, "dynamic-quantization"]], "Static Quantization & Quantization Aware Training": [[571, "static-quantization-quantization-aware-training"]], "Neural Architecture Search": [[572, "neural-architecture-search"]], "Basic NAS": [[572, "basic-nas"]], "Dynamic NAS": [[572, "dynamic-nas"]], "NAS Support Matrix": [[572, "nas-support-matrix"]], "Get Started with NAS API": [[572, "get-started-with-nas-api"]], "Basic Usage": [[572, "basic-usage"]], "1. Python code + YAML": [[572, "python-code-yaml"]], "2. Python code only": [[572, "python-code-only"]], "Advanced Usage (Custom NAS)": [[572, "advanced-usage-custom-nas"]], "Security Policy": [[573, "security-policy"]], "Report a Vulnerability": [[573, "report-a-vulnerability"]], "Intel\u00ae Neural Compressor": [[574, "intel-neural-compressor"], [633, "intel-neural-compressor"]], "Installation": [[574, "installation"], [609, "installation"], [609, "id1"], [627, "installation"], [635, "installation"], [640, "installation"]], "Install from pypi": [[574, "install-from-pypi"], [635, "install-from-pypi"]], "Getting Started": [[574, "getting-started"], [606, "getting-started"], [635, "getting-started"]], "Quantization with Python API": [[574, "quantization-with-python-api"], [606, "quantization-with-python-api"], [635, "quantization-with-python-api"]], "Documentation": [[574, "documentation"]], "Selected Publications/Events": [[574, "selected-publications-events"]], "Additional Content": [[574, "additional-content"]], "Communication": [[574, "communication"]], "Adaptor": [[575, "adaptor"], [578, "adaptor"]], "Adaptor Support Matrix": [[575, "adaptor-support-matrix"]], "Working Flow": [[575, "working-flow"], [655, "working-flow"]], "Get Started with Adaptor API": [[575, "get-started-with-adaptor-api"]], "Query API": [[575, "query-api"]], "Background": [[575, "background"], [594, "background"]], "Query API Introduction": [[575, "query-api-introduction"]], "Example of Adding a New Backend Support": [[575, "example-of-adding-a-new-backend-support"]], "Capability": [[575, "capability"]], "Implement ONNXRTAdaptor Class": [[575, "implement-onnxrtadaptor-class"]], "How to Add An Adaptor": [[576, "how-to-add-an-adaptor"]], "API List that Need to Implement": [[576, "api-list-that-need-to-implement"]], "Design the framework YAML": [[576, "design-the-framework-yaml"]], "Add query_fw_capability to Adaptor": [[576, "add-query-fw-capability-to-adaptor"]], "Add quantize API according to tune_cfg": [[576, "add-quantize-api-according-to-tune-cfg"]], "Prepare calibration model from fp32 graph": [[576, "prepare-calibration-model-from-fp32-graph"]], "Run sampling iterations of the fp32 graph to calibrate quantizable operators.": [[576, "run-sampling-iterations-of-the-fp32-graph-to-calibrate-quantizable-operators"]], "Calculate the data range and generate quantized model": [[576, "calculate-the-data-range-and-generate-quantized-model"]], "How to Support New Data Type, Like Int4, with a Few Line Changes": [[577, "how-to-support-new-data-type-like-int4-with-a-few-line-changes"]], "Define the Quantization Ability of the Specific Operator": [[577, "define-the-quantization-ability-of-the-specific-operator"]], "Invoke the Operator Kernel According to the Tuning Configuration": [[577, "invoke-the-operator-kernel-according-to-the-tuning-configuration"]], "Use the New Data Type": [[577, "use-the-new-data-type"]], "Summary": [[577, "summary"]], "ONNX Runtime": [[579, "onnx-runtime"]], "Torch Utils": [[580, "torch-utils"]], "API Document Example": [[581, "api-document-example"]], "APIs": [[582, "apis"]], "Benchmark": [[583, "benchmark"], [613, "benchmark"], [654, "benchmark"]], "Compression": [[584, "compression"]], "Config": [[585, "config"]], "Mix Precision": [[586, "mix-precision"], [613, "mix-precision"]], "Model": [[587, "model"], [615, "model"], [636, "model"], [638, "model"]], "Objective": [[588, "objective"], [646, "objective"], [647, "objective"], [648, "objective"], [650, "objective"]], "Quantization": [[589, "quantization"], [654, "quantization"], [655, "quantization"]], "Strategy": [[590, "strategy"]], "Training": [[591, "training"]], "Benchmarking": [[592, "benchmarking"]], "Benchmark Support Matrix": [[592, "benchmark-support-matrix"]], "Get Started with Benchmark API": [[592, "get-started-with-benchmark-api"]], "Calibration Algorithms in Quantization": [[593, "calibration-algorithms-in-quantization"]], "Calibration Algorithms": [[593, "calibration-algorithms"]], "Support Matrix": [[593, "support-matrix"], [618, "support-matrix"]], "Reference": [[593, "reference"], [594, "reference"], [652, "reference"], [655, "reference"], [658, "reference"], [661, "reference"]], "INC Coding Conventions": [[594, "inc-coding-conventions"]], "Rules": [[594, "rules"]], "Imports": [[594, "imports"]], "Strings": [[594, "strings"]], "Logger": [[594, "logger"]], "Type Annotations": [[594, "type-annotations"]], "Comments": [[594, "comments"]], "TODO Comments": [[594, "todo-comments"]], "Public and Internal Interfaces": [[594, "public-and-internal-interfaces"]], "Folder structure": [[594, "folder-structure"]], "Recommend VS Code settings.json": [[594, "recommend-vs-code-settings-json"]], "DataLoader": [[595, "dataloader"]], "Supported Framework Dataloader Matrix": [[595, "supported-framework-dataloader-matrix"]], "Get Started with DataLoader": [[595, "get-started-with-dataloader"]], "Use Intel\u00ae Neural Compressor DataLoader API": [[595, "use-intel-neural-compressor-dataloader-api"]], "Build Custom Dataloader with Python API": [[595, "build-custom-dataloader-with-python-api"]], "Dataset": [[596, "dataset"]], "Supported Framework Dataset Matrix": [[596, "supported-framework-dataset-matrix"]], "TensorFlow": [[596, "tensorflow"], [612, "tensorflow"], [663, "tensorflow"]], "PyTorch": [[596, "pytorch"], [612, "pytorch"], [657, "pytorch"]], "MXNet": [[596, "mxnet"], [612, "mxnet"], [663, "mxnet"]], "ONNXRT": [[596, "onnxrt"], [612, "onnxrt"], [663, "onnxrt"]], "Get start with Dataset API": [[596, "get-start-with-dataset-api"]], "Config dataloader in a yaml file": [[596, "config-dataloader-in-a-yaml-file"]], "User-specific dataset": [[596, "user-specific-dataset"]], "Design": [[597, "design"], [664, "design"], [664, "id1"], [664, "id3"], [664, "id5"], [664, "id7"], [664, "id9"], [664, "id11"], [664, "id13"], [664, "id15"], [664, "id17"], [664, "id19"], [664, "id21"]], "Architecture": [[597, "architecture"], [608, "architecture"]], "Workflow": [[597, "workflow"]], "Diagnosis": [[598, "diagnosis"]], "Diagnosis Introduction": [[598, "diagnosis-introduction"]], "Supported Feature Matrix": [[598, "supported-feature-matrix"], [601, "supported-feature-matrix"], [605, "supported-feature-matrix"], [608, "supported-feature-matrix"], [654, "supported-feature-matrix"], [655, "supported-feature-matrix"], [662, "supported-feature-matrix"], [666, "supported-feature-matrix"]], "Install Intel\u00ae Neural Compressor": [[598, "install-intel-neural-compressor"]], "Modify script": [[598, "modify-script"]], "Quantization diagnosis": [[598, "quantization-diagnosis"]], "Benchmark diagnosis": [[598, "benchmark-diagnosis"]], "Example": [[598, "example"], [612, "example"], [618, "example"], [622, "example"], [650, "example"]], "Prepare dataset": [[598, "prepare-dataset"]], "Run quantization script": [[598, "run-quantization-script"]], "Run benchmark script": [[598, "run-benchmark-script"]], "See quantization data": [[598, "see-quantization-data"]], "How to do diagnosis": [[598, "how-to-do-diagnosis"]], "Parameter description": [[598, "parameter-description"]], "Diagnosis suggestions": [[598, "diagnosis-suggestions"]], "Fallback setting example": [[598, "fallback-setting-example"]], "See profiling data": [[598, "see-profiling-data"]], "Distillation": [[599, "distillation"], [613, "distillation"], [654, "distillation"]], "Knowledge Distillation": [[599, "knowledge-distillation"]], "Intermediate Layer Knowledge Distillation": [[599, "intermediate-layer-knowledge-distillation"]], "Self Distillation": [[599, "self-distillation"]], "Distillation Support Matrix": [[599, "distillation-support-matrix"]], "Get Started with Distillation API": [[599, "get-started-with-distillation-api"]], "Distillation for Quantization": [[600, "distillation-for-quantization"]], "Distillation for Quantization Support Matrix": [[600, "distillation-for-quantization-support-matrix"]], "Get Started with Distillation for Quantization API": [[600, "get-started-with-distillation-for-quantization-api"]], "Distributed Training and Inference (Evaluation)": [[601, "distributed-training-and-inference-evaluation"]], "Get Started with Distributed Training and Inference API": [[601, "get-started-with-distributed-training-and-inference-api"]], "Option 1: Pure Yaml Configuration": [[601, "option-1-pure-yaml-configuration"]], "Option 2: User Defined Training Function": [[601, "option-2-user-defined-training-function"]], "Horovodrun Execution": [[601, "horovodrun-execution"]], "Security": [[601, "security"]], "PyTorch Examples:": [[601, "pytorch-examples"]], "TensorFlow Examples:": [[601, "tensorflow-examples"]], "Example List": [[602, "example-list"]], "Release Data": [[602, "release-data"]], "Export": [[603, "export"]], "Supported Framework Model Matrix": [[603, "supported-framework-model-matrix"], [615, "supported-framework-model-matrix"], [656, "supported-framework-model-matrix"], [658, "supported-framework-model-matrix"]], "PyTorch Model": [[603, "pytorch-model"]], "FP32 Model Export": [[603, "fp32-model-export"], [603, "id1"]], "INT8 Model Export": [[603, "int8-model-export"], [603, "id2"]], "Tensorflow Model": [[603, "tensorflow-model"]], "Appendix": [[603, "appendix"]], "Supported quantized ops": [[603, "supported-quantized-ops"]], "Frequently Asked Questions": [[604, "frequently-asked-questions"]], "Common Build Issues": [[604, "common-build-issues"]], "Issue 1:": [[604, "issue-1"]], "Issue 2:": [[604, "issue-2"]], "Issue 3:": [[604, "issue-3"]], "Issue 4:": [[604, "issue-4"]], "Framework YAML Configuration Files": [[605, "framework-yaml-configuration-files"]], "Get started with Framework YAML Files": [[605, "get-started-with-framework-yaml-files"]], "Quick Samples": [[606, "quick-samples"]], "Validated Models": [[606, "validated-models"], [661, "validated-models"], [667, "validated-models"]], "Incompatible changes between v1.2 and v1.1": [[607, "incompatible-changes-between-v1-2-and-v1-1"]], "User-facing APIs": [[607, "user-facing-apis"]], "Built-in transform/dataset/metric APIs": [[607, "built-in-transform-dataset-metric-apis"]], "Infrastructure of Intel\u00ae Neural Compressor": [[608, "infrastructure-of-intel-neural-compressor"]], "Prerequisites": [[609, "prerequisites"], [640, "prerequisites"], [641, "prerequisites"]], "Install from Binary": [[609, "install-from-binary"]], "Install from Source": [[609, "install-from-source"], [635, "install-from-source"]], "Install from AI Kit": [[609, "install-from-ai-kit"]], "System Requirements": [[609, "system-requirements"]], "Validated Hardware Environment": [[609, "validated-hardware-environment"]], "Intel\u00ae Neural Compressor supports CPUs based on Intel 64 architecture or compatible processors:": [[609, "intel-neural-compressor-supports-cpus-based-on-intel-64-architecture-or-compatible-processors"]], "Intel\u00ae Neural Compressor supports GPUs built on Intel\u2019s Xe architecture:": [[609, "intel-neural-compressor-supports-gpus-built-on-intel-s-xe-architecture"]], "Intel\u00ae Neural Compressor quantized ONNX models support multiple hardware vendors through ONNX Runtime:": [[609, "intel-neural-compressor-quantized-onnx-models-support-multiple-hardware-vendors-through-onnx-runtime"]], "Validated Software Environment": [[609, "validated-software-environment"]], "Legal Information": [[610, "legal-information"]], "License": [[610, "license"]], "Citation": [[610, "citation"]], "Trademarks": [[610, "trademarks"]], "LLMs Quantization Recipes": [[611, "llms-quantization-recipes"]], "IPEX key models": [[611, "ipex-key-models"]], "Metrics": [[612, "metrics"]], "Supported Built-in Metric Matrix": [[612, "supported-built-in-metric-matrix"]], "Get Started with Metric": [[612, "get-started-with-metric"]], "Use Intel\u00ae Neural Compressor Metric API": [[612, "use-intel-neural-compressor-metric-api"]], "Build Custom Metric with Python API": [[612, "build-custom-metric-with-python-api"]], "Code Migration from Intel Neural Compressor 1.X to Intel Neural Compressor 2.X": [[613, "code-migration-from-intel-neural-compressor-1-x-to-intel-neural-compressor-2-x"]], "Model Quantization": [[613, "model-quantization"]], "Post-training Quantization": [[613, "post-training-quantization"]], "Quantization Aware Training": [[613, "quantization-aware-training"], [655, "quantization-aware-training"], [655, "id1"]], "Pruning": [[613, "pruning"], [652, "pruning"], [654, "pruning"]], "Orchestration": [[613, "orchestration"]], "Mixed Precision": [[614, "mixed-precision"]], "Mixed Precision Support Matrix": [[614, "mixed-precision-support-matrix"]], "Hardware and Software requests for BF16": [[614, "hardware-and-software-requests-for-bf16"]], "Hardware and Software requests for FP16": [[614, "hardware-and-software-requests-for-fp16"]], "During quantization mixed precision": [[614, "during-quantization-mixed-precision"]], "Accuracy-driven mixed precision": [[614, "accuracy-driven-mixed-precision"]], "Get Started with Mixed Precision API": [[614, "get-started-with-mixed-precision-api"]], "Neural Coder": [[616, "neural-coder"], [633, "neural-coder"], [633, "id1"]], "What do we offer?": [[616, "what-do-we-offer"]], "Getting Started!": [[616, "getting-started"], [627, "getting-started"]], "Jupyter Lab Extension": [[616, "jupyter-lab-extension"]], "Python Launcher": [[616, "python-launcher"], [621, "python-launcher"]], "Python API": [[616, "python-api"]], "Contact": [[616, "contact"], [640, "contact"]], "AWS Amazon SageMaker Support": [[617, "aws-amazon-sagemaker-support"]], "Start Jupyter Lab 3": [[617, "start-jupyter-lab-3"]], "For SageMaker Studio": [[617, "for-sagemaker-studio"]], "For SageMaker Notebook instance": [[617, "for-sagemaker-notebook-instance"]], "Installation Guide": [[617, "installation-guide"]], "BigDL Nano Support": [[618, "bigdl-nano-support"]], "Intel CPU Platforms: Best Performance Setting": [[619, "intel-cpu-platforms-best-performance-setting"]], "Install MKL, OpenMP and JEMALLOC": [[619, "install-mkl-openmp-and-jemalloc"]], "Install NUMA Controller": [[619, "install-numa-controller"]], "Environment Variables": [[619, "environment-variables"]], "Frequency Governers": [[619, "frequency-governers"]], "Neural Coder as Python API": [[620, "neural-coder-as-python-api"]], "Enable": [[620, "enable"]], "Bench": [[620, "bench"]], "SuperBench": [[620, "superbench"]], "Quick-Start": [[621, "quick-start"]], "Launcher Arguments (Optional)": [[621, "launcher-arguments-optional"]], "Neural Coder for Quantization": [[622, "neural-coder-for-quantization"]], "Features Supported": [[622, "features-supported"]], "Models Supported": [[622, "models-supported"]], "Usage": [[622, "usage"], [642, "usage"], [642, "id2"], [642, "id6"], [642, "id9"], [642, "id16"], [642, "id19"], [642, "id22"], [642, "id25"], [661, "usage"], [662, "usage"], [662, "id1"], [664, "usage"], [664, "id2"], [664, "id4"], [664, "id6"], [664, "id8"], [664, "id10"], [664, "id12"], [664, "id14"], [664, "id16"], [664, "id18"], [664, "id20"], [664, "id22"]], "PyPI distribution:": [[622, "pypi-distribution"]], "Supported Optimization Features": [[623, "supported-optimization-features"]], "v0.4": [[624, "v0-4"]], "Highlights": [[624, "highlights"]], "Others": [[624, "others"]], "Changelog": [[625, "changelog"], [629, "changelog"]], "neural_compressor_ext_lab": [[626, "neural-compressor-ext-lab"]], "Requirements": [[626, "requirements"], [630, "requirements"], [636, "requirements"], [637, "requirements"], [638, "requirements"], [646, "requirements"]], "Install": [[626, "install"]], "Uninstall": [[626, "uninstall"]], "Contributing": [[626, "contributing"], [630, "contributing"]], "Development install": [[626, "development-install"], [630, "development-install"]], "Development uninstall": [[626, "development-uninstall"], [630, "development-uninstall"]], "Packaging the extension": [[626, "packaging-the-extension"], [630, "packaging-the-extension"]], "Intel\u00ae Neural Compressor as JupyterLab Extension": [[627, "intel-neural-compressor-as-jupyterlab-extension"]], "Auto-enable a feature": [[627, "auto-enable-a-feature"]], "Or let us help you auto-select the best feature": [[627, "or-let-us-help-you-auto-select-the-best-feature"]], "Pre-requisites": [[627, "pre-requisites"]], "Making a new release of neural_compressor_ext_lab": [[628, "making-a-new-release-of-neural-compressor-ext-lab"]], "Manual release": [[628, "manual-release"], [631, "manual-release"]], "Python package": [[628, "python-package"], [631, "python-package"]], "NPM package": [[628, "npm-package"], [631, "npm-package"]], "Automated releases with the Jupyter Releaser": [[628, "automated-releases-with-the-jupyter-releaser"], [631, "automated-releases-with-the-jupyter-releaser"]], "Publishing to conda-forge": [[628, "publishing-to-conda-forge"], [631, "publishing-to-conda-forge"]], "neural_compressor_ext_lab_alibaba": [[630, "neural-compressor-ext-lab-alibaba"]], "Making a new release of neural_compressor_ext_lab_alibaba": [[631, "making-a-new-release-of-neural-compressor-ext-lab-alibaba"]], "Change Log": [[632, "change-log"]], "[Unreleased]": [[632, "unreleased"]], "Background Introduction": [[633, "background-introduction"]], "Neural Coder Extension in VSCode": [[633, "neural-coder-extension-in-vscode"]], "Neural Coder Extension Usage": [[633, "neural-coder-extension-usage"]], "1. Open": [[633, "open"]], "2. Search": [[633, "search"]], "3. Setting": [[633, "setting"]], "4. Icon": [[633, "icon"]], "5. optimization (quantization)": [[633, "optimization-quantization"]], "5.1 Enable": [[633, "enable"]], "5.2 Auto": [[633, "auto"]], "Welcome to your VS Code Extension": [[634, "welcome-to-your-vs-code-extension"]], "What\u2019s in the folder": [[634, "what-s-in-the-folder"]], "Setup": [[634, "setup"]], "Get up and running straight away": [[634, "get-up-and-running-straight-away"]], "Make changes": [[634, "make-changes"]], "Explore the API": [[634, "explore-the-api"]], "Run tests": [[634, "run-tests"]], "Go further": [[634, "go-further"]], "Neural Insights": [[635, "neural-insights"]], "Start the Neural Insights": [[635, "start-the-neural-insights"]], "Tensor dump examples": [[635, "tensor-dump-examples"]], "Step by Step Diagnosis Example": [[635, "step-by-step-diagnosis-example"]], "Research Collaborations": [[635, "research-collaborations"]], "Step by step example how to debug accuracy with Neural Insights": [[636, "step-by-step-example-how-to-debug-accuracy-with-neural-insights"], [638, "step-by-step-example-how-to-debug-accuracy-with-neural-insights"]], "Preparation": [[636, "preparation"], [637, "preparation"], [638, "preparation"], [660, "preparation"]], "Running the quantization": [[636, "running-the-quantization"], [637, "running-the-quantization"], [638, "running-the-quantization"]], "Analyzing the result of quantization": [[636, "analyzing-the-result-of-quantization"], [638, "analyzing-the-result-of-quantization"]], "Weights summary": [[636, "weights-summary"]], "Activations summary": [[636, "activations-summary"]], "Step by step example how to dump weights data for PyTorch model with Neural Insights": [[637, "step-by-step-example-how-to-dump-weights-data-for-pytorch-model-with-neural-insights"]], "Source": [[637, "source"], [638, "source"]], "Prepare the dataset": [[638, "prepare-the-dataset"]], "Analyzing weight histograms": [[638, "analyzing-weight-histograms"]], "Open Neural Insights": [[638, "open-neural-insights"]], "Getting Started with Create React App": [[639, "getting-started-with-create-react-app"]], "Available Scripts": [[639, "available-scripts"]], "npm start": [[639, "npm-start"]], "npm test": [[639, "npm-test"]], "npm run build": [[639, "npm-run-build"]], "npm run eject": [[639, "npm-run-eject"]], "Learn More": [[639, "learn-more"], [640, "learn-more"]], "Code Splitting": [[639, "code-splitting"]], "Analyzing the Bundle Size": [[639, "analyzing-the-bundle-size"]], "Making a Progressive Web App": [[639, "making-a-progressive-web-app"]], "Advanced Configuration": [[639, "advanced-configuration"]], "Deployment": [[639, "deployment"]], "npm run build fails to minify": [[639, "npm-run-build-fails-to-minify"]], "What\u2019s Neural Solution?": [[640, "what-s-neural-solution"]], "Why Neural Solution?": [[640, "why-neural-solution"]], "How does Neural Solution Work?": [[640, "how-does-neural-solution-work"]], "Method 1. Using pip:": [[640, "method-1-using-pip"]], "Method 2. Building from source:": [[640, "method-2-building-from-source"]], "End-to-end examples": [[640, "end-to-end-examples"]], "Get started": [[641, "get-started"]], "Install Neural Solution": [[641, "install-neural-solution"]], "Method 1. Using pip": [[641, "method-1-using-pip"]], "Method 2. Building from source": [[641, "method-2-building-from-source"]], "Start service": [[641, "start-service"]], "Submit task": [[641, "submit-task"]], "Query task status": [[641, "query-task-status"]], "Stop service": [[641, "stop-service"]], "Inspect logs": [[641, "inspect-logs"]], "Manage resource": [[641, "manage-resource"], [646, "manage-resource"], [647, "manage-resource"]], "Node States": [[641, "node-states"]], "Query cluster": [[641, "query-cluster"]], "Add node": [[641, "add-node"]], "Remove node": [[641, "remove-node"]], "Neural Solution API": [[642, "neural-solution-api"]], "Base URL": [[642, "base-url"]], "Endpoints": [[642, "endpoints"]], "GET /": [[642, "get"]], "Description": [[642, "description"], [642, "id1"], [642, "id4"], [642, "id8"], [642, "id12"], [642, "id15"], [642, "id18"], [642, "id21"], [642, "id24"]], "Responses": [[642, "responses"], [642, "id3"], [642, "id7"], [642, "id11"], [642, "id14"], [642, "id17"], [642, "id20"], [642, "id23"], [642, "id26"]], "POST /task/submit": [[642, "post-task-submit"]], "Parameters": [[642, "parameters"], [642, "id5"], [642, "id10"], [642, "id13"]], "GET /task/status/{task_id}": [[642, "get-task-status-task-id"]], "GET /task/log/{task_id}": [[642, "get-task-log-task-id"]], "WebSocket /task/screen/{task_id}": [[642, "websocket-task-screen-task-id"]], "GET /ping": [[642, "get-ping"]], "GET /cluster": [[642, "get-cluster"]], "GET /download/{task_id}": [[642, "get-download-task-id"]], "GET /description": [[642, "get-description"]], "Design Doc for Optimization as a Service [WIP]": [[643, "design-doc-for-optimization-as-a-service-wip"]], "Contents": [[643, "contents"]], "Overview": [[643, "overview"], [665, "overview"]], "Workflow of OaaS": [[643, "workflow-of-oaas"]], "Class definition diagram": [[643, "class-definition-diagram"]], "Extensibility": [[643, "extensibility"]], "Task request description": [[644, "task-request-description"]], "Examples List": [[645, "examples-list"]], "An end-to-end example: quantize a custom model with Neural Solution": [[646, "an-end-to-end-example-quantize-a-custom-model-with-neural-solution"]], "Start the Neural Solution Service": [[646, "start-the-neural-solution-service"], [647, "start-the-neural-solution-service"], [648, "start-the-neural-solution-service"]], "Submit optimization task": [[646, "submit-optimization-task"], [647, "submit-optimization-task"], [648, "submit-optimization-task"]], "Query optimization result": [[646, "query-optimization-result"], [647, "query-optimization-result"], [648, "query-optimization-result"]], "Download optimized model": [[646, "download-optimized-model"], [647, "download-optimized-model"]], "Stop the service": [[646, "stop-the-service"], [647, "stop-the-service"], [648, "stop-the-service"]], "An end-to-end example: quantize a Hugging Face model with Neural Solution": [[647, "an-end-to-end-example-quantize-a-hugging-face-model-with-neural-solution"]], "An end-to-end example: quantize a Hugging Face model with Neural Solution gRPC API": [[648, "an-end-to-end-example-quantize-a-hugging-face-model-with-neural-solution-grpc-api"]], "Client": [[649, "client"]], "Single Objective": [[650, "single-objective"]], "Multiple Objectives": [[650, "multiple-objectives"]], "Objective Support Matrix": [[650, "objective-support-matrix"]], "Get Started with Objective API": [[650, "get-started-with-objective-api"]], "Config Single Objective": [[650, "config-single-objective"]], "Config Multiple Objectives": [[650, "config-multiple-objectives"]], "Optimization Orchestration": [[651, "optimization-orchestration"]], "One-shot": [[651, "one-shot"]], "Orchestration Support Matrix": [[651, "orchestration-support-matrix"]], "Get Started with Orchestration API": [[651, "get-started-with-orchestration-api"]], "Neural Network Pruning": [[652, "neural-network-pruning"]], "Pruning Patterns": [[652, "pruning-patterns"]], "Pruning Criteria": [[652, "pruning-criteria"]], "Pruning Types": [[652, "pruning-types"]], "Pruning Schedules": [[652, "pruning-schedules"]], "Pruning Scope": [[652, "pruning-scope"]], "Sparsity Decay Types": [[652, "sparsity-decay-types"]], "Regularization": [[652, "regularization"]], "Large Language Model Pruning": [[652, "large-language-model-pruning"]], "Pruning Support Matrix": [[652, "pruning-support-matrix"]], "Get Started with Pruning API": [[652, "get-started-with-pruning-api"]], "Training-aware pruning API": [[652, "training-aware-pruning-api"]], "Retrain-free Pruning API": [[652, "retrain-free-pruning-api"]], "Sparse Model Deployment": [[652, "sparse-model-deployment"]], "Pruning with Hyperparameter Optimization": [[652, "pruning-with-hyperparameter-optimization"]], "Full Publications/Events (79)": [[653, "full-publications-events-79"]], "2023 (25)": [[653, "id1"]], "2022 (35)": [[653, "id2"]], "2021 (15)": [[653, "id3"]], "2018 - 2020 (4)": [[653, "id4"]], "Pythonic Style Access for Configurations": [[654, "pythonic-style-access-for-configurations"]], "Pythonic API for User Configurations": [[654, "pythonic-api-for-user-configurations"], [654, "id1"]], "Pythonic API for Framework Configurations": [[654, "pythonic-api-for-framework-configurations"], [654, "id2"]], "Get Started with Pythonic API for Configurations": [[654, "get-started-with-pythonic-api-for-configurations"]], "NAS": [[654, "nas"]], "Quantization Introduction": [[655, "quantization-introduction"]], "Quantization Fundamentals": [[655, "quantization-fundamentals"], [661, "quantization-fundamentals"]], "Quantization Support Matrix": [[655, "quantization-support-matrix"]], "Quantization Scheme in TensorFlow": [[655, "quantization-scheme-in-tensorflow"]], "Quantization Scheme in PyTorch": [[655, "quantization-scheme-in-pytorch"]], "Quantization Scheme in IPEX": [[655, "quantization-scheme-in-ipex"]], "Quantization Scheme in MXNet": [[655, "quantization-scheme-in-mxnet"]], "Quantization Scheme in ONNX Runtime": [[655, "quantization-scheme-in-onnx-runtime"]], "Quantization Approaches": [[655, "quantization-approaches"]], "With or Without Accuracy Aware Tuning": [[655, "with-or-without-accuracy-aware-tuning"]], "Post Training Quantization": [[655, "post-training-quantization"]], "Specify Quantization Rules": [[655, "specify-quantization-rules"]], "Specify Quantization Recipes": [[655, "specify-quantization-recipes"]], "Specify Quantization Backend and Device": [[655, "specify-quantization-backend-and-device"]], "Layer Wise Quantization (LWQ)": [[656, "layer-wise-quantization-lwq"]], "PyTorch framework example": [[656, "pytorch-framework-example"]], "ONNX Runtime framework example": [[656, "onnx-runtime-framework-example"]], "Turn OFF Auto Mixed Precision during Quantization": [[657, "turn-off-auto-mixed-precision-during-quantization"]], "Tensorflow": [[657, "tensorflow"]], "Weight Only Quantization (WOQ)": [[658, "weight-only-quantization-woq"]], "Quantization Capability": [[658, "quantization-capability"]], "Export Compressed Model": [[658, "export-compressed-model"]], "User Code Example": [[658, "user-code-example"]], "WOQ Algorithms Tuning": [[658, "woq-algorithms-tuning"]], "User code example": [[658, "id1"]], "Release": [[659, "release"]], "Release Notes": [[659, "release-notes"]], "Known Issues": [[659, "known-issues"]], "Incompatible Changes": [[659, "incompatible-changes"]], "SigOpt Strategy": [[660, "sigopt-strategy"]], "SigOpt Platform": [[660, "sigopt-platform"]], "Neural Compressor Configuration": [[660, "neural-compressor-configuration"]], "Performance": [[660, "performance"]], "Benefit of SigOpt Strategy": [[660, "benefit-of-sigopt-strategy"]], "Performance Comparison of Different Strategies": [[660, "performance-comparison-of-different-strategies"]], "Smooth Quant": [[661, "smooth-quant"]], "Per-tensor & Per-channel": [[661, "per-tensor-per-channel"]], "Per-tensor example": [[661, "per-tensor-example"]], "Per-channel example": [[661, "per-channel-example"]], "Matmul quantization example": [[661, "matmul-quantization-example"]], "Per-channel limitation": [[661, "per-channel-limitation"]], "SmoothQuant and Our Enhancement": [[661, "smoothquant-and-our-enhancement"]], "SmoothQuant": [[661, "smoothquant"]], "Our enhancement:": [[661, "our-enhancement"]], "Algorithm: Auto-tuning of $\\alpha$.": [[661, "algorithm-auto-tuning-of-alpha"]], "Engineering": [[661, "engineering"]], "Using a fixed alpha": [[661, "using-a-fixed-alpha"]], "Determining the alpha through auto-tuning": [[661, "determining-the-alpha-through-auto-tuning"]], "Auto-tune the alpha for the entire model": [[661, "auto-tune-the-alpha-for-the-entire-model"]], "Auto-tune the alpha for each layer/block": [[661, "auto-tune-the-alpha-for-each-layer-block"]], "Supported Framework Matrix": [[661, "supported-framework-matrix"]], "TensorBoard": [[662, "tensorboard"]], "Get Started with TensorBoard": [[662, "get-started-with-tensorboard"]], "PyTorch TensorBoard": [[662, "pytorch-tensorboard"]], "TensorFlow Tensorboard": [[662, "tensorflow-tensorboard"]], "PyTorch Examples": [[662, "pytorch-examples"]], "TensorFlow Examples": [[662, "tensorflow-examples"]], "Transform": [[663, "transform"]], "Transform Support List": [[663, "transform-support-list"]], "Pytorch": [[663, "pytorch"]], "Tuning Strategies": [[664, "tuning-strategies"]], "Strategy Design": [[664, "strategy-design"]], "Tuning Space": [[664, "tuning-space"]], "Exit Policy": [[664, "exit-policy"]], "Accuracy Criteria": [[664, "accuracy-criteria"]], "Tuning Process": [[664, "tuning-process"]], "Tuning Algorithms": [[664, "tuning-algorithms"]], "Auto": [[664, "auto"]], "Conservative Tuning": [[664, "conservative-tuning"]], "Basic": [[664, "basic"]], "MSE": [[664, "mse"]], "MSE_V2": [[664, "mse-v2"]], "HAWQ_V2": [[664, "hawq-v2"]], "Bayesian": [[664, "bayesian"]], "Exhaustive": [[664, "exhaustive"]], "Random": [[664, "random"]], "SigOpt": [[664, "sigopt"]], "TPE": [[664, "tpe"]], "Distributed Tuning": [[664, "distributed-tuning"]], "Customize a New Tuning Strategy": [[664, "customize-a-new-tuning-strategy"]], "User Guide": [[665, "user-guide"]], "Python-based APIs": [[665, "python-based-apis"]], "Neural Coder (Zero-code Optimization)": [[665, "neural-coder-zero-code-optimization"]], "Advanced Topics": [[665, "advanced-topics"]], "Innovations for Productivity": [[665, "innovations-for-productivity"]], "User YAML Configuration Files": [[666, "user-yaml-configuration-files"]], "Get started with User YAML Files": [[666, "get-started-with-user-yaml-files"]], "Validated Quantization Examples": [[667, "validated-quantization-examples"]], "TensorFlow Models with Intel TensorFlow 2.13.0": [[667, "tensorflow-models-with-intel-tensorflow-2-13-0"]], "PyTorch Models with Torch 2.0.1+cpu in PTQ Mode": [[667, "pytorch-models-with-torch-2-0-1-cpu-in-ptq-mode"]], "PyTorch Models with Torch 2.0.1+cpu in QAT Mode": [[667, "pytorch-models-with-torch-2-0-1-cpu-in-qat-mode"]], "PyTorch Models with Intel\u00ae Extension for PyTorch* 2.0.1+cpu": [[667, "pytorch-models-with-intel-extension-for-pytorch-2-0-1-cpu"]], "PyTorch Models with Torch 2.0.1+cpu in WOQ Mode": [[667, "pytorch-models-with-torch-2-0-1-cpu-in-woq-mode"]], "ONNX Models with ONNX Runtime 1.15.1": [[667, "onnx-models-with-onnx-runtime-1-15-1"]], "ONNX Models with ONNX Runtime 1.15.0 in WOQ Mode": [[667, "onnx-models-with-onnx-runtime-1-15-0-in-woq-mode"]], "Validated Pruning Examples": [[667, "validated-pruning-examples"]], "Validated Knowledge Distillation Examples": [[667, "validated-knowledge-distillation-examples"]], "Validated ONNX QDQ INT8 Models on Multiple Hardware through ONNX Runtime": [[667, "validated-onnx-qdq-int8-models-on-multiple-hardware-through-onnx-runtime"]]}, "indexentries": {"block_mask": [[0, "module-block_mask"]], "module": [[0, "module-block_mask"], [1, "module-neural_compressor.adaptor.adaptor"], [2, "module-neural_compressor.adaptor"], [3, "module-neural_compressor.adaptor.keras"], [4, "module-neural_compressor.adaptor.keras_utils.conv2d"], [5, "module-neural_compressor.adaptor.keras_utils.dense"], [6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"], [7, "module-neural_compressor.adaptor.keras_utils"], [8, "module-neural_compressor.adaptor.keras_utils.pool2d"], [9, "module-neural_compressor.adaptor.keras_utils.quantizer"], [10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"], [11, "module-neural_compressor.adaptor.mxnet"], [12, "module-neural_compressor.adaptor.mxnet_utils"], [13, "module-neural_compressor.adaptor.mxnet_utils.util"], [14, "module-neural_compressor.adaptor.onnxrt"], [15, "module-neural_compressor.adaptor.ox_utils.calibration"], [16, "module-neural_compressor.adaptor.ox_utils.calibrator"], [17, "module-neural_compressor.adaptor.ox_utils"], [18, "module-neural_compressor.adaptor.ox_utils.operators.activation"], [19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"], [20, "module-neural_compressor.adaptor.ox_utils.operators.attention"], [21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"], [22, "module-neural_compressor.adaptor.ox_utils.operators.concat"], [23, "module-neural_compressor.adaptor.ox_utils.operators.conv"], [24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"], [25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"], [26, "module-neural_compressor.adaptor.ox_utils.operators.gather"], [27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"], [28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"], [29, "module-neural_compressor.adaptor.ox_utils.operators"], [30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"], [31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"], [32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"], [33, "module-neural_compressor.adaptor.ox_utils.operators.norm"], [34, "module-neural_compressor.adaptor.ox_utils.operators.ops"], [35, "module-neural_compressor.adaptor.ox_utils.operators.pad"], [36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"], [37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"], [38, "module-neural_compressor.adaptor.ox_utils.operators.resize"], [39, "module-neural_compressor.adaptor.ox_utils.operators.split"], [40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"], [41, "module-neural_compressor.adaptor.ox_utils.quantizer"], [42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"], [43, "module-neural_compressor.adaptor.ox_utils.util"], [44, "module-neural_compressor.adaptor.ox_utils.weight_only"], [45, "module-neural_compressor.adaptor.pytorch"], [46, "module-neural_compressor.adaptor.query"], [47, "module-neural_compressor.adaptor.tensorflow"], [48, "module-neural_compressor.adaptor.tf_utils.graph_converter"], [49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"], [50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"], [51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"], [52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"], [53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"], [54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"], [55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"], [56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"], [57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"], [58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"], [59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"], [60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"], [61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"], [62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"], [63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"], [64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"], [65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"], [66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"], [67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"], [68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"], [69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"], [70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"], [71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"], [72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"], [73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"], [74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"], [75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"], [76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"], [77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"], [78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"], [79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"], [80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"], [81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"], [82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"], [83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"], [84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"], [85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"], [86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"], [87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"], [88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"], [89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"], [90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"], [91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"], [92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"], [93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"], [94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"], [95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"], [96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"], [97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"], [98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"], [99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"], [100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"], [101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"], [102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"], [103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"], [104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"], [105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"], [106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"], [107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"], [108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"], [109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"], [110, "module-neural_compressor.adaptor.tf_utils.graph_util"], [111, "module-neural_compressor.adaptor.tf_utils"], [112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"], [113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"], [114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"], [115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"], [116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"], [117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"], [118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"], [119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"], [120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"], [121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"], [122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"], [123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"], [124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"], [125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"], [126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"], [127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"], [128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"], [129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"], [130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"], [131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"], [132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"], [133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"], [134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"], [135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"], [136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"], [137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"], [138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"], [139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"], [140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"], [141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"], [142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"], [143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"], [144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"], [145, "module-neural_compressor.adaptor.tf_utils.transform_graph"], [146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"], [147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"], [148, "module-neural_compressor.adaptor.tf_utils.util"], [149, "module-neural_compressor.adaptor.torch_utils.autoround.autoround"], [150, "module-neural_compressor.adaptor.torch_utils.autoround.export"], [151, "module-neural_compressor.adaptor.torch_utils.autoround"], [152, "module-neural_compressor.adaptor.torch_utils.autoround.model_wrapper"], [153, "module-neural_compressor.adaptor.torch_utils.autoround.sign_sgd"], [154, "module-neural_compressor.adaptor.torch_utils.awq"], [155, "module-neural_compressor.adaptor.torch_utils.bf16_convert"], [156, "module-neural_compressor.adaptor.torch_utils.gptq"], [157, "module-neural_compressor.adaptor.torch_utils.hawq_metric"], [158, "module-neural_compressor.adaptor.torch_utils"], [159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"], [160, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"], [161, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"], [162, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"], [163, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"], [164, "module-neural_compressor.adaptor.torch_utils.mixed_precision"], [165, "module-neural_compressor.adaptor.torch_utils.model_wrapper"], [166, "module-neural_compressor.adaptor.torch_utils.pattern_detector"], [167, "module-neural_compressor.adaptor.torch_utils.smooth_quant"], [168, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"], [169, "module-neural_compressor.adaptor.torch_utils.teq"], [170, "module-neural_compressor.adaptor.torch_utils.util"], [171, "module-neural_compressor.adaptor.torch_utils.weight_only"], [172, "module-neural_compressor.algorithm.algorithm"], [173, "module-neural_compressor.algorithm.fast_bias_correction"], [174, "module-neural_compressor.algorithm"], [175, "module-neural_compressor.algorithm.smooth_quant"], [176, "module-neural_compressor.algorithm.weight_correction"], [177, "module-neural_compressor.benchmark"], [178, "module-neural_compressor.common.base_config"], [179, "module-neural_compressor.common.base_tuning"], [180, "module-neural_compressor.common"], [181, "module-neural_compressor.common.tuning_param"], [182, "module-neural_compressor.common.utils.constants"], [183, "module-neural_compressor.common.utils"], [184, "module-neural_compressor.common.utils.logger"], [185, "module-neural_compressor.common.utils.utility"], [186, "module-neural_compressor.compression.callbacks"], [187, "module-neural_compressor.compression.distillation.criterions"], [188, "module-neural_compressor.compression.distillation"], [189, "module-neural_compressor.compression.distillation.optimizers"], [190, "module-neural_compressor.compression.distillation.utility"], [191, "module-neural_compressor.compression.hpo"], [192, "module-neural_compressor.compression.hpo.sa_optimizer"], [193, "module-neural_compressor.compression.hpo.search_algorithms"], [194, "module-neural_compressor.compression.hpo.search_space"], [195, "module-neural_compressor.compression"], [196, "module-neural_compressor.compression.pruner.criteria"], [197, "module-neural_compressor.compression.pruner.dsnot"], [198, "module-neural_compressor.compression.pruner"], [199, "module-neural_compressor.compression.pruner.model_slim.auto_slim"], [200, "module-neural_compressor.compression.pruner.model_slim"], [201, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"], [202, "module-neural_compressor.compression.pruner.model_slim.weight_slim"], [203, "module-neural_compressor.compression.pruner.patterns.base"], [204, "module-neural_compressor.compression.pruner.patterns"], [205, "module-neural_compressor.compression.pruner.patterns.mha"], [206, "module-neural_compressor.compression.pruner.patterns.ninm"], [207, "module-neural_compressor.compression.pruner.patterns.nxm"], [208, "module-neural_compressor.compression.pruner.pruners.base"], [209, "module-neural_compressor.compression.pruner.pruners.basic"], [210, "module-neural_compressor.compression.pruner.pruners.block_mask"], [211, "module-neural_compressor.compression.pruner.pruners"], [212, "module-neural_compressor.compression.pruner.pruners.mha"], [213, "module-neural_compressor.compression.pruner.pruners.pattern_lock"], [214, "module-neural_compressor.compression.pruner.pruners.progressive"], [215, "module-neural_compressor.compression.pruner.pruners.retrain_free"], [216, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"], [217, "module-neural_compressor.compression.pruner.pruning"], [218, "module-neural_compressor.compression.pruner.regs"], [219, "module-neural_compressor.compression.pruner.schedulers"], [220, "module-neural_compressor.compression.pruner.tf_criteria"], [221, "module-neural_compressor.compression.pruner.utils"], [222, "module-neural_compressor.compression.pruner.wanda"], [223, "module-neural_compressor.compression.pruner.wanda.prune"], [224, "module-neural_compressor.compression.pruner.wanda.utils"], [225, "module-neural_compressor.compression.pruner.wanda.wrapper"], [226, "module-neural_compressor.conf.config"], [227, "module-neural_compressor.conf.dotdict"], [228, "module-neural_compressor.conf"], [229, "module-neural_compressor.conf.pythonic_config"], [230, "module-neural_compressor.config"], [231, "module-neural_compressor.contrib"], [232, "module-neural_compressor.contrib.strategy"], [233, "module-neural_compressor.contrib.strategy.sigopt"], [234, "module-neural_compressor.contrib.strategy.tpe"], [235, "module-neural_compressor.data.dataloaders.base_dataloader"], [236, "module-neural_compressor.data.dataloaders.dataloader"], [237, "module-neural_compressor.data.dataloaders.default_dataloader"], [238, "module-neural_compressor.data.dataloaders.fetcher"], [239, "module-neural_compressor.data.dataloaders"], [240, "module-neural_compressor.data.dataloaders.mxnet_dataloader"], [241, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"], [242, "module-neural_compressor.data.dataloaders.pytorch_dataloader"], [243, "module-neural_compressor.data.dataloaders.sampler"], [244, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"], [245, "module-neural_compressor.data.datasets.bert_dataset"], [246, "module-neural_compressor.data.datasets.coco_dataset"], [247, "module-neural_compressor.data.datasets.dataset"], [248, "module-neural_compressor.data.datasets.dummy_dataset"], [249, "module-neural_compressor.data.datasets.dummy_dataset_v2"], [250, "module-neural_compressor.data.datasets.imagenet_dataset"], [251, "module-neural_compressor.data.datasets"], [252, "module-neural_compressor.data.datasets.style_transfer_dataset"], [253, "module-neural_compressor.data.filters.coco_filter"], [254, "module-neural_compressor.data.filters.filter"], [255, "module-neural_compressor.data.filters"], [256, "module-neural_compressor.data"], [257, "module-neural_compressor.data.transforms.coco_transform"], [258, "module-neural_compressor.data.transforms.imagenet_transform"], [259, "module-neural_compressor.data.transforms"], [260, "module-neural_compressor.data.transforms.postprocess"], [261, "module-neural_compressor.data.transforms.tokenization"], [262, "module-neural_compressor.data.transforms.transform"], [263, "module-neural_compressor.experimental.benchmark"], [264, "module-neural_compressor.experimental.common.criterion"], [265, "module-neural_compressor.experimental.common.dataloader"], [266, "module-neural_compressor.experimental.common"], [267, "module-neural_compressor.experimental.common.metric"], [268, "module-neural_compressor.experimental.common.model"], [269, "module-neural_compressor.experimental.common.optimizer"], [270, "module-neural_compressor.experimental.common.postprocess"], [271, "module-neural_compressor.experimental.common.torch_utils"], [272, "module-neural_compressor.experimental.component"], [273, "module-neural_compressor.experimental.compression"], [274, "module-neural_compressor.experimental.contrib"], [275, "module-neural_compressor.experimental.contrib.strategy"], [276, "module-neural_compressor.experimental.contrib.strategy.sigopt"], [277, "module-neural_compressor.experimental.contrib.strategy.tpe"], [278, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"], [279, "module-neural_compressor.experimental.data.dataloaders.dataloader"], [280, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"], [281, "module-neural_compressor.experimental.data.dataloaders.fetcher"], [282, "module-neural_compressor.experimental.data.dataloaders"], [283, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"], [284, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"], [285, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"], [286, "module-neural_compressor.experimental.data.dataloaders.sampler"], [287, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"], [288, "module-neural_compressor.experimental.data.datasets.bert_dataset"], [289, "module-neural_compressor.experimental.data.datasets.coco_dataset"], [290, "module-neural_compressor.experimental.data.datasets.dataset"], [291, "module-neural_compressor.experimental.data.datasets.dummy_dataset"], [292, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"], [293, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"], [294, "module-neural_compressor.experimental.data.datasets"], [295, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"], [296, "module-neural_compressor.experimental.data.filters.coco_filter"], [297, "module-neural_compressor.experimental.data.filters.filter"], [298, "module-neural_compressor.experimental.data.filters"], [299, "module-neural_compressor.experimental.data"], [300, "module-neural_compressor.experimental.data.transforms.imagenet_transform"], [301, "module-neural_compressor.experimental.data.transforms"], [302, "module-neural_compressor.experimental.data.transforms.tokenization"], [303, "module-neural_compressor.experimental.data.transforms.transform"], [304, "module-neural_compressor.experimental.distillation"], [305, "module-neural_compressor.experimental.export"], [306, "module-neural_compressor.experimental.export.qlinear2qdq"], [307, "module-neural_compressor.experimental.export.tf2onnx"], [308, "module-neural_compressor.experimental.export.torch2onnx"], [309, "module-neural_compressor.experimental.graph_optimization"], [310, "module-neural_compressor.experimental"], [311, "module-neural_compressor.experimental.metric.bleu"], [312, "module-neural_compressor.experimental.metric.bleu_util"], [313, "module-neural_compressor.experimental.metric.coco_label_map"], [314, "module-neural_compressor.experimental.metric.coco_tools"], [315, "module-neural_compressor.experimental.metric.evaluate_squad"], [316, "module-neural_compressor.experimental.metric.f1"], [317, "module-neural_compressor.experimental.metric"], [318, "module-neural_compressor.experimental.metric.metric"], [319, "module-neural_compressor.experimental.mixed_precision"], [320, "module-neural_compressor.experimental.model_conversion"], [321, "module-neural_compressor.experimental.nas.basic_nas"], [322, "module-neural_compressor.experimental.nas.dynas"], [323, "module-neural_compressor.experimental.nas"], [324, "module-neural_compressor.experimental.nas.nas"], [325, "module-neural_compressor.experimental.nas.nas_utils"], [326, "module-neural_compressor.experimental.nas.search_algorithms"], [327, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"], [328, "module-neural_compressor.experimental.pruner_legacy.group_lasso"], [329, "module-neural_compressor.experimental.pruner_legacy"], [330, "module-neural_compressor.experimental.pruner_legacy.magnitude"], [331, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"], [332, "module-neural_compressor.experimental.pruner_legacy.pruner"], [333, "module-neural_compressor.experimental.pruning"], [334, "module-neural_compressor.experimental.pruning_recipes"], [335, "module-neural_compressor.experimental.pruning_recipes.patterns"], [336, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"], [337, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"], [338, "module-neural_compressor.experimental.pruning_v2"], [339, "module-neural_compressor.experimental.pytorch_pruner"], [340, "module-neural_compressor.experimental.pytorch_pruner.logger"], [341, "module-neural_compressor.experimental.pytorch_pruner.patterns"], [342, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"], [343, "module-neural_compressor.experimental.pytorch_pruner.pruner"], [344, "module-neural_compressor.experimental.pytorch_pruner.pruning"], [345, "module-neural_compressor.experimental.pytorch_pruner.scheduler"], [346, "module-neural_compressor.experimental.quantization"], [347, "module-neural_compressor.experimental.scheduler"], [348, "module-neural_compressor.experimental.strategy.auto_mixed_precision"], [349, "module-neural_compressor.experimental.strategy.basic"], [350, "module-neural_compressor.experimental.strategy.bayesian"], [351, "module-neural_compressor.experimental.strategy.exhaustive"], [352, "module-neural_compressor.experimental.strategy"], [353, "module-neural_compressor.experimental.strategy.mse"], [354, "module-neural_compressor.experimental.strategy.mse_v2"], [355, "module-neural_compressor.experimental.strategy.random"], [356, "module-neural_compressor.experimental.strategy.strategy"], [357, "module-neural_compressor.experimental.strategy.utils.constant"], [358, "module-neural_compressor.experimental.strategy.utils"], [359, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"], [360, "module-neural_compressor.experimental.strategy.utils.tuning_space"], [361, "module-neural_compressor.experimental.strategy.utils.tuning_structs"], [362, "module-neural_compressor.experimental.strategy.utils.utility"], [363, "module-neural_compressor"], [364, "module-neural_compressor.metric.bleu"], [365, "module-neural_compressor.metric.bleu_util"], [366, "module-neural_compressor.metric.coco_label_map"], [367, "module-neural_compressor.metric.coco_tools"], [368, "module-neural_compressor.metric.evaluate_squad"], [369, "module-neural_compressor.metric.f1"], [370, "module-neural_compressor.metric"], [371, "module-neural_compressor.metric.metric"], [372, "module-neural_compressor.mix_precision"], [373, "module-neural_compressor.model.base_model"], [374, "module-neural_compressor.model"], [375, "module-neural_compressor.model.keras_model"], [376, "module-neural_compressor.model.model"], [377, "module-neural_compressor.model.mxnet_model"], [378, "module-neural_compressor.model.nets_factory"], [379, "module-neural_compressor.model.onnx_model"], [380, "module-neural_compressor.model.tensorflow_model"], [381, "module-neural_compressor.model.torch_model"], [382, "module-neural_compressor.objective"], [383, "module-neural_compressor.onnxrt.algorithms"], [384, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"], [385, "module-neural_compressor.onnxrt.algorithms.smoother.core"], [386, "module-neural_compressor.onnxrt.algorithms.smoother"], [387, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"], [388, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"], [389, "module-neural_compressor.onnxrt.algorithms.weight_only"], [390, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"], [391, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"], [392, "module-neural_compressor.onnxrt"], [393, "module-neural_compressor.onnxrt.quantization.algorithm_entry"], [394, "module-neural_compressor.onnxrt.quantization.autotune"], [395, "module-neural_compressor.onnxrt.quantization.calibrate"], [396, "module-neural_compressor.onnxrt.quantization.config"], [397, "module-neural_compressor.onnxrt.quantization"], [398, "module-neural_compressor.onnxrt.quantization.quantize"], [399, "module-neural_compressor.onnxrt.utils"], [400, "module-neural_compressor.onnxrt.utils.onnx_model"], [401, "module-neural_compressor.onnxrt.utils.utility"], [402, "module-neural_compressor.profiling"], [403, "module-neural_compressor.profiling.parser.factory"], [404, "module-neural_compressor.profiling.parser"], [405, "module-neural_compressor.profiling.parser.onnx_parser.factory"], [406, "module-neural_compressor.profiling.parser.onnx_parser"], [407, "module-neural_compressor.profiling.parser.onnx_parser.parser"], [408, "module-neural_compressor.profiling.parser.parser"], [409, "module-neural_compressor.profiling.parser.result"], [410, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"], [411, "module-neural_compressor.profiling.parser.tensorflow_parser"], [412, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"], [413, "module-neural_compressor.profiling.profiler.factory"], [414, "module-neural_compressor.profiling.profiler"], [415, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"], [416, "module-neural_compressor.profiling.profiler.onnxrt_profiler"], [417, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"], [418, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"], [419, "module-neural_compressor.profiling.profiler.profiler"], [420, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"], [421, "module-neural_compressor.profiling.profiler.tensorflow_profiler"], [422, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"], [423, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"], [424, "module-neural_compressor.quantization"], [425, "module-neural_compressor.strategy.auto"], [426, "module-neural_compressor.strategy.auto_mixed_precision"], [427, "module-neural_compressor.strategy.basic"], [428, "module-neural_compressor.strategy.bayesian"], [429, "module-neural_compressor.strategy.conservative"], [430, "module-neural_compressor.strategy.exhaustive"], [431, "module-neural_compressor.strategy.hawq_v2"], [432, "module-neural_compressor.strategy"], [433, "module-neural_compressor.strategy.mse"], [434, "module-neural_compressor.strategy.mse_v2"], [435, "module-neural_compressor.strategy.random"], [436, "module-neural_compressor.strategy.strategy"], [437, "module-neural_compressor.strategy.utils.constant"], [438, "module-neural_compressor.strategy.utils"], [439, "module-neural_compressor.strategy.utils.tuning_sampler"], [440, "module-neural_compressor.strategy.utils.tuning_space"], [441, "module-neural_compressor.strategy.utils.tuning_structs"], [442, "module-neural_compressor.strategy.utils.utility"], [443, "module-neural_compressor.template.api_doc_example"], [444, "module-neural_compressor.template"], [445, "module-neural_compressor.tensorflow.algorithms"], [446, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"], [447, "module-neural_compressor.tensorflow.algorithms.smoother.core"], [448, "module-neural_compressor.tensorflow.algorithms.smoother"], [449, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"], [450, "module-neural_compressor.tensorflow.algorithms.static_quant"], [451, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"], [452, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d"], [453, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense"], [454, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d"], [455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils"], [456, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d"], [457, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer"], [458, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d"], [459, "module-neural_compressor.tensorflow"], [460, "module-neural_compressor.tensorflow.quantization.algorithm_entry"], [461, "module-neural_compressor.tensorflow.quantization.config"], [462, "module-neural_compressor.tensorflow.quantization"], [463, "module-neural_compressor.tensorflow.quantization.quantize"], [464, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"], [465, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"], [466, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"], [467, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"], [468, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"], [469, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"], [470, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"], [471, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"], [472, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"], [473, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"], [474, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"], [475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"], [476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"], [477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"], [478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"], [479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"], [480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"], [481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"], [482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"], [483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"], [484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"], [485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"], [486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"], [487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"], [488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"], [489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"], [490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"], [491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"], [492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"], [493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"], [494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"], [495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"], [496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"], [497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"], [498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"], [499, "module-neural_compressor.tensorflow.quantization.utils.graph_util"], [500, "module-neural_compressor.tensorflow.quantization.utils"], [501, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"], [502, "module-neural_compressor.tensorflow.quantization.utils.utility"], [503, "module-neural_compressor.tensorflow.utils.constants"], [504, "module-neural_compressor.tensorflow.utils.data"], [505, "module-neural_compressor.tensorflow.utils"], [506, "module-neural_compressor.tensorflow.utils.model"], [507, "module-neural_compressor.tensorflow.utils.model_wrappers"], [508, "module-neural_compressor.tensorflow.utils.nets_factory"], [509, "module-neural_compressor.tensorflow.utils.utility"], [510, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"], [511, "module-neural_compressor.torch.algorithms.habana_fp8"], [512, "module-neural_compressor.torch.algorithms.habana_fp8.modules"], [513, "module-neural_compressor.torch.algorithms.habana_fp8.observer"], [514, "module-neural_compressor.torch.algorithms"], [515, "module-neural_compressor.torch.algorithms.layer_wise"], [516, "module-neural_compressor.torch.algorithms.layer_wise.load"], [517, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"], [518, "module-neural_compressor.torch.algorithms.layer_wise.utils"], [519, "module-neural_compressor.torch.algorithms.static_quant"], [520, "module-neural_compressor.torch.algorithms.static_quant.static_quant"], [521, "module-neural_compressor.torch.algorithms.static_quant.utility"], [522, "module-neural_compressor.torch.algorithms.weight_only.awq"], [523, "module-neural_compressor.torch.algorithms.weight_only.gptq"], [524, "module-neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator"], [525, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"], [526, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"], [527, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"], [528, "module-neural_compressor.torch.algorithms.weight_only.hqq"], [529, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"], [530, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"], [531, "module-neural_compressor.torch.algorithms.weight_only.hqq.quant_api"], [532, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"], [533, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"], [534, "module-neural_compressor.torch.algorithms.weight_only"], [535, "module-neural_compressor.torch.algorithms.weight_only.modules"], [536, "module-neural_compressor.torch.algorithms.weight_only.rtn"], [537, "module-neural_compressor.torch.algorithms.weight_only.teq"], [538, "module-neural_compressor.torch.algorithms.weight_only.utility"], [539, "module-neural_compressor.torch.amp.autocast"], [540, "module-neural_compressor.torch.amp.fp8.functions"], [541, "module-neural_compressor.torch.amp.fp8"], [542, "module-neural_compressor.torch.amp"], [543, "module-neural_compressor.torch"], [544, "module-neural_compressor.torch.quantization.algorithm_entry"], [545, "module-neural_compressor.torch.quantization.autotune"], [546, "module-neural_compressor.torch.quantization.config"], [547, "module-neural_compressor.torch.quantization"], [548, "module-neural_compressor.torch.quantization.modules"], [549, "module-neural_compressor.torch.quantization.quantize"], [550, "module-neural_compressor.torch.utils.constants"], [551, "module-neural_compressor.torch.utils.environ"], [552, "module-neural_compressor.torch.utils"], [553, "module-neural_compressor.torch.utils.utility"], [554, "module-neural_compressor.training"], [555, "module-neural_compressor.utils.collect_layer_histogram"], [556, "module-neural_compressor.utils.constant"], [557, "module-neural_compressor.utils.create_obj_from_config"], [558, "module-neural_compressor.utils"], [559, "module-neural_compressor.utils.kl_divergence"], [560, "module-neural_compressor.utils.load_huggingface"], [561, "module-neural_compressor.utils.logger"], [562, "module-neural_compressor.utils.neural_insights_utils"], [563, "module-neural_compressor.utils.options"], [564, "module-neural_compressor.utils.pytorch"], [565, "module-neural_compressor.utils.utility"], [566, "module-neural_compressor.utils.weights_details"], [567, "module-neural_compressor.version"]], "adaptor (class in neural_compressor.adaptor.adaptor)": [[1, "neural_compressor.adaptor.adaptor.Adaptor"]], "adaptor_registry() (in module neural_compressor.adaptor.adaptor)": [[1, "neural_compressor.adaptor.adaptor.adaptor_registry"]], "neural_compressor.adaptor.adaptor": [[1, "module-neural_compressor.adaptor.adaptor"]], "neural_compressor.adaptor": [[2, "module-neural_compressor.adaptor"]], "kerasadaptor (class in neural_compressor.adaptor.keras)": [[3, "neural_compressor.adaptor.keras.KerasAdaptor"]], "neural_compressor.adaptor.keras": [[3, "module-neural_compressor.adaptor.keras"]], "neural_compressor.adaptor.keras_utils.conv2d": [[4, "module-neural_compressor.adaptor.keras_utils.conv2d"]], "neural_compressor.adaptor.keras_utils.dense": [[5, "module-neural_compressor.adaptor.keras_utils.dense"]], "neural_compressor.adaptor.keras_utils.depthwise_conv2d": [[6, "module-neural_compressor.adaptor.keras_utils.depthwise_conv2d"]], "neural_compressor.adaptor.keras_utils": [[7, "module-neural_compressor.adaptor.keras_utils"]], "neural_compressor.adaptor.keras_utils.pool2d": [[8, "module-neural_compressor.adaptor.keras_utils.pool2d"]], "neural_compressor.adaptor.keras_utils.quantizer": [[9, "module-neural_compressor.adaptor.keras_utils.quantizer"]], "neural_compressor.adaptor.keras_utils.separable_conv2d": [[10, "module-neural_compressor.adaptor.keras_utils.separable_conv2d"]], "mxnetquery (class in neural_compressor.adaptor.mxnet)": [[11, "neural_compressor.adaptor.mxnet.MXNetQuery"]], "mxnetadaptor (class in neural_compressor.adaptor.mxnet)": [[11, "neural_compressor.adaptor.mxnet.MxNetAdaptor"]], "neural_compressor.adaptor.mxnet": [[11, "module-neural_compressor.adaptor.mxnet"]], "neural_compressor.adaptor.mxnet_utils": [[12, "module-neural_compressor.adaptor.mxnet_utils"]], "calibcollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CalibCollector"]], "calibdata (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CalibData"]], "collectorbase (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.CollectorBase"]], "dataiterloader (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.DataIterLoader"]], "dataloaderwrap (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.DataLoaderWrap"]], "namecollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.NameCollector"]], "optype (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.OpType"]], "tensorcollector (class in neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.TensorCollector"]], "amp_convert() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.amp_convert"]], "calib_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.calib_model"]], "check_mx_version() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.check_mx_version"]], "combine_capabilities() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.combine_capabilities"]], "create_data_example() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.create_data_example"]], "distribute_calib_tensors() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.distribute_calib_tensors"]], "ensure_list() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.ensure_list"]], "fuse() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.fuse"]], "get_framework_name() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.get_framework_name"]], "is_model_quantized() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.is_model_quantized"]], "isiterable() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.isiterable"]], "make_module() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_module"]], "make_nc_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_nc_model"]], "make_symbol_block() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.make_symbol_block"]], "ndarray_to_device() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.ndarray_to_device"]], "neural_compressor.adaptor.mxnet_utils.util": [[13, "module-neural_compressor.adaptor.mxnet_utils.util"]], "parse_tune_config() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.parse_tune_config"]], "prepare_dataloader() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_dataloader"]], "prepare_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_model"]], "prepare_model_data() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.prepare_model_data"]], "quantize_sym_model() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.quantize_sym_model"]], "query_quantizable_nodes() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.query_quantizable_nodes"]], "run_forward() (in module neural_compressor.adaptor.mxnet_utils.util)": [[13, "neural_compressor.adaptor.mxnet_utils.util.run_forward"]], "onnxrtquery (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRTQuery"]], "onnxrt_integeropsadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_IntegerOpsAdaptor"]], "onnxrt_qdqadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_QDQAdaptor"]], "onnxrt_qlinearopsadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_QLinearOpsAdaptor"]], "onnxrt_weightonlyadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRT_WeightOnlyAdaptor"]], "onnxruntimeadaptor (class in neural_compressor.adaptor.onnxrt)": [[14, "neural_compressor.adaptor.onnxrt.ONNXRUNTIMEAdaptor"]], "neural_compressor.adaptor.onnxrt": [[14, "module-neural_compressor.adaptor.onnxrt"]], "onnxrtaugment (class in neural_compressor.adaptor.ox_utils.calibration)": [[15, "neural_compressor.adaptor.ox_utils.calibration.ONNXRTAugment"]], "neural_compressor.adaptor.ox_utils.calibration": [[15, "module-neural_compressor.adaptor.ox_utils.calibration"]], "calibratorbase (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.CalibratorBase"]], "histogramcollector (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.HistogramCollector"]], "klcalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.KLCalibrator"]], "minmaxcalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.MinMaxCalibrator"]], "percentilecalibrator (class in neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.PercentileCalibrator"]], "calib_registry() (in module neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.calib_registry"]], "neural_compressor.adaptor.ox_utils.calibrator": [[16, "module-neural_compressor.adaptor.ox_utils.calibrator"]], "smooth_distribution() (in module neural_compressor.adaptor.ox_utils.calibrator)": [[16, "neural_compressor.adaptor.ox_utils.calibrator.smooth_distribution"]], "neural_compressor.adaptor.ox_utils": [[17, "module-neural_compressor.adaptor.ox_utils"]], "activationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.ActivationOperator"]], "float16activationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.Float16ActivationOperator"]], "qactivationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.QActivationOperator"]], "removableactivationoperator (class in neural_compressor.adaptor.ox_utils.operators.activation)": [[18, "neural_compressor.adaptor.ox_utils.operators.activation.RemovableActivationOperator"]], "neural_compressor.adaptor.ox_utils.operators.activation": [[18, "module-neural_compressor.adaptor.ox_utils.operators.activation"]], "argmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.argmax)": [[19, "neural_compressor.adaptor.ox_utils.operators.argmax.ArgMaxOperator"]], "qargmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.argmax)": [[19, "neural_compressor.adaptor.ox_utils.operators.argmax.QArgMaxOperator"]], "neural_compressor.adaptor.ox_utils.operators.argmax": [[19, "module-neural_compressor.adaptor.ox_utils.operators.argmax"]], "attentionoperator (class in neural_compressor.adaptor.ox_utils.operators.attention)": [[20, "neural_compressor.adaptor.ox_utils.operators.attention.AttentionOperator"]], "qattentionoperator (class in neural_compressor.adaptor.ox_utils.operators.attention)": [[20, "neural_compressor.adaptor.ox_utils.operators.attention.QAttentionOperator"]], "neural_compressor.adaptor.ox_utils.operators.attention": [[20, "module-neural_compressor.adaptor.ox_utils.operators.attention"]], "binarydirect8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.BinaryDirect8BitOperator"]], "binaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.BinaryOperator"]], "float16binaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.Float16BinaryOperator"]], "qbinaryoperator (class in neural_compressor.adaptor.ox_utils.operators.binary_op)": [[21, "neural_compressor.adaptor.ox_utils.operators.binary_op.QBinaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.binary_op": [[21, "module-neural_compressor.adaptor.ox_utils.operators.binary_op"]], "concatoperator (class in neural_compressor.adaptor.ox_utils.operators.concat)": [[22, "neural_compressor.adaptor.ox_utils.operators.concat.ConcatOperator"]], "qconcatoperator (class in neural_compressor.adaptor.ox_utils.operators.concat)": [[22, "neural_compressor.adaptor.ox_utils.operators.concat.QConcatOperator"]], "neural_compressor.adaptor.ox_utils.operators.concat": [[22, "module-neural_compressor.adaptor.ox_utils.operators.concat"]], "convoperator (class in neural_compressor.adaptor.ox_utils.operators.conv)": [[23, "neural_compressor.adaptor.ox_utils.operators.conv.ConvOperator"]], "qconvoperator (class in neural_compressor.adaptor.ox_utils.operators.conv)": [[23, "neural_compressor.adaptor.ox_utils.operators.conv.QConvOperator"]], "neural_compressor.adaptor.ox_utils.operators.conv": [[23, "module-neural_compressor.adaptor.ox_utils.operators.conv"]], "direct8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.direct_q8)": [[24, "neural_compressor.adaptor.ox_utils.operators.direct_q8.Direct8BitOperator"]], "qdirectoperator (class in neural_compressor.adaptor.ox_utils.operators.direct_q8)": [[24, "neural_compressor.adaptor.ox_utils.operators.direct_q8.QDirectOperator"]], "neural_compressor.adaptor.ox_utils.operators.direct_q8": [[24, "module-neural_compressor.adaptor.ox_utils.operators.direct_q8"]], "embedlayernormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.embed_layernorm)": [[25, "neural_compressor.adaptor.ox_utils.operators.embed_layernorm.EmbedLayerNormalizationOperator"]], "qembedlayernormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.embed_layernorm)": [[25, "neural_compressor.adaptor.ox_utils.operators.embed_layernorm.QEmbedLayerNormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.embed_layernorm": [[25, "module-neural_compressor.adaptor.ox_utils.operators.embed_layernorm"]], "gatheroperator (class in neural_compressor.adaptor.ox_utils.operators.gather)": [[26, "neural_compressor.adaptor.ox_utils.operators.gather.GatherOperator"]], "qgatheroperator (class in neural_compressor.adaptor.ox_utils.operators.gather)": [[26, "neural_compressor.adaptor.ox_utils.operators.gather.QGatherOperator"]], "neural_compressor.adaptor.ox_utils.operators.gather": [[26, "module-neural_compressor.adaptor.ox_utils.operators.gather"]], "globalaveragepooloperator (class in neural_compressor.adaptor.ox_utils.operators.gavgpool)": [[27, "neural_compressor.adaptor.ox_utils.operators.gavgpool.GlobalAveragePoolOperator"]], "qglobalaveragepooloperator (class in neural_compressor.adaptor.ox_utils.operators.gavgpool)": [[27, "neural_compressor.adaptor.ox_utils.operators.gavgpool.QGlobalAveragePoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.gavgpool": [[27, "module-neural_compressor.adaptor.ox_utils.operators.gavgpool"]], "gemmoperator (class in neural_compressor.adaptor.ox_utils.operators.gemm)": [[28, "neural_compressor.adaptor.ox_utils.operators.gemm.GemmOperator"]], "qgemmoperator (class in neural_compressor.adaptor.ox_utils.operators.gemm)": [[28, "neural_compressor.adaptor.ox_utils.operators.gemm.QGemmOperator"]], "neural_compressor.adaptor.ox_utils.operators.gemm": [[28, "module-neural_compressor.adaptor.ox_utils.operators.gemm"]], "neural_compressor.adaptor.ox_utils.operators": [[29, "module-neural_compressor.adaptor.ox_utils.operators"]], "lstmoperator (class in neural_compressor.adaptor.ox_utils.operators.lstm)": [[30, "neural_compressor.adaptor.ox_utils.operators.lstm.LSTMOperator"]], "neural_compressor.adaptor.ox_utils.operators.lstm": [[30, "module-neural_compressor.adaptor.ox_utils.operators.lstm"]], "fusedmatmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.FusedMatMulOperator"]], "matmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.MatMulOperator"]], "qmatmuloperator (class in neural_compressor.adaptor.ox_utils.operators.matmul)": [[31, "neural_compressor.adaptor.ox_utils.operators.matmul.QMatMulOperator"]], "neural_compressor.adaptor.ox_utils.operators.matmul": [[31, "module-neural_compressor.adaptor.ox_utils.operators.matmul"]], "maxpooloperator (class in neural_compressor.adaptor.ox_utils.operators.maxpool)": [[32, "neural_compressor.adaptor.ox_utils.operators.maxpool.MaxPoolOperator"]], "qmaxpooloperator (class in neural_compressor.adaptor.ox_utils.operators.maxpool)": [[32, "neural_compressor.adaptor.ox_utils.operators.maxpool.QMaxPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.maxpool": [[32, "module-neural_compressor.adaptor.ox_utils.operators.maxpool"]], "batchnormalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.norm)": [[33, "neural_compressor.adaptor.ox_utils.operators.norm.BatchNormalizationOperator"]], "normalizationoperator (class in neural_compressor.adaptor.ox_utils.operators.norm)": [[33, "neural_compressor.adaptor.ox_utils.operators.norm.NormalizationOperator"]], "neural_compressor.adaptor.ox_utils.operators.norm": [[33, "module-neural_compressor.adaptor.ox_utils.operators.norm"]], "operator (class in neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.Operator"]], "qoperator (class in neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.QOperator"]], "neural_compressor.adaptor.ox_utils.operators.ops": [[34, "module-neural_compressor.adaptor.ox_utils.operators.ops"]], "op_registry() (in module neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.op_registry"]], "qop_registry() (in module neural_compressor.adaptor.ox_utils.operators.ops)": [[34, "neural_compressor.adaptor.ox_utils.operators.ops.qop_registry"]], "padoperator (class in neural_compressor.adaptor.ox_utils.operators.pad)": [[35, "neural_compressor.adaptor.ox_utils.operators.pad.PadOperator"]], "qpadoperator (class in neural_compressor.adaptor.ox_utils.operators.pad)": [[35, "neural_compressor.adaptor.ox_utils.operators.pad.QPadOperator"]], "neural_compressor.adaptor.ox_utils.operators.pad": [[35, "module-neural_compressor.adaptor.ox_utils.operators.pad"]], "pooloperator (class in neural_compressor.adaptor.ox_utils.operators.pooling)": [[36, "neural_compressor.adaptor.ox_utils.operators.pooling.PoolOperator"]], "qpooloperator (class in neural_compressor.adaptor.ox_utils.operators.pooling)": [[36, "neural_compressor.adaptor.ox_utils.operators.pooling.QPoolOperator"]], "neural_compressor.adaptor.ox_utils.operators.pooling": [[36, "module-neural_compressor.adaptor.ox_utils.operators.pooling"]], "reduceminmaxoperator (class in neural_compressor.adaptor.ox_utils.operators.reduce)": [[37, "neural_compressor.adaptor.ox_utils.operators.reduce.ReduceMinMaxOperator"]], "reduceoperator (class in neural_compressor.adaptor.ox_utils.operators.reduce)": [[37, "neural_compressor.adaptor.ox_utils.operators.reduce.ReduceOperator"]], "neural_compressor.adaptor.ox_utils.operators.reduce": [[37, "module-neural_compressor.adaptor.ox_utils.operators.reduce"]], "qresizeoperator (class in neural_compressor.adaptor.ox_utils.operators.resize)": [[38, "neural_compressor.adaptor.ox_utils.operators.resize.QResizeOperator"]], "resizeoperator (class in neural_compressor.adaptor.ox_utils.operators.resize)": [[38, "neural_compressor.adaptor.ox_utils.operators.resize.ResizeOperator"]], "neural_compressor.adaptor.ox_utils.operators.resize": [[38, "module-neural_compressor.adaptor.ox_utils.operators.resize"]], "qsplitoperator (class in neural_compressor.adaptor.ox_utils.operators.split)": [[39, "neural_compressor.adaptor.ox_utils.operators.split.QSplitOperator"]], "splitoperator (class in neural_compressor.adaptor.ox_utils.operators.split)": [[39, "neural_compressor.adaptor.ox_utils.operators.split.SplitOperator"]], "neural_compressor.adaptor.ox_utils.operators.split": [[39, "module-neural_compressor.adaptor.ox_utils.operators.split"]], "unarydirect8bitoperator (class in neural_compressor.adaptor.ox_utils.operators.unary_op)": [[40, "neural_compressor.adaptor.ox_utils.operators.unary_op.UnaryDirect8BitOperator"]], "unaryoperator (class in neural_compressor.adaptor.ox_utils.operators.unary_op)": [[40, "neural_compressor.adaptor.ox_utils.operators.unary_op.UnaryOperator"]], "neural_compressor.adaptor.ox_utils.operators.unary_op": [[40, "module-neural_compressor.adaptor.ox_utils.operators.unary_op"]], "quantizer (class in neural_compressor.adaptor.ox_utils.quantizer)": [[41, "neural_compressor.adaptor.ox_utils.quantizer.Quantizer"]], "neural_compressor.adaptor.ox_utils.quantizer": [[41, "module-neural_compressor.adaptor.ox_utils.quantizer"]], "ortsmoothquant (class in neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.ORTSmoothQuant"]], "get_quant_dequant_output() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.get_quant_dequant_output"]], "make_sub_graph() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.make_sub_graph"]], "neural_compressor.adaptor.ox_utils.smooth_quant": [[42, "module-neural_compressor.adaptor.ox_utils.smooth_quant"]], "quant_dequant_data() (in module neural_compressor.adaptor.ox_utils.smooth_quant)": [[42, "neural_compressor.adaptor.ox_utils.smooth_quant.quant_dequant_data"]], "quantformat (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantFormat"]], "quanttype (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantType"]], "quantizationmode (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizationMode"]], "quantizedinitializer (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedInitializer"]], "quantizedvalue (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedValue"]], "quantizedvaluetype (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.QuantizedValueType"]], "valueinfo (class in neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.ValueInfo"]], "attribute_to_kwarg() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.attribute_to_kwarg"]], "calculate_scale_zp() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.calculate_scale_zp"]], "cast_tensor() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.cast_tensor"]], "collate_preds() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.collate_preds"]], "dequantize_data() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dequantize_data"]], "dequantize_data_with_scale_zero() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dequantize_data_with_scale_zero"]], "dtype_to_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.dtype_to_name"]], "find_by_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.find_by_name"]], "float_to_bfloat16() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.float_to_bfloat16"]], "float_to_float16() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.float_to_float16"]], "get_node_original_name() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.get_node_original_name"]], "infer_shapes() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.infer_shapes"]], "is_b_transposed() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.is_B_transposed"]], "make_dquant_node() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.make_dquant_node"]], "make_quant_node() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.make_quant_node"]], "neural_compressor.adaptor.ox_utils.util": [[43, "module-neural_compressor.adaptor.ox_utils.util"]], "quantize_data() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data"]], "quantize_data_per_channel() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data_per_channel"]], "quantize_data_with_scale_zero() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_data_with_scale_zero"]], "quantize_nparray() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.quantize_nparray"]], "remove_init_from_model_input() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.remove_init_from_model_input"]], "simple_progress_bar() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.simple_progress_bar"]], "split_shared_bias() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.split_shared_bias"]], "to_numpy() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.to_numpy"]], "trt_env_setup() (in module neural_compressor.adaptor.ox_utils.util)": [[43, "neural_compressor.adaptor.ox_utils.util.trt_env_setup"]], "apply_awq_clip() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.apply_awq_clip"]], "apply_awq_scale() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.apply_awq_scale"]], "awq_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.awq_quantize"]], "get_blob_size() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.get_blob_size"]], "get_weight_scale() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.get_weight_scale"]], "gptq() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.gptq"]], "gptq_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.gptq_quantize"]], "make_matmul_weight_only_node() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.make_matmul_weight_only_node"]], "neural_compressor.adaptor.ox_utils.weight_only": [[44, "module-neural_compressor.adaptor.ox_utils.weight_only"]], "pad_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.pad_tensor"]], "prepare_inputs() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.prepare_inputs"]], "qdq_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.qdq_tensor"]], "quant_tensor() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.quant_tensor"]], "rtn_quantize() (in module neural_compressor.adaptor.ox_utils.weight_only)": [[44, "neural_compressor.adaptor.ox_utils.weight_only.rtn_quantize"]], "pytorchadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorchAdaptor"]], "pytorchweightonlyadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorchWeightOnlyAdaptor"]], "pytorch_fxadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorch_FXAdaptor"]], "pytorch_ipexadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.PyTorch_IPEXAdaptor"]], "templateadaptor (class in neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.TemplateAdaptor"]], "get_ops_recursively() (in module neural_compressor.adaptor.pytorch)": [[45, "neural_compressor.adaptor.pytorch.get_ops_recursively"]], "neural_compressor.adaptor.pytorch": [[45, "module-neural_compressor.adaptor.pytorch"]], "querybackendcapability (class in neural_compressor.adaptor.query)": [[46, "neural_compressor.adaptor.query.QueryBackendCapability"]], "neural_compressor.adaptor.query": [[46, "module-neural_compressor.adaptor.query"]], "tensorflowadaptor (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.TensorFlowAdaptor"]], "tensorflowquery (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.TensorflowQuery"]], "tensorflow_itexadaptor (class in neural_compressor.adaptor.tensorflow)": [[47, "neural_compressor.adaptor.tensorflow.Tensorflow_ITEXAdaptor"]], "neural_compressor.adaptor.tensorflow": [[47, "module-neural_compressor.adaptor.tensorflow"]], "graphconverter (class in neural_compressor.adaptor.tf_utils.graph_converter)": [[48, "neural_compressor.adaptor.tf_utils.graph_converter.GraphConverter"]], "neural_compressor.adaptor.tf_utils.graph_converter": [[48, "module-neural_compressor.adaptor.tf_utils.graph_converter"]], "graphconverterwithoutcalib (class in neural_compressor.adaptor.tf_utils.graph_converter_without_calib)": [[49, "neural_compressor.adaptor.tf_utils.graph_converter_without_calib.GraphConverterWithoutCalib"]], "neural_compressor.adaptor.tf_utils.graph_converter_without_calib": [[49, "module-neural_compressor.adaptor.tf_utils.graph_converter_without_calib"]], "bf16convert (class in neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert)": [[50, "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert.BF16Convert"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert": [[50, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.bf16_convert"]], "dequantizecastoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer)": [[51, "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer.DequantizeCastOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer": [[51, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16.dequantize_cast_optimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.bf16": [[52, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.bf16"]], "convertaddtobiasaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd)": [[53, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd": [[53, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_add_to_biasadd"]], "convertlayoutoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout)": [[54, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout": [[54, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_layout"]], "convertleakyreluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu)": [[55, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu": [[55, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_leakyrelu"]], "convertnantorandom (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random)": [[56, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random": [[56, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_nan_to_random"]], "convertplaceholdertoconst (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const)": [[57, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const": [[57, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.convert_placeholder_to_const"]], "dilatedcontraction (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction)": [[58, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction.DilatedContraction"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction": [[58, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dilated_contraction"]], "injectdummybiasaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd)": [[59, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd": [[59, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.dummy_biasadd"]], "expanddimsoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer)": [[60, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer": [[60, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.expanddims_optimizer"]], "fetchweightfromreshapeoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape)": [[61, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape": [[61, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "foldbatchnormnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm)": [[62, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm": [[62, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_batch_norm"]], "graphfoldconstantoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant)": [[63, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant": [[63, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fold_constant"]], "fusebiasaddandaddoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add)": [[64, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add": [[64, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_biasadd_add"]], "fusecolumnwisemuloptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul)": [[65, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul": [[65, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_column_wise_mul"]], "fuseconvwithmathoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math)": [[66, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math": [[66, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_conv_with_math"]], "fusedecomposedbnoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer"]], "bypass_reshape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn": [[67, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn)": [[67, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const"]], "fusedecomposedinoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer"]], "bypass_reshape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in": [[68, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in)": [[68, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const"]], "fusegeluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu)": [[69, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu": [[69, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_gelu"]], "fuselayernormoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm": [[70, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm"]], "node_from_map() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.node_from_map"]], "node_name_from_input() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input"]], "values_from_const() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm)": [[70, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_layer_norm.values_from_const"]], "fusepadwithconv2doptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv)": [[71, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv": [[71, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_conv"]], "fusepadwithfp32conv2doptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)": [[72, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[72, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "fusetransposereshapeoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose)": [[73, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose": [[73, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.fuse_reshape_transpose"]], "graphcseoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer)": [[74, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer": [[74, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.graph_cse_optimizer"]], "grappleroptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass)": [[75, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass": [[75, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic": [[76, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic"]], "insertprintminmaxnode (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node)": [[77, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node": [[77, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.insert_print_node"]], "movesqueezeafterreluoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu)": [[78, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu": [[78, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.move_squeeze_after_relu"]], "preoptimization (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize)": [[79, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize.PreOptimization"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize": [[79, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.pre_optimize"]], "removetrainingnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes)": [[80, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes": [[80, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.remove_training_nodes"]], "renamebatchnormoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm)": [[81, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm": [[81, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.rename_batch_norm"]], "splitsharedinputoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input)": [[82, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input": [[82, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.split_shared_input"]], "stripequivalentnodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes)": [[83, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes": [[83, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_equivalent_nodes"]], "stripunusednodesoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes)": [[84, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes": [[84, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.strip_unused_nodes"]], "switchoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer)": [[85, "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer": [[85, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.generic.switch_optimizer"]], "graphrewriterbase (class in neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base)": [[86, "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base.GraphRewriterBase"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base": [[86, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.graph_base"]], "neural_compressor.adaptor.tf_utils.graph_rewriter": [[87, "module-neural_compressor.adaptor.tf_utils.graph_rewriter"]], "freezefakequantopoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant)": [[88, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant.FreezeFakeQuantOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant": [[88, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_fake_quant"]], "freezevaluetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value)": [[89, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value.FreezeValueTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value": [[89, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value"]], "freezevaluewithoutcalibtransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib)": [[90, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib.FreezeValueWithoutCalibTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib": [[90, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.freeze_value_without_calib"]], "fuseconvredundantdequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize)": [[91, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize.FuseConvRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize": [[91, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_redundant_dequantize"]], "fuseconvrequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize)": [[92, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize.FuseConvRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize": [[92, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_conv_requantize"]], "fusematmulredundantdequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize)": [[93, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize.FuseMatMulRedundantDequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize": [[93, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_redundant_dequantize"]], "fusematmulrequantizedequantizenewapitransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeNewAPITransformer"]], "fusematmulrequantizedequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeDequantizeTransformer"]], "fusematmulrequantizenewapitransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeNewAPITransformer"]], "fusematmulrequantizetransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize)": [[94, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize.FuseMatMulRequantizeTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize": [[94, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.fuse_matmul_requantize"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8": [[95, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8"]], "metainfochangingmemopoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer)": [[96, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer.MetaInfoChangingMemOpOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer": [[96, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.meta_op_optimizer"]], "posthostconstconverter (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter)": [[97, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter.PostHostConstConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter": [[97, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_hostconst_converter"]], "postcseoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse)": [[98, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse.PostCseOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse": [[98, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.post_quantized_op_cse"]], "quantizedrnnconverter (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert)": [[99, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert.QuantizedRNNConverter"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert": [[99, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.rnn_convert"]], "scalepropagationtransformer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation)": [[100, "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation.ScaleProPagationTransformer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation": [[100, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.int8.scale_propagation"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx": [[101, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx"]], "onnxgraph (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph)": [[102, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph.OnnxGraph"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph": [[102, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_graph"]], "onnxnode (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node)": [[103, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node.OnnxNode"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node": [[103, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_node"]], "onnxopschema (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.OnnxOpSchema"]], "get_max_supported_opset_version() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.get_max_supported_opset_version"]], "get_schema() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema)": [[104, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema.get_schema"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema": [[104, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.onnx_schema"]], "seqtype (class in neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.SeqType"]], "add_port_to_name() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.add_port_to_name"]], "are_shapes_equal() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.are_shapes_equal"]], "assert_error() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.assert_error"]], "compute_const_folding_using_tf() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.compute_const_folding_using_tf"]], "convert_tensorflow_tensor_to_onnx() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.convert_tensorflow_tensor_to_onnx"]], "find_opset() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.find_opset"]], "get_index_from_strided_slice_of_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_index_from_strided_slice_of_shape"]], "get_subgraphs_from_onnx() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_subgraphs_from_onnx"]], "get_tensorflow_node_attr() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_node_attr"]], "get_tensorflow_node_shape_attr() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_node_shape_attr"]], "get_tensorflow_tensor_data() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_tensor_data"]], "get_tensorflow_tensor_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.get_tensorflow_tensor_shape"]], "infer_onnx_shape_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.infer_onnx_shape_dtype"]], "initialize_name_counter() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.initialize_name_counter"]], "is_list_or_tuple() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.is_list_or_tuple"]], "is_onnx_domain() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.is_onnx_domain"]], "make_onnx_inputs_outputs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.make_onnx_inputs_outputs"]], "make_onnx_shape() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.make_onnx_shape"]], "map_numpy_to_onnx_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_numpy_to_onnx_dtype"]], "map_onnx_to_numpy_type() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_onnx_to_numpy_type"]], "map_tensorflow_dtype() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.map_tensorflow_dtype"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils": [[105, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils"]], "read_tensorflow_node_attrs() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.read_tensorflow_node_attrs"]], "save_protobuf() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.save_protobuf"]], "set_name() (in module neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils)": [[105, "neural_compressor.adaptor.tf_utils.graph_rewriter.onnx.tf2onnx_utils.set_name"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq": [[106, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq"]], "generategraphwithqdqpattern (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern)": [[107, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern.GenerateGraphWithQDQPattern"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern": [[107, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.insert_qdq_pattern"]], "mergeduplicatedqdqoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq)": [[108, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq.MergeDuplicatedQDQOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq": [[108, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.merge_duplicated_qdq"]], "shareqdqforitexypatternoptimizer (class in neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern)": [[109, "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern.ShareQDQForItexYPatternOptimizer"]], "neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern": [[109, "module-neural_compressor.adaptor.tf_utils.graph_rewriter.qdq.share_qdq_y_pattern"]], "graphanalyzer (class in neural_compressor.adaptor.tf_utils.graph_util)": [[110, "neural_compressor.adaptor.tf_utils.graph_util.GraphAnalyzer"]], "graphrewriterhelper (class in neural_compressor.adaptor.tf_utils.graph_util)": [[110, "neural_compressor.adaptor.tf_utils.graph_util.GraphRewriterHelper"]], "neural_compressor.adaptor.tf_utils.graph_util": [[110, "module-neural_compressor.adaptor.tf_utils.graph_util"]], "neural_compressor.adaptor.tf_utils": [[111, "module-neural_compressor.adaptor.tf_utils"]], "neural_compressor.adaptor.tf_utils.quantize_graph": [[112, "module-neural_compressor.adaptor.tf_utils.quantize_graph"]], "fakequantize (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize)": [[113, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize.FakeQuantize"]], "fakequantizebase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize)": [[113, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize.FakeQuantizeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize": [[113, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.fake_quantize"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat": [[114, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat"]], "quantizeconfig (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config)": [[115, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config.QuantizeConfig"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config": [[115, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_config"]], "init_quantize_config() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper)": [[116, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper.init_quantize_config"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper": [[116, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper"]], "qat_clone_function() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper)": [[116, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_helper.qat_clone_function"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers": [[117, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers"]], "config_quantizable_layers() (in module neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer)": [[118, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer.config_quantizable_layers"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer": [[118, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.optimize_layer"]], "quantizelayeradd (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add)": [[119, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add.QuantizeLayerAdd"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add": [[119, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_add"]], "quantizelayerbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base)": [[120, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base.QuantizeLayerBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base": [[120, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_base"]], "quantizelayerbatchnormalization (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn)": [[121, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn.QuantizeLayerBatchNormalization"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn": [[121, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_layers.quantize_layer_bn"]], "quantizewrapper (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper)": [[122, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapper"]], "quantizewrapperbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper)": [[122, "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper.QuantizeWrapperBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper": [[122, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qat.quantize_wrapper"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn)": [[123, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn": [[123, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2)": [[124, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2": [[124, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv)": [[125, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv.FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv": [[125, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_conv"]], "fusenodestartwithdeconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv)": [[126, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv.FuseNodeStartWithDeconv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv": [[126, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_deconv"]], "fusenodestartwithfusedinstancenorm (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in)": [[127, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in.FuseNodeStartWithFusedInstanceNorm"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in": [[127, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_in"]], "fusenodestartwithmatmul (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul)": [[128, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul": [[128, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_matmul"]], "fusenodestartwithpooling (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling)": [[129, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling.FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling": [[129, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.fuse_qdq_pooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq": [[130, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq"]], "optimizeqdqgraph (class in neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq)": [[131, "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq.OptimizeQDQGraph"]], "neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq": [[131, "module-neural_compressor.adaptor.tf_utils.quantize_graph.qdq.optimize_qdq"]], "quantizegraphbase (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base)": [[132, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base.QuantizeGraphBase"]], "quantizenodebase (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base)": [[132, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base.QuantizeNodeBase"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base": [[132, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_base"]], "fusenodestartwithfusedbatchnormv3 (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn)": [[133, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn.FuseNodeStartWithFusedBatchNormV3"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn": [[133, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_bn"]], "fusenodestartwithconcatv2 (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2)": [[134, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2.FuseNodeStartWithConcatV2"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2": [[134, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_concatv2"]], "fusenodestartwithconv2d (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv)": [[135, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv.FuseNodeStartWithConv2d"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv": [[135, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_conv"]], "quantizegraphforintel (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu)": [[136, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu.QuantizeGraphForIntel"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu": [[136, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_for_intel_cpu"]], "fusenodestartwithmatmul (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul)": [[137, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul.FuseNodeStartWithMatmul"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul": [[137, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_matmul"]], "fusenodestartwithpooling (class in neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling)": [[138, "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling.FuseNodeStartWithPooling"]], "neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling": [[138, "module-neural_compressor.adaptor.tf_utils.quantize_graph.quantize_graph_pooling"]], "quantizegraphhelper (class in neural_compressor.adaptor.tf_utils.quantize_graph_common)": [[139, "neural_compressor.adaptor.tf_utils.quantize_graph_common.QuantizeGraphHelper"]], "neural_compressor.adaptor.tf_utils.quantize_graph_common": [[139, "module-neural_compressor.adaptor.tf_utils.quantize_graph_common"]], "smoothquantcalibration (class in neural_compressor.adaptor.tf_utils.smooth_quant_calibration)": [[140, "neural_compressor.adaptor.tf_utils.smooth_quant_calibration.SmoothQuantCalibration"]], "smoothquantcalibrationllm (class in neural_compressor.adaptor.tf_utils.smooth_quant_calibration)": [[140, "neural_compressor.adaptor.tf_utils.smooth_quant_calibration.SmoothQuantCalibrationLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_calibration": [[140, "module-neural_compressor.adaptor.tf_utils.smooth_quant_calibration"]], "smoothquantscaler (class in neural_compressor.adaptor.tf_utils.smooth_quant_scaler)": [[141, "neural_compressor.adaptor.tf_utils.smooth_quant_scaler.SmoothQuantScaler"]], "smoothquantscalerllm (class in neural_compressor.adaptor.tf_utils.smooth_quant_scaler)": [[141, "neural_compressor.adaptor.tf_utils.smooth_quant_scaler.SmoothQuantScalerLLM"]], "neural_compressor.adaptor.tf_utils.smooth_quant_scaler": [[141, "module-neural_compressor.adaptor.tf_utils.smooth_quant_scaler"]], "tensorflowqdqtoonnxqdqconverter (class in neural_compressor.adaptor.tf_utils.tf2onnx_converter)": [[142, "neural_compressor.adaptor.tf_utils.tf2onnx_converter.TensorflowQDQToOnnxQDQConverter"]], "neural_compressor.adaptor.tf_utils.tf2onnx_converter": [[142, "module-neural_compressor.adaptor.tf_utils.tf2onnx_converter"]], "biascorrection (class in neural_compressor.adaptor.tf_utils.transform_graph.bias_correction)": [[143, "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction.BiasCorrection"]], "neural_compressor.adaptor.tf_utils.transform_graph.bias_correction": [[143, "module-neural_compressor.adaptor.tf_utils.transform_graph.bias_correction"]], "graphtransformbase (class in neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base)": [[144, "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base.GraphTransformBase"]], "neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base": [[144, "module-neural_compressor.adaptor.tf_utils.transform_graph.graph_transform_base"]], "neural_compressor.adaptor.tf_utils.transform_graph": [[145, "module-neural_compressor.adaptor.tf_utils.transform_graph"]], "insertlogging (class in neural_compressor.adaptor.tf_utils.transform_graph.insert_logging)": [[146, "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging.InsertLogging"]], "neural_compressor.adaptor.tf_utils.transform_graph.insert_logging": [[146, "module-neural_compressor.adaptor.tf_utils.transform_graph.insert_logging"]], "rerangequantizedconcat (class in neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat)": [[147, "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat.RerangeQuantizedConcat"]], "neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat": [[147, "module-neural_compressor.adaptor.tf_utils.transform_graph.rerange_quantized_concat"]], "apply_inlining() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.apply_inlining"]], "collate_tf_preds() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.collate_tf_preds"]], "construct_function_from_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.construct_function_from_graph_def"]], "disable_random() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.disable_random"]], "fix_ref_type_of_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.fix_ref_type_of_graph_def"]], "generate_feed_dict() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.generate_feed_dict"]], "get_estimator_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_estimator_graph"]], "get_graph_def() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_graph_def"]], "get_input_output_node_names() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_input_output_node_names"]], "get_model_input_shape() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_model_input_shape"]], "get_tensor_by_name() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_tensor_by_name"]], "get_tensor_val_from_graph_node() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_tensor_val_from_graph_node"]], "get_weight_from_input_tensor() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.get_weight_from_input_tensor"]], "int8_node_name_reverse() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.int8_node_name_reverse"]], "is_ckpt_format() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.is_ckpt_format"]], "is_saved_model_format() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.is_saved_model_format"]], "iterator_sess_run() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.iterator_sess_run"]], "neural_compressor.adaptor.tf_utils.util": [[148, "module-neural_compressor.adaptor.tf_utils.util"]], "parse_saved_model() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.parse_saved_model"]], "read_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.read_graph"]], "reconstruct_saved_model() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.reconstruct_saved_model"]], "strip_equivalent_nodes() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.strip_equivalent_nodes"]], "strip_unused_nodes() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.strip_unused_nodes"]], "tf_diagnosis_helper() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.tf_diagnosis_helper"]], "version1_eq_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.version1_lte_version2"]], "write_graph() (in module neural_compressor.adaptor.tf_utils.util)": [[148, "neural_compressor.adaptor.tf_utils.util.write_graph"]], "autoadamround (class in neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.AutoAdamRound"]], "autooptround (class in neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.AutoOPTRound"]], "autoround (class in neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.AutoRound"]], "saveinputs (class in neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.SaveInputs"]], "wrappermultiblock (class in neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.WrapperMultiblock"]], "block_forward() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.block_forward"]], "check_is_cpu() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.check_is_cpu"]], "collect_minmax_scale() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.collect_minmax_scale"]], "collect_round_v() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.collect_round_v"]], "get_batch_dim() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_batch_dim"]], "get_block_names() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_block_names"]], "get_dataloader() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_dataloader"]], "get_module() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_module"]], "get_scale_shape() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_scale_shape"]], "get_tokenizer_function() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.get_tokenizer_function"]], "move_input_to_device() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.move_input_to_device"]], "neural_compressor.adaptor.torch_utils.autoround.autoround": [[149, "module-neural_compressor.adaptor.torch_utils.autoround.autoround"]], "quant_weight() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.quant_weight"]], "quant_weight_actor() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.quant_weight_actor"]], "quant_weight_asym() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.quant_weight_asym"]], "quant_weight_sym() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.quant_weight_sym"]], "quant_weight_w_scale() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.quant_weight_w_scale"]], "round_ste() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.round_ste"]], "sampling_inputs() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.sampling_inputs"]], "set_module() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.set_module"]], "unwrapper_block() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.unwrapper_block"]], "wrapper_block() (in module neural_compressor.adaptor.torch_utils.autoround.autoround)": [[149, "neural_compressor.adaptor.torch_utils.autoround.autoround.wrapper_block"]], "export_compressed_model() (in module neural_compressor.adaptor.torch_utils.autoround.export)": [[150, "neural_compressor.adaptor.torch_utils.autoround.export.export_compressed_model"]], "neural_compressor.adaptor.torch_utils.autoround.export": [[150, "module-neural_compressor.adaptor.torch_utils.autoround.export"]], "neural_compressor.adaptor.torch_utils.autoround": [[151, "module-neural_compressor.adaptor.torch_utils.autoround"]], "neural_compressor.adaptor.torch_utils.autoround.model_wrapper": [[152, "module-neural_compressor.adaptor.torch_utils.autoround.model_wrapper"]], "sgd (class in neural_compressor.adaptor.torch_utils.autoround.sign_sgd)": [[153, "neural_compressor.adaptor.torch_utils.autoround.sign_sgd.SGD"]], "neural_compressor.adaptor.torch_utils.autoround.sign_sgd": [[153, "module-neural_compressor.adaptor.torch_utils.autoround.sign_sgd"]], "sgd() (in module neural_compressor.adaptor.torch_utils.autoround.sign_sgd)": [[153, "neural_compressor.adaptor.torch_utils.autoround.sign_sgd.sgd"]], "actawareweightquant (class in neural_compressor.adaptor.torch_utils.awq)": [[154, "neural_compressor.adaptor.torch_utils.awq.ActAwareWeightQuant"]], "neural_compressor.adaptor.torch_utils.awq": [[154, "module-neural_compressor.adaptor.torch_utils.awq"]], "bf16modulewrapper (class in neural_compressor.adaptor.torch_utils.bf16_convert)": [[155, "neural_compressor.adaptor.torch_utils.bf16_convert.BF16ModuleWrapper"]], "convert() (in module neural_compressor.adaptor.torch_utils.bf16_convert)": [[155, "neural_compressor.adaptor.torch_utils.bf16_convert.Convert"]], "bf16_symbolic_trace() (in module neural_compressor.adaptor.torch_utils.bf16_convert)": [[155, "neural_compressor.adaptor.torch_utils.bf16_convert.bf16_symbolic_trace"]], "neural_compressor.adaptor.torch_utils.bf16_convert": [[155, "module-neural_compressor.adaptor.torch_utils.bf16_convert"]], "gptq (class in neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.GPTQ"]], "gptquantizer (class in neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.GPTQuantizer"]], "find_layers() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.find_layers"]], "find_layers_name() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.find_layers_name"]], "is_leaf() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.is_leaf"]], "log_quantizable_layers_per_transformer() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.log_quantizable_layers_per_transformer"]], "neural_compressor.adaptor.torch_utils.gptq": [[156, "module-neural_compressor.adaptor.torch_utils.gptq"]], "quantize() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.quantize"]], "trace_gptq_target_blocks() (in module neural_compressor.adaptor.torch_utils.gptq)": [[156, "neural_compressor.adaptor.torch_utils.gptq.trace_gptq_target_blocks"]], "hessiantrace (class in neural_compressor.adaptor.torch_utils.hawq_metric)": [[157, "neural_compressor.adaptor.torch_utils.hawq_metric.HessianTrace"]], "node_collector (class in neural_compressor.adaptor.torch_utils.hawq_metric)": [[157, "neural_compressor.adaptor.torch_utils.hawq_metric.Node_collector"]], "compare_weights() (in module neural_compressor.adaptor.torch_utils.hawq_metric)": [[157, "neural_compressor.adaptor.torch_utils.hawq_metric.compare_weights"]], "hawq_top() (in module neural_compressor.adaptor.torch_utils.hawq_metric)": [[157, "neural_compressor.adaptor.torch_utils.hawq_metric.hawq_top"]], "neural_compressor.adaptor.torch_utils.hawq_metric": [[157, "module-neural_compressor.adaptor.torch_utils.hawq_metric"]], "neural_compressor.adaptor.torch_utils": [[158, "module-neural_compressor.adaptor.torch_utils"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant": [[159, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant"]], "pickleerror": [[160, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.PickleError"], [517, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PickleError"]], "picklingerror": [[160, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.PicklingError"], [517, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.PicklingError"]], "unpicklingerror": [[160, "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle.UnpicklingError"], [517, "neural_compressor.torch.algorithms.layer_wise.modified_pickle.UnpicklingError"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle": [[160, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.modified_pickle"]], "layerwisequant (class in neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize)": [[161, "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize.LayerWiseQuant"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize": [[161, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.quantize"]], "load() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load)": [[162, "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load.load"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load": [[162, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.torch_load"]], "dowload_hf_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.dowload_hf_model"]], "get_children() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_children"]], "get_module() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_module"]], "get_named_children() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_named_children"]], "get_super_module_by_name() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.get_super_module_by_name"]], "load_empty_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_empty_model"]], "load_layer_wise_quantized_model() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_layer_wise_quantized_model"]], "load_tensor() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_tensor"]], "load_tensor_from_shard() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.load_tensor_from_shard"]], "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils": [[163, "module-neural_compressor.adaptor.torch_utils.layer_wise_quant.utils"]], "update_module() (in module neural_compressor.adaptor.torch_utils.layer_wise_quant.utils)": [[163, "neural_compressor.adaptor.torch_utils.layer_wise_quant.utils.update_module"]], "ipex_mixed_precision() (in module neural_compressor.adaptor.torch_utils.mixed_precision)": [[164, "neural_compressor.adaptor.torch_utils.mixed_precision.ipex_mixed_precision"]], "neural_compressor.adaptor.torch_utils.mixed_precision": [[164, "module-neural_compressor.adaptor.torch_utils.mixed_precision"]], "fakeaffinetensorquantfunction (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[165, "neural_compressor.adaptor.torch_utils.model_wrapper.FakeAffineTensorQuantFunction"]], "mullinear (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[165, "neural_compressor.adaptor.torch_utils.model_wrapper.MulLinear"]], "teqlinearfakequant (class in neural_compressor.adaptor.torch_utils.model_wrapper)": [[165, "neural_compressor.adaptor.torch_utils.model_wrapper.TEQLinearFakeQuant"]], "neural_compressor.adaptor.torch_utils.model_wrapper": [[165, "module-neural_compressor.adaptor.torch_utils.model_wrapper"]], "transformerbasedmodelblockpatterndetector (class in neural_compressor.adaptor.torch_utils.pattern_detector)": [[166, "neural_compressor.adaptor.torch_utils.pattern_detector.TransformerBasedModelBlockPatternDetector"]], "neural_compressor.adaptor.torch_utils.pattern_detector": [[166, "module-neural_compressor.adaptor.torch_utils.pattern_detector"]], "torchsmoothquant (class in neural_compressor.adaptor.torch_utils.smooth_quant)": [[167, "neural_compressor.adaptor.torch_utils.smooth_quant.TorchSmoothQuant"]], "get_module() (in module neural_compressor.adaptor.torch_utils.smooth_quant)": [[167, "neural_compressor.adaptor.torch_utils.smooth_quant.get_module"]], "neural_compressor.adaptor.torch_utils.smooth_quant": [[167, "module-neural_compressor.adaptor.torch_utils.smooth_quant"]], "set_module() (in module neural_compressor.adaptor.torch_utils.smooth_quant)": [[167, "neural_compressor.adaptor.torch_utils.smooth_quant.set_module"]], "neural_compressor.adaptor.torch_utils.symbolic_trace": [[168, "module-neural_compressor.adaptor.torch_utils.symbolic_trace"]], "symbolic_trace() (in module neural_compressor.adaptor.torch_utils.symbolic_trace)": [[168, "neural_compressor.adaptor.torch_utils.symbolic_trace.symbolic_trace"]], "trace_and_fuse_sub_graph() (in module neural_compressor.adaptor.torch_utils.symbolic_trace)": [[168, "neural_compressor.adaptor.torch_utils.symbolic_trace.trace_and_fuse_sub_graph"]], "tequantizer (class in neural_compressor.adaptor.torch_utils.teq)": [[169, "neural_compressor.adaptor.torch_utils.teq.TEQuantizer"]], "neural_compressor.adaptor.torch_utils.teq": [[169, "module-neural_compressor.adaptor.torch_utils.teq"]], "append_attr() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.append_attr"]], "auto_copy() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.auto_copy"]], "calculate_quant_min_max() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.calculate_quant_min_max"]], "calibration() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.calibration"]], "check_cfg_and_qconfig() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.check_cfg_and_qconfig"]], "collate_torch_preds() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.collate_torch_preds"]], "collect_weight_info() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.collect_weight_info"]], "fetch_module() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.fetch_module"]], "forward_wrapper() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.forward_wrapper"]], "generate_activation_observer() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.generate_activation_observer"]], "get_absorb_layers() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_absorb_layers"]], "get_block_prefix() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_block_prefix"]], "get_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_depth"]], "get_dict_at_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_dict_at_depth"]], "get_element_under_depth() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_element_under_depth"]], "get_embedding_contiguous() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_embedding_contiguous"]], "get_example_input() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_example_input"]], "get_fallback_order() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_fallback_order"]], "get_hidden_states() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_hidden_states"]], "get_module_input_output() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_module_input_output"]], "get_mse_order_per_fp32() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_mse_order_per_fp32"]], "get_mse_order_per_int8() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_mse_order_per_int8"]], "get_op_type_by_name() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_op_type_by_name"]], "get_quantizable_ops_from_cfgs() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_quantizable_ops_from_cfgs"]], "get_torch_version() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.get_torch_version"]], "input2tuple() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.input2tuple"]], "is_fused_module() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.is_fused_module"]], "match_datatype_pattern() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.match_datatype_pattern"]], "move_input_device() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.move_input_device"]], "neural_compressor.adaptor.torch_utils.util": [[170, "module-neural_compressor.adaptor.torch_utils.util"]], "paser_cfgs() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.paser_cfgs"]], "set_module() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.set_module"]], "simple_inference() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.simple_inference"]], "update_sq_scale() (in module neural_compressor.adaptor.torch_utils.util)": [[170, "neural_compressor.adaptor.torch_utils.util.update_sq_scale"]], "awq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.awq_quantize"]], "gptq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.gptq_quantize"]], "neural_compressor.adaptor.torch_utils.weight_only": [[171, "module-neural_compressor.adaptor.torch_utils.weight_only"]], "qdq_weight_actor() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_actor"]], "qdq_weight_asym() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_asym"]], "qdq_weight_sym() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.qdq_weight_sym"]], "quant_weight() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.quant_weight"]], "quant_weight_w_scale() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.quant_weight_w_scale"]], "quantize_4bit() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.quantize_4bit"]], "rtn_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.rtn_quantize"]], "search_clip() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.search_clip"]], "teq_quantize() (in module neural_compressor.adaptor.torch_utils.weight_only)": [[171, "neural_compressor.adaptor.torch_utils.weight_only.teq_quantize"]], "algorithms (class in neural_compressor.algorithm.algorithm)": [[172, "neural_compressor.algorithm.algorithm.ALGORITHMS"]], "algorithm (class in neural_compressor.algorithm.algorithm)": [[172, "neural_compressor.algorithm.algorithm.Algorithm"]], "algorithmscheduler (class in neural_compressor.algorithm.algorithm)": [[172, "neural_compressor.algorithm.algorithm.AlgorithmScheduler"]], "algorithm_registry() (in module neural_compressor.algorithm.algorithm)": [[172, "neural_compressor.algorithm.algorithm.algorithm_registry"]], "neural_compressor.algorithm.algorithm": [[172, "module-neural_compressor.algorithm.algorithm"]], "fastbiascorrection (class in neural_compressor.algorithm.fast_bias_correction)": [[173, "neural_compressor.algorithm.fast_bias_correction.FastBiasCorrection"]], "neural_compressor.algorithm.fast_bias_correction": [[173, "module-neural_compressor.algorithm.fast_bias_correction"]], "neural_compressor.algorithm": [[174, "module-neural_compressor.algorithm"]], "smoothquant (class in neural_compressor.algorithm.smooth_quant)": [[175, "neural_compressor.algorithm.smooth_quant.SmoothQuant"]], "neural_compressor.algorithm.smooth_quant": [[175, "module-neural_compressor.algorithm.smooth_quant"]], "weightcorrection (class in neural_compressor.algorithm.weight_correction)": [[176, "neural_compressor.algorithm.weight_correction.WeightCorrection"]], "neural_compressor.algorithm.weight_correction": [[176, "module-neural_compressor.algorithm.weight_correction"]], "benchmark_with_raw_cmd() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.benchmark_with_raw_cmd"]], "call_one() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.call_one"]], "config_instance() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.config_instance"]], "fit() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.fit"]], "generate_prefix() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.generate_prefix"]], "get_architecture() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_architecture"]], "get_bounded_threads() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_bounded_threads"]], "get_core_ids() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_core_ids"]], "get_physical_ids() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_physical_ids"]], "get_threads() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_threads"]], "get_threads_per_core() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.get_threads_per_core"]], "neural_compressor.benchmark": [[177, "module-neural_compressor.benchmark"]], "profile() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.profile"]], "run_instance() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.run_instance"]], "set_all_env_var() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.set_all_env_var"]], "set_env_var() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.set_env_var"]], "summary_benchmark() (in module neural_compressor.benchmark)": [[177, "neural_compressor.benchmark.summary_benchmark"]], "baseconfig (class in neural_compressor.common.base_config)": [[178, "neural_compressor.common.base_config.BaseConfig"]], "composableconfig (class in neural_compressor.common.base_config)": [[178, "neural_compressor.common.base_config.ComposableConfig"]], "neural_compressor.common.base_config": [[178, "module-neural_compressor.common.base_config"]], "register_config() (in module neural_compressor.common.base_config)": [[178, "neural_compressor.common.base_config.register_config"]], "register_supported_configs_for_fwk() (in module neural_compressor.common.base_config)": [[178, "neural_compressor.common.base_config.register_supported_configs_for_fwk"]], "evaluator (class in neural_compressor.common.base_tuning)": [[179, "neural_compressor.common.base_tuning.Evaluator"]], "sequentialsampler (class in neural_compressor.common.base_tuning)": [[179, "neural_compressor.common.base_tuning.SequentialSampler"]], "tuningconfig (class in neural_compressor.common.base_tuning)": [[179, "neural_compressor.common.base_tuning.TuningConfig"]], "neural_compressor.common.base_tuning": [[179, "module-neural_compressor.common.base_tuning"]], "neural_compressor.common": [[180, "module-neural_compressor.common"]], "paramlevel (class in neural_compressor.common.tuning_param)": [[181, "neural_compressor.common.tuning_param.ParamLevel"]], "tuningparam (class in neural_compressor.common.tuning_param)": [[181, "neural_compressor.common.tuning_param.TuningParam"]], "neural_compressor.common.tuning_param": [[181, "module-neural_compressor.common.tuning_param"]], "neural_compressor.common.utils.constants": [[182, "module-neural_compressor.common.utils.constants"]], "neural_compressor.common.utils": [[183, "module-neural_compressor.common.utils"]], "logger (class in neural_compressor.common.utils.logger)": [[184, "neural_compressor.common.utils.logger.Logger"]], "tuninglogger (class in neural_compressor.common.utils.logger)": [[184, "neural_compressor.common.utils.logger.TuningLogger"]], "neural_compressor.common.utils.logger": [[184, "module-neural_compressor.common.utils.logger"]], "dump_elapsed_time() (in module neural_compressor.common.utils.utility)": [[185, "neural_compressor.common.utils.utility.dump_elapsed_time"]], "neural_compressor.common.utils.utility": [[185, "module-neural_compressor.common.utils.utility"]], "set_random_seed() (in module neural_compressor.common.utils.utility)": [[185, "neural_compressor.common.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.common.utils.utility)": [[185, "neural_compressor.common.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.common.utils.utility)": [[185, "neural_compressor.common.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.common.utils.utility)": [[185, "neural_compressor.common.utils.utility.set_workspace"]], "basecallbacks (class in neural_compressor.compression.callbacks)": [[186, "neural_compressor.compression.callbacks.BaseCallbacks"]], "distillationcallbacks (class in neural_compressor.compression.callbacks)": [[186, "neural_compressor.compression.callbacks.DistillationCallbacks"]], "pruningcallbacks (class in neural_compressor.compression.callbacks)": [[186, "neural_compressor.compression.callbacks.PruningCallbacks"]], "quantizationawaretrainingcallbacks (class in neural_compressor.compression.callbacks)": [[186, "neural_compressor.compression.callbacks.QuantizationAwareTrainingCallbacks"]], "_epoch_ran (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[186, "neural_compressor.compression.callbacks.DistillationCallbacks._epoch_ran"]], "best_model (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[186, "neural_compressor.compression.callbacks.DistillationCallbacks.best_model"]], "best_score (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[186, "neural_compressor.compression.callbacks.DistillationCallbacks.best_score"]], "eval_frequency (neural_compressor.compression.callbacks.distillationcallbacks attribute)": [[186, "neural_compressor.compression.callbacks.DistillationCallbacks.eval_frequency"]], "neural_compressor.compression.callbacks": [[186, "module-neural_compressor.compression.callbacks"]], "criterions (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.Criterions"]], "intermediatelayersknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.IntermediateLayersKnowledgeDistillationLoss"]], "knowledgedistillationframework (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.KnowledgeDistillationFramework"]], "knowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.KnowledgeDistillationLoss"]], "pytorchcriterions (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchCriterions"]], "pytorchcrossentropyloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchCrossEntropyLoss"]], "pytorchintermediatelayersknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchIntermediateLayersKnowledgeDistillationLoss"]], "pytorchintermediatelayersknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"]], "pytorchknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchKnowledgeDistillationLoss"]], "pytorchknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchKnowledgeDistillationLossWrapper"]], "pytorchselfknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchSelfKnowledgeDistillationLoss"]], "pytorchselfknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.PyTorchSelfKnowledgeDistillationLossWrapper"]], "selfknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.SelfKnowledgeDistillationLoss"]], "tensorflowcrossentropyloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorFlowCrossEntropyLoss"]], "tensorflowsparsecategoricalcrossentropy (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorFlowSparseCategoricalCrossentropy"]], "tensorflowcriterions (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorflowCriterions"]], "tensorflowknowledgedistillationloss (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLoss"]], "tensorflowknowledgedistillationlossexternal (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLossExternal"]], "tensorflowknowledgedistillationlosswrapper (class in neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.TensorflowKnowledgeDistillationLossWrapper"]], "criterion_registry() (in module neural_compressor.compression.distillation.criterions)": [[187, "neural_compressor.compression.distillation.criterions.criterion_registry"]], "neural_compressor.compression.distillation.criterions": [[187, "module-neural_compressor.compression.distillation.criterions"]], "neural_compressor.compression.distillation": [[188, "module-neural_compressor.compression.distillation"]], "optimizers (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.Optimizers"]], "pytorchoptimizers (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.PyTorchOptimizers"]], "pytorchsgd (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.PyTorchSGD"]], "tensorflowadam (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.TensorFlowAdam"]], "tensorflowadamw (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.TensorFlowAdamW"]], "tensorflowsgd (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.TensorFlowSGD"]], "tensorflowoptimizers (class in neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.TensorflowOptimizers"]], "neural_compressor.compression.distillation.optimizers": [[189, "module-neural_compressor.compression.distillation.optimizers"]], "optimizer_registry() (in module neural_compressor.compression.distillation.optimizers)": [[189, "neural_compressor.compression.distillation.optimizers.optimizer_registry"]], "get_activation() (in module neural_compressor.compression.distillation.utility)": [[190, "neural_compressor.compression.distillation.utility.get_activation"]], "neural_compressor.compression.distillation.utility": [[190, "module-neural_compressor.compression.distillation.utility"]], "record_output() (in module neural_compressor.compression.distillation.utility)": [[190, "neural_compressor.compression.distillation.utility.record_output"]], "neural_compressor.compression.hpo": [[191, "module-neural_compressor.compression.hpo"]], "neural_compressor.compression.hpo.sa_optimizer": [[192, "module-neural_compressor.compression.hpo.sa_optimizer"]], "bayesianoptimizationsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.BayesianOptimizationSearcher"]], "gridsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.GridSearcher"]], "randomsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.RandomSearcher"]], "searcher (class in neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.Searcher"]], "xgbsearcher (class in neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.XgbSearcher"]], "neural_compressor.compression.hpo.search_algorithms": [[193, "module-neural_compressor.compression.hpo.search_algorithms"]], "register_searcher() (in module neural_compressor.compression.hpo.search_algorithms)": [[193, "neural_compressor.compression.hpo.search_algorithms.register_searcher"]], "basesearchspace (class in neural_compressor.compression.hpo.search_space)": [[194, "neural_compressor.compression.hpo.search_space.BaseSearchSpace"]], "continuoussearchspace (class in neural_compressor.compression.hpo.search_space)": [[194, "neural_compressor.compression.hpo.search_space.ContinuousSearchSpace"]], "discretesearchspace (class in neural_compressor.compression.hpo.search_space)": [[194, "neural_compressor.compression.hpo.search_space.DiscreteSearchSpace"]], "searchspace (class in neural_compressor.compression.hpo.search_space)": [[194, "neural_compressor.compression.hpo.search_space.SearchSpace"]], "neural_compressor.compression.hpo.search_space": [[194, "module-neural_compressor.compression.hpo.search_space"]], "register_searchspace() (in module neural_compressor.compression.hpo.search_space)": [[194, "neural_compressor.compression.hpo.search_space.register_searchspace"]], "neural_compressor.compression": [[195, "module-neural_compressor.compression"]], "blockmaskcriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.BlockMaskCriterion"]], "gradientcriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.GradientCriterion"]], "magnitudecriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.MagnitudeCriterion"]], "pruningcriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.PruningCriterion"]], "retrainfreecriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion"]], "snipcriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.SnipCriterion"]], "snipmomentumcriterion (class in neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion"]], "get_criterion() (in module neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.get_criterion"]], "neural_compressor.compression.pruner.criteria": [[196, "module-neural_compressor.compression.pruner.criteria"]], "register_criterion() (in module neural_compressor.compression.pruner.criteria)": [[196, "neural_compressor.compression.pruner.criteria.register_criterion"]], "scores (neural_compressor.compression.pruner.criteria.blockmaskcriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.BlockMaskCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.gradientcriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.GradientCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.magnitudecriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.MagnitudeCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.pruningcriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.PruningCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.retrainfreecriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.RetrainFreeCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.snipcriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.SnipCriterion.scores"]], "scores (neural_compressor.compression.pruner.criteria.snipmomentumcriterion attribute)": [[196, "neural_compressor.compression.pruner.criteria.SnipMomentumCriterion.scores"]], "dsnot() (in module neural_compressor.compression.pruner.dsnot)": [[197, "neural_compressor.compression.pruner.dsnot.DSnoT"]], "neural_compressor.compression.pruner.dsnot": [[197, "module-neural_compressor.compression.pruner.dsnot"]], "return_reorder_indice() (in module neural_compressor.compression.pruner.dsnot)": [[197, "neural_compressor.compression.pruner.dsnot.return_reorder_indice"]], "neural_compressor.compression.pruner": [[198, "module-neural_compressor.compression.pruner"]], "prepare_pruning() (in module neural_compressor.compression.pruner)": [[198, "neural_compressor.compression.pruner.prepare_pruning"]], "save() (in module neural_compressor.compression.pruner)": [[198, "neural_compressor.compression.pruner.save"]], "generate_ffn2_pruning_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.generate_ffn2_pruning_config"]], "generate_mha_pruning_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.generate_mha_pruning_config"]], "model_slim() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim"]], "model_slim_ffn2() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim_ffn2"]], "model_slim_mha() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.model_slim_mha"]], "neural_compressor.compression.pruner.model_slim.auto_slim": [[199, "module-neural_compressor.compression.pruner.model_slim.auto_slim"]], "parse_auto_slim_config() (in module neural_compressor.compression.pruner.model_slim.auto_slim)": [[199, "neural_compressor.compression.pruner.model_slim.auto_slim.parse_auto_slim_config"]], "neural_compressor.compression.pruner.model_slim": [[200, "module-neural_compressor.compression.pruner.model_slim"]], "classifierheadsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher"]], "classifierheadsearchertf (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF"]], "jitbasicsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher"]], "linear2linearsearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher"]], "recipesearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher"]], "selfmhasearcher (class in neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher"]], "current_pattern (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.current_pattern"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.device"]], "device (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.device"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.flatten_static_graph"]], "flatten_static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.flatten_static_graph"]], "get_attributes() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.get_attributes"]], "get_common_module() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.get_common_module"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.model"]], "model (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.model"]], "neural_compressor.compression.pruner.model_slim.pattern_analyzer": [[201, "module-neural_compressor.compression.pruner.model_slim.pattern_analyzer"]], "print_iterables() (in module neural_compressor.compression.pruner.model_slim.pattern_analyzer)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.print_iterables"]], "recipe (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.recipe"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.searching_results"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.searching_results"]], "searching_results (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.searching_results"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.classifierheadsearchertf attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.ClassifierHeadSearcherTF.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.static_graph"]], "static_graph (neural_compressor.compression.pruner.model_slim.pattern_analyzer.selfmhasearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.SelfMHASearcher.static_graph"]], "target_layers (neural_compressor.compression.pruner.model_slim.pattern_analyzer.jitbasicsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.JitBasicSearcher.target_layers"]], "target_layers (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.target_layers"]], "target_op_lut (neural_compressor.compression.pruner.model_slim.pattern_analyzer.linear2linearsearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.Linear2LinearSearcher.target_op_lut"]], "targets (neural_compressor.compression.pruner.model_slim.pattern_analyzer.recipesearcher attribute)": [[201, "neural_compressor.compression.pruner.model_slim.pattern_analyzer.RecipeSearcher.targets"]], "linearcompression (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression"]], "linearcompressioniterator (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator"]], "postcompressionutils (class in neural_compressor.compression.pruner.model_slim.weight_slim)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.PostCompressionUtils"]], "device (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.device"]], "layer_1 (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.layer_1"]], "layer_2 (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompression attribute)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompression.layer_2"]], "linear_patterns (neural_compressor.compression.pruner.model_slim.weight_slim.linearcompressioniterator attribute)": [[202, "neural_compressor.compression.pruner.model_slim.weight_slim.LinearCompressionIterator.linear_patterns"]], "neural_compressor.compression.pruner.model_slim.weight_slim": [[202, "module-neural_compressor.compression.pruner.model_slim.weight_slim"]], "basepattern (class in neural_compressor.compression.pruner.patterns.base)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern"]], "kerasbasepattern (class in neural_compressor.compression.pruner.patterns.base)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern"]], "pytorchbasepattern (class in neural_compressor.compression.pruner.patterns.base)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern"]], "config (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.config"]], "config (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.config"]], "config (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.config"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.invalid_layers"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.invalid_layers"]], "invalid_layers (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.invalid_layers"]], "is_global (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.is_global"]], "is_global (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.is_global"]], "is_global (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.is_global"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.keep_mask_layers"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.keep_mask_layers"]], "keep_mask_layers (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.keep_mask_layers"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.max_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.min_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.min_sparsity_ratio_per_op"]], "min_sparsity_ratio_per_op (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.min_sparsity_ratio_per_op"]], "modules (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.modules"]], "modules (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.modules"]], "modules (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.modules"]], "neural_compressor.compression.pruner.patterns.base": [[203, "module-neural_compressor.compression.pruner.patterns.base"]], "pattern (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.pattern"]], "pattern (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.pattern"]], "pattern (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.pattern"]], "register_pattern() (in module neural_compressor.compression.pruner.patterns.base)": [[203, "neural_compressor.compression.pruner.patterns.base.register_pattern"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.basepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.BasePattern.target_sparsity"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.kerasbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.KerasBasePattern.target_sparsity"]], "target_sparsity (neural_compressor.compression.pruner.patterns.base.pytorchbasepattern attribute)": [[203, "neural_compressor.compression.pruner.patterns.base.PytorchBasePattern.target_sparsity"]], "get_pattern() (in module neural_compressor.compression.pruner.patterns)": [[204, "neural_compressor.compression.pruner.patterns.get_pattern"]], "neural_compressor.compression.pruner.patterns": [[204, "module-neural_compressor.compression.pruner.patterns"]], "m (neural_compressor.compression.pruner.patterns.mha.patternmha attribute)": [[205, "neural_compressor.compression.pruner.patterns.mha.PatternMHA.M"]], "n (neural_compressor.compression.pruner.patterns.mha.patternmha attribute)": [[205, "neural_compressor.compression.pruner.patterns.mha.PatternMHA.N"]], "patternmha (class in neural_compressor.compression.pruner.patterns.mha)": [[205, "neural_compressor.compression.pruner.patterns.mha.PatternMHA"]], "neural_compressor.compression.pruner.patterns.mha": [[205, "module-neural_compressor.compression.pruner.patterns.mha"]], "m (neural_compressor.compression.pruner.patterns.ninm.pytorchpatternninm attribute)": [[206, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM.M"]], "n (neural_compressor.compression.pruner.patterns.ninm.pytorchpatternninm attribute)": [[206, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM.N"]], "pytorchpatternninm (class in neural_compressor.compression.pruner.patterns.ninm)": [[206, "neural_compressor.compression.pruner.patterns.ninm.PytorchPatternNInM"]], "neural_compressor.compression.pruner.patterns.ninm": [[206, "module-neural_compressor.compression.pruner.patterns.ninm"]], "keraspatternnxm (class in neural_compressor.compression.pruner.patterns.nxm)": [[207, "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM"]], "pytorchpatternnxm (class in neural_compressor.compression.pruner.patterns.nxm)": [[207, "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM"]], "block_size (neural_compressor.compression.pruner.patterns.nxm.keraspatternnxm attribute)": [[207, "neural_compressor.compression.pruner.patterns.nxm.KerasPatternNxM.block_size"]], "block_size (neural_compressor.compression.pruner.patterns.nxm.pytorchpatternnxm attribute)": [[207, "neural_compressor.compression.pruner.patterns.nxm.PytorchPatternNxM.block_size"]], "neural_compressor.compression.pruner.patterns.nxm": [[207, "module-neural_compressor.compression.pruner.patterns.nxm"]], "basepruner (class in neural_compressor.compression.pruner.pruners.base)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner"]], "kerasbasepruner (class in neural_compressor.compression.pruner.pruners.base)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner"]], "pytorchbasepruner (class in neural_compressor.compression.pruner.pruners.base)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner"]], "config (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.config"]], "config (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.config"]], "config (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.config"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.current_sparsity_ratio"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.current_sparsity_ratio"]], "current_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.current_sparsity_ratio"]], "end_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.end_step"]], "end_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.end_step"]], "end_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.end_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.global_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.global_step"]], "global_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.global_step"]], "masks (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.masks"]], "masks (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.masks"]], "masks (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.masks"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.max_sparsity_ratio_per_op"]], "max_sparsity_ratio_per_op (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.max_sparsity_ratio_per_op"]], "modules (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.modules"]], "modules (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.modules"]], "modules (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.modules"]], "neural_compressor.compression.pruner.pruners.base": [[208, "module-neural_compressor.compression.pruner.pruners.base"]], "pattern (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.pattern"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.pruning_frequency"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.pruning_frequency"]], "pruning_frequency (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.pruning_frequency"]], "register_pruner() (in module neural_compressor.compression.pruner.pruners.base)": [[208, "neural_compressor.compression.pruner.pruners.base.register_pruner"]], "scheduler (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.scheduler"]], "scores (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.scores"]], "scores (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.scores"]], "scores (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.scores"]], "start_step (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.start_step"]], "start_step (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.start_step"]], "start_step (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.start_step"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.basepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.BasePruner.target_sparsity_ratio"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.kerasbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.KerasBasePruner.target_sparsity_ratio"]], "target_sparsity_ratio (neural_compressor.compression.pruner.pruners.base.pytorchbasepruner attribute)": [[208, "neural_compressor.compression.pruner.pruners.base.PytorchBasePruner.target_sparsity_ratio"]], "kerasbasicpruner (class in neural_compressor.compression.pruner.pruners.basic)": [[209, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner"]], "pytorchbasicpruner (class in neural_compressor.compression.pruner.pruners.basic)": [[209, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner"]], "criterion (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.criterion"]], "criterion (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.criterion"]], "neural_compressor.compression.pruner.pruners.basic": [[209, "module-neural_compressor.compression.pruner.pruners.basic"]], "pattern (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.pattern"]], "pattern (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.reg"]], "reg (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.basic.kerasbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.KerasBasicPruner.scheduler"]], "scheduler (neural_compressor.compression.pruner.pruners.basic.pytorchbasicpruner attribute)": [[209, "neural_compressor.compression.pruner.pruners.basic.PytorchBasicPruner.scheduler"]], "pytorchblockmaskpruner (class in neural_compressor.compression.pruner.pruners.block_mask)": [[210, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner"]], "criterion (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.criterion"]], "neural_compressor.compression.pruner.pruners.block_mask": [[210, "module-neural_compressor.compression.pruner.pruners.block_mask"]], "pattern (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.block_mask.pytorchblockmaskpruner attribute)": [[210, "neural_compressor.compression.pruner.pruners.block_mask.PytorchBlockMaskPruner.scheduler"]], "get_pruner() (in module neural_compressor.compression.pruner.pruners)": [[211, "neural_compressor.compression.pruner.pruners.get_pruner"]], "neural_compressor.compression.pruner.pruners": [[211, "module-neural_compressor.compression.pruner.pruners"]], "parse_valid_pruner_types() (in module neural_compressor.compression.pruner.pruners)": [[211, "neural_compressor.compression.pruner.pruners.parse_valid_pruner_types"]], "pythonmultiheadattentionpruner (class in neural_compressor.compression.pruner.pruners.mha)": [[212, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner"]], "head_masks (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.head_masks"]], "linear_layers (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.linear_layers"]], "mha_compressions (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.mha_compressions"]], "mha_scores (neural_compressor.compression.pruner.pruners.mha.pythonmultiheadattentionpruner attribute)": [[212, "neural_compressor.compression.pruner.pruners.mha.PythonMultiheadAttentionPruner.mha_scores"]], "neural_compressor.compression.pruner.pruners.mha": [[212, "module-neural_compressor.compression.pruner.pruners.mha"]], "pytorchpatternlockpruner (class in neural_compressor.compression.pruner.pruners.pattern_lock)": [[213, "neural_compressor.compression.pruner.pruners.pattern_lock.PytorchPatternLockPruner"]], "neural_compressor.compression.pruner.pruners.pattern_lock": [[213, "module-neural_compressor.compression.pruner.pruners.pattern_lock"]], "pytorchprogressivepruner (class in neural_compressor.compression.pruner.pruners.progressive)": [[214, "neural_compressor.compression.pruner.pruners.progressive.PytorchProgressivePruner"]], "neural_compressor.compression.pruner.pruners.progressive": [[214, "module-neural_compressor.compression.pruner.pruners.progressive"]], "pytorchretrainfreepruner (class in neural_compressor.compression.pruner.pruners.retrain_free)": [[215, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner"]], "criterion (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[215, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.criterion"]], "neural_compressor.compression.pruner.pruners.retrain_free": [[215, "module-neural_compressor.compression.pruner.pruners.retrain_free"]], "pattern (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[215, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[215, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.retrain_free.pytorchretrainfreepruner attribute)": [[215, "neural_compressor.compression.pruner.pruners.retrain_free.PytorchRetrainFreePruner.scheduler"]], "sparsegptpruner (class in neural_compressor.compression.pruner.pruners.sparse_gpt)": [[216, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner"]], "criterion (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[216, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.criterion"]], "neural_compressor.compression.pruner.pruners.sparse_gpt": [[216, "module-neural_compressor.compression.pruner.pruners.sparse_gpt"]], "pattern (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[216, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.pattern"]], "reg (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[216, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.reg"]], "scheduler (neural_compressor.compression.pruner.pruners.sparse_gpt.sparsegptpruner attribute)": [[216, "neural_compressor.compression.pruner.pruners.sparse_gpt.SparseGPTPruner.scheduler"]], "basepruning (class in neural_compressor.compression.pruner.pruning)": [[217, "neural_compressor.compression.pruner.pruning.BasePruning"]], "basicpruning (class in neural_compressor.compression.pruner.pruning)": [[217, "neural_compressor.compression.pruner.pruning.BasicPruning"]], "retrainfreepruning (class in neural_compressor.compression.pruner.pruning)": [[217, "neural_compressor.compression.pruner.pruning.RetrainFreePruning"]], "sparsegptpruning (class in neural_compressor.compression.pruner.pruning)": [[217, "neural_compressor.compression.pruner.pruning.SparseGPTPruning"]], "config_file_path (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasePruning.config_file_path"]], "config_file_path (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasicPruning.config_file_path"]], "config_file_path (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.config_file_path"]], "model (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasePruning.model"]], "model (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasicPruning.model"]], "model (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.model"]], "neural_compressor.compression.pruner.pruning": [[217, "module-neural_compressor.compression.pruner.pruning"]], "pruner_info (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasePruning.pruner_info"]], "pruner_info (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasicPruning.pruner_info"]], "pruner_info (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.pruner_info"]], "pruners (neural_compressor.compression.pruner.pruning.basepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasePruning.pruners"]], "pruners (neural_compressor.compression.pruner.pruning.basicpruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.BasicPruning.pruners"]], "pruners (neural_compressor.compression.pruner.pruning.retrainfreepruning attribute)": [[217, "neural_compressor.compression.pruner.pruning.RetrainFreePruning.pruners"]], "register_pruning() (in module neural_compressor.compression.pruner.pruning)": [[217, "neural_compressor.compression.pruner.pruning.register_pruning"]], "basereg (class in neural_compressor.compression.pruner.regs)": [[218, "neural_compressor.compression.pruner.regs.BaseReg"]], "grouplasso (class in neural_compressor.compression.pruner.regs)": [[218, "neural_compressor.compression.pruner.regs.GroupLasso"]], "alpha (neural_compressor.compression.pruner.regs.grouplasso attribute)": [[218, "neural_compressor.compression.pruner.regs.GroupLasso.alpha"]], "get_reg() (in module neural_compressor.compression.pruner.regs)": [[218, "neural_compressor.compression.pruner.regs.get_reg"]], "get_reg_type() (in module neural_compressor.compression.pruner.regs)": [[218, "neural_compressor.compression.pruner.regs.get_reg_type"]], "neural_compressor.compression.pruner.regs": [[218, "module-neural_compressor.compression.pruner.regs"]], "reg_terms (neural_compressor.compression.pruner.regs.grouplasso attribute)": [[218, "neural_compressor.compression.pruner.regs.GroupLasso.reg_terms"]], "register_reg() (in module neural_compressor.compression.pruner.regs)": [[218, "neural_compressor.compression.pruner.regs.register_reg"]], "iterativescheduler (class in neural_compressor.compression.pruner.schedulers)": [[219, "neural_compressor.compression.pruner.schedulers.IterativeScheduler"]], "oneshotscheduler (class in neural_compressor.compression.pruner.schedulers)": [[219, "neural_compressor.compression.pruner.schedulers.OneshotScheduler"]], "pruningscheduler (class in neural_compressor.compression.pruner.schedulers)": [[219, "neural_compressor.compression.pruner.schedulers.PruningScheduler"]], "config (neural_compressor.compression.pruner.schedulers.pruningscheduler attribute)": [[219, "neural_compressor.compression.pruner.schedulers.PruningScheduler.config"]], "get_scheduler() (in module neural_compressor.compression.pruner.schedulers)": [[219, "neural_compressor.compression.pruner.schedulers.get_scheduler"]], "neural_compressor.compression.pruner.schedulers": [[219, "module-neural_compressor.compression.pruner.schedulers"]], "register_scheduler() (in module neural_compressor.compression.pruner.schedulers)": [[219, "neural_compressor.compression.pruner.schedulers.register_scheduler"]], "magnitudecriterion (class in neural_compressor.compression.pruner.tf_criteria)": [[220, "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion"]], "pruningcriterion (class in neural_compressor.compression.pruner.tf_criteria)": [[220, "neural_compressor.compression.pruner.tf_criteria.PruningCriterion"]], "get_tf_criterion() (in module neural_compressor.compression.pruner.tf_criteria)": [[220, "neural_compressor.compression.pruner.tf_criteria.get_tf_criterion"]], "neural_compressor.compression.pruner.tf_criteria": [[220, "module-neural_compressor.compression.pruner.tf_criteria"]], "register_criterion() (in module neural_compressor.compression.pruner.tf_criteria)": [[220, "neural_compressor.compression.pruner.tf_criteria.register_criterion"]], "scores (neural_compressor.compression.pruner.tf_criteria.magnitudecriterion attribute)": [[220, "neural_compressor.compression.pruner.tf_criteria.MagnitudeCriterion.scores"]], "scores (neural_compressor.compression.pruner.tf_criteria.pruningcriterion attribute)": [[220, "neural_compressor.compression.pruner.tf_criteria.PruningCriterion.scores"]], "check_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.check_config"]], "check_key_validity() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.check_key_validity"]], "collect_layer_inputs() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.collect_layer_inputs"]], "generate_pruner_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.generate_pruner_config"]], "get_layers() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.get_layers"]], "get_sparsity_ratio() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.get_sparsity_ratio"]], "get_sparsity_ratio_tf() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.get_sparsity_ratio_tf"]], "neural_compressor.compression.pruner.utils": [[221, "module-neural_compressor.compression.pruner.utils"]], "parse_last_linear() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.parse_last_linear"]], "parse_last_linear_tf() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.parse_last_linear_tf"]], "parse_to_prune() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.parse_to_prune"]], "parse_to_prune_tf() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.parse_to_prune_tf"]], "process_and_check_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.process_and_check_config"]], "process_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.process_config"]], "process_weight_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.process_weight_config"]], "process_yaml_config() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.process_yaml_config"]], "reset_none_to_default() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.reset_none_to_default"]], "update_params() (in module neural_compressor.compression.pruner.utils)": [[221, "neural_compressor.compression.pruner.utils.update_params"]], "neural_compressor.compression.pruner.wanda": [[222, "module-neural_compressor.compression.pruner.wanda"]], "neural_compressor.compression.pruner.wanda.prune": [[223, "module-neural_compressor.compression.pruner.wanda.prune"]], "prune_wanda() (in module neural_compressor.compression.pruner.wanda.prune)": [[223, "neural_compressor.compression.pruner.wanda.prune.prune_wanda"]], "find_layers() (in module neural_compressor.compression.pruner.wanda.utils)": [[224, "neural_compressor.compression.pruner.wanda.utils.find_layers"]], "neural_compressor.compression.pruner.wanda.utils": [[224, "module-neural_compressor.compression.pruner.wanda.utils"]], "wrappedgpt (class in neural_compressor.compression.pruner.wanda.wrapper)": [[225, "neural_compressor.compression.pruner.wanda.wrapper.WrappedGPT"]], "neural_compressor.compression.pruner.wanda.wrapper": [[225, "module-neural_compressor.compression.pruner.wanda.wrapper"]], "benchmark_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Benchmark_Conf"]], "conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Conf"]], "distillation_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Distillation_Conf"]], "graph_optimization_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Graph_Optimization_Conf"]], "mixedprecision_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.MixedPrecision_Conf"]], "nasconfig (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.NASConfig"]], "prunerv2 (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.PrunerV2"]], "pruning_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Pruning_Conf"]], "quantization_conf (class in neural_compressor.conf.config)": [[226, "neural_compressor.conf.config.Quantization_Conf"]], "neural_compressor.conf.config": [[226, "module-neural_compressor.conf.config"]], "dotdict (class in neural_compressor.conf.dotdict)": [[227, "neural_compressor.conf.dotdict.DotDict"]], "deep_get() (in module neural_compressor.conf.dotdict)": [[227, "neural_compressor.conf.dotdict.deep_get"]], "deep_set() (in module neural_compressor.conf.dotdict)": [[227, "neural_compressor.conf.dotdict.deep_set"]], "neural_compressor.conf.dotdict": [[227, "module-neural_compressor.conf.dotdict"]], "neural_compressor.conf": [[228, "module-neural_compressor.conf"]], "accuracycriterion (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.AccuracyCriterion"]], "benchmarkconfig (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.BenchmarkConfig"]], "distillationconfig (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.DistillationConfig"]], "knowledgedistillationlossconfig (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.KnowledgeDistillationLossConfig"]], "options (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.Options"]], "quantizationconfig (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.QuantizationConfig"]], "weightpruningconfig (class in neural_compressor.conf.pythonic_config)": [[229, "neural_compressor.conf.pythonic_config.WeightPruningConfig"]], "neural_compressor.conf.pythonic_config": [[229, "module-neural_compressor.conf.pythonic_config"]], "accuracycriterion (class in neural_compressor.config)": [[230, "neural_compressor.config.AccuracyCriterion"]], "benchmarkconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.BenchmarkConfig"]], "distillationconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.DistillationConfig"]], "dotdict (class in neural_compressor.config)": [[230, "neural_compressor.config.DotDict"]], "exportconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.ExportConfig"]], "hpoconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.HPOConfig"]], "intermediatelayersknowledgedistillationlossconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.IntermediateLayersKnowledgeDistillationLossConfig"]], "keras (class in neural_compressor.config)": [[230, "neural_compressor.config.Keras"]], "knowledgedistillationlossconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.KnowledgeDistillationLossConfig"]], "mxnet (class in neural_compressor.config)": [[230, "neural_compressor.config.MXNet"]], "mixedprecisionconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.MixedPrecisionConfig"]], "nasconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.NASConfig"]], "onnx (class in neural_compressor.config)": [[230, "neural_compressor.config.ONNX"]], "onnxqlinear2qdqconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.ONNXQlinear2QDQConfig"]], "options (class in neural_compressor.config)": [[230, "neural_compressor.config.Options"]], "posttrainingquantconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.PostTrainingQuantConfig"]], "pytorch (class in neural_compressor.config)": [[230, "neural_compressor.config.PyTorch"]], "quantizationawaretrainingconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.QuantizationAwareTrainingConfig"]], "selfknowledgedistillationlossconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.SelfKnowledgeDistillationLossConfig"]], "tf2onnxconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.TF2ONNXConfig"]], "tensorflow (class in neural_compressor.config)": [[230, "neural_compressor.config.TensorFlow"]], "torch2onnxconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.Torch2ONNXConfig"]], "tuningcriterion (class in neural_compressor.config)": [[230, "neural_compressor.config.TuningCriterion"]], "weightpruningconfig (class in neural_compressor.config)": [[230, "neural_compressor.config.WeightPruningConfig"]], "neural_compressor.config": [[230, "module-neural_compressor.config"]], "neural_compressor.contrib": [[231, "module-neural_compressor.contrib"]], "neural_compressor.contrib.strategy": [[232, "module-neural_compressor.contrib.strategy"]], "sigopttunestrategy (class in neural_compressor.contrib.strategy.sigopt)": [[233, "neural_compressor.contrib.strategy.sigopt.SigOptTuneStrategy"]], "neural_compressor.contrib.strategy.sigopt": [[233, "module-neural_compressor.contrib.strategy.sigopt"]], "tpetunestrategy (class in neural_compressor.contrib.strategy.tpe)": [[234, "neural_compressor.contrib.strategy.tpe.TpeTuneStrategy"]], "neural_compressor.contrib.strategy.tpe": [[234, "module-neural_compressor.contrib.strategy.tpe"]], "basedataloader (class in neural_compressor.data.dataloaders.base_dataloader)": [[235, "neural_compressor.data.dataloaders.base_dataloader.BaseDataLoader"]], "neural_compressor.data.dataloaders.base_dataloader": [[235, "module-neural_compressor.data.dataloaders.base_dataloader"]], "dataloader (class in neural_compressor.data.dataloaders.dataloader)": [[236, "neural_compressor.data.dataloaders.dataloader.DataLoader"]], "check_dataloader() (in module neural_compressor.data.dataloaders.dataloader)": [[236, "neural_compressor.data.dataloaders.dataloader.check_dataloader"]], "neural_compressor.data.dataloaders.dataloader": [[236, "module-neural_compressor.data.dataloaders.dataloader"]], "defaultdataloader (class in neural_compressor.data.dataloaders.default_dataloader)": [[237, "neural_compressor.data.dataloaders.default_dataloader.DefaultDataLoader"]], "default_collate() (in module neural_compressor.data.dataloaders.default_dataloader)": [[237, "neural_compressor.data.dataloaders.default_dataloader.default_collate"]], "neural_compressor.data.dataloaders.default_dataloader": [[237, "module-neural_compressor.data.dataloaders.default_dataloader"]], "fetcher (class in neural_compressor.data.dataloaders.fetcher)": [[238, "neural_compressor.data.dataloaders.fetcher.Fetcher"]], "indexfetcher (class in neural_compressor.data.dataloaders.fetcher)": [[238, "neural_compressor.data.dataloaders.fetcher.IndexFetcher"]], "iterablefetcher (class in neural_compressor.data.dataloaders.fetcher)": [[238, "neural_compressor.data.dataloaders.fetcher.IterableFetcher"]], "neural_compressor.data.dataloaders.fetcher": [[238, "module-neural_compressor.data.dataloaders.fetcher"]], "neural_compressor.data.dataloaders": [[239, "module-neural_compressor.data.dataloaders"]], "mxnetdataloader (class in neural_compressor.data.dataloaders.mxnet_dataloader)": [[240, "neural_compressor.data.dataloaders.mxnet_dataloader.MXNetDataLoader"]], "neural_compressor.data.dataloaders.mxnet_dataloader": [[240, "module-neural_compressor.data.dataloaders.mxnet_dataloader"]], "onnxrtbertdataloader (class in neural_compressor.data.dataloaders.onnxrt_dataloader)": [[241, "neural_compressor.data.dataloaders.onnxrt_dataloader.ONNXRTBertDataLoader"]], "onnxrtdataloader (class in neural_compressor.data.dataloaders.onnxrt_dataloader)": [[241, "neural_compressor.data.dataloaders.onnxrt_dataloader.ONNXRTDataLoader"]], "neural_compressor.data.dataloaders.onnxrt_dataloader": [[241, "module-neural_compressor.data.dataloaders.onnxrt_dataloader"]], "pytorchdataloader (class in neural_compressor.data.dataloaders.pytorch_dataloader)": [[242, "neural_compressor.data.dataloaders.pytorch_dataloader.PyTorchDataLoader"]], "neural_compressor.data.dataloaders.pytorch_dataloader": [[242, "module-neural_compressor.data.dataloaders.pytorch_dataloader"]], "batchsampler (class in neural_compressor.data.dataloaders.sampler)": [[243, "neural_compressor.data.dataloaders.sampler.BatchSampler"]], "iterablesampler (class in neural_compressor.data.dataloaders.sampler)": [[243, "neural_compressor.data.dataloaders.sampler.IterableSampler"]], "sampler (class in neural_compressor.data.dataloaders.sampler)": [[243, "neural_compressor.data.dataloaders.sampler.Sampler"]], "sequentialsampler (class in neural_compressor.data.dataloaders.sampler)": [[243, "neural_compressor.data.dataloaders.sampler.SequentialSampler"]], "neural_compressor.data.dataloaders.sampler": [[243, "module-neural_compressor.data.dataloaders.sampler"]], "tfdatadataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[244, "neural_compressor.data.dataloaders.tensorflow_dataloader.TFDataDataLoader"]], "tensorflowbertdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[244, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowBertDataLoader"]], "tensorflowdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[244, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowDataLoader"]], "tensorflowmodelzoobertdataloader (class in neural_compressor.data.dataloaders.tensorflow_dataloader)": [[244, "neural_compressor.data.dataloaders.tensorflow_dataloader.TensorflowModelZooBertDataLoader"]], "neural_compressor.data.dataloaders.tensorflow_dataloader": [[244, "module-neural_compressor.data.dataloaders.tensorflow_dataloader"]], "inputfeatures (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.InputFeatures"]], "onnxrtbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.ONNXRTBertDataset"]], "parsedecodebert (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.ParseDecodeBert"]], "pytorchbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.PytorchBertDataset"]], "tensorflowbertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.TensorflowBertDataset"]], "tensorflowmodelzoobertdataset (class in neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.TensorflowModelZooBertDataset"]], "convert_examples_to_features() (in module neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.convert_examples_to_features"]], "load_and_cache_examples() (in module neural_compressor.data.datasets.bert_dataset)": [[245, "neural_compressor.data.datasets.bert_dataset.load_and_cache_examples"]], "neural_compressor.data.datasets.bert_dataset": [[245, "module-neural_compressor.data.datasets.bert_dataset"]], "coconpy (class in neural_compressor.data.datasets.coco_dataset)": [[246, "neural_compressor.data.datasets.coco_dataset.COCONpy"]], "cocoraw (class in neural_compressor.data.datasets.coco_dataset)": [[246, "neural_compressor.data.datasets.coco_dataset.COCORaw"]], "cocorecorddataset (class in neural_compressor.data.datasets.coco_dataset)": [[246, "neural_compressor.data.datasets.coco_dataset.COCORecordDataset"]], "parsedecodecoco (class in neural_compressor.data.datasets.coco_dataset)": [[246, "neural_compressor.data.datasets.coco_dataset.ParseDecodeCoco"]], "neural_compressor.data.datasets.coco_dataset": [[246, "module-neural_compressor.data.datasets.coco_dataset"]], "cifar10 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.CIFAR10"]], "cifar100 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.CIFAR100"]], "dataset (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.Dataset"]], "datasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.Datasets"]], "fashionmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.FashionMNIST"]], "imagefolder (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.ImageFolder"]], "iterabledataset (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.IterableDataset"]], "mnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MNIST"]], "mxnetcifar10 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetCIFAR10"]], "mxnetcifar100 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetCIFAR100"]], "mxnetdatasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetDatasets"]], "mxnetfashionmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetFashionMNIST"]], "mxnetimagefolder (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetImageFolder"]], "mxnetmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.MXNetMNIST"]], "onnxrtitdatasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.ONNXRTITDatasets"]], "onnxrtqldatasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.ONNXRTQLDatasets"]], "pytorchdatasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PyTorchDatasets"]], "pytorchcifar10 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchCIFAR10"]], "pytorchcifar100 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchCIFAR100"]], "pytorchfashionmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchFashionMNIST"]], "pytorchmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchMNIST"]], "pytorchmxnetwrapdataset (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapDataset"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.PytorchMxnetWrapFunction"]], "tensorflow (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.Tensorflow"]], "tensorflowcifar10 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowCIFAR10"]], "tensorflowcifar100 (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowCIFAR100"]], "tensorflowdatasets (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowDatasets"]], "tensorflowfashionmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowFashionMNIST"]], "tensorflowimagerecord (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowImageRecord"]], "tensorflowmnist (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowMNIST"]], "tensorflowtfrecorddataset (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowTFRecordDataset"]], "tensorflowvocrecord (class in neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.TensorflowVOCRecord"]], "calculate_md5() (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.calculate_md5"]], "check_integrity() (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.check_integrity"]], "dataset_registry() (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.dataset_registry"]], "download_url() (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.download_url"]], "framework_datasets (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.framework_datasets"]], "gen_bar_updater() (in module neural_compressor.data.datasets.dataset)": [[247, "neural_compressor.data.datasets.dataset.gen_bar_updater"]], "neural_compressor.data.datasets.dataset": [[247, "module-neural_compressor.data.datasets.dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset)": [[248, "neural_compressor.data.datasets.dummy_dataset.DummyDataset"]], "neural_compressor.data.datasets.dummy_dataset": [[248, "module-neural_compressor.data.datasets.dummy_dataset"]], "dummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[249, "neural_compressor.data.datasets.dummy_dataset_v2.DummyDataset"]], "sparsedummydataset (class in neural_compressor.data.datasets.dummy_dataset_v2)": [[249, "neural_compressor.data.datasets.dummy_dataset_v2.SparseDummyDataset"]], "neural_compressor.data.datasets.dummy_dataset_v2": [[249, "module-neural_compressor.data.datasets.dummy_dataset_v2"]], "imagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.ImagenetRaw"]], "mxnetimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.MXNetImagenetRaw"]], "onnxrtimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.ONNXRTImagenetDataset"]], "pytorchimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.PytorchImagenetRaw"]], "tensorflowimagenetdataset (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetDataset"]], "tensorflowimagenetraw (class in neural_compressor.data.datasets.imagenet_dataset)": [[250, "neural_compressor.data.datasets.imagenet_dataset.TensorflowImagenetRaw"]], "neural_compressor.data.datasets.imagenet_dataset": [[250, "module-neural_compressor.data.datasets.imagenet_dataset"]], "neural_compressor.data.datasets": [[251, "module-neural_compressor.data.datasets"]], "styletransferdataset (class in neural_compressor.data.datasets.style_transfer_dataset)": [[252, "neural_compressor.data.datasets.style_transfer_dataset.StyleTransferDataset"]], "neural_compressor.data.datasets.style_transfer_dataset": [[252, "module-neural_compressor.data.datasets.style_transfer_dataset"]], "labelbalancecocorawfilter (class in neural_compressor.data.filters.coco_filter)": [[253, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORawFilter"]], "labelbalancecocorecordfilter (class in neural_compressor.data.filters.coco_filter)": [[253, "neural_compressor.data.filters.coco_filter.LabelBalanceCOCORecordFilter"]], "neural_compressor.data.filters.coco_filter": [[253, "module-neural_compressor.data.filters.coco_filter"]], "filters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.FILTERS"]], "filter (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.Filter"]], "mxnetfilters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.MXNetFilters"]], "onnxrtitfilters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.ONNXRTITFilters"]], "onnxrtqlfilters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.ONNXRTQLFilters"]], "pytorchfilters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.PyTorchFilters"]], "tensorflowfilters (class in neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.TensorflowFilters"]], "filter_registry() (in module neural_compressor.data.filters.filter)": [[254, "neural_compressor.data.filters.filter.filter_registry"]], "neural_compressor.data.filters.filter": [[254, "module-neural_compressor.data.filters.filter"]], "neural_compressor.data.filters": [[255, "module-neural_compressor.data.filters"]], "neural_compressor.data": [[256, "module-neural_compressor.data"]], "parsedecodecocotransform (class in neural_compressor.data.transforms.coco_transform)": [[257, "neural_compressor.data.transforms.coco_transform.ParseDecodeCocoTransform"]], "neural_compressor.data.transforms.coco_transform": [[257, "module-neural_compressor.data.transforms.coco_transform"]], "bilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.BilinearImagenetTransform"]], "labelshift (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.LabelShift"]], "onnxresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.ONNXResizeCropImagenetTransform"]], "onnxbilinearimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.OnnxBilinearImagenetTransform"]], "parsedecodeimagenet (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenet"]], "parsedecodeimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.ParseDecodeImagenetTransform"]], "quantizedinput (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.QuantizedInput"]], "resizewithaspectratio (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.ResizeWithAspectRatio"]], "tensorflowresizecropimagenettransform (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.TensorflowResizeCropImagenetTransform"]], "tensorflowshiftrescale (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.TensorflowShiftRescale"]], "tensorflowtransposelastchannel (class in neural_compressor.data.transforms.imagenet_transform)": [[258, "neural_compressor.data.transforms.imagenet_transform.TensorflowTransposeLastChannel"]], "neural_compressor.data.transforms.imagenet_transform": [[258, "module-neural_compressor.data.transforms.imagenet_transform"]], "neural_compressor.data.transforms": [[259, "module-neural_compressor.data.transforms"]], "postprocess (class in neural_compressor.data.transforms.postprocess)": [[260, "neural_compressor.data.transforms.postprocess.Postprocess"]], "neural_compressor.data.transforms.postprocess": [[260, "module-neural_compressor.data.transforms.postprocess"]], "basictokenizer (class in neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.BasicTokenizer"]], "fulltokenizer (class in neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.FullTokenizer"]], "wordpiecetokenizer (class in neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.WordpieceTokenizer"]], "convert_by_vocab() (in module neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.convert_by_vocab"]], "convert_to_unicode() (in module neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.convert_to_unicode"]], "load_vocab() (in module neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.load_vocab"]], "neural_compressor.data.transforms.tokenization": [[261, "module-neural_compressor.data.transforms.tokenization"]], "whitespace_tokenize() (in module neural_compressor.data.transforms.tokenization)": [[261, "neural_compressor.data.transforms.tokenization.whitespace_tokenize"]], "alignimagechanneltransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.AlignImageChannelTransform"]], "basetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.BaseTransform"]], "castonnxtransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CastONNXTransform"]], "castpytorchtransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CastPyTorchTransform"]], "casttftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CastTFTransform"]], "centercroptftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CenterCropTFTransform"]], "centercroptransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CenterCropTransform"]], "collecttransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CollectTransform"]], "composetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ComposeTransform"]], "cropresizetftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CropResizeTFTransform"]], "cropresizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CropResizeTransform"]], "croptoboundingbox (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.CropToBoundingBox"]], "inputfeatures (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.InputFeatures"]], "mxnetcropresizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.MXNetCropResizeTransform"]], "mxnetcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.MXNetCropToBoundingBox"]], "mxnetnormalizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.MXNetNormalizeTransform"]], "mxnettransforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.MXNetTransforms"]], "mxnettranspose (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.MXNetTranspose"]], "normalizetftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.NormalizeTFTransform"]], "normalizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.NormalizeTransform"]], "onnxrtcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ONNXRTCropToBoundingBox"]], "onnxrtittransforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ONNXRTITTransforms"]], "onnxrtqltransforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ONNXRTQLTransforms"]], "paddedcentercroptransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PaddedCenterCropTransform"]], "parsedecodevoctransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ParseDecodeVocTransform"]], "pytorchalignimagechannel (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PyTorchAlignImageChannel"]], "pytorchcropresizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PyTorchCropResizeTransform"]], "pytorchnormalizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PyTorchNormalizeTransform"]], "pytorchtransforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PyTorchTransforms"]], "pytorchtranspose (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PyTorchTranspose"]], "pytorchmxnettransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PytorchMxnetTransform"]], "pytorchmxnetwrapfunction (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.PytorchMxnetWrapFunction"]], "randomcroptftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomCropTFTransform"]], "randomcroptransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomCropTransform"]], "randomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomHorizontalFlip"]], "randomresizedcropmxnettransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomResizedCropMXNetTransform"]], "randomresizedcroppytorchtransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomResizedCropPytorchTransform"]], "randomresizedcroptftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomResizedCropTFTransform"]], "randomresizedcroptransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomResizedCropTransform"]], "randomverticalflip (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RandomVerticalFlip"]], "rescalekeraspretraintransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RescaleKerasPretrainTransform"]], "rescaletftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RescaleTFTransform"]], "rescaletransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.RescaleTransform"]], "resizemxnettransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ResizeMXNetTransform"]], "resizepytorchtransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ResizePytorchTransform"]], "resizetftransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ResizeTFTransform"]], "resizetransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ResizeTransform"]], "resizewithratio (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ResizeWithRatio"]], "squadexample (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.SquadExample"]], "tfmodelzoocollecttransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TFModelZooCollectTransform"]], "tfsquadv1modelzooposttransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TFSquadV1ModelZooPostTransform"]], "tfsquadv1posttransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TFSquadV1PostTransform"]], "transforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TRANSFORMS"], [262, "neural_compressor.data.transforms.transform.Transforms"]], "tensorflowcroptoboundingbox (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowCropToBoundingBox"]], "tensorflowrandomhorizontalflip (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowRandomHorizontalFlip"]], "tensorflowrandomverticalflip (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowRandomVerticalFlip"]], "tensorflowresizewithratio (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowResizeWithRatio"]], "tensorflowtransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowTransform"]], "tensorflowtransforms (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowTransforms"]], "tensorflowtranspose (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowTranspose"]], "tensorflowwrapfunction (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.TensorflowWrapFunction"]], "toarray (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ToArray"]], "tondarraytransform (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.ToNDArrayTransform"]], "transpose (class in neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.Transpose"]], "convert_examples_to_features() (in module neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.convert_examples_to_features"]], "get_final_text() (in module neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.get_final_text"]], "get_torchvision_map() (in module neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.get_torchvision_map"]], "neural_compressor.data.transforms.transform": [[262, "module-neural_compressor.data.transforms.transform"]], "read_squad_examples() (in module neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.read_squad_examples"]], "transform_registry() (in module neural_compressor.data.transforms.transform)": [[262, "neural_compressor.data.transforms.transform.transform_registry"]], "benchmark (class in neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.Benchmark"]], "get_architecture() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_architecture"]], "get_bounded_threads() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_bounded_threads"]], "get_core_ids() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_core_ids"]], "get_physical_ids() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_physical_ids"]], "get_threads() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_threads"]], "get_threads_per_core() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.get_threads_per_core"]], "neural_compressor.experimental.benchmark": [[263, "module-neural_compressor.experimental.benchmark"]], "set_all_env_var() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.set_all_env_var"]], "set_env_var() (in module neural_compressor.experimental.benchmark)": [[263, "neural_compressor.experimental.benchmark.set_env_var"]], "criterions (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.Criterions"]], "intermediatelayersknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.IntermediateLayersKnowledgeDistillationLoss"]], "knowledgedistillationframework (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.KnowledgeDistillationFramework"]], "knowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.KnowledgeDistillationLoss"]], "pytorchcriterions (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.PyTorchCriterions"]], "pytorchintermediatelayersknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.PyTorchIntermediateLayersKnowledgeDistillationLoss"]], "pytorchintermediatelayersknowledgedistillationlosswrapper (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.PyTorchIntermediateLayersKnowledgeDistillationLossWrapper"]], "pytorchknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.PyTorchKnowledgeDistillationLoss"]], "pytorchknowledgedistillationlosswrapper (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.PyTorchKnowledgeDistillationLossWrapper"]], "selfknowledgedistillationloss (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.SelfKnowledgeDistillationLoss"]], "tensorflowcriterions (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.TensorflowCriterions"]], "tensorflowknowledgedistillationlossexternal (class in neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.TensorflowKnowledgeDistillationLossExternal"]], "criterion_registry() (in module neural_compressor.experimental.common.criterion)": [[264, "neural_compressor.experimental.common.criterion.criterion_registry"]], "neural_compressor.experimental.common.criterion": [[264, "module-neural_compressor.experimental.common.criterion"]], "dataloader (class in neural_compressor.experimental.common.dataloader)": [[265, "neural_compressor.experimental.common.dataloader.DataLoader"]], "neural_compressor.experimental.common.dataloader": [[265, "module-neural_compressor.experimental.common.dataloader"]], "neural_compressor.experimental.common": [[266, "module-neural_compressor.experimental.common"]], "metric (class in neural_compressor.experimental.common.metric)": [[267, "neural_compressor.experimental.common.metric.Metric"]], "neural_compressor.experimental.common.metric": [[267, "module-neural_compressor.experimental.common.metric"]], "model (class in neural_compressor.experimental.common.model)": [[268, "neural_compressor.experimental.common.model.Model"]], "neural_compressor.experimental.common.model": [[268, "module-neural_compressor.experimental.common.model"]], "set_backend() (in module neural_compressor.experimental.common.model)": [[268, "neural_compressor.experimental.common.model.set_backend"]], "optimizers (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.Optimizers"]], "pytorchoptimizers (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.PyTorchOptimizers"]], "pytorchsgd (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.PyTorchSGD"]], "tensorflowadamw (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.TensorFlowAdamW"]], "tensorflowsgd (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.TensorFlowSGD"]], "tensorflowoptimizers (class in neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.TensorflowOptimizers"]], "neural_compressor.experimental.common.optimizer": [[269, "module-neural_compressor.experimental.common.optimizer"]], "optimizer_registry() (in module neural_compressor.experimental.common.optimizer)": [[269, "neural_compressor.experimental.common.optimizer.optimizer_registry"]], "postprocess (class in neural_compressor.experimental.common.postprocess)": [[270, "neural_compressor.experimental.common.postprocess.Postprocess"]], "neural_compressor.experimental.common.postprocess": [[270, "module-neural_compressor.experimental.common.postprocess"]], "get_activation() (in module neural_compressor.experimental.common.torch_utils)": [[271, "neural_compressor.experimental.common.torch_utils.get_activation"]], "neural_compressor.experimental.common.torch_utils": [[271, "module-neural_compressor.experimental.common.torch_utils"]], "record_output() (in module neural_compressor.experimental.common.torch_utils)": [[271, "neural_compressor.experimental.common.torch_utils.record_output"]], "component (class in neural_compressor.experimental.component)": [[272, "neural_compressor.experimental.component.Component"]], "neural_compressor.experimental.component": [[272, "module-neural_compressor.experimental.component"]], "neural_compressor.experimental.compression": [[273, "module-neural_compressor.experimental.compression"]], "neural_compressor.experimental.contrib": [[274, "module-neural_compressor.experimental.contrib"]], "neural_compressor.experimental.contrib.strategy": [[275, "module-neural_compressor.experimental.contrib.strategy"]], "sigopttunestrategy (class in neural_compressor.experimental.contrib.strategy.sigopt)": [[276, "neural_compressor.experimental.contrib.strategy.sigopt.SigOptTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.sigopt": [[276, "module-neural_compressor.experimental.contrib.strategy.sigopt"]], "tpetunestrategy (class in neural_compressor.experimental.contrib.strategy.tpe)": [[277, "neural_compressor.experimental.contrib.strategy.tpe.TpeTuneStrategy"]], "neural_compressor.experimental.contrib.strategy.tpe": [[277, "module-neural_compressor.experimental.contrib.strategy.tpe"]], "basedataloader (class in neural_compressor.experimental.data.dataloaders.base_dataloader)": [[278, "neural_compressor.experimental.data.dataloaders.base_dataloader.BaseDataLoader"]], "neural_compressor.experimental.data.dataloaders.base_dataloader": [[278, "module-neural_compressor.experimental.data.dataloaders.base_dataloader"]], "neural_compressor.experimental.data.dataloaders.dataloader": [[279, "module-neural_compressor.experimental.data.dataloaders.dataloader"]], "defaultdataloader (class in neural_compressor.experimental.data.dataloaders.default_dataloader)": [[280, "neural_compressor.experimental.data.dataloaders.default_dataloader.DefaultDataLoader"]], "default_collate() (in module neural_compressor.experimental.data.dataloaders.default_dataloader)": [[280, "neural_compressor.experimental.data.dataloaders.default_dataloader.default_collate"]], "neural_compressor.experimental.data.dataloaders.default_dataloader": [[280, "module-neural_compressor.experimental.data.dataloaders.default_dataloader"]], "fetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[281, "neural_compressor.experimental.data.dataloaders.fetcher.Fetcher"]], "indexfetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[281, "neural_compressor.experimental.data.dataloaders.fetcher.IndexFetcher"]], "iterablefetcher (class in neural_compressor.experimental.data.dataloaders.fetcher)": [[281, "neural_compressor.experimental.data.dataloaders.fetcher.IterableFetcher"]], "neural_compressor.experimental.data.dataloaders.fetcher": [[281, "module-neural_compressor.experimental.data.dataloaders.fetcher"]], "neural_compressor.experimental.data.dataloaders": [[282, "module-neural_compressor.experimental.data.dataloaders"]], "mxnetdataloader (class in neural_compressor.experimental.data.dataloaders.mxnet_dataloader)": [[283, "neural_compressor.experimental.data.dataloaders.mxnet_dataloader.MXNetDataLoader"]], "neural_compressor.experimental.data.dataloaders.mxnet_dataloader": [[283, "module-neural_compressor.experimental.data.dataloaders.mxnet_dataloader"]], "onnxrtbertdataloader (class in neural_compressor.experimental.data.dataloaders.onnxrt_dataloader)": [[284, "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader.ONNXRTBertDataLoader"]], "onnxrtdataloader (class in neural_compressor.experimental.data.dataloaders.onnxrt_dataloader)": [[284, "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader.ONNXRTDataLoader"]], "neural_compressor.experimental.data.dataloaders.onnxrt_dataloader": [[284, "module-neural_compressor.experimental.data.dataloaders.onnxrt_dataloader"]], "pytorchdataloader (class in neural_compressor.experimental.data.dataloaders.pytorch_dataloader)": [[285, "neural_compressor.experimental.data.dataloaders.pytorch_dataloader.PyTorchDataLoader"]], "neural_compressor.experimental.data.dataloaders.pytorch_dataloader": [[285, "module-neural_compressor.experimental.data.dataloaders.pytorch_dataloader"]], "batchsampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[286, "neural_compressor.experimental.data.dataloaders.sampler.BatchSampler"]], "iterablesampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[286, "neural_compressor.experimental.data.dataloaders.sampler.IterableSampler"]], "sampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[286, "neural_compressor.experimental.data.dataloaders.sampler.Sampler"]], "sequentialsampler (class in neural_compressor.experimental.data.dataloaders.sampler)": [[286, "neural_compressor.experimental.data.dataloaders.sampler.SequentialSampler"]], "neural_compressor.experimental.data.dataloaders.sampler": [[286, "module-neural_compressor.experimental.data.dataloaders.sampler"]], "tfdatadataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[287, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TFDataDataLoader"]], "tensorflowbertdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[287, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowBertDataLoader"]], "tensorflowdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[287, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowDataLoader"]], "tensorflowmodelzoobertdataloader (class in neural_compressor.experimental.data.dataloaders.tensorflow_dataloader)": [[287, "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader.TensorflowModelZooBertDataLoader"]], "neural_compressor.experimental.data.dataloaders.tensorflow_dataloader": [[287, "module-neural_compressor.experimental.data.dataloaders.tensorflow_dataloader"]], "inputfeatures (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.InputFeatures"]], "onnxrtbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.ONNXRTBertDataset"]], "parsedecodebert (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.ParseDecodeBert"]], "pytorchbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.PytorchBertDataset"]], "tensorflowbertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.TensorflowBertDataset"]], "tensorflowmodelzoobertdataset (class in neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.TensorflowModelZooBertDataset"]], "convert_examples_to_features() (in module neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.convert_examples_to_features"]], "load_and_cache_examples() (in module neural_compressor.experimental.data.datasets.bert_dataset)": [[288, "neural_compressor.experimental.data.datasets.bert_dataset.load_and_cache_examples"]], "neural_compressor.experimental.data.datasets.bert_dataset": [[288, "module-neural_compressor.experimental.data.datasets.bert_dataset"]], "coconpy (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[289, "neural_compressor.experimental.data.datasets.coco_dataset.COCONpy"]], "cocoraw (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[289, "neural_compressor.experimental.data.datasets.coco_dataset.COCORaw"]], "cocorecorddataset (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[289, "neural_compressor.experimental.data.datasets.coco_dataset.COCORecordDataset"]], "parsedecodecoco (class in neural_compressor.experimental.data.datasets.coco_dataset)": [[289, "neural_compressor.experimental.data.datasets.coco_dataset.ParseDecodeCoco"]], "neural_compressor.experimental.data.datasets.coco_dataset": [[289, "module-neural_compressor.experimental.data.datasets.coco_dataset"]], "cifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.CIFAR10"]], "cifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.CIFAR100"]], "dataset (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.Dataset"]], "datasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.Datasets"]], "fashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.FashionMNIST"]], "imagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.ImageFolder"]], "iterabledataset (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.IterableDataset"]], "mnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MNIST"]], "mxnetcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR10"]], "mxnetcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetCIFAR100"]], "mxnetdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetDatasets"]], "mxnetfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetFashionMNIST"]], "mxnetimagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetImageFolder"]], "mxnetmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.MXNetMNIST"]], "onnxrtitdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.ONNXRTITDatasets"]], "onnxrtqldatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.ONNXRTQLDatasets"]], "pytorchdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PyTorchDatasets"]], "pytorchcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR10"]], "pytorchcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchCIFAR100"]], "pytorchfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchFashionMNIST"]], "pytorchmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchMNIST"]], "pytorchmxnetwrapdataset (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchMxnetWrapDataset"]], "pytorchmxnetwrapfunction (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.PytorchMxnetWrapFunction"]], "tensorflowcifar10 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR10"]], "tensorflowcifar100 (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowCIFAR100"]], "tensorflowdatasets (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowDatasets"]], "tensorflowfashionmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowFashionMNIST"]], "tensorflowimagefolder (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowImageFolder"]], "tensorflowimagerecord (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowImageRecord"]], "tensorflowmnist (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowMNIST"]], "tensorflowtfrecorddataset (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowTFRecordDataset"]], "tensorflowvocrecord (class in neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.TensorflowVOCRecord"]], "calculate_md5() (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.calculate_md5"]], "check_integrity() (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.check_integrity"]], "dataset_registry() (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.dataset_registry"]], "download_url() (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.download_url"]], "framework_datasets (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.framework_datasets"]], "gen_bar_updater() (in module neural_compressor.experimental.data.datasets.dataset)": [[290, "neural_compressor.experimental.data.datasets.dataset.gen_bar_updater"]], "neural_compressor.experimental.data.datasets.dataset": [[290, "module-neural_compressor.experimental.data.datasets.dataset"]], "dummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset)": [[291, "neural_compressor.experimental.data.datasets.dummy_dataset.DummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset": [[291, "module-neural_compressor.experimental.data.datasets.dummy_dataset"]], "dummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset_v2)": [[292, "neural_compressor.experimental.data.datasets.dummy_dataset_v2.DummyDataset"]], "sparsedummydataset (class in neural_compressor.experimental.data.datasets.dummy_dataset_v2)": [[292, "neural_compressor.experimental.data.datasets.dummy_dataset_v2.SparseDummyDataset"]], "neural_compressor.experimental.data.datasets.dummy_dataset_v2": [[292, "module-neural_compressor.experimental.data.datasets.dummy_dataset_v2"]], "imagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.ImagenetRaw"]], "mxnetimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.MXNetImagenetRaw"]], "onnxrtimagenetdataset (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.ONNXRTImagenetDataset"]], "pytorchimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.PytorchImagenetRaw"]], "tensorflowimagenetdataset (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.TensorflowImagenetDataset"]], "tensorflowimagenetraw (class in neural_compressor.experimental.data.datasets.imagenet_dataset)": [[293, "neural_compressor.experimental.data.datasets.imagenet_dataset.TensorflowImagenetRaw"]], "neural_compressor.experimental.data.datasets.imagenet_dataset": [[293, "module-neural_compressor.experimental.data.datasets.imagenet_dataset"]], "neural_compressor.experimental.data.datasets": [[294, "module-neural_compressor.experimental.data.datasets"]], "styletransferdataset (class in neural_compressor.experimental.data.datasets.style_transfer_dataset)": [[295, "neural_compressor.experimental.data.datasets.style_transfer_dataset.StyleTransferDataset"]], "neural_compressor.experimental.data.datasets.style_transfer_dataset": [[295, "module-neural_compressor.experimental.data.datasets.style_transfer_dataset"]], "labelbalancecocorawfilter (class in neural_compressor.experimental.data.filters.coco_filter)": [[296, "neural_compressor.experimental.data.filters.coco_filter.LabelBalanceCOCORawFilter"]], "labelbalancecocorecordfilter (class in neural_compressor.experimental.data.filters.coco_filter)": [[296, "neural_compressor.experimental.data.filters.coco_filter.LabelBalanceCOCORecordFilter"]], "neural_compressor.experimental.data.filters.coco_filter": [[296, "module-neural_compressor.experimental.data.filters.coco_filter"]], "filters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.FILTERS"]], "filter (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.Filter"]], "mxnetfilters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.MXNetFilters"]], "onnxrtitfilters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.ONNXRTITFilters"]], "onnxrtqlfilters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.ONNXRTQLFilters"]], "pytorchfilters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.PyTorchFilters"]], "tensorflowfilters (class in neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.TensorflowFilters"]], "filter_registry() (in module neural_compressor.experimental.data.filters.filter)": [[297, "neural_compressor.experimental.data.filters.filter.filter_registry"]], "neural_compressor.experimental.data.filters.filter": [[297, "module-neural_compressor.experimental.data.filters.filter"]], "neural_compressor.experimental.data.filters": [[298, "module-neural_compressor.experimental.data.filters"]], "neural_compressor.experimental.data": [[299, "module-neural_compressor.experimental.data"]], "bilinearimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.BilinearImagenetTransform"]], "labelshift (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.LabelShift"]], "onnxresizecropimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.ONNXResizeCropImagenetTransform"]], "onnxbilinearimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.OnnxBilinearImagenetTransform"]], "parsedecodeimagenet (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.ParseDecodeImagenet"]], "parsedecodeimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.ParseDecodeImagenetTransform"]], "quantizedinput (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.QuantizedInput"]], "resizewithaspectratio (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.ResizeWithAspectRatio"]], "tensorflowresizecropimagenettransform (class in neural_compressor.experimental.data.transforms.imagenet_transform)": [[300, "neural_compressor.experimental.data.transforms.imagenet_transform.TensorflowResizeCropImagenetTransform"]], "neural_compressor.experimental.data.transforms.imagenet_transform": [[300, "module-neural_compressor.experimental.data.transforms.imagenet_transform"]], "neural_compressor.experimental.data.transforms": [[301, "module-neural_compressor.experimental.data.transforms"]], "basictokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.BasicTokenizer"]], "fulltokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.FullTokenizer"]], "wordpiecetokenizer (class in neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.WordpieceTokenizer"]], "convert_by_vocab() (in module neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.convert_by_vocab"]], "convert_to_unicode() (in module neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.convert_to_unicode"]], "load_vocab() (in module neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.load_vocab"]], "neural_compressor.experimental.data.transforms.tokenization": [[302, "module-neural_compressor.experimental.data.transforms.tokenization"]], "whitespace_tokenize() (in module neural_compressor.experimental.data.transforms.tokenization)": [[302, "neural_compressor.experimental.data.transforms.tokenization.whitespace_tokenize"]], "alignimagechanneltransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.AlignImageChannelTransform"]], "basetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.BaseTransform"]], "castonnxtransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CastONNXTransform"]], "castpytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CastPyTorchTransform"]], "casttftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CastTFTransform"]], "centercroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CenterCropTFTransform"]], "centercroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CenterCropTransform"]], "collecttransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CollectTransform"]], "composetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ComposeTransform"]], "cropresizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CropResizeTFTransform"]], "cropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CropResizeTransform"]], "croptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.CropToBoundingBox"]], "inputfeatures (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.InputFeatures"]], "mxnetcropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.MXNetCropResizeTransform"]], "mxnetcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.MXNetCropToBoundingBox"]], "mxnetnormalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.MXNetNormalizeTransform"]], "mxnettransforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.MXNetTransforms"]], "mxnettranspose (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.MXNetTranspose"]], "normalizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.NormalizeTFTransform"]], "normalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.NormalizeTransform"]], "onnxrtcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ONNXRTCropToBoundingBox"]], "onnxrtittransforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ONNXRTITTransforms"]], "onnxrtqltransforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ONNXRTQLTransforms"]], "paddedcentercroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PaddedCenterCropTransform"]], "parsedecodevoctransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ParseDecodeVocTransform"]], "pytorchalignimagechannel (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PyTorchAlignImageChannel"]], "pytorchcropresizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PyTorchCropResizeTransform"]], "pytorchnormalizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PyTorchNormalizeTransform"]], "pytorchtransforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PyTorchTransforms"]], "pytorchtranspose (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PyTorchTranspose"]], "pytorchmxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PytorchMxnetTransform"]], "pytorchmxnetwrapfunction (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.PytorchMxnetWrapFunction"]], "randomcroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomCropTFTransform"]], "randomcroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomCropTransform"]], "randomhorizontalflip (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomHorizontalFlip"]], "randomresizedcropmxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropMXNetTransform"]], "randomresizedcroppytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropPytorchTransform"]], "randomresizedcroptftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropTFTransform"]], "randomresizedcroptransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomResizedCropTransform"]], "randomverticalflip (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RandomVerticalFlip"]], "rescalekeraspretraintransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RescaleKerasPretrainTransform"]], "rescaletftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RescaleTFTransform"]], "rescaletransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.RescaleTransform"]], "resizemxnettransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ResizeMXNetTransform"]], "resizepytorchtransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ResizePytorchTransform"]], "resizetftransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ResizeTFTransform"]], "resizetransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ResizeTransform"]], "resizewithratio (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ResizeWithRatio"]], "squadexample (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.SquadExample"]], "tfmodelzoocollecttransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TFModelZooCollectTransform"]], "tfsquadv1modelzooposttransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TFSquadV1ModelZooPostTransform"]], "tfsquadv1posttransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TFSquadV1PostTransform"]], "transforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TRANSFORMS"], [303, "neural_compressor.experimental.data.transforms.transform.Transforms"]], "tensorflowcroptoboundingbox (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowCropToBoundingBox"]], "tensorflowrandomhorizontalflip (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowRandomHorizontalFlip"]], "tensorflowrandomverticalflip (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowRandomVerticalFlip"]], "tensorflowresizewithratio (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowResizeWithRatio"]], "tensorflowtransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowTransform"]], "tensorflowtransforms (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowTransforms"]], "tensorflowtranspose (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowTranspose"]], "tensorflowwrapfunction (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.TensorflowWrapFunction"]], "toarray (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ToArray"]], "tondarraytransform (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.ToNDArrayTransform"]], "transpose (class in neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.Transpose"]], "convert_examples_to_features() (in module neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.convert_examples_to_features"]], "get_final_text() (in module neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.get_final_text"]], "get_torchvision_map() (in module neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.get_torchvision_map"]], "neural_compressor.experimental.data.transforms.transform": [[303, "module-neural_compressor.experimental.data.transforms.transform"]], "read_squad_examples() (in module neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.read_squad_examples"]], "transform_registry() (in module neural_compressor.experimental.data.transforms.transform)": [[303, "neural_compressor.experimental.data.transforms.transform.transform_registry"]], "distillation (class in neural_compressor.experimental.distillation)": [[304, "neural_compressor.experimental.distillation.Distillation"]], "_epoch_ran (neural_compressor.experimental.distillation.distillation attribute)": [[304, "neural_compressor.experimental.distillation.Distillation._epoch_ran"]], "best_model (neural_compressor.experimental.distillation.distillation attribute)": [[304, "neural_compressor.experimental.distillation.Distillation.best_model"]], "best_score (neural_compressor.experimental.distillation.distillation attribute)": [[304, "neural_compressor.experimental.distillation.Distillation.best_score"]], "eval_frequency (neural_compressor.experimental.distillation.distillation attribute)": [[304, "neural_compressor.experimental.distillation.Distillation.eval_frequency"]], "neural_compressor.experimental.distillation": [[304, "module-neural_compressor.experimental.distillation"]], "neural_compressor.experimental.export": [[305, "module-neural_compressor.experimental.export"]], "check_model() (in module neural_compressor.experimental.export.qlinear2qdq)": [[306, "neural_compressor.experimental.export.qlinear2qdq.check_model"]], "neural_compressor.experimental.export.qlinear2qdq": [[306, "module-neural_compressor.experimental.export.qlinear2qdq"]], "onnx_qlinear_to_qdq() (in module neural_compressor.experimental.export.qlinear2qdq)": [[306, "neural_compressor.experimental.export.qlinear2qdq.onnx_qlinear_to_qdq"]], "neural_compressor.experimental.export.tf2onnx": [[307, "module-neural_compressor.experimental.export.tf2onnx"]], "tf_to_fp32_onnx() (in module neural_compressor.experimental.export.tf2onnx)": [[307, "neural_compressor.experimental.export.tf2onnx.tf_to_fp32_onnx"]], "tf_to_int8_onnx() (in module neural_compressor.experimental.export.tf2onnx)": [[307, "neural_compressor.experimental.export.tf2onnx.tf_to_int8_onnx"]], "dynamic_quant_export() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.dynamic_quant_export"]], "get_node_mapping() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.get_node_mapping"]], "get_quantizable_onnx_ops() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.get_quantizable_onnx_ops"]], "neural_compressor.experimental.export.torch2onnx": [[308, "module-neural_compressor.experimental.export.torch2onnx"]], "static_quant_export() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.static_quant_export"]], "torch_to_fp32_onnx() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.torch_to_fp32_onnx"]], "torch_to_int8_onnx() (in module neural_compressor.experimental.export.torch2onnx)": [[308, "neural_compressor.experimental.export.torch2onnx.torch_to_int8_onnx"]], "graph_optimization (class in neural_compressor.experimental.graph_optimization)": [[309, "neural_compressor.experimental.graph_optimization.Graph_Optimization"]], "neural_compressor.experimental.graph_optimization": [[309, "module-neural_compressor.experimental.graph_optimization"]], "neural_compressor.experimental": [[310, "module-neural_compressor.experimental"]], "bleu (class in neural_compressor.experimental.metric.bleu)": [[311, "neural_compressor.experimental.metric.bleu.BLEU"]], "unicoderegex (class in neural_compressor.experimental.metric.bleu)": [[311, "neural_compressor.experimental.metric.bleu.UnicodeRegex"]], "bleu_tokenize() (in module neural_compressor.experimental.metric.bleu)": [[311, "neural_compressor.experimental.metric.bleu.bleu_tokenize"]], "labels (neural_compressor.experimental.metric.bleu.bleu attribute)": [[311, "neural_compressor.experimental.metric.bleu.BLEU.labels"]], "neural_compressor.experimental.metric.bleu": [[311, "module-neural_compressor.experimental.metric.bleu"]], "nondigit_punct_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[311, "neural_compressor.experimental.metric.bleu.UnicodeRegex.nondigit_punct_re"]], "predictions (neural_compressor.experimental.metric.bleu.bleu attribute)": [[311, "neural_compressor.experimental.metric.bleu.BLEU.predictions"]], "punct_nondigit_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[311, "neural_compressor.experimental.metric.bleu.UnicodeRegex.punct_nondigit_re"]], "symbol_re (neural_compressor.experimental.metric.bleu.unicoderegex attribute)": [[311, "neural_compressor.experimental.metric.bleu.UnicodeRegex.symbol_re"]], "compute_bleu() (in module neural_compressor.experimental.metric.bleu_util)": [[312, "neural_compressor.experimental.metric.bleu_util.compute_bleu"]], "neural_compressor.experimental.metric.bleu_util": [[312, "module-neural_compressor.experimental.metric.bleu_util"]], "neural_compressor.experimental.metric.coco_label_map": [[313, "module-neural_compressor.experimental.metric.coco_label_map"]], "cocoevalwrapper (class in neural_compressor.experimental.metric.coco_tools)": [[314, "neural_compressor.experimental.metric.coco_tools.COCOEvalWrapper"]], "cocowrapper (class in neural_compressor.experimental.metric.coco_tools)": [[314, "neural_compressor.experimental.metric.coco_tools.COCOWrapper"]], "exportsingleimagedetectionboxestococo() (in module neural_compressor.experimental.metric.coco_tools)": [[314, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageDetectionBoxesToCoco"]], "exportsingleimagedetectionmaskstococo() (in module neural_compressor.experimental.metric.coco_tools)": [[314, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageDetectionMasksToCoco"]], "exportsingleimagegroundtruthtococo() (in module neural_compressor.experimental.metric.coco_tools)": [[314, "neural_compressor.experimental.metric.coco_tools.ExportSingleImageGroundtruthToCoco"]], "dataset (neural_compressor.experimental.metric.coco_tools.cocowrapper attribute)": [[314, "neural_compressor.experimental.metric.coco_tools.COCOWrapper.dataset"]], "detection_type (neural_compressor.experimental.metric.coco_tools.cocowrapper attribute)": [[314, "neural_compressor.experimental.metric.coco_tools.COCOWrapper.detection_type"]], "neural_compressor.experimental.metric.coco_tools": [[314, "module-neural_compressor.experimental.metric.coco_tools"]], "evaluate() (in module neural_compressor.experimental.metric.evaluate_squad)": [[315, "neural_compressor.experimental.metric.evaluate_squad.evaluate"]], "exact_match_score() (in module neural_compressor.experimental.metric.evaluate_squad)": [[315, "neural_compressor.experimental.metric.evaluate_squad.exact_match_score"]], "f1_score() (in module neural_compressor.experimental.metric.evaluate_squad)": [[315, "neural_compressor.experimental.metric.evaluate_squad.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.experimental.metric.evaluate_squad)": [[315, "neural_compressor.experimental.metric.evaluate_squad.metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.evaluate_squad": [[315, "module-neural_compressor.experimental.metric.evaluate_squad"]], "evaluate() (in module neural_compressor.experimental.metric.f1)": [[316, "neural_compressor.experimental.metric.f1.evaluate"]], "f1_score() (in module neural_compressor.experimental.metric.f1)": [[316, "neural_compressor.experimental.metric.f1.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.experimental.metric.f1)": [[316, "neural_compressor.experimental.metric.f1.metric_max_over_ground_truths"]], "neural_compressor.experimental.metric.f1": [[316, "module-neural_compressor.experimental.metric.f1"]], "normalize_answer() (in module neural_compressor.experimental.metric.f1)": [[316, "neural_compressor.experimental.metric.f1.normalize_answer"]], "neural_compressor.experimental.metric": [[317, "module-neural_compressor.experimental.metric"]], "accuracy (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.Accuracy"]], "basemetric (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.BaseMetric"]], "cocomapv2 (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.COCOmAPv2"]], "f1 (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.F1"]], "generaltopk (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.GeneralTopK"]], "loss (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.Loss"]], "mae (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.MAE"]], "metrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.METRICS"]], "mse (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.MSE"]], "mxnetmetrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.MXNetMetrics"]], "onnxrtglue (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.ONNXRTGLUE"]], "onnxrtitmetrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.ONNXRTITMetrics"]], "onnxrtqlmetrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics"]], "pytorchloss (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.PyTorchLoss"]], "pytorchmetrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.PyTorchMetrics"]], "rmse (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.RMSE"]], "roc (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.ROC"]], "squadf1 (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.SquadF1"]], "tensorflowcocomap (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.TensorflowCOCOMAP"]], "tensorflowmap (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.TensorflowMAP"]], "tensorflowmetrics (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.TensorflowMetrics"]], "tensorflowtopk (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.TensorflowTopK"]], "tensorflowvocmap (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.TensorflowVOCMAP"]], "wrapmxnetmetric (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.WrapMXNetMetric"]], "wraponnxrtmetric (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.WrapONNXRTMetric"]], "wrappytorchmetric (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.WrapPyTorchMetric"]], "compare_label (neural_compressor.experimental.metric.metric.mae attribute)": [[318, "neural_compressor.experimental.metric.metric.MAE.compare_label"]], "compare_label (neural_compressor.experimental.metric.metric.mse attribute)": [[318, "neural_compressor.experimental.metric.metric.MSE.compare_label"]], "k (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[318, "neural_compressor.experimental.metric.metric.GeneralTopK.k"]], "k (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[318, "neural_compressor.experimental.metric.metric.TensorflowTopK.k"]], "label_list (neural_compressor.experimental.metric.metric.accuracy attribute)": [[318, "neural_compressor.experimental.metric.metric.Accuracy.label_list"]], "label_list (neural_compressor.experimental.metric.metric.mae attribute)": [[318, "neural_compressor.experimental.metric.metric.MAE.label_list"]], "label_list (neural_compressor.experimental.metric.metric.mse attribute)": [[318, "neural_compressor.experimental.metric.metric.MSE.label_list"]], "miou (class in neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.mIOU"]], "metric_registry() (in module neural_compressor.experimental.metric.metric)": [[318, "neural_compressor.experimental.metric.metric.metric_registry"]], "metrics (neural_compressor.experimental.metric.metric.metrics attribute)": [[318, "neural_compressor.experimental.metric.metric.METRICS.metrics"]], "metrics (neural_compressor.experimental.metric.metric.mxnetmetrics attribute)": [[318, "neural_compressor.experimental.metric.metric.MXNetMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.onnxrtitmetrics attribute)": [[318, "neural_compressor.experimental.metric.metric.ONNXRTITMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.onnxrtqlmetrics attribute)": [[318, "neural_compressor.experimental.metric.metric.ONNXRTQLMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.pytorchmetrics attribute)": [[318, "neural_compressor.experimental.metric.metric.PyTorchMetrics.metrics"]], "metrics (neural_compressor.experimental.metric.metric.tensorflowmetrics attribute)": [[318, "neural_compressor.experimental.metric.metric.TensorflowMetrics.metrics"]], "mse (neural_compressor.experimental.metric.metric.rmse attribute)": [[318, "neural_compressor.experimental.metric.metric.RMSE.mse"]], "neural_compressor.experimental.metric.metric": [[318, "module-neural_compressor.experimental.metric.metric"]], "num_correct (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[318, "neural_compressor.experimental.metric.metric.GeneralTopK.num_correct"]], "num_correct (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[318, "neural_compressor.experimental.metric.metric.TensorflowTopK.num_correct"]], "num_sample (neural_compressor.experimental.metric.metric.generaltopk attribute)": [[318, "neural_compressor.experimental.metric.metric.GeneralTopK.num_sample"]], "num_sample (neural_compressor.experimental.metric.metric.tensorflowtopk attribute)": [[318, "neural_compressor.experimental.metric.metric.TensorflowTopK.num_sample"]], "pred_list (neural_compressor.experimental.metric.metric.accuracy attribute)": [[318, "neural_compressor.experimental.metric.metric.Accuracy.pred_list"]], "pred_list (neural_compressor.experimental.metric.metric.mae attribute)": [[318, "neural_compressor.experimental.metric.metric.MAE.pred_list"]], "pred_list (neural_compressor.experimental.metric.metric.mse attribute)": [[318, "neural_compressor.experimental.metric.metric.MSE.pred_list"]], "sample (neural_compressor.experimental.metric.metric.accuracy attribute)": [[318, "neural_compressor.experimental.metric.metric.Accuracy.sample"]], "sample (neural_compressor.experimental.metric.metric.loss attribute)": [[318, "neural_compressor.experimental.metric.metric.Loss.sample"]], "sum (neural_compressor.experimental.metric.metric.loss attribute)": [[318, "neural_compressor.experimental.metric.metric.Loss.sum"]], "mixedprecision (class in neural_compressor.experimental.mixed_precision)": [[319, "neural_compressor.experimental.mixed_precision.MixedPrecision"]], "neural_compressor.experimental.mixed_precision": [[319, "module-neural_compressor.experimental.mixed_precision"]], "modelconversion (class in neural_compressor.experimental.model_conversion)": [[320, "neural_compressor.experimental.model_conversion.ModelConversion"]], "neural_compressor.experimental.model_conversion": [[320, "module-neural_compressor.experimental.model_conversion"]], "basicnas (class in neural_compressor.experimental.nas.basic_nas)": [[321, "neural_compressor.experimental.nas.basic_nas.BasicNAS"]], "neural_compressor.experimental.nas.basic_nas": [[321, "module-neural_compressor.experimental.nas.basic_nas"]], "dynas (class in neural_compressor.experimental.nas.dynas)": [[322, "neural_compressor.experimental.nas.dynas.DyNAS"]], "neural_compressor.experimental.nas.dynas": [[322, "module-neural_compressor.experimental.nas.dynas"]], "neural_compressor.experimental.nas": [[323, "module-neural_compressor.experimental.nas"]], "nas (class in neural_compressor.experimental.nas.nas)": [[324, "neural_compressor.experimental.nas.nas.NAS"]], "nasbase (class in neural_compressor.experimental.nas.nas)": [[324, "neural_compressor.experimental.nas.nas.NASBase"]], "neural_compressor.experimental.nas.nas": [[324, "module-neural_compressor.experimental.nas.nas"]], "create_search_space_pool() (in module neural_compressor.experimental.nas.nas_utils)": [[325, "neural_compressor.experimental.nas.nas_utils.create_search_space_pool"]], "find_pareto_front() (in module neural_compressor.experimental.nas.nas_utils)": [[325, "neural_compressor.experimental.nas.nas_utils.find_pareto_front"]], "nas_registry() (in module neural_compressor.experimental.nas.nas_utils)": [[325, "neural_compressor.experimental.nas.nas_utils.nas_registry"]], "neural_compressor.experimental.nas.nas_utils": [[325, "module-neural_compressor.experimental.nas.nas_utils"]], "bayesianoptimizationsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[326, "neural_compressor.experimental.nas.search_algorithms.BayesianOptimizationSearcher"]], "gridsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[326, "neural_compressor.experimental.nas.search_algorithms.GridSearcher"]], "randomsearcher (class in neural_compressor.experimental.nas.search_algorithms)": [[326, "neural_compressor.experimental.nas.search_algorithms.RandomSearcher"]], "searcher (class in neural_compressor.experimental.nas.search_algorithms)": [[326, "neural_compressor.experimental.nas.search_algorithms.Searcher"]], "neural_compressor.experimental.nas.search_algorithms": [[326, "module-neural_compressor.experimental.nas.search_algorithms"]], "gradientsensitivitypruner (class in neural_compressor.experimental.pruner_legacy.gradient_sensitivity)": [[327, "neural_compressor.experimental.pruner_legacy.gradient_sensitivity.GradientSensitivityPruner"]], "neural_compressor.experimental.pruner_legacy.gradient_sensitivity": [[327, "module-neural_compressor.experimental.pruner_legacy.gradient_sensitivity"]], "grouplassopruner (class in neural_compressor.experimental.pruner_legacy.group_lasso)": [[328, "neural_compressor.experimental.pruner_legacy.group_lasso.GroupLassoPruner"]], "neural_compressor.experimental.pruner_legacy.group_lasso": [[328, "module-neural_compressor.experimental.pruner_legacy.group_lasso"]], "neural_compressor.experimental.pruner_legacy": [[329, "module-neural_compressor.experimental.pruner_legacy"]], "basicmagnitudepruner (class in neural_compressor.experimental.pruner_legacy.magnitude)": [[330, "neural_compressor.experimental.pruner_legacy.magnitude.BasicMagnitudePruner"]], "neural_compressor.experimental.pruner_legacy.magnitude": [[330, "module-neural_compressor.experimental.pruner_legacy.magnitude"]], "patternlockpruner (class in neural_compressor.experimental.pruner_legacy.pattern_lock)": [[331, "neural_compressor.experimental.pruner_legacy.pattern_lock.PatternLockPruner"]], "neural_compressor.experimental.pruner_legacy.pattern_lock": [[331, "module-neural_compressor.experimental.pruner_legacy.pattern_lock"]], "pruner (class in neural_compressor.experimental.pruner_legacy.pruner)": [[332, "neural_compressor.experimental.pruner_legacy.pruner.Pruner"]], "neural_compressor.experimental.pruner_legacy.pruner": [[332, "module-neural_compressor.experimental.pruner_legacy.pruner"]], "pruner_registry() (in module neural_compressor.experimental.pruner_legacy.pruner)": [[332, "neural_compressor.experimental.pruner_legacy.pruner.pruner_registry"]], "pruning (class in neural_compressor.experimental.pruning)": [[333, "neural_compressor.experimental.pruning.Pruning"]], "tfpruningcallback (class in neural_compressor.experimental.pruning)": [[333, "neural_compressor.experimental.pruning.TfPruningCallback"]], "conf (neural_compressor.experimental.pruning.pruning attribute)": [[333, "neural_compressor.experimental.pruning.Pruning.conf"]], "neural_compressor.experimental.pruning": [[333, "module-neural_compressor.experimental.pruning"]], "pruners (neural_compressor.experimental.pruning.pruning attribute)": [[333, "neural_compressor.experimental.pruning.Pruning.pruners"]], "neural_compressor.experimental.pruning_recipes": [[334, "module-neural_compressor.experimental.pruning_recipes"]], "neural_compressor.experimental.pruning_recipes.patterns": [[335, "module-neural_compressor.experimental.pruning_recipes.patterns"]], "patterns (class in neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[336, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS"]], "patternbase (class in neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[336, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PatternBase"]], "neural_compressor.experimental.pruning_recipes.patterns.pattern": [[336, "module-neural_compressor.experimental.pruning_recipes.patterns.pattern"]], "pattern_registry() (in module neural_compressor.experimental.pruning_recipes.patterns.pattern)": [[336, "neural_compressor.experimental.pruning_recipes.patterns.pattern.pattern_registry"]], "patterns (neural_compressor.experimental.pruning_recipes.patterns.pattern.patterns attribute)": [[336, "neural_compressor.experimental.pruning_recipes.patterns.pattern.PATTERNS.patterns"]], "tilepatternbase (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePatternBase"]], "tilepattern_1x1 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x1"]], "tilepattern_1x16 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x16"]], "tilepattern_1x2 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_1x2"]], "tilepattern_2x2 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_2x2"]], "tilepattern_4x1 (class in neural_compressor.experimental.pruning_recipes.patterns.tile_pattern)": [[337, "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern.TilePattern_4x1"]], "neural_compressor.experimental.pruning_recipes.patterns.tile_pattern": [[337, "module-neural_compressor.experimental.pruning_recipes.patterns.tile_pattern"]], "pruning (class in neural_compressor.experimental.pruning_v2)": [[338, "neural_compressor.experimental.pruning_v2.Pruning"]], "tfpruningcallback (class in neural_compressor.experimental.pruning_v2)": [[338, "neural_compressor.experimental.pruning_v2.TfPruningCallback"]], "conf (neural_compressor.experimental.pruning_v2.pruning attribute)": [[338, "neural_compressor.experimental.pruning_v2.Pruning.conf"]], "neural_compressor.experimental.pruning_v2": [[338, "module-neural_compressor.experimental.pruning_v2"]], "pruners (neural_compressor.experimental.pruning_v2.pruning attribute)": [[338, "neural_compressor.experimental.pruning_v2.Pruning.pruners"]], "neural_compressor.experimental.pytorch_pruner": [[339, "module-neural_compressor.experimental.pytorch_pruner"]], "neural_compressor.experimental.pytorch_pruner.logger": [[340, "module-neural_compressor.experimental.pytorch_pruner.logger"]], "m (neural_compressor.experimental.pytorch_pruner.patterns.patternninm attribute)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM.M"]], "n (neural_compressor.experimental.pytorch_pruner.patterns.patternninm attribute)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM.N"]], "pattern (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern"]], "patternninm (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNInM"]], "patternnxm (class in neural_compressor.experimental.pytorch_pruner.patterns)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM"]], "block_size (neural_compressor.experimental.pytorch_pruner.patterns.patternnxm attribute)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.PatternNxM.block_size"]], "get_pattern() (in module neural_compressor.experimental.pytorch_pruner.patterns)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.get_pattern"]], "is_global (neural_compressor.experimental.pytorch_pruner.patterns.pattern attribute)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern.is_global"]], "neural_compressor.experimental.pytorch_pruner.patterns": [[341, "module-neural_compressor.experimental.pytorch_pruner.patterns"]], "pattern (neural_compressor.experimental.pytorch_pruner.patterns.pattern attribute)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.Pattern.pattern"]], "register_pattern() (in module neural_compressor.experimental.pytorch_pruner.patterns)": [[341, "neural_compressor.experimental.pytorch_pruner.patterns.register_pattern"]], "check_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.check_config"]], "neural_compressor.experimental.pytorch_pruner.prune_utils": [[342, "module-neural_compressor.experimental.pytorch_pruner.prune_utils"]], "parse_not_to_prune() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.parse_not_to_prune"]], "parse_to_prune() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.parse_to_prune"]], "process_and_check_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.process_and_check_config"]], "process_config() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.process_config"]], "reset_non_value_to_default() (in module neural_compressor.experimental.pytorch_pruner.prune_utils)": [[342, "neural_compressor.experimental.pytorch_pruner.prune_utils.reset_non_value_to_default"]], "magnitudepruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.MagnitudePruner"]], "patternlockpruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.PatternLockPruner"]], "pruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner"]], "snipmomentumpruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.SnipMomentumPruner"]], "snippruner (class in neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.SnipPruner"]], "config (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.config"]], "current_sparsity_ratio (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.current_sparsity_ratio"]], "end_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.end_step"]], "get_pruner() (in module neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.get_pruner"]], "global_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.global_step"]], "masks (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.masks"]], "max_sparsity_ratio_per_layer (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.max_sparsity_ratio_per_layer"]], "modules (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.modules"]], "neural_compressor.experimental.pytorch_pruner.pruner": [[343, "module-neural_compressor.experimental.pytorch_pruner.pruner"]], "pattern (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.pattern"]], "register_pruners() (in module neural_compressor.experimental.pytorch_pruner.pruner)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.register_pruners"]], "scheduler (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.scheduler"]], "scores (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.scores"]], "start_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.start_step"]], "target_sparsity_ratio (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.target_sparsity_ratio"]], "update_frequency_on_step (neural_compressor.experimental.pytorch_pruner.pruner.pruner attribute)": [[343, "neural_compressor.experimental.pytorch_pruner.pruner.Pruner.update_frequency_on_step"]], "pruning (class in neural_compressor.experimental.pytorch_pruner.pruning)": [[344, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning"]], "config_file_path (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[344, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.config_file_path"]], "model (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[344, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.model"]], "neural_compressor.experimental.pytorch_pruner.pruning": [[344, "module-neural_compressor.experimental.pytorch_pruner.pruning"]], "pruner_info (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[344, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.pruner_info"]], "pruners (neural_compressor.experimental.pytorch_pruner.pruning.pruning attribute)": [[344, "neural_compressor.experimental.pytorch_pruner.pruning.Pruning.pruners"]], "iterativescheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.IterativeScheduler"]], "oneshotscheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.OneshotScheduler"]], "scheduler (class in neural_compressor.experimental.pytorch_pruner.scheduler)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler"]], "config (neural_compressor.experimental.pytorch_pruner.scheduler.scheduler attribute)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.Scheduler.config"]], "get_scheduler() (in module neural_compressor.experimental.pytorch_pruner.scheduler)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.get_scheduler"]], "neural_compressor.experimental.pytorch_pruner.scheduler": [[345, "module-neural_compressor.experimental.pytorch_pruner.scheduler"]], "register_scheduler() (in module neural_compressor.experimental.pytorch_pruner.scheduler)": [[345, "neural_compressor.experimental.pytorch_pruner.scheduler.register_scheduler"]], "quantization (class in neural_compressor.experimental.quantization)": [[346, "neural_compressor.experimental.quantization.Quantization"]], "neural_compressor.experimental.quantization": [[346, "module-neural_compressor.experimental.quantization"]], "scheduler (class in neural_compressor.experimental.scheduler)": [[347, "neural_compressor.experimental.scheduler.Scheduler"]], "neural_compressor.experimental.scheduler": [[347, "module-neural_compressor.experimental.scheduler"]], "automixedprecisiontunestrategy (class in neural_compressor.experimental.strategy.auto_mixed_precision)": [[348, "neural_compressor.experimental.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy"]], "neural_compressor.experimental.strategy.auto_mixed_precision": [[348, "module-neural_compressor.experimental.strategy.auto_mixed_precision"]], "basictunestrategy (class in neural_compressor.experimental.strategy.basic)": [[349, "neural_compressor.experimental.strategy.basic.BasicTuneStrategy"]], "neural_compressor.experimental.strategy.basic": [[349, "module-neural_compressor.experimental.strategy.basic"]], "bayesianoptimization (class in neural_compressor.experimental.strategy.bayesian)": [[350, "neural_compressor.experimental.strategy.bayesian.BayesianOptimization"]], "bayesiantunestrategy (class in neural_compressor.experimental.strategy.bayesian)": [[350, "neural_compressor.experimental.strategy.bayesian.BayesianTuneStrategy"]], "targetspace (class in neural_compressor.experimental.strategy.bayesian)": [[350, "neural_compressor.experimental.strategy.bayesian.TargetSpace"]], "acq_max() (in module neural_compressor.experimental.strategy.bayesian)": [[350, "neural_compressor.experimental.strategy.bayesian.acq_max"]], "neural_compressor.experimental.strategy.bayesian": [[350, "module-neural_compressor.experimental.strategy.bayesian"]], "exhaustivetunestrategy (class in neural_compressor.experimental.strategy.exhaustive)": [[351, "neural_compressor.experimental.strategy.exhaustive.ExhaustiveTuneStrategy"]], "neural_compressor.experimental.strategy.exhaustive": [[351, "module-neural_compressor.experimental.strategy.exhaustive"]], "neural_compressor.experimental.strategy": [[352, "module-neural_compressor.experimental.strategy"]], "msetunestrategy (class in neural_compressor.experimental.strategy.mse)": [[353, "neural_compressor.experimental.strategy.mse.MSETuneStrategy"]], "neural_compressor.experimental.strategy.mse": [[353, "module-neural_compressor.experimental.strategy.mse"]], "mse_v2tunestrategy (class in neural_compressor.experimental.strategy.mse_v2)": [[354, "neural_compressor.experimental.strategy.mse_v2.MSE_V2TuneStrategy"]], "neural_compressor.experimental.strategy.mse_v2": [[354, "module-neural_compressor.experimental.strategy.mse_v2"]], "randomtunestrategy (class in neural_compressor.experimental.strategy.random)": [[355, "neural_compressor.experimental.strategy.random.RandomTuneStrategy"]], "neural_compressor.experimental.strategy.random": [[355, "module-neural_compressor.experimental.strategy.random"]], "tunestrategy (class in neural_compressor.experimental.strategy.strategy)": [[356, "neural_compressor.experimental.strategy.strategy.TuneStrategy"]], "neural_compressor.experimental.strategy.strategy": [[356, "module-neural_compressor.experimental.strategy.strategy"]], "strategy_registry() (in module neural_compressor.experimental.strategy.strategy)": [[356, "neural_compressor.experimental.strategy.strategy.strategy_registry"]], "neural_compressor.experimental.strategy.utils.constant": [[357, "module-neural_compressor.experimental.strategy.utils.constant"]], "neural_compressor.experimental.strategy.utils": [[358, "module-neural_compressor.experimental.strategy.utils"]], "fallbacktuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.FallbackTuningSampler"]], "modelwisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.ModelWiseTuningSampler"]], "optypewisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.OpTypeWiseTuningSampler"]], "opwisetuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.OpWiseTuningSampler"]], "smoothquantsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.SmoothQuantSampler"]], "tuningorder (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningOrder"]], "tuningsampler (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningSampler"]], "tuningsamplerregistry (class in neural_compressor.experimental.strategy.utils.tuning_sampler)": [[359, "neural_compressor.experimental.strategy.utils.tuning_sampler.TuningSamplerRegistry"]], "neural_compressor.experimental.strategy.utils.tuning_sampler": [[359, "module-neural_compressor.experimental.strategy.utils.tuning_sampler"]], "tuningitem (class in neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.TuningItem"]], "tuningspace (class in neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.TuningSpace"]], "initial_tuning_cfg_with_quant_mode() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.initial_tuning_cfg_with_quant_mode"]], "neural_compressor.experimental.strategy.utils.tuning_space": [[360, "module-neural_compressor.experimental.strategy.utils.tuning_space"]], "pattern_to_internal() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.pattern_to_internal"]], "pattern_to_path() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.pattern_to_path"]], "quant_mode_from_pattern() (in module neural_compressor.experimental.strategy.utils.tuning_space)": [[360, "neural_compressor.experimental.strategy.utils.tuning_space.quant_mode_from_pattern"]], "optuningconfig (class in neural_compressor.experimental.strategy.utils.tuning_structs)": [[361, "neural_compressor.experimental.strategy.utils.tuning_structs.OpTuningConfig"]], "neural_compressor.experimental.strategy.utils.tuning_structs": [[361, "module-neural_compressor.experimental.strategy.utils.tuning_structs"]], "ordereddefaultdict (class in neural_compressor.experimental.strategy.utils.utility)": [[362, "neural_compressor.experimental.strategy.utils.utility.OrderedDefaultDict"]], "extract_data_type() (in module neural_compressor.experimental.strategy.utils.utility)": [[362, "neural_compressor.experimental.strategy.utils.utility.extract_data_type"]], "get_adaptor_name() (in module neural_compressor.experimental.strategy.utils.utility)": [[362, "neural_compressor.experimental.strategy.utils.utility.get_adaptor_name"]], "neural_compressor.experimental.strategy.utils.utility": [[362, "module-neural_compressor.experimental.strategy.utils.utility"]], "reverted_data_type() (in module neural_compressor.experimental.strategy.utils.utility)": [[362, "neural_compressor.experimental.strategy.utils.utility.reverted_data_type"]], "neural_compressor": [[363, "module-neural_compressor"]], "bleu (class in neural_compressor.metric.bleu)": [[364, "neural_compressor.metric.bleu.BLEU"]], "unicoderegex (class in neural_compressor.metric.bleu)": [[364, "neural_compressor.metric.bleu.UnicodeRegex"]], "bleu_tokenize() (in module neural_compressor.metric.bleu)": [[364, "neural_compressor.metric.bleu.bleu_tokenize"]], "labels (neural_compressor.metric.bleu.bleu attribute)": [[364, "neural_compressor.metric.bleu.BLEU.labels"]], "neural_compressor.metric.bleu": [[364, "module-neural_compressor.metric.bleu"]], "nondigit_punct_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[364, "neural_compressor.metric.bleu.UnicodeRegex.nondigit_punct_re"]], "predictions (neural_compressor.metric.bleu.bleu attribute)": [[364, "neural_compressor.metric.bleu.BLEU.predictions"]], "punct_nondigit_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[364, "neural_compressor.metric.bleu.UnicodeRegex.punct_nondigit_re"]], "symbol_re (neural_compressor.metric.bleu.unicoderegex attribute)": [[364, "neural_compressor.metric.bleu.UnicodeRegex.symbol_re"]], "compute_bleu() (in module neural_compressor.metric.bleu_util)": [[365, "neural_compressor.metric.bleu_util.compute_bleu"]], "neural_compressor.metric.bleu_util": [[365, "module-neural_compressor.metric.bleu_util"]], "neural_compressor.metric.coco_label_map": [[366, "module-neural_compressor.metric.coco_label_map"]], "cocoevalwrapper (class in neural_compressor.metric.coco_tools)": [[367, "neural_compressor.metric.coco_tools.COCOEvalWrapper"]], "cocowrapper (class in neural_compressor.metric.coco_tools)": [[367, "neural_compressor.metric.coco_tools.COCOWrapper"]], "exportsingleimagedetectionboxestococo() (in module neural_compressor.metric.coco_tools)": [[367, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionBoxesToCoco"]], "exportsingleimagedetectionmaskstococo() (in module neural_compressor.metric.coco_tools)": [[367, "neural_compressor.metric.coco_tools.ExportSingleImageDetectionMasksToCoco"]], "exportsingleimagegroundtruthtococo() (in module neural_compressor.metric.coco_tools)": [[367, "neural_compressor.metric.coco_tools.ExportSingleImageGroundtruthToCoco"]], "dataset (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[367, "neural_compressor.metric.coco_tools.COCOWrapper.dataset"]], "detection_type (neural_compressor.metric.coco_tools.cocowrapper attribute)": [[367, "neural_compressor.metric.coco_tools.COCOWrapper.detection_type"]], "neural_compressor.metric.coco_tools": [[367, "module-neural_compressor.metric.coco_tools"]], "evaluate() (in module neural_compressor.metric.evaluate_squad)": [[368, "neural_compressor.metric.evaluate_squad.evaluate"]], "exact_match_score() (in module neural_compressor.metric.evaluate_squad)": [[368, "neural_compressor.metric.evaluate_squad.exact_match_score"]], "f1_score() (in module neural_compressor.metric.evaluate_squad)": [[368, "neural_compressor.metric.evaluate_squad.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.evaluate_squad)": [[368, "neural_compressor.metric.evaluate_squad.metric_max_over_ground_truths"]], "neural_compressor.metric.evaluate_squad": [[368, "module-neural_compressor.metric.evaluate_squad"]], "evaluate() (in module neural_compressor.metric.f1)": [[369, "neural_compressor.metric.f1.evaluate"]], "f1_score() (in module neural_compressor.metric.f1)": [[369, "neural_compressor.metric.f1.f1_score"]], "metric_max_over_ground_truths() (in module neural_compressor.metric.f1)": [[369, "neural_compressor.metric.f1.metric_max_over_ground_truths"]], "neural_compressor.metric.f1": [[369, "module-neural_compressor.metric.f1"]], "normalize_answer() (in module neural_compressor.metric.f1)": [[369, "neural_compressor.metric.f1.normalize_answer"]], "neural_compressor.metric": [[370, "module-neural_compressor.metric"]], "accuracy (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.Accuracy"]], "basemetric (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.BaseMetric"]], "cocomapv2 (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.COCOmAPv2"]], "f1 (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.F1"]], "generaltopk (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.GeneralTopK"]], "loss (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.Loss"]], "mae (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.MAE"]], "metrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.METRICS"]], "mse (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.MSE"]], "mxnetmetrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.MXNetMetrics"]], "metric (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.Metric"]], "onnxrtglue (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.ONNXRTGLUE"]], "onnxrtitmetrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.ONNXRTITMetrics"]], "onnxrtqlmetrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.ONNXRTQLMetrics"]], "pytorchloss (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.PyTorchLoss"]], "pytorchmetrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.PyTorchMetrics"]], "rmse (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.RMSE"]], "roc (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.ROC"]], "squadf1 (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.SquadF1"]], "tensorflowcocomap (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.TensorflowCOCOMAP"]], "tensorflowmap (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.TensorflowMAP"]], "tensorflowmetrics (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.TensorflowMetrics"]], "tensorflowtopk (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.TensorflowTopK"]], "tensorflowvocmap (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.TensorflowVOCMAP"]], "wrapmxnetmetric (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.WrapMXNetMetric"]], "wraponnxrtmetric (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.WrapONNXRTMetric"]], "wrappytorchmetric (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.WrapPyTorchMetric"]], "compare_label (neural_compressor.metric.metric.mae attribute)": [[371, "neural_compressor.metric.metric.MAE.compare_label"]], "compare_label (neural_compressor.metric.metric.mse attribute)": [[371, "neural_compressor.metric.metric.MSE.compare_label"]], "k (neural_compressor.metric.metric.generaltopk attribute)": [[371, "neural_compressor.metric.metric.GeneralTopK.k"]], "k (neural_compressor.metric.metric.tensorflowtopk attribute)": [[371, "neural_compressor.metric.metric.TensorflowTopK.k"]], "label_list (neural_compressor.metric.metric.accuracy attribute)": [[371, "neural_compressor.metric.metric.Accuracy.label_list"]], "label_list (neural_compressor.metric.metric.mae attribute)": [[371, "neural_compressor.metric.metric.MAE.label_list"]], "label_list (neural_compressor.metric.metric.mse attribute)": [[371, "neural_compressor.metric.metric.MSE.label_list"]], "miou (class in neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.mIOU"]], "metric_registry() (in module neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.metric_registry"]], "metrics (neural_compressor.metric.metric.metrics attribute)": [[371, "neural_compressor.metric.metric.METRICS.metrics"]], "metrics (neural_compressor.metric.metric.mxnetmetrics attribute)": [[371, "neural_compressor.metric.metric.MXNetMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtitmetrics attribute)": [[371, "neural_compressor.metric.metric.ONNXRTITMetrics.metrics"]], "metrics (neural_compressor.metric.metric.onnxrtqlmetrics attribute)": [[371, "neural_compressor.metric.metric.ONNXRTQLMetrics.metrics"]], "metrics (neural_compressor.metric.metric.pytorchmetrics attribute)": [[371, "neural_compressor.metric.metric.PyTorchMetrics.metrics"]], "metrics (neural_compressor.metric.metric.tensorflowmetrics attribute)": [[371, "neural_compressor.metric.metric.TensorflowMetrics.metrics"]], "mse (neural_compressor.metric.metric.rmse attribute)": [[371, "neural_compressor.metric.metric.RMSE.mse"]], "neural_compressor.metric.metric": [[371, "module-neural_compressor.metric.metric"]], "num_correct (neural_compressor.metric.metric.generaltopk attribute)": [[371, "neural_compressor.metric.metric.GeneralTopK.num_correct"]], "num_correct (neural_compressor.metric.metric.tensorflowtopk attribute)": [[371, "neural_compressor.metric.metric.TensorflowTopK.num_correct"]], "num_sample (neural_compressor.metric.metric.generaltopk attribute)": [[371, "neural_compressor.metric.metric.GeneralTopK.num_sample"]], "num_sample (neural_compressor.metric.metric.tensorflowtopk attribute)": [[371, "neural_compressor.metric.metric.TensorflowTopK.num_sample"]], "pred_list (neural_compressor.metric.metric.accuracy attribute)": [[371, "neural_compressor.metric.metric.Accuracy.pred_list"]], "pred_list (neural_compressor.metric.metric.mae attribute)": [[371, "neural_compressor.metric.metric.MAE.pred_list"]], "pred_list (neural_compressor.metric.metric.mse attribute)": [[371, "neural_compressor.metric.metric.MSE.pred_list"]], "register_customer_metric() (in module neural_compressor.metric.metric)": [[371, "neural_compressor.metric.metric.register_customer_metric"]], "sample (neural_compressor.metric.metric.accuracy attribute)": [[371, "neural_compressor.metric.metric.Accuracy.sample"]], "sample (neural_compressor.metric.metric.loss attribute)": [[371, "neural_compressor.metric.metric.Loss.sample"]], "sum (neural_compressor.metric.metric.loss attribute)": [[371, "neural_compressor.metric.metric.Loss.sum"]], "fit() (in module neural_compressor.mix_precision)": [[372, "neural_compressor.mix_precision.fit"]], "neural_compressor.mix_precision": [[372, "module-neural_compressor.mix_precision"]], "basemodel (class in neural_compressor.model.base_model)": [[373, "neural_compressor.model.base_model.BaseModel"]], "neural_compressor.model.base_model": [[373, "module-neural_compressor.model.base_model"]], "neural_compressor.model": [[374, "module-neural_compressor.model"]], "kerasmodel (class in neural_compressor.model.keras_model)": [[375, "neural_compressor.model.keras_model.KerasModel"]], "neural_compressor.model.keras_model": [[375, "module-neural_compressor.model.keras_model"]], "model (class in neural_compressor.model.model)": [[376, "neural_compressor.model.model.Model"]], "get_model_fwk_name() (in module neural_compressor.model.model)": [[376, "neural_compressor.model.model.get_model_fwk_name"]], "neural_compressor.model.model": [[376, "module-neural_compressor.model.model"]], "mxnetmodel (class in neural_compressor.model.mxnet_model)": [[377, "neural_compressor.model.mxnet_model.MXNetModel"]], "neural_compressor.model.mxnet_model": [[377, "module-neural_compressor.model.mxnet_model"]], "tfslimnetsfactory (class in neural_compressor.model.nets_factory)": [[378, "neural_compressor.model.nets_factory.TFSlimNetsFactory"]], "neural_compressor.model.nets_factory": [[378, "module-neural_compressor.model.nets_factory"]], "onnxmodel (class in neural_compressor.model.onnx_model)": [[379, "neural_compressor.model.onnx_model.ONNXModel"]], "neural_compressor.model.onnx_model": [[379, "module-neural_compressor.model.onnx_model"]], "tensorflowbasemodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowModel"]], "tensorflowqatmodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowQATModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.checkpoint_session"]], "estimator_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.estimator_session"]], "frozen_pb_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.frozen_pb_session"]], "get_model_type() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.get_model_type"]], "graph_def_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.graph_def_session"]], "graph_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.graph_session"]], "keras_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.keras_session"]], "load_saved_model() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.load_saved_model"]], "neural_compressor.model.tensorflow_model": [[380, "module-neural_compressor.model.tensorflow_model"]], "saved_model_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.saved_model_session"]], "slim_session() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.slim_session"]], "validate_and_inference_input_output() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.model.tensorflow_model)": [[380, "neural_compressor.model.tensorflow_model.validate_graph_node"]], "ipexmodel (class in neural_compressor.model.torch_model)": [[381, "neural_compressor.model.torch_model.IPEXModel"]], "pytorchbasemodel (class in neural_compressor.model.torch_model)": [[381, "neural_compressor.model.torch_model.PyTorchBaseModel"]], "pytorchfxmodel (class in neural_compressor.model.torch_model)": [[381, "neural_compressor.model.torch_model.PyTorchFXModel"]], "pytorchmodel (class in neural_compressor.model.torch_model)": [[381, "neural_compressor.model.torch_model.PyTorchModel"]], "neural_compressor.model.torch_model": [[381, "module-neural_compressor.model.torch_model"]], "accuracy (class in neural_compressor.objective)": [[382, "neural_compressor.objective.Accuracy"]], "footprint (class in neural_compressor.objective)": [[382, "neural_compressor.objective.Footprint"]], "modelsize (class in neural_compressor.objective)": [[382, "neural_compressor.objective.ModelSize"]], "multiobjective (class in neural_compressor.objective)": [[382, "neural_compressor.objective.MultiObjective"]], "objective (class in neural_compressor.objective)": [[382, "neural_compressor.objective.Objective"]], "performance (class in neural_compressor.objective)": [[382, "neural_compressor.objective.Performance"]], "neural_compressor.objective": [[382, "module-neural_compressor.objective"]], "objective_custom_registry() (in module neural_compressor.objective)": [[382, "neural_compressor.objective.objective_custom_registry"]], "objective_registry() (in module neural_compressor.objective)": [[382, "neural_compressor.objective.objective_registry"]], "neural_compressor.onnxrt.algorithms": [[383, "module-neural_compressor.onnxrt.algorithms"]], "calibrator (class in neural_compressor.onnxrt.algorithms.smoother.calibrator)": [[384, "neural_compressor.onnxrt.algorithms.smoother.calibrator.Calibrator"]], "neural_compressor.onnxrt.algorithms.smoother.calibrator": [[384, "module-neural_compressor.onnxrt.algorithms.smoother.calibrator"]], "smoother (class in neural_compressor.onnxrt.algorithms.smoother.core)": [[385, "neural_compressor.onnxrt.algorithms.smoother.core.Smoother"]], "neural_compressor.onnxrt.algorithms.smoother.core": [[385, "module-neural_compressor.onnxrt.algorithms.smoother.core"]], "neural_compressor.onnxrt.algorithms.smoother": [[386, "module-neural_compressor.onnxrt.algorithms.smoother"]], "apply_awq_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.awq)": [[387, "neural_compressor.onnxrt.algorithms.weight_only.awq.apply_awq_on_model"]], "awq_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.awq)": [[387, "neural_compressor.onnxrt.algorithms.weight_only.awq.awq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.awq": [[387, "module-neural_compressor.onnxrt.algorithms.weight_only.awq"]], "apply_gptq_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.gptq)": [[388, "neural_compressor.onnxrt.algorithms.weight_only.gptq.apply_gptq_on_model"]], "gptq_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.gptq)": [[388, "neural_compressor.onnxrt.algorithms.weight_only.gptq.gptq_quantize"]], "neural_compressor.onnxrt.algorithms.weight_only.gptq": [[388, "module-neural_compressor.onnxrt.algorithms.weight_only.gptq"]], "neural_compressor.onnxrt.algorithms.weight_only": [[389, "module-neural_compressor.onnxrt.algorithms.weight_only"]], "apply_rtn_on_model() (in module neural_compressor.onnxrt.algorithms.weight_only.rtn)": [[390, "neural_compressor.onnxrt.algorithms.weight_only.rtn.apply_rtn_on_model"]], "neural_compressor.onnxrt.algorithms.weight_only.rtn": [[390, "module-neural_compressor.onnxrt.algorithms.weight_only.rtn"]], "rtn_quantize() (in module neural_compressor.onnxrt.algorithms.weight_only.rtn)": [[390, "neural_compressor.onnxrt.algorithms.weight_only.rtn.rtn_quantize"]], "make_matmul_weight_only_node() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.utility.make_matmul_weight_only_node"]], "neural_compressor.onnxrt.algorithms.weight_only.utility": [[391, "module-neural_compressor.onnxrt.algorithms.weight_only.utility"]], "pad_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.utility.pad_tensor"]], "prepare_inputs() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.utility.prepare_inputs"]], "qdq_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.utility.qdq_tensor"]], "quant_tensor() (in module neural_compressor.onnxrt.algorithms.weight_only.utility)": [[391, "neural_compressor.onnxrt.algorithms.weight_only.utility.quant_tensor"]], "neural_compressor.onnxrt": [[392, "module-neural_compressor.onnxrt"]], "awq_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[393, "neural_compressor.onnxrt.quantization.algorithm_entry.awq_quantize_entry"]], "gptq_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[393, "neural_compressor.onnxrt.quantization.algorithm_entry.gptq_quantize_entry"]], "neural_compressor.onnxrt.quantization.algorithm_entry": [[393, "module-neural_compressor.onnxrt.quantization.algorithm_entry"]], "rtn_quantize_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[393, "neural_compressor.onnxrt.quantization.algorithm_entry.rtn_quantize_entry"]], "smooth_quant_entry() (in module neural_compressor.onnxrt.quantization.algorithm_entry)": [[393, "neural_compressor.onnxrt.quantization.algorithm_entry.smooth_quant_entry"]], "autotune() (in module neural_compressor.onnxrt.quantization.autotune)": [[394, "neural_compressor.onnxrt.quantization.autotune.autotune"]], "neural_compressor.onnxrt.quantization.autotune": [[394, "module-neural_compressor.onnxrt.quantization.autotune"]], "calibrationdatareader (class in neural_compressor.onnxrt.quantization.calibrate)": [[395, "neural_compressor.onnxrt.quantization.calibrate.CalibrationDataReader"]], "neural_compressor.onnxrt.quantization.calibrate": [[395, "module-neural_compressor.onnxrt.quantization.calibrate"]], "awqconfig (class in neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.AWQConfig"]], "gptqconfig (class in neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.GPTQConfig"]], "rtnconfig (class in neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.RTNConfig"]], "smoohquantconfig (class in neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.SmoohQuantConfig"]], "get_default_awq_config() (in module neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.get_default_awq_config"]], "get_default_gptq_config() (in module neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.get_default_gptq_config"]], "get_default_rtn_config() (in module neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.get_default_rtn_config"]], "get_default_sq_config() (in module neural_compressor.onnxrt.quantization.config)": [[396, "neural_compressor.onnxrt.quantization.config.get_default_sq_config"]], "neural_compressor.onnxrt.quantization.config": [[396, "module-neural_compressor.onnxrt.quantization.config"]], "neural_compressor.onnxrt.quantization": [[397, "module-neural_compressor.onnxrt.quantization"]], "neural_compressor.onnxrt.quantization.quantize": [[398, "module-neural_compressor.onnxrt.quantization.quantize"]], "neural_compressor.onnxrt.utils": [[399, "module-neural_compressor.onnxrt.utils"]], "onnxmodel (class in neural_compressor.onnxrt.utils.onnx_model)": [[400, "neural_compressor.onnxrt.utils.onnx_model.ONNXModel"]], "neural_compressor.onnxrt.utils.onnx_model": [[400, "module-neural_compressor.onnxrt.utils.onnx_model"]], "find_by_name() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.find_by_name"]], "get_qrange_for_qtype() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.get_qrange_for_qType"]], "is_b_transposed() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.is_B_transposed"]], "neural_compressor.onnxrt.utils.utility": [[401, "module-neural_compressor.onnxrt.utils.utility"]], "quantize_data() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.quantize_data"]], "register_algo() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.register_algo"]], "simple_progress_bar() (in module neural_compressor.onnxrt.utils.utility)": [[401, "neural_compressor.onnxrt.utils.utility.simple_progress_bar"]], "neural_compressor.profiling": [[402, "module-neural_compressor.profiling"]], "parserfactory (class in neural_compressor.profiling.parser.factory)": [[403, "neural_compressor.profiling.parser.factory.ParserFactory"]], "neural_compressor.profiling.parser.factory": [[403, "module-neural_compressor.profiling.parser.factory"]], "neural_compressor.profiling.parser": [[404, "module-neural_compressor.profiling.parser"]], "onnxrtparserfactory (class in neural_compressor.profiling.parser.onnx_parser.factory)": [[405, "neural_compressor.profiling.parser.onnx_parser.factory.OnnxrtParserFactory"]], "neural_compressor.profiling.parser.onnx_parser.factory": [[405, "module-neural_compressor.profiling.parser.onnx_parser.factory"]], "neural_compressor.profiling.parser.onnx_parser": [[406, "module-neural_compressor.profiling.parser.onnx_parser"]], "onnxprofilingparser (class in neural_compressor.profiling.parser.onnx_parser.parser)": [[407, "neural_compressor.profiling.parser.onnx_parser.parser.OnnxProfilingParser"]], "neural_compressor.profiling.parser.onnx_parser.parser": [[407, "module-neural_compressor.profiling.parser.onnx_parser.parser"]], "profilingparser (class in neural_compressor.profiling.parser.parser)": [[408, "neural_compressor.profiling.parser.parser.ProfilingParser"]], "neural_compressor.profiling.parser.parser": [[408, "module-neural_compressor.profiling.parser.parser"]], "profilingresult (class in neural_compressor.profiling.parser.result)": [[409, "neural_compressor.profiling.parser.result.ProfilingResult"]], "neural_compressor.profiling.parser.result": [[409, "module-neural_compressor.profiling.parser.result"]], "tensorflowparserfactory (class in neural_compressor.profiling.parser.tensorflow_parser.factory)": [[410, "neural_compressor.profiling.parser.tensorflow_parser.factory.TensorFlowParserFactory"]], "neural_compressor.profiling.parser.tensorflow_parser.factory": [[410, "module-neural_compressor.profiling.parser.tensorflow_parser.factory"]], "neural_compressor.profiling.parser.tensorflow_parser": [[411, "module-neural_compressor.profiling.parser.tensorflow_parser"]], "tensorflowprofilingparser (class in neural_compressor.profiling.parser.tensorflow_parser.parser)": [[412, "neural_compressor.profiling.parser.tensorflow_parser.parser.TensorFlowProfilingParser"]], "neural_compressor.profiling.parser.tensorflow_parser.parser": [[412, "module-neural_compressor.profiling.parser.tensorflow_parser.parser"]], "profilerfactory (class in neural_compressor.profiling.profiler.factory)": [[413, "neural_compressor.profiling.profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.factory": [[413, "module-neural_compressor.profiling.profiler.factory"]], "neural_compressor.profiling.profiler": [[414, "module-neural_compressor.profiling.profiler"]], "profilerfactory (class in neural_compressor.profiling.profiler.onnxrt_profiler.factory)": [[415, "neural_compressor.profiling.profiler.onnxrt_profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.onnxrt_profiler.factory": [[415, "module-neural_compressor.profiling.profiler.onnxrt_profiler.factory"]], "neural_compressor.profiling.profiler.onnxrt_profiler": [[416, "module-neural_compressor.profiling.profiler.onnxrt_profiler"]], "profiler (class in neural_compressor.profiling.profiler.onnxrt_profiler.profiler)": [[417, "neural_compressor.profiling.profiler.onnxrt_profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.onnxrt_profiler.profiler": [[417, "module-neural_compressor.profiling.profiler.onnxrt_profiler.profiler"]], "create_onnx_config() (in module neural_compressor.profiling.profiler.onnxrt_profiler.utils)": [[418, "neural_compressor.profiling.profiler.onnxrt_profiler.utils.create_onnx_config"]], "neural_compressor.profiling.profiler.onnxrt_profiler.utils": [[418, "module-neural_compressor.profiling.profiler.onnxrt_profiler.utils"]], "profiler (class in neural_compressor.profiling.profiler.profiler)": [[419, "neural_compressor.profiling.profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.profiler": [[419, "module-neural_compressor.profiling.profiler.profiler"]], "profilerfactory (class in neural_compressor.profiling.profiler.tensorflow_profiler.factory)": [[420, "neural_compressor.profiling.profiler.tensorflow_profiler.factory.ProfilerFactory"]], "neural_compressor.profiling.profiler.tensorflow_profiler.factory": [[420, "module-neural_compressor.profiling.profiler.tensorflow_profiler.factory"]], "neural_compressor.profiling.profiler.tensorflow_profiler": [[421, "module-neural_compressor.profiling.profiler.tensorflow_profiler"]], "profiler (class in neural_compressor.profiling.profiler.tensorflow_profiler.profiler)": [[422, "neural_compressor.profiling.profiler.tensorflow_profiler.profiler.Profiler"]], "neural_compressor.profiling.profiler.tensorflow_profiler.profiler": [[422, "module-neural_compressor.profiling.profiler.tensorflow_profiler.profiler"]], "create_tf_config() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[423, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.create_tf_config"]], "delete_assign() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[423, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.delete_assign"]], "neural_compressor.profiling.profiler.tensorflow_profiler.utils": [[423, "module-neural_compressor.profiling.profiler.tensorflow_profiler.utils"]], "set_eager_execution() (in module neural_compressor.profiling.profiler.tensorflow_profiler.utils)": [[423, "neural_compressor.profiling.profiler.tensorflow_profiler.utils.set_eager_execution"]], "fit() (in module neural_compressor.quantization)": [[424, "neural_compressor.quantization.fit"]], "neural_compressor.quantization": [[424, "module-neural_compressor.quantization"]], "autotunestrategy (class in neural_compressor.strategy.auto)": [[425, "neural_compressor.strategy.auto.AutoTuneStrategy"]], "neural_compressor.strategy.auto": [[425, "module-neural_compressor.strategy.auto"]], "automixedprecisiontunestrategy (class in neural_compressor.strategy.auto_mixed_precision)": [[426, "neural_compressor.strategy.auto_mixed_precision.AutoMixedPrecisionTuneStrategy"]], "neural_compressor.strategy.auto_mixed_precision": [[426, "module-neural_compressor.strategy.auto_mixed_precision"]], "basictunestrategy (class in neural_compressor.strategy.basic)": [[427, "neural_compressor.strategy.basic.BasicTuneStrategy"]], "neural_compressor.strategy.basic": [[427, "module-neural_compressor.strategy.basic"]], "bayesianoptimization (class in neural_compressor.strategy.bayesian)": [[428, "neural_compressor.strategy.bayesian.BayesianOptimization"]], "bayesiantunestrategy (class in neural_compressor.strategy.bayesian)": [[428, "neural_compressor.strategy.bayesian.BayesianTuneStrategy"]], "targetspace (class in neural_compressor.strategy.bayesian)": [[428, "neural_compressor.strategy.bayesian.TargetSpace"]], "acq_max() (in module neural_compressor.strategy.bayesian)": [[428, "neural_compressor.strategy.bayesian.acq_max"]], "neural_compressor.strategy.bayesian": [[428, "module-neural_compressor.strategy.bayesian"]], "conservativetunestrategy (class in neural_compressor.strategy.conservative)": [[429, "neural_compressor.strategy.conservative.ConservativeTuneStrategy"]], "neural_compressor.strategy.conservative": [[429, "module-neural_compressor.strategy.conservative"]], "exhaustivetunestrategy (class in neural_compressor.strategy.exhaustive)": [[430, "neural_compressor.strategy.exhaustive.ExhaustiveTuneStrategy"]], "neural_compressor.strategy.exhaustive": [[430, "module-neural_compressor.strategy.exhaustive"]], "hawq_v2tunestrategy (class in neural_compressor.strategy.hawq_v2)": [[431, "neural_compressor.strategy.hawq_v2.HAWQ_V2TuneStrategy"]], "neural_compressor.strategy.hawq_v2": [[431, "module-neural_compressor.strategy.hawq_v2"]], "neural_compressor.strategy": [[432, "module-neural_compressor.strategy"]], "msetunestrategy (class in neural_compressor.strategy.mse)": [[433, "neural_compressor.strategy.mse.MSETuneStrategy"]], "neural_compressor.strategy.mse": [[433, "module-neural_compressor.strategy.mse"]], "mse_v2tunestrategy (class in neural_compressor.strategy.mse_v2)": [[434, "neural_compressor.strategy.mse_v2.MSE_V2TuneStrategy"]], "neural_compressor.strategy.mse_v2": [[434, "module-neural_compressor.strategy.mse_v2"]], "randomtunestrategy (class in neural_compressor.strategy.random)": [[435, "neural_compressor.strategy.random.RandomTuneStrategy"]], "neural_compressor.strategy.random": [[435, "module-neural_compressor.strategy.random"]], "tunestrategy (class in neural_compressor.strategy.strategy)": [[436, "neural_compressor.strategy.strategy.TuneStrategy"]], "tunestrategymeta (class in neural_compressor.strategy.strategy)": [[436, "neural_compressor.strategy.strategy.TuneStrategyMeta"]], "neural_compressor.strategy.strategy": [[436, "module-neural_compressor.strategy.strategy"]], "strategy_registry() (in module neural_compressor.strategy.strategy)": [[436, "neural_compressor.strategy.strategy.strategy_registry"]], "neural_compressor.strategy.utils.constant": [[437, "module-neural_compressor.strategy.utils.constant"]], "neural_compressor.strategy.utils": [[438, "module-neural_compressor.strategy.utils"]], "blockfallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.BlockFallbackTuningSampler"]], "fallbacktuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.FallbackTuningSampler"]], "lowerbitssampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.LowerBitsSampler"]], "modelwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.ModelWiseTuningSampler"]], "optypewisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.OpTypeWiseTuningSampler"]], "opwisetuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.OpWiseTuningSampler"]], "smoothquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.SmoothQuantSampler"]], "tuningorder (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.TuningOrder"]], "tuningsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.TuningSampler"]], "weightonlyquantsampler (class in neural_compressor.strategy.utils.tuning_sampler)": [[439, "neural_compressor.strategy.utils.tuning_sampler.WeightOnlyQuantSampler"]], "neural_compressor.strategy.utils.tuning_sampler": [[439, "module-neural_compressor.strategy.utils.tuning_sampler"]], "tuningitem (class in neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.TuningItem"]], "tuningspace (class in neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.TuningSpace"]], "initial_tuning_cfg_with_quant_mode() (in module neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.initial_tuning_cfg_with_quant_mode"]], "neural_compressor.strategy.utils.tuning_space": [[440, "module-neural_compressor.strategy.utils.tuning_space"]], "pattern_to_internal() (in module neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.pattern_to_internal"]], "pattern_to_path() (in module neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.pattern_to_path"]], "quant_mode_from_pattern() (in module neural_compressor.strategy.utils.tuning_space)": [[440, "neural_compressor.strategy.utils.tuning_space.quant_mode_from_pattern"]], "optuningconfig (class in neural_compressor.strategy.utils.tuning_structs)": [[441, "neural_compressor.strategy.utils.tuning_structs.OpTuningConfig"]], "neural_compressor.strategy.utils.tuning_structs": [[441, "module-neural_compressor.strategy.utils.tuning_structs"]], "classregister (class in neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.ClassRegister"]], "ordereddefaultdict (class in neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.OrderedDefaultDict"]], "quantoptions (class in neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.QuantOptions"]], "quanttype (class in neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.QuantType"]], "build_slave_faker_model() (in module neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.build_slave_faker_model"]], "extract_data_type() (in module neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.extract_data_type"]], "get_adaptor_name() (in module neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.get_adaptor_name"]], "neural_compressor.strategy.utils.utility": [[442, "module-neural_compressor.strategy.utils.utility"]], "preprocess_user_cfg() (in module neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.preprocess_user_cfg"]], "reverted_data_type() (in module neural_compressor.strategy.utils.utility)": [[442, "neural_compressor.strategy.utils.utility.reverted_data_type"]], "exampleclass (class in neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.ExampleClass"]], "attr1 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[443, "neural_compressor.template.api_doc_example.ExampleClass.attr1"]], "attr2 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[443, "neural_compressor.template.api_doc_example.ExampleClass.attr2"]], "attr5 (neural_compressor.template.api_doc_example.exampleclass attribute)": [[443, "neural_compressor.template.api_doc_example.ExampleClass.attr5"]], "attribute1 (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.attribute1"]], "function1() (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.function1"]], "function2() (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.function2"]], "function3() (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.function3"]], "generator1() (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.generator1"]], "module_debug_level1 (in module neural_compressor.template.api_doc_example)": [[443, "neural_compressor.template.api_doc_example.module_debug_level1"]], "neural_compressor.template.api_doc_example": [[443, "module-neural_compressor.template.api_doc_example"]], "neural_compressor.template": [[444, "module-neural_compressor.template"]], "neural_compressor.tensorflow.algorithms": [[445, "module-neural_compressor.tensorflow.algorithms"]], "smoothquantcalibration (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[446, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibration"]], "smoothquantcalibrationllm (class in neural_compressor.tensorflow.algorithms.smoother.calibration)": [[446, "neural_compressor.tensorflow.algorithms.smoother.calibration.SmoothQuantCalibrationLLM"]], "neural_compressor.tensorflow.algorithms.smoother.calibration": [[446, "module-neural_compressor.tensorflow.algorithms.smoother.calibration"]], "smoothquant (class in neural_compressor.tensorflow.algorithms.smoother.core)": [[447, "neural_compressor.tensorflow.algorithms.smoother.core.SmoothQuant"]], "neural_compressor.tensorflow.algorithms.smoother.core": [[447, "module-neural_compressor.tensorflow.algorithms.smoother.core"]], "neural_compressor.tensorflow.algorithms.smoother": [[448, "module-neural_compressor.tensorflow.algorithms.smoother"]], "smoothquantscaler (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[449, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScaler"]], "smoothquantscalerllm (class in neural_compressor.tensorflow.algorithms.smoother.scaler)": [[449, "neural_compressor.tensorflow.algorithms.smoother.scaler.SmoothQuantScalerLLM"]], "neural_compressor.tensorflow.algorithms.smoother.scaler": [[449, "module-neural_compressor.tensorflow.algorithms.smoother.scaler"]], "neural_compressor.tensorflow.algorithms.static_quant": [[450, "module-neural_compressor.tensorflow.algorithms.static_quant"]], "kerasadaptor (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[451, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasAdaptor"]], "kerasconfigconverter (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[451, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasConfigConverter"]], "kerasquery (class in neural_compressor.tensorflow.algorithms.static_quant.keras)": [[451, "neural_compressor.tensorflow.algorithms.static_quant.keras.KerasQuery"]], "neural_compressor.tensorflow.algorithms.static_quant.keras": [[451, "module-neural_compressor.tensorflow.algorithms.static_quant.keras"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d": [[452, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.conv2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense": [[453, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.dense"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d": [[454, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.depthwise_conv2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils": [[455, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d": [[456, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.pool2d"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer": [[457, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.quantizer"]], "neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d": [[458, "module-neural_compressor.tensorflow.algorithms.static_quant.keras_utils.separable_conv2d"]], "neural_compressor.tensorflow": [[459, "module-neural_compressor.tensorflow"]], "neural_compressor.tensorflow.quantization.algorithm_entry": [[460, "module-neural_compressor.tensorflow.quantization.algorithm_entry"]], "static_quantize_entry() (in module neural_compressor.tensorflow.quantization.algorithm_entry)": [[460, "neural_compressor.tensorflow.quantization.algorithm_entry.static_quantize_entry"]], "smoothquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[461, "neural_compressor.tensorflow.quantization.config.SmoothQuantConfig"]], "staticquantconfig (class in neural_compressor.tensorflow.quantization.config)": [[461, "neural_compressor.tensorflow.quantization.config.StaticQuantConfig"]], "get_all_registered_configs() (in module neural_compressor.tensorflow.quantization.config)": [[461, "neural_compressor.tensorflow.quantization.config.get_all_registered_configs"]], "get_default_sq_config() (in module neural_compressor.tensorflow.quantization.config)": [[461, "neural_compressor.tensorflow.quantization.config.get_default_sq_config"]], "get_default_static_quant_config() (in module neural_compressor.tensorflow.quantization.config)": [[461, "neural_compressor.tensorflow.quantization.config.get_default_static_quant_config"]], "neural_compressor.tensorflow.quantization.config": [[461, "module-neural_compressor.tensorflow.quantization.config"]], "neural_compressor.tensorflow.quantization": [[462, "module-neural_compressor.tensorflow.quantization"]], "neural_compressor.tensorflow.quantization.quantize": [[463, "module-neural_compressor.tensorflow.quantization.quantize"]], "quantize_model() (in module neural_compressor.tensorflow.quantization.quantize)": [[463, "neural_compressor.tensorflow.quantization.quantize.quantize_model"]], "convertaddtobiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd)": [[464, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd.ConvertAddToBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd": [[464, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_add_to_biasadd"]], "convertlayoutoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout)": [[465, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout.ConvertLayoutOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout": [[465, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_layout"]], "convertleakyreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu)": [[466, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu.ConvertLeakyReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu": [[466, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_leakyrelu"]], "convertnantorandom (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random)": [[467, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random.ConvertNanToRandom"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random": [[467, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_nan_to_random"]], "convertplaceholdertoconst (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const)": [[468, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const.ConvertPlaceholderToConst"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const": [[468, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.convert_placeholder_to_const"]], "dilatedcontraction (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction)": [[469, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction.DilatedContraction"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction": [[469, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dilated_contraction"]], "injectdummybiasaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd)": [[470, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd.InjectDummyBiasAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd": [[470, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.dummy_biasadd"]], "expanddimsoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer)": [[471, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer.ExpandDimsOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer": [[471, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.expanddims_optimizer"]], "fetchweightfromreshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape)": [[472, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape.FetchWeightFromReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape": [[472, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fetch_weight_from_reshape"]], "foldbatchnormnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm)": [[473, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm.FoldBatchNormNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm": [[473, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_batch_norm"]], "graphfoldconstantoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant)": [[474, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant.GraphFoldConstantOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant": [[474, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fold_constant"]], "fusebiasaddandaddoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add)": [[475, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add.FuseBiasAddAndAddOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add": [[475, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_biasadd_add"]], "fusecolumnwisemuloptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul)": [[476, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul.FuseColumnWiseMulOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul": [[476, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_column_wise_mul"]], "fuseconvwithmathoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math)": [[477, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math.FuseConvWithMathOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math": [[477, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_conv_with_math"]], "fusedecomposedbnoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.FuseDecomposedBNOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn": [[478, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn)": [[478, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_bn.values_from_const"]], "fusedecomposedinoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.FuseDecomposedINOptimizer"]], "bypass_reshape() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.bypass_reshape"]], "get_const_dim_count() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.get_const_dim_count"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in": [[479, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.node_name_from_input"]], "valid_reshape_inputs() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.valid_reshape_inputs"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in)": [[479, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_decomposed_in.values_from_const"]], "fusegeluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu)": [[480, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu.FuseGeluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu": [[480, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_gelu"]], "fuselayernormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[481, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.FuseLayerNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm": [[481, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm"]], "node_from_map() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[481, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_from_map"]], "node_name_from_input() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[481, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.node_name_from_input"]], "values_from_const() (in module neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm)": [[481, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_layer_norm.values_from_const"]], "fusepadwithconv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv)": [[482, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv.FusePadWithConv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv": [[482, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_conv"]], "fusepadwithfp32conv2doptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv)": [[483, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv.FusePadWithFP32Conv2DOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv": [[483, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_pad_with_fp32_conv"]], "fusetransposereshapeoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose)": [[484, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose.FuseTransposeReshapeOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose": [[484, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.fuse_reshape_transpose"]], "graphcseoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer)": [[485, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer.GraphCseOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer": [[485, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.graph_cse_optimizer"]], "grappleroptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass)": [[486, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass.GrapplerOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass": [[486, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.grappler_pass"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic": [[487, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic"]], "insertprintminmaxnode (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node)": [[488, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node.InsertPrintMinMaxNode"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node": [[488, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.insert_print_node"]], "movesqueezeafterreluoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu)": [[489, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu.MoveSqueezeAfterReluOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu": [[489, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.move_squeeze_after_relu"]], "preoptimization (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize)": [[490, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize.PreOptimization"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize": [[490, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.pre_optimize"]], "removetrainingnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes)": [[491, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes.RemoveTrainingNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes": [[491, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.remove_training_nodes"]], "renamebatchnormoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm)": [[492, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm.RenameBatchNormOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm": [[492, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.rename_batch_norm"]], "splitsharedinputoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input)": [[493, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input.SplitSharedInputOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input": [[493, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.split_shared_input"]], "stripequivalentnodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes)": [[494, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes.StripEquivalentNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes": [[494, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_equivalent_nodes"]], "stripunusednodesoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes)": [[495, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes.StripUnusedNodesOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes": [[495, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.strip_unused_nodes"]], "switchoptimizer (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer)": [[496, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer.SwitchOptimizer"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer": [[496, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.generic.switch_optimizer"]], "graphrewriterbase (class in neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base)": [[497, "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base.GraphRewriterBase"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base": [[497, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter.graph_base"]], "neural_compressor.tensorflow.quantization.utils.graph_rewriter": [[498, "module-neural_compressor.tensorflow.quantization.utils.graph_rewriter"]], "graphanalyzer (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[499, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphAnalyzer"]], "graphrewriterhelper (class in neural_compressor.tensorflow.quantization.utils.graph_util)": [[499, "neural_compressor.tensorflow.quantization.utils.graph_util.GraphRewriterHelper"]], "neural_compressor.tensorflow.quantization.utils.graph_util": [[499, "module-neural_compressor.tensorflow.quantization.utils.graph_util"]], "neural_compressor.tensorflow.quantization.utils": [[500, "module-neural_compressor.tensorflow.quantization.utils"]], "quantizegraphhelper (class in neural_compressor.tensorflow.quantization.utils.quantize_graph_common)": [[501, "neural_compressor.tensorflow.quantization.utils.quantize_graph_common.QuantizeGraphHelper"]], "neural_compressor.tensorflow.quantization.utils.quantize_graph_common": [[501, "module-neural_compressor.tensorflow.quantization.utils.quantize_graph_common"]], "apply_inlining() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.apply_inlining"]], "collate_tf_preds() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.collate_tf_preds"]], "construct_function_from_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.construct_function_from_graph_def"]], "disable_random() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.disable_random"]], "fix_ref_type_of_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.fix_ref_type_of_graph_def"]], "generate_feed_dict() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.generate_feed_dict"]], "get_graph_def() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_graph_def"]], "get_input_output_node_names() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_input_output_node_names"]], "get_model_input_shape() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_model_input_shape"]], "get_tensor_by_name() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_tensor_by_name"]], "get_tensor_val_from_graph_node() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_tensor_val_from_graph_node"]], "get_weight_from_input_tensor() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.get_weight_from_input_tensor"]], "int8_node_name_reverse() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.int8_node_name_reverse"]], "is_ckpt_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.is_ckpt_format"]], "is_saved_model_format() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.is_saved_model_format"]], "iterator_sess_run() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.iterator_sess_run"]], "neural_compressor.tensorflow.quantization.utils.utility": [[502, "module-neural_compressor.tensorflow.quantization.utils.utility"]], "parse_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.parse_saved_model"]], "read_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.read_graph"]], "reconstruct_saved_model() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.reconstruct_saved_model"]], "strip_equivalent_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.strip_equivalent_nodes"]], "strip_unused_nodes() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.strip_unused_nodes"]], "tf_diagnosis_helper() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.tf_diagnosis_helper"]], "write_graph() (in module neural_compressor.tensorflow.quantization.utils.utility)": [[502, "neural_compressor.tensorflow.quantization.utils.utility.write_graph"]], "neural_compressor.tensorflow.utils.constants": [[503, "module-neural_compressor.tensorflow.utils.constants"]], "basedataloader (class in neural_compressor.tensorflow.utils.data)": [[504, "neural_compressor.tensorflow.utils.data.BaseDataLoader"]], "dummydataset (class in neural_compressor.tensorflow.utils.data)": [[504, "neural_compressor.tensorflow.utils.data.DummyDataset"]], "dummydatasetv2 (class in neural_compressor.tensorflow.utils.data)": [[504, "neural_compressor.tensorflow.utils.data.DummyDatasetV2"]], "neural_compressor.tensorflow.utils.data": [[504, "module-neural_compressor.tensorflow.utils.data"]], "neural_compressor.tensorflow.utils": [[505, "module-neural_compressor.tensorflow.utils"]], "model (class in neural_compressor.tensorflow.utils.model)": [[506, "neural_compressor.tensorflow.utils.model.Model"]], "neural_compressor.tensorflow.utils.model": [[506, "module-neural_compressor.tensorflow.utils.model"]], "basemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.BaseModel"]], "kerasmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.KerasModel"]], "tensorflowbasemodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowBaseModel"]], "tensorflowcheckpointmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowCheckpointModel"]], "tensorflowllmmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowLLMModel"]], "tensorflowmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowModel"]], "tensorflowqatmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowQATModel"]], "tensorflowsavedmodelmodel (class in neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.TensorflowSavedModelModel"]], "checkpoint_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.checkpoint_session"]], "estimator_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.estimator_session"]], "frozen_pb_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.frozen_pb_session"]], "get_model_type() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.get_model_type"]], "graph_def_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.graph_def_session"]], "graph_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.graph_session"]], "keras_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.keras_session"]], "load_saved_model() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.load_saved_model"]], "neural_compressor.tensorflow.utils.model_wrappers": [[507, "module-neural_compressor.tensorflow.utils.model_wrappers"]], "saved_model_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.saved_model_session"]], "slim_session() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.slim_session"]], "validate_and_inference_input_output() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.validate_and_inference_input_output"]], "validate_graph_node() (in module neural_compressor.tensorflow.utils.model_wrappers)": [[507, "neural_compressor.tensorflow.utils.model_wrappers.validate_graph_node"]], "tfslimnetsfactory (class in neural_compressor.tensorflow.utils.nets_factory)": [[508, "neural_compressor.tensorflow.utils.nets_factory.TFSlimNetsFactory"]], "neural_compressor.tensorflow.utils.nets_factory": [[508, "module-neural_compressor.tensorflow.utils.nets_factory"]], "captureoutputtofile (class in neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.CpuInfo"]], "dequantize() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.Dequantize"]], "lazyimport (class in neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.LazyImport"]], "statistics (class in neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.Statistics"]], "combine_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.combine_histogram"]], "deep_get() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.deep_get"]], "dequantize_weight() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.dequantize_weight"]], "disable_random() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.disable_random"]], "dump_data_to_local() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.dump_data_to_local"]], "dump_elapsed_time() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.dump_elapsed_time"]], "get_all_fp32_data() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.get_all_fp32_data"]], "get_tensor_histogram() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.get_tensor_histogram"]], "itex_installed() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.itex_installed"]], "load_data_from_pkl() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.load_data_from_pkl"]], "neural_compressor.tensorflow.utils.utility": [[509, "module-neural_compressor.tensorflow.utils.utility"]], "register_algo() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.register_algo"]], "singleton() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.singleton"]], "version1_eq_version2() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.tensorflow.utils.utility)": [[509, "neural_compressor.tensorflow.utils.utility.version1_lte_version2"]], "neural_compressor.torch.algorithms.habana_fp8.fp8_quant": [[510, "module-neural_compressor.torch.algorithms.habana_fp8.fp8_quant"]], "neural_compressor.torch.algorithms.habana_fp8": [[511, "module-neural_compressor.torch.algorithms.habana_fp8"]], "neural_compressor.torch.algorithms.habana_fp8.modules": [[512, "module-neural_compressor.torch.algorithms.habana_fp8.modules"]], "neural_compressor.torch.algorithms.habana_fp8.observer": [[513, "module-neural_compressor.torch.algorithms.habana_fp8.observer"]], "neural_compressor.torch.algorithms": [[514, "module-neural_compressor.torch.algorithms"]], "neural_compressor.torch.algorithms.layer_wise": [[515, "module-neural_compressor.torch.algorithms.layer_wise"]], "load() (in module neural_compressor.torch.algorithms.layer_wise.load)": [[516, "neural_compressor.torch.algorithms.layer_wise.load.load"]], "neural_compressor.torch.algorithms.layer_wise.load": [[516, "module-neural_compressor.torch.algorithms.layer_wise.load"]], "neural_compressor.torch.algorithms.layer_wise.modified_pickle": [[517, "module-neural_compressor.torch.algorithms.layer_wise.modified_pickle"]], "dowload_hf_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.dowload_hf_model"]], "get_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.get_children"]], "get_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.get_module"]], "get_named_children() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.get_named_children"]], "get_super_module_by_name() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.get_super_module_by_name"]], "load_empty_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.load_empty_model"]], "load_layer_wise_quantized_model() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.load_layer_wise_quantized_model"]], "load_tensor() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor"]], "load_tensor_from_shard() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.load_tensor_from_shard"]], "neural_compressor.torch.algorithms.layer_wise.utils": [[518, "module-neural_compressor.torch.algorithms.layer_wise.utils"]], "update_module() (in module neural_compressor.torch.algorithms.layer_wise.utils)": [[518, "neural_compressor.torch.algorithms.layer_wise.utils.update_module"]], "neural_compressor.torch.algorithms.static_quant": [[519, "module-neural_compressor.torch.algorithms.static_quant"]], "neural_compressor.torch.algorithms.static_quant.static_quant": [[520, "module-neural_compressor.torch.algorithms.static_quant.static_quant"]], "static_quantize() (in module neural_compressor.torch.algorithms.static_quant.static_quant)": [[520, "neural_compressor.torch.algorithms.static_quant.static_quant.static_quantize"]], "statistics (class in neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.Statistics"]], "transformerbasedmodelblockpatterndetector (class in neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.TransformerBasedModelBlockPatternDetector"]], "dump_model_op_stats() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.dump_model_op_stats"]], "get_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.get_depth"]], "get_dict_at_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.get_dict_at_depth"]], "get_element_under_depth() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.get_element_under_depth"]], "get_quantizable_ops_from_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_from_cfgs"]], "get_quantizable_ops_recursively() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.get_quantizable_ops_recursively"]], "neural_compressor.torch.algorithms.static_quant.utility": [[521, "module-neural_compressor.torch.algorithms.static_quant.utility"]], "paser_cfgs() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.paser_cfgs"]], "simple_inference() (in module neural_compressor.torch.algorithms.static_quant.utility)": [[521, "neural_compressor.torch.algorithms.static_quant.utility.simple_inference"]], "actawareweightquant (class in neural_compressor.torch.algorithms.weight_only.awq)": [[522, "neural_compressor.torch.algorithms.weight_only.awq.ActAwareWeightQuant"]], "awq_quantize() (in module neural_compressor.torch.algorithms.weight_only.awq)": [[522, "neural_compressor.torch.algorithms.weight_only.awq.awq_quantize"]], "neural_compressor.torch.algorithms.weight_only.awq": [[522, "module-neural_compressor.torch.algorithms.weight_only.awq"]], "gptq (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQ"]], "gptquantizer (class in neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.GPTQuantizer"]], "find_layers() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers"]], "find_layers_name() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.find_layers_name"]], "gptq_quantize() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.gptq_quantize"]], "is_leaf() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.is_leaf"]], "log_quantizable_layers_per_transformer() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.log_quantizable_layers_per_transformer"]], "neural_compressor.torch.algorithms.weight_only.gptq": [[523, "module-neural_compressor.torch.algorithms.weight_only.gptq"]], "quantize() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.quantize"]], "trace_gptq_target_blocks() (in module neural_compressor.torch.algorithms.weight_only.gptq)": [[523, "neural_compressor.torch.algorithms.weight_only.gptq.trace_gptq_target_blocks"]], "auto_accelerator (class in neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator)": [[524, "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator.Auto_Accelerator"]], "cpu_accelerator (class in neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator)": [[524, "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator.CPU_Accelerator"]], "cuda_accelerator (class in neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator)": [[524, "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator.CUDA_Accelerator"]], "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator": [[524, "module-neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator"]], "register_accelerator() (in module neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator)": [[524, "neural_compressor.torch.algorithms.weight_only.hqq.auto_accelerator.register_accelerator"]], "neural_compressor.torch.algorithms.weight_only.hqq.bitpack": [[525, "module-neural_compressor.torch.algorithms.weight_only.hqq.bitpack"]], "hqqmoduleconfig (class in neural_compressor.torch.algorithms.weight_only.hqq.config)": [[526, "neural_compressor.torch.algorithms.weight_only.hqq.config.HQQModuleConfig"]], "neural_compressor.torch.algorithms.weight_only.hqq.config": [[526, "module-neural_compressor.torch.algorithms.weight_only.hqq.config"]], "neural_compressor.torch.algorithms.weight_only.hqq.core": [[527, "module-neural_compressor.torch.algorithms.weight_only.hqq.core"]], "neural_compressor.torch.algorithms.weight_only.hqq": [[528, "module-neural_compressor.torch.algorithms.weight_only.hqq"]], "neural_compressor.torch.algorithms.weight_only.hqq.optimizer": [[529, "module-neural_compressor.torch.algorithms.weight_only.hqq.optimizer"]], "neural_compressor.torch.algorithms.weight_only.hqq.qtensor": [[530, "module-neural_compressor.torch.algorithms.weight_only.hqq.qtensor"]], "neural_compressor.torch.algorithms.weight_only.hqq.quant_api": [[531, "module-neural_compressor.torch.algorithms.weight_only.hqq.quant_api"]], "neural_compressor.torch.algorithms.weight_only.hqq.quantizer": [[532, "module-neural_compressor.torch.algorithms.weight_only.hqq.quantizer"]], "dump_elapsed_time() (in module neural_compressor.torch.algorithms.weight_only.hqq.utility)": [[533, "neural_compressor.torch.algorithms.weight_only.hqq.utility.dump_elapsed_time"]], "neural_compressor.torch.algorithms.weight_only.hqq.utility": [[533, "module-neural_compressor.torch.algorithms.weight_only.hqq.utility"]], "neural_compressor.torch.algorithms.weight_only": [[534, "module-neural_compressor.torch.algorithms.weight_only"]], "fakeaffinetensorquantfunction (class in neural_compressor.torch.algorithms.weight_only.modules)": [[535, "neural_compressor.torch.algorithms.weight_only.modules.FakeAffineTensorQuantFunction"]], "mullinear (class in neural_compressor.torch.algorithms.weight_only.modules)": [[535, "neural_compressor.torch.algorithms.weight_only.modules.MulLinear"]], "teqlinearfakequant (class in neural_compressor.torch.algorithms.weight_only.modules)": [[535, "neural_compressor.torch.algorithms.weight_only.modules.TEQLinearFakeQuant"]], "neural_compressor.torch.algorithms.weight_only.modules": [[535, "module-neural_compressor.torch.algorithms.weight_only.modules"]], "neural_compressor.torch.algorithms.weight_only.rtn": [[536, "module-neural_compressor.torch.algorithms.weight_only.rtn"]], "rtn_quantize() (in module neural_compressor.torch.algorithms.weight_only.rtn)": [[536, "neural_compressor.torch.algorithms.weight_only.rtn.rtn_quantize"]], "tequantizer (class in neural_compressor.torch.algorithms.weight_only.teq)": [[537, "neural_compressor.torch.algorithms.weight_only.teq.TEQuantizer"]], "neural_compressor.torch.algorithms.weight_only.teq": [[537, "module-neural_compressor.torch.algorithms.weight_only.teq"]], "teq_quantize() (in module neural_compressor.torch.algorithms.weight_only.teq)": [[537, "neural_compressor.torch.algorithms.weight_only.teq.teq_quantize"]], "calibration() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.calibration"]], "fetch_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.fetch_module"]], "get_absorb_layers() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_absorb_layers"]], "get_block_prefix() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_block_prefix"]], "get_example_input() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_example_input"]], "get_hidden_states() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_hidden_states"]], "get_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_module"]], "get_module_input_output() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.get_module_input_output"]], "neural_compressor.torch.algorithms.weight_only.utility": [[538, "module-neural_compressor.torch.algorithms.weight_only.utility"]], "qdq_weight_actor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_actor"]], "qdq_weight_asym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_asym"]], "qdq_weight_sym() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.qdq_weight_sym"]], "quant_tensor() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.quant_tensor"]], "quant_weight_w_scale() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.quant_weight_w_scale"]], "quantize_4bit() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.quantize_4bit"]], "search_clip() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.search_clip"]], "set_module() (in module neural_compressor.torch.algorithms.weight_only.utility)": [[538, "neural_compressor.torch.algorithms.weight_only.utility.set_module"]], "autocast (class in neural_compressor.torch.amp.autocast)": [[539, "neural_compressor.torch.amp.autocast.autocast"]], "neural_compressor.torch.amp.autocast": [[539, "module-neural_compressor.torch.amp.autocast"]], "neural_compressor.torch.amp.fp8.functions": [[540, "module-neural_compressor.torch.amp.fp8.functions"]], "neural_compressor.torch.amp.fp8": [[541, "module-neural_compressor.torch.amp.fp8"]], "neural_compressor.torch.amp": [[542, "module-neural_compressor.torch.amp"]], "neural_compressor.torch": [[543, "module-neural_compressor.torch"]], "neural_compressor.torch.quantization.algorithm_entry": [[544, "module-neural_compressor.torch.quantization.algorithm_entry"]], "rtn_entry() (in module neural_compressor.torch.quantization.algorithm_entry)": [[544, "neural_compressor.torch.quantization.algorithm_entry.rtn_entry"]], "autotune() (in module neural_compressor.torch.quantization.autotune)": [[545, "neural_compressor.torch.quantization.autotune.autotune"]], "neural_compressor.torch.quantization.autotune": [[545, "module-neural_compressor.torch.quantization.autotune"]], "gptqconfig (class in neural_compressor.torch.quantization.config)": [[546, "neural_compressor.torch.quantization.config.GPTQConfig"]], "rtnconfig (class in neural_compressor.torch.quantization.config)": [[546, "neural_compressor.torch.quantization.config.RTNConfig"]], "get_default_gptq_config() (in module neural_compressor.torch.quantization.config)": [[546, "neural_compressor.torch.quantization.config.get_default_gptq_config"]], "get_default_hqq_config() (in module neural_compressor.torch.quantization.config)": [[546, "neural_compressor.torch.quantization.config.get_default_hqq_config"]], "get_default_rtn_config() (in module neural_compressor.torch.quantization.config)": [[546, "neural_compressor.torch.quantization.config.get_default_rtn_config"]], "neural_compressor.torch.quantization.config": [[546, "module-neural_compressor.torch.quantization.config"]], "neural_compressor.torch.quantization": [[547, "module-neural_compressor.torch.quantization"]], "neural_compressor.torch.quantization.modules": [[548, "module-neural_compressor.torch.quantization.modules"]], "neural_compressor.torch.quantization.quantize": [[549, "module-neural_compressor.torch.quantization.quantize"]], "quantize() (in module neural_compressor.torch.quantization.quantize)": [[549, "neural_compressor.torch.quantization.quantize.quantize"]], "neural_compressor.torch.utils.constants": [[550, "module-neural_compressor.torch.utils.constants"]], "neural_compressor.torch.utils.environ": [[551, "module-neural_compressor.torch.utils.environ"]], "neural_compressor.torch.utils": [[552, "module-neural_compressor.torch.utils"]], "fetch_module() (in module neural_compressor.torch.utils.utility)": [[553, "neural_compressor.torch.utils.utility.fetch_module"]], "neural_compressor.torch.utils.utility": [[553, "module-neural_compressor.torch.utils.utility"]], "register_algo() (in module neural_compressor.torch.utils.utility)": [[553, "neural_compressor.torch.utils.utility.register_algo"]], "set_module() (in module neural_compressor.torch.utils.utility)": [[553, "neural_compressor.torch.utils.utility.set_module"]], "callbacks (class in neural_compressor.training)": [[554, "neural_compressor.training.CallBacks"]], "compressionmanager (class in neural_compressor.training)": [[554, "neural_compressor.training.CompressionManager"]], "fit() (in module neural_compressor.training)": [[554, "neural_compressor.training.fit"]], "neural_compressor.training": [[554, "module-neural_compressor.training"]], "prepare_compression() (in module neural_compressor.training)": [[554, "neural_compressor.training.prepare_compression"]], "layerhistogramcollector (class in neural_compressor.utils.collect_layer_histogram)": [[555, "neural_compressor.utils.collect_layer_histogram.LayerHistogramCollector"]], "neural_compressor.utils.collect_layer_histogram": [[555, "module-neural_compressor.utils.collect_layer_histogram"]], "neural_compressor.utils.constant": [[556, "module-neural_compressor.utils.constant"]], "create_dataloader() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.create_dataloader"]], "create_dataset() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.create_dataset"]], "create_eval_func() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.create_eval_func"]], "create_train_func() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.create_train_func"]], "get_algorithm() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.get_algorithm"]], "get_func_from_config() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.get_func_from_config"]], "get_metrics() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.get_metrics"]], "get_postprocess() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.get_postprocess"]], "get_preprocess() (in module neural_compressor.utils.create_obj_from_config)": [[557, "neural_compressor.utils.create_obj_from_config.get_preprocess"]], "neural_compressor.utils.create_obj_from_config": [[557, "module-neural_compressor.utils.create_obj_from_config"]], "neural_compressor.utils": [[558, "module-neural_compressor.utils"]], "kl_divergence (class in neural_compressor.utils.kl_divergence)": [[559, "neural_compressor.utils.kl_divergence.KL_Divergence"]], "neural_compressor.utils.kl_divergence": [[559, "module-neural_compressor.utils.kl_divergence"]], "optimizedmodel (class in neural_compressor.utils.load_huggingface)": [[560, "neural_compressor.utils.load_huggingface.OptimizedModel"]], "export_compressed_model() (in module neural_compressor.utils.load_huggingface)": [[560, "neural_compressor.utils.load_huggingface.export_compressed_model"]], "neural_compressor.utils.load_huggingface": [[560, "module-neural_compressor.utils.load_huggingface"]], "save_for_huggingface_upstream() (in module neural_compressor.utils.load_huggingface)": [[560, "neural_compressor.utils.load_huggingface.save_for_huggingface_upstream"]], "logger (class in neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.Logger"]], "debug() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.debug"]], "error() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.error"]], "fatal() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.fatal"]], "info() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.info"]], "log() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.log"]], "neural_compressor.utils.logger": [[561, "module-neural_compressor.utils.logger"]], "warn() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.warn"]], "warning() (in module neural_compressor.utils.logger)": [[561, "neural_compressor.utils.logger.warning"]], "get_model_path() (in module neural_compressor.utils.neural_insights_utils)": [[562, "neural_compressor.utils.neural_insights_utils.get_model_path"]], "neural_compressor.utils.neural_insights_utils": [[562, "module-neural_compressor.utils.neural_insights_utils"]], "register_neural_insights_workload() (in module neural_compressor.utils.neural_insights_utils)": [[562, "neural_compressor.utils.neural_insights_utils.register_neural_insights_workload"]], "update_neural_insights_workload() (in module neural_compressor.utils.neural_insights_utils)": [[562, "neural_compressor.utils.neural_insights_utils.update_neural_insights_workload"]], "update_neural_insights_workload_accuracy_data() (in module neural_compressor.utils.neural_insights_utils)": [[562, "neural_compressor.utils.neural_insights_utils.update_neural_insights_workload_accuracy_data"]], "neural_compressor.utils.options": [[563, "module-neural_compressor.utils.options"]], "onnxrt (class in neural_compressor.utils.options)": [[563, "neural_compressor.utils.options.onnxrt"]], "is_int8_model() (in module neural_compressor.utils.pytorch)": [[564, "neural_compressor.utils.pytorch.is_int8_model"]], "load() (in module neural_compressor.utils.pytorch)": [[564, "neural_compressor.utils.pytorch.load"]], "load_weight_only() (in module neural_compressor.utils.pytorch)": [[564, "neural_compressor.utils.pytorch.load_weight_only"]], "neural_compressor.utils.pytorch": [[564, "module-neural_compressor.utils.pytorch"]], "recover_model_from_json() (in module neural_compressor.utils.pytorch)": [[564, "neural_compressor.utils.pytorch.recover_model_from_json"]], "captureoutputtofile (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.CaptureOutputToFile"]], "cpuinfo (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.CpuInfo"]], "dequantize() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.Dequantize"]], "dotdict (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.DotDict"]], "global_state (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.GLOBAL_STATE"]], "lazyimport (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.LazyImport"]], "mode (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.MODE"]], "opentry (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.OpEntry"]], "statistics (class in neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.Statistics"]], "alias_param() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.alias_param"]], "calculate_mse() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.calculate_mse"]], "check_key_exist() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.check_key_exist"]], "combine_histogram() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.combine_histogram"]], "compare_objects() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.compare_objects"]], "compute_sparsity() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.compute_sparsity"]], "dequantize_weight() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dequantize_weight"]], "dump_class_attrs() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dump_class_attrs"]], "dump_data_to_local() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dump_data_to_local"]], "dump_elapsed_time() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dump_elapsed_time"]], "dump_table() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dump_table"]], "dump_table_to_csv() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.dump_table_to_csv"]], "equal_dicts() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.equal_dicts"]], "fault_tolerant_file() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.fault_tolerant_file"]], "get_all_fp32_data() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_all_fp32_data"]], "get_number_of_sockets() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_number_of_sockets"]], "get_op_list() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_op_list"]], "get_size() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_size"]], "get_tensor_histogram() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_tensor_histogram"]], "get_tensors_info() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_tensors_info"]], "get_tuning_history() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_tuning_history"]], "get_weights_details() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.get_weights_details"]], "load_data_from_pkl() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.load_data_from_pkl"]], "mse_metric_gap() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.mse_metric_gap"]], "neural_compressor.utils.utility": [[565, "module-neural_compressor.utils.utility"]], "print_op_list() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.print_op_list"]], "print_table() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.print_table"]], "recover() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.recover"]], "set_random_seed() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.set_random_seed"]], "set_resume_from() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.set_resume_from"]], "set_tensorboard() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.set_tensorboard"]], "set_workspace() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.set_workspace"]], "show_memory_info() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.show_memory_info"]], "singleton() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.singleton"]], "str2array() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.str2array"]], "time_limit() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.time_limit"]], "version1_eq_version2() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.version1_eq_version2"]], "version1_gt_version2() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.version1_gt_version2"]], "version1_gte_version2() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.version1_gte_version2"]], "version1_lt_version2() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.version1_lt_version2"]], "version1_lte_version2() (in module neural_compressor.utils.utility)": [[565, "neural_compressor.utils.utility.version1_lte_version2"]], "weightsdetails (class in neural_compressor.utils.weights_details)": [[566, "neural_compressor.utils.weights_details.WeightsDetails"]], "weightsstatistics (class in neural_compressor.utils.weights_details)": [[566, "neural_compressor.utils.weights_details.WeightsStatistics"]], "neural_compressor.utils.weights_details": [[566, "module-neural_compressor.utils.weights_details"]], "neural_compressor.version": [[567, "module-neural_compressor.version"]]}})